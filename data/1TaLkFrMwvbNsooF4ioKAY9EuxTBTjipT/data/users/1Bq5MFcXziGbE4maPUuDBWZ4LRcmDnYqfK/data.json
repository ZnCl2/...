{
	"next_topic_id": 1,
	"topic": [],
	"topic_vote": {
		"1555406623_13oRBYqNeUr6Tvgt4KkAT9FT4XRiKFBjnE": 1
	},
	"next_comment_id": 9,
	"comment": {
		"1555389717_1CV23652pUmbK7yQtjyrBp7ZRhaV7U97aa": [
			{
				"comment_id": 1,
				"body": ">Wish we could downvote shit\n\nHere's one fork of ZeroTalk that has down-votes (and nested comments): http://127.0.0.1:43110/1P7FMP3qngJxRhJidG2C41faCo6yozj2KJ\n\nRegarding DemonSaw, yes it's old and unmaintained and John McAfee is fishy",
				"added": 1555405789
			}
		],
		"1555406623_13oRBYqNeUr6Tvgt4KkAT9FT4XRiKFBjnE": [
			{
				"comment_id": 2,
				"body": ">The idea is that when a file is moved/renamed with intact content, it should not be re-downloaded by everyone\n\nYes, I've said this for more than a year. Whatever.\n\nSo the way to fix this is to look at the files already downloaded for a given site and see whether the \"new file\" has the same hash digest, if it does simply move the file to its new location (or copy it).",
				"added": 1555407584
			},
			{
				"comment_id": 4,
				"body": "> [caryoscelus](#comment_119_13oRBYqNeUr6Tvgt4KkAT9FT4XRiKFBjnE): Is it on GH issues list?\n\n~~No, I'm not on GitHub still haven't got around registering an email address for it ...~~\n\nThough there's a related issue for it: https://github.com/HelloZeroNet/ZeroNet/issues/1318",
				"added": 1555409264
			},
			{
				"comment_id": 5,
				"body": "> [caryoscelus](#comment_120_13oRBYqNeUr6Tvgt4KkAT9FT4XRiKFBjnE): Ok, thanks, so as expected this was already proposed both on 0talk and gh-issues..\n\nYes. There are a lot of things that can be improved with ZeroNet, but I can't build up enough discipline to work on it because it really is a mess right now. Maybe some day :^)\n\nHere's a list of things I've made a few months ago:\n\nhttp://127.0.0.1:43110/Talk.ZeroNetwork.bit/?Topic:1545423165_13CFz29UuNbUx54HmLqQBfxPQNN2FmfdAq/ZeroNet+improvements+updated+2018+12+29",
				"added": 1555409998
			},
			{
				"comment_id": 6,
				"body": "> [1pgallery](#comment_60_1GDcCK6cWoj98mg541Yj9rW1nwXcBz87eE): \n\nI know, you'll need to keep track of all files downloaded through ZeroNet (excluding the JSON files) and simply do a local copy when you see a file with the same hash. In the end you don't even want to do a copy but simply have files stored by its hash digest.\n\nI've shown in the past that it's very worthwhile to de-duplicate unlike @nofish thought, I'm unsure where that post is, I'll go look for it. I've downloaded over 3000 sites and checked for duplicates.",
				"added": 1555410239
			},
			{
				"comment_id": 8,
				"body": ">What were the results? I'm curious.\n\nI'm not quite sure where I had posted the results, I thought on ZeroTalk but I can no longer find them. Anyway, I think roughly 20% of files were duplicate files, now this is logical since many sites are clones of one another as well as there are many empty or barely used Zites.",
				"added": 1555427420
			}
		],
		"1545423165_13CFz29UuNbUx54HmLqQBfxPQNN2FmfdAq": [
			{
				"comment_id": 3,
				"body": "Bump.",
				"added": 1555407921
			}
		],
		"1554997177_1CVLeFVQw2wWbBdpM5PtQhtzd7wjKzB24b": [
			{
				"comment_id": 7,
				"body": "Clearly, you having access to a laptop, internet connection, and browsing ZeroNet makes me think you're not in financial trouble. Maybe ask somewhere else, people aren't gonna spent money on some stranger who could be lying (and probably is).",
				"added": 1555420302
			}
		]
	},
	"comment_vote": {}
}