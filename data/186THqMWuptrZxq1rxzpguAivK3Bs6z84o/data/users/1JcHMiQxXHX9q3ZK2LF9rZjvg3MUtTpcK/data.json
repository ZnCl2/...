{
	"next_topic_id": 6,
	"topic": [
		{
			"topic_id": 1,
			"title": "Blurhy's blog",
			"body": "http://127.0.0.1:43110/12q9YNb5oJ331nTjUxWefV9W2EXpMu8RWi/",
			"added": 1530777072
		},
		{
			"topic_id": 2,
			"title": "DemoOne",
			"body": "http://127.0.0.1:43110/1BpjbPLPb2Vyipqu2Y8Dk54ngbesNrt7iG/",
			"added": 1532229440
		},
		{
			"topic_id": 3,
			"title": "Search Engine - Horizon",
			"body": "~~http://127.0.0.1:43110/1CjMsvhJ2JsV4B5qo3FDHnF3mvRCcHuxBn~~\nhttp://127.0.0.1:43110/1HoRiznsHbJAqs2bmrVcSd79NTGVFp4Ju2/",
			"added": 1535027655
		},
		{
			"topic_id": 1537183563,
			"title": "HorizonTalk - A necessary thing for the search eninge Horizon",
			"body": "http://127.0.0.1:43110/1KkHNyD9TA5bi4gwGDYuTKSWp94MQEqrS1/",
			"added": 1537183559
		},
		{
			"topic_id": 1545449704,
			"title": "Zeronet Truth Zh-CN - A complete tutorial for Chinese users",
			"body": "http://127.0.0.1:43110/1DocZhy99FDWnAQLaVFbs8ZrZddnaSgK3f/",
			"added": 1545449699
		}
	],
	"topic_vote": {
		"3_1JcHMiQxXHX9q3ZK2LF9rZjvg3MUtTpcK": 1,
		"1535862457_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di": 1
	},
	"next_comment_id": 40,
	"comment": {
		"1_1DLe4EqaMdwPirPtBXRb2oAREPbhXfCEty": [
			{
				"comment_id": 1,
				"body": "node not found\ncontent.json download failed",
				"added": 1530796778
			}
		],
		"2_1JcHMiQxXHX9q3ZK2LF9rZjvg3MUtTpcK": [
			{
				"comment_id": 2,
				"body": "The zite contains a ZeroChat.",
				"added": 1532260041
			},
			{
				"comment_id": 3,
				"body": "zeromus是什么？",
				"added": 1532787617
			},
			{
				"comment_id": 4,
				"body": "> [kai0](#comment_42_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 你是用zeromux做的？\n\n~~zeromux是啥~~，刚查了一下，是网盘。网站做好了啊\n为啥要用zeromux做，我用了ui框架而已。",
				"added": 1532787644
			},
			{
				"comment_id": 5,
				"body": "> [kai0](#comment_43_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 看上去像zeromux。我以为你参考它做的。我打开你的站点只有一个index界面，其它都没有，用【检查文件】也没有发现要同步的文件，是不是你有文件没有签名？所以无法同步出来？\n\n再试一下，刷新什么的",
				"added": 1532788175
			},
			{
				"comment_id": 6,
				"body": "> [kai0](#comment_43_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 看上去像zeromux。我以为你参考它做的。我打开你的站点只有一个index界面，其它都没有，用【检查文件】也没有发现要同步的文件，是不是你有文件没有签名？所以无法同步出来？\n\n有没有chat界面",
				"added": 1532788462
			},
			{
				"comment_id": 7,
				"body": "> [kai0](#comment_44_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 站内链接都是空的，看看吧，等明天会不会有数据同步过来。\n\n截图在zerome上发下可否",
				"added": 1532788524
			},
			{
				"comment_id": 8,
				"body": "> [kai0](#comment_45_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 打开你这站点的文件夹，里面只有一个html文件，肯定还有其它的html文件没有同步过来。你不会只做了一个html文件吧。\n\n不可能，要么是content.json出问题了",
				"added": 1532788903
			},
			{
				"comment_id": 9,
				"body": "> [kai0](#comment_46_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 可能是我还没有收到新的content，不用急，明天就知道了。\n\n我检查一下，修好@你",
				"added": 1532789065
			},
			{
				"comment_id": 10,
				"body": "> [kai0](#comment_46_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 可能是我还没有收到新的content，不用急，明天就知道了。\n\n改好了，估计正则表达式有问题",
				"added": 1532789224
			},
			{
				"comment_id": 11,
				"body": "> [kai0](#comment_48_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 还是不行，是有问题，因为站点已经更新了。东西没过来。\n\n我开个虚拟机测试一下",
				"added": 1532789359
			},
			{
				"comment_id": 12,
				"body": "> [kai0](#comment_48_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 还是不行，是有问题，因为站点已经更新了。东西没过来。\n\n真不希望自己的网站打不开",
				"added": 1532789400
			},
			{
				"comment_id": 13,
				"body": "> [kai0](#comment_49_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 不是大问题，应该文件签名有些问题。\n\n都签名了",
				"added": 1532789519
			},
			{
				"comment_id": 14,
				"body": "> [kai0](#comment_50_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 查过肯定都签名了，就自己同步一下看看有没有问题，用另外一个设备同步一下。\n\n我在虚拟机上试了一下（data已删），没问题啊",
				"added": 1532827331
			},
			{
				"comment_id": 15,
				"body": "> [kai0](#comment_50_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 查过肯定都签名了，就自己同步一下看看有没有问题，用另外一个设备同步一下。\n\n你用的什么浏览器，什么系统，zeronet什么版本。",
				"added": 1532828626
			},
			{
				"comment_id": 16,
				"body": "> [kai0](#comment_50_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 查过肯定都签名了，就自己同步一下看看有没有问题，用另外一个设备同步一下。\n\n估计是我更新的频率太高了，节点跟不上我节奏",
				"added": 1532828944
			},
			{
				"comment_id": 17,
				"body": "> [kai0](#comment_52_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 先把其它东西去掉，就放个聊天室试试看。\n\n你用的什么浏览器，什么系统，zeronet什么版本。可以发下DemoOne网站界面的截图吗",
				"added": 1532937894
			},
			{
				"comment_id": 18,
				"body": "> [kai0](#comment_52_1EZTWytasXcKdiUFnN4KHqAfvg1nwkTkKv): 先把其它东西去掉，就放个聊天室试试看。\n\n我在虚拟机上试过了，没有问题啊。",
				"added": 1532937956
			}
		],
		"3_1JcHMiQxXHX9q3ZK2LF9rZjvg3MUtTpcK": [
			{
				"comment_id": 19,
				"body": "Crawler1:Selenium+Chrome+Mysql to scrape webpage. \nCrawler2:Directly scrape the zites' database",
				"added": 1535033809
			},
			{
				"comment_id": 20,
				"body": "crawl links from zerosites\\0list\\new zeronet sites and visit the target zites of the links.Then use nlp library analyse the content of the zites to get the keywords.",
				"added": 1535036181
			},
			{
				"comment_id": 21,
				"body": "The data of 0list and others is not enough for the search engine,i think",
				"added": 1535036354
			},
			{
				"comment_id": 22,
				"body": "The data maybe huge.",
				"added": 1535073349
			},
			{
				"comment_id": 23,
				"body": "> [ssdifnskdjfnsdjk](#comment_21_1L4dZcDF2maSKHDy788yhxpYnBWnXadUtS): 1 . > blurhy: The data maybe huge.\n> is it a problem? What about using merger sites to distribute data across multipe sites/DBs?\n> 2 . Another thing is, when i search for \"nettalk\", it shows two entries both for same site, one .bit one standard address, may be handy to keep only one link (i prefer standard address as .bit can expire).\n> 3 . Another think is that nettalk search query returned a topic URL which is nice, but apparently it does not find topics from ZeroTalk? Can you add ZeroTalk?\n> 4 . Next think, the URLs are light green color, to better see it, it can be in darker green so there is bigger contrast\n\nI'm making a filter feature.That can be used for filter. For example,  same title / same domain / only sites(root url of sites)\nAlso I'm going to write a spider that crawls user data and get the keywords.That spider will returns topic url.",
				"added": 1535096346
			},
			{
				"comment_id": 24,
				"body": "> [ssdifnskdjfnsdjk](#comment_22_1L4dZcDF2maSKHDy788yhxpYnBWnXadUtS): @blurhyWhen you add this search query: create zeronet site -zerosecurityyou see alot of irrelevant results, it can be handy to allow user use the operators like exclusion (-zerosecurity)Next thing that would help user filter the results is to allow requiring exact phrase which have to exist, example query:+\"create site\" OR \"make a website\" +zeronet +tutorial -zerosecurity\n> (same syntax that most popular search engine - Google is using)This would greatly help user to filter out exactly what is needed.\n\ni added a lot of features today,but not publish yet.i will add that tomorrow",
				"added": 1535206980
			},
			{
				"comment_id": 25,
				"body": "I added some Cross Origin Search features.That's useful.Added zerosites,zerotalk,plan to add zerowiki and more",
				"added": 1535208987
			},
			{
				"comment_id": 26,
				"body": "The right side container is for zerowiki",
				"added": 1535209080
			},
			{
				"comment_id": 27,
				"body": "The github repo <https://github.com/blurHY/Horizon> ,i uploaded just now @daniell @ssdifnskdjfnsdjk",
				"added": 1535253219
			},
			{
				"comment_id": 28,
				"body": "> [ssdifnskdjfnsdjk](#comment_23_1L4dZcDF2maSKHDy788yhxpYnBWnXadUtS): @blurhy if you are able to figure out a decentralized way of crawling, that would be better than relying on single person computer or server running\n> @daniell @blurhy\n> \n> Unsure at which database size the Zeronet start lagging or when search will be too slow. Currently i seen 3 seconds delay, in results being shown, so far not problem but in future?\n\nBecause of the crawler crawls keywords.So you should not use sentence as search query.Or it will be slow.",
				"added": 1535272202
			},
			{
				"comment_id": 29,
				"body": "@ssdifnskdjfnsdjk Do you mean distributed crawling.",
				"added": 1535272493
			},
			{
				"comment_id": 30,
				"body": "and i uploaded the spider to github <https://github.com/blurHY/ZeronetSpider>",
				"added": 1535273124
			},
			{
				"comment_id": 31,
				"body": "Distributed crawling needs a main peer.Or there will be duplicate links in database.\nBut we can make a zeronet plugin,that generates the keywords for each sites that doesn't appear in public database then publish the keywords data to my search engine..   @ssdifnskdjfnsdjk",
				"added": 1535284073
			},
			{
				"comment_id": 32,
				"body": "#### My Final Idea:\n\nThe crawling system needs a Main Crawler\n- Main Crawler publish the need-crawl sites list.(Actully, it is that some crawler wants to crawl then it send a request (like posting a comment) to the sitelist board via zeronet and the crawler gets an id.Then the main crawler publish the zite with new content that describes each crawler's sites list (to crawl) )\n- Each crawler only crawls the specified zites.Then publish the crawled data.(keywords,phrases,list of links that links to new zites)\n- Only main crawler discovers new zites.\n\n@ssdifnskdjfnsdjk ,@daniell \n\nI will write a blog post with a svg",
				"added": 1535285604
			},
			{
				"comment_id": 33,
				"body": "Please issue on github or PR <https://github.com/blurHY/Horizon>",
				"added": 1535792399
			},
			{
				"comment_id": 34,
				"body": "I'm rafactoring my code.So don't use Horizon this few weeks.",
				"added": 1535792500
			},
			{
				"comment_id": 35,
				"body": "[Project Board](https://github.com/blurHY/Horizon/projects)",
				"added": 1535796477
			},
			{
				"comment_id": 36,
				"body": "The code is ok.So if there is any bug.Please tell me",
				"added": 1536741999
			},
			{
				"comment_id": 37,
				"body": "Address changed",
				"added": 1537714141
			}
		],
		"1545449704_1JcHMiQxXHX9q3ZK2LF9rZjvg3MUtTpcK": [
			{
				"comment_id": 38,
				"body": "Translated The-truth-about-zeronet and tutorials in zeronet dev center",
				"added": 1545450088
			}
		],
		"1550871167_1LbP2cNA6NkvuFJvs7McUmv9qGjkNqVkTa": [
			{
				"comment_id": 39,
				"body": "> [ssdifnskdjfnsdjk](#comment_37_1L4dZcDF2maSKHDy788yhxpYnBWnXadUtS): On ZeroBlog page can be found \"Full support fileGet, fileList, dirList calls on tar.gz/zip files.\"i read somewhere on zeronet (possibly zerotalk - is searchable from ZeroHello) that there is some support to archive important files to reduce the size. Search for tar.gz in this topic.Another option is to convert the static site texts into a zerotalk or zeroblog posts. though i am unsure what .db size becomes too much nowadays. @nofish @blurhy possibly know it.btw: many (or all?) subpages of your site shows \"Not Found\" atm.\n\nYes. ZeroNet has .json.gz support. The usage is the same",
				"added": 1551001938
			}
		]
	},
	"comment_vote": {}
}