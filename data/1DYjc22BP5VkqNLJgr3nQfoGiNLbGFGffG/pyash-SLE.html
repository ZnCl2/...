<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
        <link rel="stylesheet" type="text/css" href="css/normalize.css">   
        <link rel="stylesheet" type="text/css" href="css/skeleton.css">   
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Htaf (Logan) Dwes" />
  <title>Pyash: One Language to Unite Them All</title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
  <div id="container">
<div id="header">
<h1 class="title">Pyash: One Language to Unite Them All</h1>
<h2 class="author">Htaf (Logan) Dwes</h2>
</div>
<p>&lt;ccs2012&gt; &lt;concept&gt; &lt;concept_id&gt;10011007.10011006.10011008&lt;/concept_id&gt; &lt;concept_desc&gt;Software and its engineering General programming languages&lt;/concept_desc&gt; &lt;concept_significance&gt;500&lt;/concept_significance&gt; &lt;/concept&gt; &lt;concept&gt; &lt;concept_id&gt;10003120.10003121.10003124.10010870&lt;/concept_id&gt; &lt;concept_desc&gt;Human-centered computing Natural language interfaces&lt;/concept_desc&gt; &lt;concept_significance&gt;300&lt;/concept_significance&gt; &lt;/concept&gt; &lt;/ccs2012&gt;</p>
<h1 id="introduction">Introduction</h1>
<p>The purpose of software languages is to help humans communicate with machines. To achieve this, the language has to be regular and sufficiently well defined that both parties understand what the other is saying. Though contemporarily the computer is programmed in one language, and error messages have a different protocol (mini-language).</p>
<p>Homo-sapien language has been evolving since at least Mitochondrial Eve, she lived possibly one or two hundred thousand years ago. There are already over 6,000 human languages, so it is acceptable to add another one, which happens to also be a general purpose software language.</p>
<p>The goal of the software language, is complete vertical integration. So that if one is to reincarnate into a robot, then everything from the lowest to highest levels can be accomplished using the same language. Similar to how English can be used to communicate everything from the lowest to highest levels.</p>
<p>Several versions of implementing this idea have been made over the last decade. This paper uses Pyash as the word for the pivot language (Intermediary Representation), it means language and is the result of data mining world language vocabularies ([vocabulary]).</p>
<p>Natural English is not formal enough to be directly used as a software language, however Pyash English is. Pyash also acts as a bridge, for high precision translation, so Pyash English documents could be rapidly and precisely translated to Pyash Hindi, Pyash Spanish, Pyash Swahili, or any other supported human language.</p>
<p>This high precision translation could open the door to software languages for the majority of humanity which is not fluent in English.</p>
<h1 id="literature-review">Literature Review</h1>
<p>This section will review some of the common references and mention how Pyash is different from them.</p>
<p>The main difference is that Pyash is based on the fundamentals of human language, and has a complete and orthogonal vocabulary.</p>
<h2 id="cobol">COBOL</h2>
<p>COBOL, originally intended to be a business programming language, was designed by several committees, some of the committee members were unfamiliar with computer programming and-or linguistics, the committees also had issues with discontinuity of personnel. This led to a language that was neither very good for computer programming, nor very easy for humans to understand, while also having issues with repeals due to changing personnel.</p>
<p>By contrast, Pyash’s design takes into consideration many academic and real world sources for its grammar ([grammar]), vocabulary ([vocabulary]) and instruction set architecture ([ISA]). It’s evolution has also run through several different iterations though all with the same informed personnel to keep it on track.</p>
<h2 id="hypertalk">Hypertalk</h2>
<p>Hypertalk uses English keywords to replace common programming syntax symbols, so is largely just a relexification of standard (ALGOL inspired) programming.</p>
<p>Pyash on the other hand starts with a human grammar base and then adapts it to usage as a software language.</p>
<h2 id="lojban">Lojban</h2>
<p>Lojban is a language intended for human use, but based on the structure of programming languages, in particular predicate logic<span class="citation"></span>. Because of this Lojban is more of an API rather than a human language, making it very difficult to gain fluency<span class="citation"></span><span class="citation"></span>.</p>
<p>While there have been some cursory motions towards making Lojban a programming language<span class="citation"></span>, none have gotten much past the concept stage.</p>
<p>The net result is that Lojban has not proven suitable for human communication, nor as a software language. Though it has been a useful stepping stone and point of inspiration.</p>
<h1 id="method">Method</h1>
<p>Many different approaches have been taken to the creation of software languages. Rather than basing Pyash on the Chomsky Hierarchy of formal languages and formal grammars, it is based it on human grammar.</p>
<h2 id="grammar">Grammar</h2>
<p>Linguistic Universals<span class="citation"></span> are patterns found systematically across large groups of languages, possibly all languages. In particular all languages have verb phrases and noun phrases, and mark their phrases either with placement, adpositions or affixes. All can also express tense, mood and aspect.</p>
<p>However there is the issue of making the pivot language. Which of the many options should the language use? To the rescue comes the World Atlas of Language Structures<span class="citation"></span> (WALS), which allows one to see what are the most common features around the world.</p>
<p>In particular Pyash is Verb-final, or Subject-Object-Verb word-order, similar to Hindi, Japanese and Amharic. Linguistic Universals point toward suffixes and-or postpositions for verb-final languages, so they are used.</p>
<p>But what of the grammar words themselves? A variety of contenders were reviewed, such as Universal Networking Language<span class="citation"></span> from the United Nations University, and FrameNet<span class="citation"></span> from Berkley. A more organic solution was chosen consisting of the list of Glossing Abbreviations<span class="citation"></span> used by linguists when transcribing foreign languages.</p>
<h2 id="vocabulary">Vocabulary</h2>
<p>Contemporary Software Languages generally lack a root vocabulary. Keywords may have a special meaning, but they are typically of a syntactic or grammatical nature, so are at most a grammatical vocabulary. API’s naming convention of being series of unreserved letters, means that all unreserved words are proper nouns.</p>
<p>Pyash has a root vocabulary so that documentation, description and discussion can all happen in the same language as computer programming. The encoding requires API names to be words with a proper morphology ([morphology]), and may be restricted to only being official dictionary defined ones, ensuring standardization and ease of translation.</p>
<p>To generate the vocabulary first several word-lists were put together, including WordNet core<span class="citation"></span>, Oxford-3000<span class="citation"></span>, UNL-core<span class="citation"></span>, Special English<span class="citation"></span>, FrameNet<span class="citation"></span>, New Academic Word List (NAWL)<span class="citation"></span>, New General Service List (NGSL)<span class="citation"></span> and Project Gutenberg Frequency List<span class="citation"></span>. After collating them all and taking out the duplicates, the language was left with almost 39 thousand words.</p>
<p>Google Cloud Translation API<span class="citation"></span> was used to translate each word on the list individually into the top 48 languages by number of native speakers. Giving an overall coverage of greater than 70% of the world population.</p>
<p>A script to sort the vocabulary based on the frequency list<span class="citation"></span> was made and it filtered them for uniqueness. Words were removed that were:</p>
<dl>
<dt>Overborrowed</dt>
<dd><p>If more than <span class="math inline">38%</span><a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> languages use the English term.</p>
</dd>
<dt>Ambigious</dt>
<dd><p>If it means multiple things in more than <span class="math inline">38%</span> of the languages.</p>
</dd>
<dt>Homographs</dt>
<dd><p>If it is a homograph of an already defined word in any of the languages.</p>
</dd>
</dl>
<p>This left the language with a fairly orthogonal pool of about eight thousand words.</p>
<h2 id="morphology">Morphology</h2>
<p>The pivot language needs to be sufficiently easily spoken by humans for it to be usable by humans in conversation. This was particularly the case in early prototypes, as it wasn’t realized that the pivot language could be used for translating between possibly all human languages — which would negate the need for actually learning the pivot language, a Pyash controlled natural language would be sufficient.</p>
<table>
<caption>ASCII alphabet used by Pyash, the letter’s IPA equivalents, description and English pronunciation key.<span data-label="table:phonology"></span></caption>
<thead>
<tr class="header">
<th align="left">ASCII</th>
<th align="left">IPA</th>
<th align="left">Description</th>
<th align="left">English</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">a</td>
<td align="left"><span> ä</span></td>
<td align="left">central open vowel</td>
<td align="left">rm</td>
</tr>
<tr class="even">
<td align="left">b</td>
<td align="left"><span> b</span></td>
<td align="left">voiced bilabial plosive</td>
<td align="left">all</td>
</tr>
<tr class="odd">
<td align="left">c</td>
<td align="left"><span> ʃ</span></td>
<td align="left">unvoiced post-alveolar fricative</td>
<td align="left">out</td>
</tr>
<tr class="even">
<td align="left">d</td>
<td align="left"><span> d</span></td>
<td align="left">voiced alveolar dental</td>
<td align="left">oor</td>
</tr>
<tr class="odd">
<td align="left">e</td>
<td align="left"><span> e̞</span></td>
<td align="left">mid front unrounded vowel</td>
<td align="left">nter</td>
</tr>
<tr class="even">
<td align="left">f</td>
<td align="left"><span> f</span></td>
<td align="left">unvoiced labio dental fricative</td>
<td align="left">ire</td>
</tr>
<tr class="odd">
<td align="left">g</td>
<td align="left"><span> g</span></td>
<td align="left">voiced velar plosive</td>
<td align="left">reat</td>
</tr>
<tr class="even">
<td align="left">h</td>
<td align="left"><span> ʰ</span></td>
<td align="left">aspiration</td>
<td align="left">appy</td>
</tr>
<tr class="odd">
<td align="left">i</td>
<td align="left"><span> i</span></td>
<td align="left">unrounded closed front vowel</td>
<td align="left">sk</td>
</tr>
<tr class="even">
<td align="left">j</td>
<td align="left"><span> ʒ</span></td>
<td align="left">voiced post-alveolar fricative</td>
<td align="left">garae</td>
</tr>
<tr class="odd">
<td align="left">k</td>
<td align="left"><span> k</span></td>
<td align="left">unvoiced velar plosive</td>
<td align="left">eep</td>
</tr>
<tr class="even">
<td align="left">l</td>
<td align="left"><span> l</span></td>
<td align="left">lateral approximants</td>
<td align="left">ove</td>
</tr>
<tr class="odd">
<td align="left">m</td>
<td align="left"><span> m</span></td>
<td align="left">bilabial nasal</td>
<td align="left">ap</td>
</tr>
<tr class="even">
<td align="left">n</td>
<td align="left"><span> n</span></td>
<td align="left">alveolar nasal</td>
<td align="left">ap</td>
</tr>
<tr class="odd">
<td align="left">o</td>
<td align="left"><span> o̞</span></td>
<td align="left">mid back rounded vowel</td>
<td align="left">rbot</td>
</tr>
<tr class="even">
<td align="left">p</td>
<td align="left"><span> p</span></td>
<td align="left">unvoiced bilabial plosive</td>
<td align="left">an</td>
</tr>
<tr class="odd">
<td align="left">q</td>
<td align="left"><span> ŋ</span></td>
<td align="left">velar nasal</td>
<td align="left">Elish</td>
</tr>
<tr class="even">
<td align="left">r</td>
<td align="left"><span> r</span></td>
<td align="left">alveolar trill</td>
<td align="left">(Scottish) cud</td>
</tr>
<tr class="odd">
<td align="left">s</td>
<td align="left"><span> s</span></td>
<td align="left">unvoiced alveolar fricative</td>
<td align="left">nake</td>
</tr>
<tr class="even">
<td align="left">t</td>
<td align="left"><span> t</span></td>
<td align="left">unvoiced alveolar plosive</td>
<td align="left">ime</td>
</tr>
<tr class="odd">
<td align="left">u</td>
<td align="left"><span> u</span></td>
<td align="left">rounded closed back vowel</td>
<td align="left">bl</td>
</tr>
<tr class="even">
<td align="left">v</td>
<td align="left"><span> v</span></td>
<td align="left">voiced labio dental fricative</td>
<td align="left">oice</td>
</tr>
<tr class="odd">
<td align="left">w</td>
<td align="left"><span> w</span></td>
<td align="left">labio velar approximant</td>
<td align="left">ater</td>
</tr>
<tr class="even">
<td align="left">x</td>
<td align="left"><span> x</span></td>
<td align="left">velar fricative</td>
<td align="left">(Scottish) lo</td>
</tr>
<tr class="odd">
<td align="left">y</td>
<td align="left"><span> j</span></td>
<td align="left">palatal approximant</td>
<td align="left">ou</td>
</tr>
<tr class="even">
<td align="left">z</td>
<td align="left"><span> z</span></td>
<td align="left">voiced alveolar fricative</td>
<td align="left">oom</td>
</tr>
<tr class="odd">
<td align="left">.</td>
<td align="left"><span> ʔ</span></td>
<td align="left">glottal stop</td>
<td align="left">uhoh</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left"><span> ə</span></td>
<td align="left">mid central vowel</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">7</td>
<td align="left"><span> ˦</span></td>
<td align="left">high tone</td>
<td align="left">wha</td>
</tr>
<tr class="even">
<td align="left">_</td>
<td align="left"><span> ˨</span></td>
<td align="left">low tone</td>
<td align="left">no</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left"><span> ǀ</span></td>
<td align="left">dental click</td>
<td align="left">tsk</td>
</tr>
<tr class="even">
<td align="left">8</td>
<td align="left"><span> ǁ</span></td>
<td align="left">lateral click</td>
<td align="left">winking</td>
</tr>
</tbody>
</table>
<p>First, an alphabet representing phonemes which are popular in human languages was required, for this PHOIBLE<span class="citation"></span> was used. Then WALS’<span class="citation"></span> chapters on phoneme inventories was used to find what a common ratio of consonants to vowels is, as well as common number of consonants and vowels, and picked the most popular single phonemes which are reasonably distinct. Two tones were also included to increase the number of words. Two clicks were included for temporary document specific words — in place of acronyms. An ASCII letter for each IPA phoneme was also selected (Table [table:phonology]) to make sure Pyash is web compatible.</p>
<p>Second, a morphology of how the phonemes are put together to make words was required. For this phonotactics of the sonority scale<span class="citation"></span> was used, paired with the WALS<span class="citation"></span> chapter on syllable structure.</p>
<table>
<caption>Pyash word morphology. <span data-label="table:morphology"></span></caption>
<thead>
<tr class="header">
<th align="left">Code</th>
<th align="left">ASCII Example</th>
<th align="left">IPA</th>
<th align="left">Name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><strong>CV</strong></td>
<td align="left">ka</td>
<td align="left">/<span>kä</span>/</td>
<td align="left">short grammar word</td>
</tr>
<tr class="even">
<td align="left"><strong>CSVH</strong></td>
<td align="left">kyah</td>
<td align="left">/<span>kjäʰ</span>/</td>
<td align="left">long grammar word</td>
</tr>
<tr class="odd">
<td align="left"><strong>HCVC</strong></td>
<td align="left">hkap</td>
<td align="left">/<span>ʰkäp</span>/</td>
<td align="left">short root word</td>
</tr>
<tr class="even">
<td align="left"><strong>CSVC</strong></td>
<td align="left">kyap</td>
<td align="left">/<span>kjäp</span>/</td>
<td align="left">long root word</td>
</tr>
</tbody>
</table>
<dl>
<dt>H</dt>
<dd><p>/<span>ʰ</span>/ aspiration or spectrographically an unvoiced vowel.</p>
</dd>
<dt>C</dt>
<dd><p>a consonant.</p>
</dd>
<dt>S</dt>
<dd><p>a consonant of higher sonority than the preceding one.</p>
</dd>
<dt>V</dt>
<dd><p>a vowel (highest sonority).</p>
</dd>
</dl>
<p>The language was also made easily parsed even if there are no spaces or pauses between words. Each word is either two or four letters long. The two letter words start with a consonant and end with a vowel, and the four letter ones start with two consonants and end with a consonant (Table [table:morphology]).</p>
<p>The valid words were generated with several alphabets, and a script was made to assign words based on the phonemes in the source languages weighed by their representative native speaking populations. The highest frequency words were assigned to the easier to pronounce and understand smaller alphabets. And the more rare words were assigned to the more difficult extended alphabets — with voice contrast and-or tones for instance.</p>
<h2 id="ISA">Instruction Set Architecture</h2>
<p>For complete vertical integration the language has to boil down to machine level instruction, or an instruction set architecture. The JVM bytecode is an example of a different language which can also be implemented as an instruction set architecture<span class="citation"></span>.</p>
<p>Understanding that the future of computing is going towards parallelism much research into how to make the language as parallel-friendly as possible was done. In particular the Heads and Tails ISA<span class="citation"></span> was found to be quite inspiring.</p>
<p>Each Pyash word fits in sixteen bits (a uint16_t). There are four word types and one quote type which are encoded. The quote type allows for including literals.</p>
<ol>
<li><p><strong>Pyash English</strong> do say the quoted’word’hey world’word’quoted.</p></li>
<li><p><strong>Pyash</strong> zi.wo.hwacwu.wo.zika hsactu</p></li>
<li><p><strong>Codelet</strong> 0051 291D E928 28BE 245E E948 295E 0000 0000 0000 0000 0000 0000 0000 0000 0000</p></li>
<li><p><strong>Codelet Explained</strong> (0051 index) (291D quoting two words) (E928 28BE hwac wu) (245E ka accusative-case) (E948 hsac say) (295E tu deonitic-mood) 0000 0000 0000 0000 0000 0000 0000 0000 0000</p></li>
<li><p><strong>C</strong></p>
<pre><code>   wotyutdokahsac(_(&quot;hwacwu&quot;));
   </code></pre></li>
<li><p><strong>Output with en_US locale</strong> hey world<br />
<strong>Output with ru locale</strong> эй мир</p></li>
</ol>
<p>For parallelism sentences are encoded into codelets<span class="citation"></span>, which are comprised of one or more vectors of sixteen, sixteen bit values. The first sixteen bit value of a vector is the index for the vector, marking the location of grammatical cases and moods (ends of noun and verb phrases).</p>
<dl>
<dt>Pyash</dt>
<dd><p>mina ryopyi syutka kwinli</p>
</dd>
<dt>Gloss</dt>
<dd><p>me NOM robot DAT liberty ACC giving REAL</p>
</dd>
<dt>Pyash English</dt>
<dd><p>I be giving the liberty to robot.</p>
</dd>
</dl>
<p>This encoding can then be translated to any supported human language (Table [table:translation]). In terms of compiling to a programming language, it compiles to OpenCL C. There is also a design<span class="citation"></span> for making a code-parallel virtual machine, that can process linear code on GPU’s using Pyash ISA.</p>
<p>The encoding could also be used for storage of information, similar to a database, as well as for knowledge management, similar to how human languages are used for storing information.</p>
<h2 id="parser-or-encoder">Parser or Encoder</h2>
<p>The parser is probably of some interest due to its refined simplicity. It is a hand coded, single pass type, modeled on how a human would parse text. There are no parse trees or any such complexities.</p>
<p>First the parser checks if a word is a valid Pyash word, if so, then checks if it is a grammatical-case word, a grammatical-mood word or a quote word, if not then simply adds it to the codelet.</p>
<p>If it is a quote word then acts accordingly either upon the literals ahead or the words behind, adding what is necessary to the codelet, and adjusting the codelet and text index pointer to just after the quote.</p>
<p>If it is a grammatical-case word, then in addition to adding the word to the codelet, also marks it on the index.</p>
<p>If it is a grammatical-mood word then does as with the grammatical-case word but also ends the codelet. With the exception of the conditional mood, which is treated the same as a grammatical-case for encoding.</p>
<p>For reading and writing to the codelet there is a function, which manages which vector is being added to. If the addition over-runs one vector, then it’s index is inverted, and the next vector receives the additions. This way when reading indexes, it is known if it is the end of the codelet based on the first bit of the index — if it is a one then it is the final vector.</p>
<p>This simple parser/encoder could parse/encode sentences in parallel, and should be adaptable for parsing spoken streams of phonemes. A more complicated version of the parser/encoder will be necessary once support is added for subordinate clauses, since they would have to be broken up into multiple codelets for the encoding.</p>
<h1 id="discussion">Discussion</h1>
<p>Various variations of the language have been worked on since 2007. The first implementation<span class="citation"></span> was in Haskell and second was in Java<span class="citation"></span>, both were recursive parsers.</p>
<p>The third implementation<span class="citation"></span> followed the Jones Forth<span class="citation"></span> model, hoping to bootstrap something small and scaleable, so Intel assembly was used for a few years and succeeded in making a basic interpreter.</p>
<p>The fourth attempt<span class="citation"></span> was in nodejs Javascript, since by that time it was realized that the language could be used for translation, and something portable was desired which could written quickly — the antithesis of assembly. A translator was made and a basic compiler to Javascript, but was severely limited by a hand picked vocabulary, so an automated vocabulary ([vocabulary]) was made. While it was being made, it was realized that the object oriented implementation in Javascript was difficult or impossible to make parallel, combined with its plain text encoding led to it running extremely slow. So the Javascript translator and compiler was abandoned, but the automated vocabulary was kept.</p>
<p>The fifth and current attempt<span class="citation"></span> it was motivated by the realization that something fast, scaleable and future-friendly was needed, so a parallelizeable ISA ([ISA]) was designed and the implementation was done in OpenCL C. As of this writing (May 2017) it compiles hello world, does variable assignment, for loops, and function declarations are being implemented.</p>
<h2 id="vertical-integration">Vertical Integration</h2>
<p>While the main focus of the current implementations has been computer programming languages and related documentation. The language can be used to cover the areas of other software language types as well.</p>
<h3 id="database-languages">Database Languages</h3>
<table>
<caption>Sampling of SQL keywords and their Pyash equivalents<span data-label="table:SQL"></span></caption>
<thead>
<tr class="header">
<th align="left">SQL</th>
<th align="left">Pyash</th>
<th align="left">Pyash English</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">CREATE</td>
<td align="left">tlip</td>
<td align="left">establish</td>
</tr>
<tr class="even">
<td align="left">SELECT</td>
<td align="left">kcot</td>
<td align="left">gather</td>
</tr>
<tr class="odd">
<td align="left">UPDATE</td>
<td align="left">draf</td>
<td align="left">modernize</td>
</tr>
<tr class="even">
<td align="left">DELETE</td>
<td align="left">dlas</td>
<td align="left">delete</td>
</tr>
<tr class="odd">
<td align="left">INSERT</td>
<td align="left">hquk</td>
<td align="left">inject</td>
</tr>
<tr class="even">
<td align="left">FROM</td>
<td align="left">pwih</td>
<td align="left">from</td>
</tr>
<tr class="odd">
<td align="left">WHERE</td>
<td align="left">te</td>
<td align="left">at</td>
</tr>
<tr class="even">
<td align="left">INTO</td>
<td align="left">twih</td>
<td align="left">into</td>
</tr>
</tbody>
</table>
<p>For example SQL database access and creation language, can easily fit as a subset of Pyash, with some slight vocabulary changes (Table [table:SQL]). Due to this rather fortunate grammatical-case design of SQL it should be possible to translate from SQL to Pyash and vice-versa — whereas with most placement based parameter family of languages it is a non-trivial process.</p>
<h3 id="ontology-languages">Ontology Languages</h3>
<p>For knowledge representation or ontology languages, the databases could simply be made of Pyash codelets. They could be rapidly queried in parallel on GPU for any particular piece of information. They could be translated to and from human language, for sharing gathered knowledge with humans, or acquiring knowledge from humans.</p>
<p>Even a few people having a conversation, such as at a meeting could generate programs and-or machine knowledge if they were speaking with enough formality to be Pyash accessible.</p>
<p>Pyash accessibility is currently rather low, having a rather strict grammar. But with machine learning algorithms to help with converting natural language speech into Pyash controlled natural languages the amount of machine accessible knowledge that could be harvest from the spoken and written word should dramatically increase.</p>
<h3 id="modeling-languages">Modeling Languages</h3>
<p>Considering that Gellish is a modeling language, and that Pyash has a much more developed grammar, it should be fairly straightforward to adapt Pyash to be a universal modeling language.</p>
<p>For visual people, graphics could be generated from Pyash descriptions. So in the hypothetical scenario of some people talking in a meeting, the computer could be projecting the model of what is described on the screen. Or running and showing simulations to see the potential outcomes of various policy or program changes.</p>
<h3 id="domain-specific-programming-languages">Domain Specific Programming Languages</h3>
<p>The majority of domain specific languages seem to have placement based parameters. This means that reading the API is likely necessary to understanding how to use any functions. Thus, unless the API is written in Pyash or some other machine-accessible format, translating to and particularly from those languages to Pyash is non-trivial.</p>
<p>Translating to those languages is easier, as a human can read the API and make an appropriate Pyash side function to access it. However if someone adds a new function to that other language, without following something like the Pyash function naming convention, then it will be nearly impossibly to translate to Pyash without reading it’s corresponding API and-or analyzing it’s code.</p>
<p>Possibly when machine learning and AI gets sufficiently sophisticated it will be able to do those translations, but that is quite possibly decades away.</p>
<p>For now it makes sense to limit official Pyash programming development to compiling to popular C libraries, and also making native libraries.</p>
<h3 id="communications-protocols-and-serialization-formats">Communications Protocols and Serialization formats</h3>
<p>There are a wide range of communication protocols, all serving their own niches. For example, HTTP, SMTP, and IRC.</p>
<p>With the advent of XML there was an increase of protocol creation, for example XMPP, SOAP and XML-RPC. However since XML doesn’t have a root vocabulary most of these different protocols have different naming conventions and so are not easily inter-operable.</p>
<p>XML is also rather bulky, so in certain areas, such as configuration and data storage, more compact alternative such as JSON, Lua and YAML have gained. Though like XML, they lack a root vocabulary.</p>
<p>Pyash does have a root vocabulary so it is fairly straightforward to use as a communication protocol. Having the root vocabulary could encourage people to extend the language rather than make entirely new protocols. The binary encoding of Pyash, which can store various types including binary data, is both compact and can be decoded into a human readable format in a variety of human languages.</p>
<p>In terms of usage of space, Pyash is likely to be more bulky than any of the early terse ones like HTTP, but will typically use less space than XML, approaching JSON or YAML — depending on the length of names used.</p>
<p>The goal of using Pyash for protocols is making it easier to collect, consume and process large amounts of data. Especially now that many of us have more storage and processing power than we know what to do with. For example, may people have powerful GPU’s in their computers, which most of the time sit relatively idle.</p>
<dl>
<dt>Error message</dt>
<dd><p>encoding:570:text_encoding debug text</p>
</dd>
<dt>Pyash English</dt>
<dd><p>from encoding file at num five seven zero line in text encoding cereomony the debug text be emitting.</p>
</dd>
<dt>Pyash</dt>
<dd><p>kfinhfaspwih hfakhsipzrondo lyinlwoh htetkfinsricnwih dyekhtetka mwa7nli</p>
</dd>
</dl>
<p>Since the error reporting was mentioned earlier, here is an example (Table [errorMessage]). Though the Pyash versions are longer, they are more portable, and non-English speaking people can help debug the program, as the Pyash could be translated to an approximation of their native language.</p>
<p>Additionally a variety of protocols could be translated into Pyash, not necessarily so they would be faster, but to make it easier for an AI or AGI to understand and communicate using them.</p>
<h3 id="markup-languages">Markup Languages</h3>
<p>LaTeX, HTML and Markdown are some of the most popular markup languages on the internet today. Of course they are mostly for formatting, and do not include a vocabulary for the content.</p>
<p>However for writing modern documents, it is often important to have chapters, sections and subsections. Spoken speech has an (arguable) analog of bold and italics, via the focus and topic of the sentence — which is already a part of Pyash grammar. However spoken language generally doesn’t have long enough monologues for people to even mark their spoken paragraphs.</p>
<p>The grammar of Pyash could be extended enough to allow for such mark up. An example would be to make a grammar word for paragraph, module (section), and frame (chapter).</p>
<p>Pyash as a markup language would be particularly useful in using Pyash for writing international content, such as stories, news articles or even legislation.</p>
<h1 id="conclusion-and-further-work">Conclusion and Further Work</h1>
<p>A software language based on the fundamentals of human language that is usable for human communication and computer programming is certainly viable and implementable, as it has been done.</p>
<p>Translating all or most human languages, or at least controlled variants of them does on the surface appear viable. Though further research would have to be done to see what level of conjugation is comfortable for, and how long it would take for native language speakers to adapt to the controlled variants.</p>
<p>Translating everything between software languages is unfortunately not viable due to the much smaller scope of them, as they can’t be used for human communication. Though existing codebase can be used via foreign function interface.</p>
<p>Complete vertical integration of everything that a computer might need to do seems to be viable, though further work would need to happen to prove it.</p>
<p>This implementation of the language seems to be satisfactory. Language adoption is a major hurdle, which motivates this article. Pyash is being used to write an automated programmer to more quickly write the standard libraries, and general intelligence operating system to follow.</p>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><span class="math inline">2 − <em>ϕ</em> = 38%</span> where <span class="math inline"><em>ϕ</em></span> is golden ratio or 1.618. A golden fraction was felt to be a natural choice.<a href="#fnref1">↩</a></p></li>
</ol>
</div>
  </div>
</body>
</html>

