{
	"next_topic_id": 1,
	"topic": [],
	"topic_vote": {},
	"next_comment_id": 3,
	"comment": {
		"1535704655_1L4dZcDF2maSKHDy788yhxpYnBWnXadUtS": [
			{
				"comment_id": 1,
				"body": "> [ssdifnskdjfnsdjk](#comment_10_1L4dZcDF2maSKHDy788yhxpYnBWnXadUtS): I was wondering if i can somehow setup a recurring Linux command that would discover recent KopyKate videos and automatically download them. This way i can add this script to some non-stop running server (VPS) with open port, so there is always one seed for me and other people home computers. Though not yet spent time on this :-/ Maybe curl command would DL site, then i would have to extract links from that file and then maybe curl, wget or \".../ZeroNet.py siteDownload URL\" command on the video link. Then setting up a tmpwatch to delete oldest files so i do not fill the HDD.\n\nJust fetch from the SQL db which is locally stored on your computer. That will give you access to the whole list of videos. From there, just grab any new ones (you can sort by date), and have it visit the site and download.",
				"added": 1535711894
			},
			{
				"comment_id": 2,
				"body": "> [balancer73](#comment_20_1PniNzyi8fygvwyBaLpA9oBDVWZ5fXuJUw): ZeroNet stores all data in JSON-files. So it's best to look for the latest updates via find or inotifywatch and jq.\n\nEasier to just go with the SQL file. Looking for json files would be more work.",
				"added": 1535762850
			}
		]
	},
	"comment_vote": {}
}