{
	"next_topic_id": 2,
	"topic": [
		{
			"topic_id": 1537907056,
			"title": "Client-side file deduplication",
			"body": "###Client-side file deduplication\n\n- Detect duplicates, and move them to a dedicated folder, with files addressed by their hash\n  - So duplicate files would not be accessed by their site-specified path but by their hash\n- Before requesting a new file from peers, check if the client already has the file by comparing hashes\n  - Possibly checking first if the data on disk isn't corrupted (by hash or file size)\n\n---\n\n####How much data or how many files are duplicate?\n\nChecking the  `content.json` file of 3014 sites (not the user data) gave this result:\n\n#####Required files\n\n**1635 MiB (21.0%)** of 7773 MiB was duplicate data\n38692 (24.8%) of 155575 were duplicate files\n\n#####Optional files\n\n**20537 MiB (~3%)** of 685679 MiB was duplicate data\n46619 (21.9%) of 212718 were duplicate files",
			"added": 1537907055
		}
	],
	"topic_vote": {},
	"next_comment_id": 1,
	"comment": {},
	"comment_vote": {}
}