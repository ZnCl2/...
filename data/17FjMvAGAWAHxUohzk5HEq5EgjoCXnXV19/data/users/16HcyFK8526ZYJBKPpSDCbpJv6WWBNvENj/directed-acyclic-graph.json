{
    "article": [
        {
            "title": "Directed Acyclic Graph",
            "text": "#REDIRECT [[Directed acyclic graph]] {{R from other capitalisation}}",
            "slug": "directed-acyclic-graph",
            "date_updated": 1518062028828,
            "imported": "https://en.wikipedia.org/wiki/Directed Acyclic Graph"
        },
        {
            "title": "Directed acyclic graph",
            "text": " \n{{good article}}\n[[File:Topological Ordering.svg|thumb|A [[Topological sorting|topological ordering]] of a directed acyclic graph: every edge goes from earlier in the ordering (upper left) to later in the ordering (lower right). A directed graph is acyclic if and only if it has a topological ordering.]]\nIn [[mathematics]] and [[computer science]], a '''directed acyclic graph''' ('''DAG''' {{IPAc-en|audio=en-us-DAG.ogg|ˈ|d|æ|g}}), is a finite [[directed graph]] with no [[Cycle graph#Directed cycle graph|directed cycles]]. That is, it consists of finitely many [[Vertex (graph theory)|vertices]] and [[edge (graph theory)|edges]], with each edge directed from one vertex to another, such that there is no way to start at any vertex {{mvar|v}} and follow a consistently-directed sequence of edges that eventually loops back to {{mvar|v}} again. Equivalently, a DAG is a directed graph that has a [[topological ordering]], a sequence of the vertices such that every edge is directed from earlier to later in the sequence.\n\nDAGs can model many different kinds of information. A [[spreadsheet]] can be modeled as a DAG, with a vertex for each cell and an edge whenever the formula in one cell uses the value from another; a topological ordering of this DAG can be used to update all cell values when the spreadsheet is changed.\nSimilarly, topological orderings of DAGs can be used to order the compilation operations in a [[makefile]]. The [[program evaluation and review technique]] uses DAGs to model the milestones and activities of large human projects, and schedule these projects to use as little total time as possible. [[Combinational logic]] blocks in electronic circuit design, and the operations in [[dataflow programming]] languages, involve acyclic networks of processing elements. DAGs can also represent collections of events and their influence on each other, either in a probabilistic structure such as a [[Bayesian network]] or as a record of historical data such as [[family tree]]s or the version histories of  [[distributed revision control]] systems. DAGs can also be used as a [[data compression|compact representation]] of sequence data, such as the [[Deterministic acyclic finite state automaton|directed acyclic word graph]] representation of a collection of strings, or the [[binary decision diagram]] representation of sequences of binary choices. More abstractly, \nthe [[reachability]] relation in a DAG forms a [[partial order]], and any [[finite set|finite]] partial order may be represented by a DAG using reachability.\n\nImportant [[polynomial time]] computational problems on DAGs include [[topological sorting]] (finding a topological ordering), construction of the [[transitive closure]] and [[transitive reduction]] (the largest and smallest DAGs with the same reachability relation, respectively), and the [[closure problem]], in which the goal is to find a minimum-weight subset of vertices with no edges connecting them to the rest of the graph. Transforming a directed graph with cycles into a DAG by deleting as few vertices or edges as possible (the [[feedback vertex set]] and [[feedback edge set]] problem, respectively) is [[NP-hard]], but any directed graph can be made into a DAG (its [[condensation (graph theory)|condensation]]) by contracting each [[strongly connected component]] into a single supervertex. The problems of finding [[shortest path]]s and [[longest path problem|longest paths]] can be solved on DAGs in [[linear time]], in contrast to arbitrary graphs for which shortest path algorithms are slower and longest path problems are NP-hard.\n\nThe corresponding concept for [[undirected graph]]s is a [[forest (graph theory)|forest]], an undirected graph without cycles. Choosing an orientation for a forest produces a special kind of directed acyclic graph called a [[polytree]]. However there are many other kinds of directed acyclic graph that are not formed by orienting the edges of an undirected acyclic graph. Moreover, every undirected graph has an [[acyclic orientation]], an assignment of a direction for its edges that makes it into a directed acyclic graph. To emphasize that DAGs are not the same thing as directed versions of undirected acyclic graphs, some authors call them '''acyclic directed graphs'''<ref name=\"thul\"/> or '''acyclic digraphs'''.<ref name=\"bang\"/>\n\n==Definitions==\nA [[Graph (discrete mathematics)|graph]] is formed by a collection of [[vertex (graph theory)|vertices]] and [[edge (graph theory)|edges]], where the vertices are structureless objects that are connected in pairs by edges. In the case of a [[directed graph]], each edge has an orientation, from one vertex to another vertex.\nA [[Path (graph theory)|path]] in a directed graph can be described by a sequence of edges having the property that the ending vertex of each edge in the sequence is the same as the starting vertex of the next edge in the sequence; a path forms a cycle if the starting vertex of its first edge equals the ending vertex of its last edge. A directed acyclic graph is a directed graph that has no cycles.<ref name=\"thul\">{{citation|title=Graphs: Theory and Algorithms|first1=K.|last1=Thulasiraman|first2=M. N. S.|last2=Swamy|publisher=John Wiley and Son|year=1992|isbn=978-0-471-51356-8|contribution=5.7 Acyclic Directed Graphs|page=118}}.</ref><ref name=\"bang\">{{citation|title=Digraphs: Theory, Algorithms and Applications|first1=Jørgen|last1=Bang-Jensen|series=Springer Monographs in Mathematics|edition=2nd|publisher=Springer-Verlag|year=2008|isbn=978-1-84800-997-4|contribution=2.1 Acyclic Digraphs|pages=32–34}}.</ref><ref>{{citation|title=Graph theory: an algorithmic approach|first=Nicos|last=Christofides|publisher=Academic Press|year=1975|pages=170–174}}.</ref>\n\n[[File:Transitive Closure.svg|thumb|upright=1.2|Adding the red edges to the blue directed acyclic graph produces another DAG, the [[transitive closure]] of the blue graph. For each red or blue edge {{mvar|uv}}, {{mvar|v}} is [[Reachability|reachable]] from {{mvar|u}}: there exists a blue path starting at {{mvar|u}} and ending at {{mvar|v}}.]]\nA vertex {{mvar|v}} of a directed graph is said to be [[Reachability|reachable]] from another vertex {{mvar|u}} when there exists a path that starts at {{mvar|u}} and ends at {{mvar|v}}. As a special case, every vertex is considered to be reachable from itself (by a path with zero edges). If a vertex can reach itself via a nontrivial path (a path with one or more edges), then that path is a cycle, so another way to define directed acyclic graphs is that they are the graphs in which no vertex can reach itself via a nontrivial path.<ref>{{citation|title=Simulation Techniques for Discrete Event Systems|volume=14|series=Cambridge Computer Science Texts|first=I.|last=Mitrani|year=1982|publisher=Cambridge University Press|isbn=9780521282826|page=27|url=https://books.google.com/books?id=CF04AAAAIAAJ&pg=PA27}}.</ref>\n\nA [[topological ordering]] of a directed graph is an ordering of its vertices into a sequence, such that for every edge the start vertex of the edge occurs earlier in the sequence than the ending vertex of the edge.\nA graph that has a topological ordering cannot have any cycles, because the edge into the earliest vertex of a cycle would have to be oriented the wrong way. Therefore, every graph with a topological ordering is acyclic.\nConversely, every directed acyclic graph has at least one topological ordering. Therefore, this property can be used as an alternative definition of the directed acyclic graphs: they are exactly the graphs that have topological orderings.<ref name=\"bang\"/>\n\n== Mathematical properties ==\n\n=== Reachability, transitive closure, and transitive reduction ===\nThe [[reachability]] relationship in any directed acyclic graph can be formalized as a [[partial order]] {{math|≤}} on the vertices of the DAG. In this partial order, two vertices {{mvar|u}} and {{mvar|v}} are ordered as {{math|''u'' ≤ ''v''}} exactly when there exists a directed path from {{mvar|u}} to {{mvar|v}} in the DAG; that is, when {{mvar|v}} is reachable from {{mvar|u}}.<ref>{{citation|title=The Design and Analysis of Algorithms|series=Monographs in Computer Science|first=Dexter|last=Kozen|authorlink=Dexter Kozen|publisher=Springer|year=1992|isbn=978-0-387-97687-7|page=9|url=https://books.google.com/books?id=L_AMnf9UF9QC&pg=PA9}}.</ref> However, different DAGs may give rise to the same reachability relation and the same partial order.<ref>{{citation|title=Loop Transformations for Restructuring Compilers: The Foundations|first=Utpal|last=Banerjee|publisher=Springer|year=1993|isbn=978-0-7923-9318-4|page=19|contribution=Exercise 2(c)|url=https://books.google.com/books?id=Cog7zSSlqFwC&pg=PA19}}.</ref> For example, the DAG with two edges {{math|''a'' → ''b''}} and {{math|''b'' → ''c''}} has the same reachability relation as the graph with three edges {{math|''a'' → ''b''}}, {{math|''b'' → ''c''}}, and {{math|''a'' → ''c''}}. Both of these DAGS produce the same partial order, in which the vertices are ordered as {{math|''a'' ≤ ''b'' ≤ ''c''}}.\n\nIf {{mvar|G}} is a DAG, its [[transitive closure]] is the graph with the most edges that represents the same reachability relation. It has an edge {{math|''u'' → ''v''}} whenever {{mvar|u}} can reach {{mvar|v}}. That is, it has an edge for every related pair {{math|''u''&nbsp;≤&nbsp;''v''}} of distinct elements in the reachability relation of {{mvar|G}}, and may therefore be thought of as a direct translation of the reachability relation {{math|≤}} into graph-theoretic terms. The same method of translating partial orders into DAGs works more generally: for every finite partially ordered set {{math|(''S'', ≤)}}, the graph that has a vertex for each member of {{mvar|S}} and an edge for each pair of elements related by {{math|''u''&nbsp;≤&nbsp;''v''}} is automatically a transitively closed DAG, and has {{math|(''S'', ≤)}} as its reachability relation. In this way, every finite partially ordered set can be represented as the reachability relation of a DAG.\n\n{{multiple image|image1=Tred-G.svg|width1=175|image2=Tred-Gprime.svg|width2=124|caption1=A DAG {{mvar|G}}|caption2=Transitive reduction of {{mvar|G}}}}\nThe [[transitive reduction]] of a DAG {{mvar|G}} is the graph with the fewest edges that represents the same reachability relation as {{mvar|G}}. It is a subgraph of {{mvar|G}}, formed by discarding the edges {{math|''u'' → ''v''}} for which {{mvar|G}} also contains a longer path connecting the same two vertices.\nLike the transitive closure, the transitive reduction is uniquely defined for DAGs. In contrast, for a directed graph that is not acyclic, there can be more than one minimal subgraph with the same reachability relation.<ref>{{citation|title=Digraphs: Theory, Algorithms and Applications|series=Springer Monographs in Mathematics|first1=Jørgen|last1=Bang-Jensen|first2=Gregory Z.|last2=Gutin|publisher=Springer|year=2008|isbn=978-1-84800-998-1|url=https://books.google.com/books?id=4UY-ucucWucC&pg=PA36|contribution=2.3 Transitive Digraphs, Transitive Closures and Reductions|pages=36–39}}.</ref>\n\n[[File:Hasse diagram of powerset of 3.svg|thumb|300px|A [[Hasse diagram]] representing the partial order of set inclusion (⊆) among the subsets of a three-element set.]]\nIf a DAG {{mvar|G}} has a reachability relation described by the partial order {{math|≤}}, then the transitive reduction of {{mvar|G}} is a subgraph of {{mvar|G}} that has an edge {{math|''u'' → ''v''}} for every pair in the [[covering relation]] of {{math|≤}}. Transitive reductions are useful in visualizing the partial orders they represent, because they have fewer edges than other graphs representing the same orders and therefore lead to simpler [[graph drawing]]s. A [[Hasse diagram]] of a partial order is a drawing of the transitive reduction in which the orientation of each edge is shown by placing the starting vertex of the edge in a lower position than its ending vertex.<ref>{{citation|title=Graphs, Networks and Algorithms|volume=5|series=Algorithms and Computation in Mathematics|first=Dieter|last=Jungnickel|publisher=Springer|year=2012|isbn=978-3-642-32278-5|pages=92–93|url=https://books.google.com/books?id=PrXxFHmchwcC&pg=PA92}}.</ref>\n\n=== Topological ordering ===\nEvery directed acyclic graph has a [[topological ordering]], an ordering of the vertices such that the starting endpoint of every edge occurs earlier in the ordering than the ending endpoint of the edge. The existence of such an ordering can be used to characterize DAGs: a directed graph is a DAG if and only if it has a topological ordering.  In general, this ordering is not unique; a DAG has a unique topological ordering if and only if it has a directed path containing all the vertices, in which case the ordering is the same as the order in which the vertices appear in the path.<ref>{{citation|title=Algorithms|first1=Robert|last1=Sedgewick|author1-link=Robert Sedgewick (computer scientist)|first2=Kevin|last2=Wayne|edition=4th|publisher=Addison-Wesley|year=2011|isbn=978-0-13-276256-4|url=https://books.google.com/books?id=idUdqdDXqnAC&pg=PA598|pages=598–599|contribution=4,2,25 Unique topological ordering}}.</ref>\n\nThe family of topological orderings of a DAG is the same as the family of [[linear extension]]s of the reachability relation for the DAG,<ref>{{citation|title=A Short Course in Discrete Mathematics|series=Dover Books on Computer Science|first1=Edward A.|last1=Bender|first2=S. Gill|last2=Williamson|publisher=Courier Dover Publications|year=2005|isbn=978-0-486-43946-4|page=142|url=https://books.google.com/books?id=iuEoAwAAQBAJ&pg=PA142|contribution=Example 26 (Linear extensions – topological sorts)}}.</ref> so any two graphs representing the same partial order have the same set of topological orders.\n\n=== Combinatorial enumeration ===\nThe [[graph enumeration]] problem of counting directed acyclic graphs was studied by {{harvtxt|Robinson|1973}}.<ref name=\"enum\">{{citation|first=R. W.|last=Robinson|contribution=Counting labeled acyclic digraphs|pages=239–273|editor-first=F.|editor-last=Harary|editor-link=Frank Harary|title=New Directions in the Theory of Graphs|publisher=Academic Press|year=1973}}. See also {{citation\n|last1 = Harary | first1 = Frank | author1-link = Frank Harary | first2 = Edgar M. | last2 = Palmer | year =  1973| title = Graphical Enumeration  | publisher = [[Academic Press]] | isbn = 0-12-324245-2 | page=19}}.</ref>\nThe number of DAGs on {{mvar|n}} labeled vertices, for {{math|1=''n''&nbsp;=&nbsp;0, 1, 2, 3, …}} (without restrictions on the order in which these numbers appear in a topological ordering of the DAG) is\n:1, 1, 3, 25, 543, 29281, 3781503, … {{OEIS|id=A003024}}.\nThese numbers may be computed by the [[recurrence relation]]\n:<math>a_n = \\sum_{k=1}^n (-1)^{k-1} {n\\choose k}2^{k(n-k)} a_{n-k}.</math><ref name=\"enum\" />\n[[Eric W. Weisstein]] conjectured,<ref>{{MathWorld | urlname=WeissteinsConjecture | title=Weisstein's Conjecture}}</ref> and {{harvtxt|McKay|Royle|Wanless|Oggier|2004}} proved, that the same numbers count the [[Logical matrix|(0,1) matrices]] for which all [[eigenvalue]]s are positive [[real number]]s. The proof is [[bijective proof|bijective]]: a matrix {{mvar|A}} is an [[adjacency matrix]] of a DAG if and only if {{math|''A''&nbsp;+&nbsp;''I''}} is a (0,1) matrix with all eigenvalues positive, where {{mvar|I}} denotes the [[identity matrix]]. Because a DAG cannot have [[Loop (graph theory)|self-loops]], its adjacency matrix must have a zero diagonal, so adding {{mvar|I}} preserves the property that all matrix coefficients are 0 or 1.<ref>{{citation|last1=McKay|first1=B. D.|author1-link=Brendan McKay|last2=Royle|first2=G. F.|author2-link=Gordon Royle|last3=Wanless|first3=I. M.|last4=Oggier|first4=F. E.|last5=Sloane|first5=N. J. A.|author5-link= Neil Sloane|last6=Wilf|first6=H.|author6-link=Herbert Wilf|title=Acyclic digraphs and eigenvalues of (0,1)-matrices|journal=[[Journal of Integer Sequences]]|volume=7|year=2004|url=http://www.cs.uwaterloo.ca/journals/JIS/VOL7/Sloane/sloane15.html}}, Article 04.3.3.</ref>\n\n=== Related families of graphs ===\n{{multiple image\n|image1=Polytree.svg|caption1=A [[polytree]], a DAG formed by [[Orientation (graph theory)|orienting]] the edges of an undirected tree\n|image2=Butterfly multitree.svg|caption2=A [[multitree]], A DAG in which each subgraph reachable from a single vertex (red) is a tree\n|width2=254<!---adjust to make both images the same height-->\n}}\nA [[polytree]] is a directed graph formed by orienting the edges of a [[tree (graph theory)|free tree]].<ref>{{citation\n | last1 = Rebane | first1 = George\n | last2 = Pearl | first2 = Judea | author2-link = Judea Pearl\n | contribution = The recovery of causal poly-trees from statistical data\n | pages = 222–228\n | title = in Proc. 3rd Annual Conference on Uncertainty in Artificial Intelligence (UAI 1987), Seattle, WA, USA, July 1987\n | url = ftp://ftp.cs.ucla.edu/tech-report/198_-reports/870031.pdf\n | year = 1987}}.</ref> Every polytree is a DAG. In particular, this is true of the [[Arborescence (graph theory)|arborescences]] formed by directing all edges outwards from the roots of a tree.\n\nA [[multitree]] (also called a strongly unambiguous graph or a mangrove) is a directed graph in which there is at most one directed path (in either direction) between any two vertices; equivalently, it is a DAG in which, for every vertex {{mvar|v}}, the subgraph reachable from {{mvar|v}} forms a tree.<ref>{{citation\n | last1 = Furnas | first1 = George W. | author1-link = George Furnas\n | last2 = Zacks | first2 = Jeff\n | contribution = Multitrees: enriching and reusing hierarchical structure\n | doi = 10.1145/191666.191778\n | pages = 330–336\n | title = Proc. SIGCHI conference on Human Factors in Computing Systems (CHI '94)\n | year = 1994}}.</ref>\n\n== Computational problems ==\n\n=== Topological sorting and recognition ===\n{{Main article|Topological sorting}}\n[[Topological sorting]] is the algorithmic problem of finding a topological ordering of a given DAG. It can be solved in [[linear time]].<ref name=\"clrs\">{{Introduction to Algorithms|edition=2}}  Section 22.4, Topological sort, pp. 549–552.</ref> Kahn's algorithm for topological sorting builds the vertex ordering directly. It maintains a list of vertices that have no incoming edges from other vertices that have not already been included in the partially constructed topological ordering; initially this list consists of the vertices with no incoming edges at all. Then, it repeatedly adds one vertex from this list to the end of the partially constructed topological ordering, and checks whether its neighbors should be added to the list. The algorithm terminates when all vertices have been processed in this way.<ref name=\"j50\" /> Alternatively, a topological ordering may be constructed by reversing a [[postorder]] numbering of a [[depth-first search]] graph traversal.<ref name=\"clrs\" />\n\nIt is also possible to check whether a given directed graph is a DAG in linear time, either by attempting to find a topological ordering and then testing for each edge whether the resulting ordering is valid<ref>For [[depth-first search]] based topological sorting algorithm, this validity check can be interleaved with the topological sorting algorithm itself; see e.g. {{citation|title=The Algorithm Design Manual|first=Steven S.|last=Skiena|publisher=Springer|year=2009|isbn=978-1-84800-070-4|pages=179–181|url=https://books.google.com/books?id=7XUSn0IKQEgC&pg=PA179}}.</ref> or alternatively, for some topological sorting algorithms, by verifying that the algorithm successfully orders all the vertices without meeting an error condition.<ref name=\"j50\">{{harvtxt|Jungnickel|2012}}, pp. 50–51.</ref>\n\n=== Construction from cyclic graphs ===\nAny undirected graph may be made into a DAG by choosing a [[total order]] for its vertices and directing every edge from the earlier endpoint in the order to the later endpoint. The resulting [[Orientation (graph theory)|orientation]] of the edges is called an [[acyclic orientation]]. Different total orders may lead to the same acyclic orientation, so an {{mvar|n}}-vertex graph can have fewer than {{math|''n''!}} acyclic orientations. The number of acyclic orientations is equal to {{math|{{!}}''χ''(−1){{!}}}}, where {{mvar|χ}} is the [[chromatic polynomial]] of the given graph.<ref>{{citation|first=Richard P.|last=Stanley|authorlink=Richard P. Stanley|title=Acyclic orientations of graphs|journal=Discrete Mathematics|volume=5|issue=2 |pages=171–178|year= 1973|doi=10.1016/0012-365X(73)90108-8}}.</ref>\n\n[[File:Graph Condensation.svg|thumb|upright=1.5|The yellow directed acyclic graph is the [[Condensation (graph theory)|condensation]] of the blue directed graph. It is formed by [[Edge contraction|contracting]] each [[strongly connected component]] of the blue graph into a single yellow vertex.]]\nAny directed graph may be made into a DAG by removing a [[feedback vertex set]] or a [[feedback arc set]], a set of vertices or edges (respectively) that touches all cycles. However, the smallest such set is [[NP-hard]] to find.<ref>{{Garey-Johnson}}, Problems GT7 and GT8, pp.&nbsp;191–192.</ref> An arbitrary directed graph may also be transformed into a DAG, called its [[condensation (graph theory)|condensation]], by [[Edge contraction|contracting]] each of its [[strongly connected component]]s into a single supervertex.<ref>{{citation|title=Structural Models: An Introduction to the Theory of Directed Graphs|last1=Harary|first1=Frank|author1-link=Frank Harary|last2=Norman|first2=Robert Z.|last3=Cartwright|first3=Dorwin|publisher=John Wiley & Sons|year=1965|page=63}}.</ref> When the graph is already acyclic, its smallest feedback vertex sets and feedback arc sets are [[empty set|empty]], and its condensation is the graph itself.\n\n=== Transitive closure and transitive reduction ===\nThe transitive closure of a given DAG, with {{mvar|n}} vertices and {{mvar|m}} edges, may be constructed in time {{math|''O''(''mn'')}} by using either [[breadth-first search]] or [[depth-first search]] to test reachability from each vertex.<ref>{{harvtxt|Skiena|2009}}, p. 495.</ref> Alternatively, it can be solved in time {{math|''O''(''n''<sup>''ω''</sup>)}} where {{math|''ω''&nbsp;<&nbsp;2.373}} is the exponent for [[Coppersmith–Winograd algorithm|fast matrix multiplication algorithms]]; this is a theoretical improvement over the {{math|''O''(''mn'')}} bound for [[dense graph]]s.<ref>{{harvtxt|Skiena|2009}}, p. 496.</ref>\n\nIn all of these transitive closure algorithms, it is possible to distinguish pairs of vertices that are reachable by at least one path of length two or more from pairs that can only be connected by a length-one path. The transitive reduction consists of the edges that form length-one paths that are the only paths connecting their endpoints. Therefore, the transitive reduction can be constructed in the same asymptotic time bounds as the transitive closure.<ref>{{harvtxt|Bang-Jensen|Gutin|2008}}, p. 38.</ref>\n\n=== Closure problem ===\n{{Main article|Closure problem}}\nThe [[closure problem]] takes as input a directed acyclic graph with weights on its vertices and seeks the minimum (or maximum) weight of a closure, a set of vertices with no outgoing edges. (The problem may be formulated for directed graphs without the assumption of acyclicity, but with no greater generality, because in this case it is equivalent to the same problem on the condensation of the graph.) It may be solved in polynomial time using a reduction to the [[maximum flow problem]].<ref>{{citation\n | last = Picard | first = Jean-Claude\n | doi = 10.1287/mnsc.22.11.1268\n | issue = 11\n | journal = [[Management Science (journal)|Management Science]]\n | mr = 0403596\n | pages = 1268–1272\n | title = Maximal closure of a graph and applications to combinatorial problems\n | volume = 22\n | year = 1976}}.</ref>\n\n=== Path algorithms ===\nSome algorithms become simpler when used on DAGs instead of general graphs, based on the principle of topological ordering. For example, it is possible to find [[shortest path]]s and [[longest path problem|longest paths]] from a given starting vertex in DAGs in linear time by processing the vertices in a topological order, and calculating the path length for each vertex to be the minimum or maximum length obtained via any of its incoming edges.<ref>Cormen et al. 2001, Section 24.2, Single-source shortest paths in directed acyclic graphs, pp. 592–595.</ref> In contrast, for arbitrary graphs the shortest path may require slower algorithms such as [[Dijkstra's algorithm]] or the [[Bellman–Ford algorithm]],<ref>Cormen et al. 2001, Sections 24.1, The Bellman–Ford algorithm, pp. 588–592, and 24.3, Dijkstra's algorithm, pp. 595–601.</ref> and longest paths in arbitrary graphs are [[NP-hard]] to find.<ref>Cormen et al. 2001, p. 966.</ref>\n\n== Applications ==\n\n=== Scheduling ===\nDirected acyclic graphs representations of partial orderings have many applications in [[Schedule|scheduling]] for systems of tasks with ordering constraints.<ref>{{harvtxt|Skiena|2009}}, p. 469.</ref>\nAn important class of problems of this type concern collections of objects that need to be updated, such as the cells of a [[spreadsheet]] after one of the cells has been changed, or the [[object file]]s of a piece of computer software after its [[source code]] has been changed.\nIn this context, a [[dependency graph]] is a graph that has a vertex for each object to be updated, and an edge connecting two objects whenever one of them needs to be updated earlier than the other. A cycle in this graph is called a [[circular dependency]], and is generally not allowed, because there would be no way to consistently schedule the tasks involved in the cycle.\nDependency graphs without circular dependencies form DAGs.<ref>{{citation | last1=Al-Mutawa | first1=H. A. | last2=Dietrich | first2=J. | last3=Marsland | first3=S. | last4=McCartin | first4=C. | contribution=On the shape of circular dependencies in Java programs | doi=10.1109/ASWEC.2014.15 | pages=48–57 | publisher=IEEE | title=23rd Australian Software Engineering Conference | year=2014}}.</ref>\n\nFor instance, when one cell of a [[spreadsheet]] changes, it is necessary to recalculate the values of other cells that depend directly or indirectly on the changed cell. For this problem, the tasks to be scheduled are the recalculations of the values of individual cells of the spreadsheet. Dependencies arise when an expression in one cell uses a value from another cell. In such a case, the value that is used must be recalculated earlier than the expression that uses it. Topologically ordering the dependency graph, and using this topological order to schedule the cell updates, allows the whole spreadsheet to be updated with only a single evaluation per cell.<ref name=\"hgt1181\">{{citation |title=Handbook of Graph Theory |first1=Jonathan L. |last1=Gross |first2=Jay |last2=Yellen |first3=Ping |last3=Zhang |edition=2nd |publisher=CRC Press |year=2013 |isbn=978-1-4398-8018-0 |page=1181 |url=https://books.google.com/books?id=cntcAgAAQBAJ&pg=PA1181}}.</ref> Similar problems of task ordering arise in [[makefile]]s for program compilation<ref name=\"hgt1181\" /> and [[instruction scheduling]] for low-level computer program optimization.<ref>{{citation |title=The Compiler Design Handbook: Optimizations and Machine Code Generation |first1=Y. N. |last1=Srikant |first2=Priti |last2=Shankar |edition=2nd |publisher=CRC Press|year=2007 |isbn=978-1-4200-4383-9 |pages=19–39 |url=https://books.google.com/books?id=1kqAv-uDEPEC&pg=SA19-PA39}}.</ref>\n\n[[File:Pert chart colored.svg|thumb|PERT chart for a project with five milestones (labeled 10–50) and six tasks (labeled A–F). There are two critical paths, ADF and BC.]]\nA somewhat different DAG-based formulation of scheduling constraints is used by the [[program evaluation and review technique]] (PERT), a method for management of large human projects that was one of the first applications of DAGs. In this method, the vertices of a DAG represent [[Milestone (project management)|milestones]] of a project rather than specific tasks to be performed. Instead, a task or activity is represented by an edge of a DAG, connecting two milestones that mark the beginning and completion of the task. Each such edge is labeled with an estimate for the amount of time that it will take a team of workers to perform the task. The [[Longest path problem|longest path]] in this DAG represents the [[Critical path method|critical path]] of the project, the one that controls the total time for the project. Individual milestones can be scheduled according to the lengths of the longest paths ending at their vertices.<ref>{{citation |title=What Every Engineer Should Know About Decision Making Under Uncertainty |first=John X. |last=Wang |publisher=CRC Press |year=2002 |isbn=978-0-8247-4373-4 |page=160 |url=https://books.google.com/books?id=C3yKML0dUVIC&pg=PA160}}.</ref>\n\n=== Data processing networks ===\nA directed acyclic graph may be used to represent a network of processing elements. In this representation, data enters a processing element through its incoming edges and leaves the element through its outgoing edges.\n\nFor instance, in electronic circuit design, static [[combinational logic]] blocks can be represented as an acyclic system of [[logic gate]]s that computes a function of an input, where the input and output of the function are represented as individual [[bit]]s. In general, the output of these blocks cannot be used as the input unless it is captured by a register or state element which maintains its acyclic properties.<ref>{{citation|title=Timing|first=Sachin|last=Sapatnekar|publisher=Springer|year=2004|isbn=978-1-4020-7671-8|page=133|url=https://books.google.com/books?id=fL9k-VkZVr0C&pg=PA133}}.</ref>  Electronic circuit schematics either on paper or in a database are a form of directed acyclic graphs using instances or components to form a directed reference to a lower level component.  Electronic circuits themselves are not necessarily acyclic or directed.\n\n[[Dataflow programming]] languages describe systems of operations on [[data stream]]s, and the connections between the outputs of some operations and the inputs of others. These languages can be convenient for describing repetitive data processing tasks, in which the same acyclically-connected collection of operations is applied to many data items. They can be executed as a [[parallel algorithm]] in which each operation is performed by a parallel process as soon as another set of inputs becomes available to it.<ref>{{citation|title=Programming Symposium|series=Lecture Notes in Computer Science|volume=19|year=1974|pages=362–376|contribution=First version of a data flow procedure language|first=Jack B.|last=Dennis|doi=10.1007/3-540-06859-7_145}}.</ref>\n\nIn [[compiler]]s, straight line code (that is, sequences of statements without loops or conditional branches) may be represented by a DAG describing the inputs and outputs of each of the arithmetic operations performed within the code. This representation allows the compiler to perform [[common subexpression elimination]] efficiently.<ref>{{citation|title=Advanced Backend Optimization|first1=Sid|last1=Touati|first2=Benoit|last2=de Dinechin|publisher=John Wiley & Sons|year=2014|isbn=978-1-118-64894-0|page=123|url=https://books.google.com/books?id=nO2-AwAAQBAJ&pg=PA123}}.</ref> At a higher level of code organization, the [[acyclic dependencies principle]] states that the dependencies between modules or components of a large software system should form a directed acyclic graph.<ref>{{citation|title=Large-Scale Software Architecture: A Practical Guide using UML|first1=Jeff|last1=Garland|first2=Richard|last2=Anthony|publisher=John Wiley & Sons|year=2003|isbn=9780470856383|page=215|url=https://books.google.com/books?id=_2oQLLSqZ88C&pg=PA215}}.</ref>\n\n=== Causal structures ===\n{{main article|Bayesian network}}\nGraphs in which vertices represent events occurring at a definite time, and where the edges are always point from the early time vertex to a late time vertex of the edge, are necessarily directed and acyclic. The lack of a cycle follows because the time associated with a vertex always increases as you follow any [[Path (graph theory)|path]] in the graph so you can never return to a vertex on a path.  This reflects our natural intuition that causality means events can only affect the future, they never affect the past, and thus we have no [[causal loop]]s. An example of this type of directed acyclic graph are those encountered in the [[Causal sets|causal set approach to quantum gravity]] though in this case the graphs considered are [[#Transitive closure and transitive reduction|transitively complete]]. The version history example, each version of the software is associated with a unique time, typically the time the version was saved, committed or released. For citation graphs, the documents are published at one time and can only refer to older documents.\n\nSometimes events are not associated with a specific physical time.  Provided that pairs of events have a purely causal relationship, that is edges represent [[causality|causal relations]] between the events, we will have a directed acyclic graph.<ref>{{citation|title=Causal Learning|first1=Alison|last1=Gopnik|first2=Laura|last2=Schulz|publisher=Oxford University Press|year=2007|isbn=978-0-19-803928-0|page=4|url=https://books.google.com/books?id=35MKXlKoXIUC&pg=PA4}}.</ref> For instance, a [[Bayesian network]] represents a system of probabilistic events as vertices in a directed acyclic graph, in which the likelihood of an event may be calculated from the likelihoods of its predecessors in the DAG.<ref>{{citation|title=Probabilistic Boolean Networks: The Modeling and Control of Gene Regulatory Networks|publisher=Society for Industrial and Applied Mathematics|first1=Ilya|last1=Shmulevich|first2=Edward R.|last2=Dougherty|year=2010|isbn=978-0-89871-692-4|page=58|url=https://books.google.com/books?id=RfshqEgO7KgC&pg=PA58}}.</ref> In this context, the [[moral graph]] of a DAG is the undirected graph created by adding an (undirected) edge between all parents of the same vertex (sometimes called ''marrying''), and then replacing all directed edges by undirected edges.<ref>{{citation |last1= Cowell |first1= Robert G. |author2-link=Philip Dawid|last2=Dawid|first2=A. Philip|author3-link=Steffen Lauritzen|last3=Lauritzen|first3=Steffen L.|author4-link=David Spiegelhalter|last4=Spiegelhalter|first4=David J.|title= Probabilistic Networks and Expert Systems |publisher= Springer |year= 1999 |isbn= 0-387-98767-3 |chapter= 3.2.1 Moralization|pages= 31–33 }}.</ref> Another type of graph with a similar causal structure is an [[influence diagram]], the vertices of which represent either decisions to be made or unknown information, and the edges of which represent causal influences from one vertex to another.<ref>{{citation|title=The Technology Management Handbook|first=Richard C.|last=Dorf|publisher=CRC Press|year=1998|isbn=978-0-8493-8577-3|page=9{{hyphen}}7<!-- Do not conver this hyphen into a dash! It is a section-page number, not a range of page numbers. -->|url=https://books.google.com/books?id=C2u8I0DFo4IC&pg=SA9-PA7}}.</ref> In [[epidemiology]], for instance, these diagrams are often used to estimate the expected value of different choices for intervention.<ref>{{citation|title=Encyclopedia of Epidemiology, Volume 1|first=Sarah|last=Boslaugh|publisher=SAGE|year=2008|isbn=978-1-4129-2816-8|page=255|url=https://books.google.com/books?id=wObgnN3x14kC&pg=PA255}}.</ref><ref name=\"pearl:95\">{{citation | last = Pearl | first = Judea | doi = 10.1093/biomet/82.4.669 | issue = 4 | journal = Biometrika | pages = 669–709 | title = Causal diagrams for empirical research | volume = 82 | year = 1995}}.</ref>\n\nThe converse is also true.  That is in any application represented by a directed acyclic graph there is a causal structure, either an explicit order or time in the example or an order can be derived from the which can be derived from graph structure. This follows because all directed acyclic graphs have a [[#Topological ordering|topological ordering]], i.e. there is at least one way to put the vertices in an order such that all edges point in the same direction along that order.\n\n=== Genealogy and version history ===\n[[File:EgyptianPtolemies.png|thumb|upright=1.5|Family tree of the [[Ptolemaic dynasty]], with many marriages between [[Consanguinity|close relatives]] causing [[pedigree collapse]]]]\n[[Family tree]]s may be seen as directed acyclic graphs, with a vertex for each family member and an edge for each parent-child relationship.<ref>{{citation|journal=Algorithms for Molecular Biology|date=April 2011|volume=6|issue=10|title=Haplotypes versus genotypes on pedigrees|first=Bonnie B.|last=Kirkpatrick|doi=10.1186/1748-7188-6-10|pmc=3102622|pmid=21504603}}.</ref> Despite the name, these graphs are not necessarily trees because of the possibility of marriages between relatives (so a child has a common ancestor on both the mother's and father's side) causing [[pedigree collapse]].<ref>{{citation\n | last1 = McGuffin | first1 = M. J.\n | last2 = Balakrishnan | first2 = R.\n | contribution = Interactive visualization of genealogical graphs\n | contribution-url = http://profs.etsmtl.ca/mMcGuffin/research/genealogyVis/genealogyVis.pdf\n | doi = 10.1109/INFVIS.2005.1532124\n | pages = 16–23\n | title = IEEE Symposium on Information Visualization (INFOVIS 2005)\n | year = 2005}}.</ref> The graphs of [[matrilineal]] descent (\"mother\" relationships between women) and [[patrilineal]] descent (\"father\" relationships between men) are trees within this graph.  Because\nno one can become their own ancestor, family trees are acyclic.<ref>{{citation\n | last1 = Bender | first1 = Michael A.\n | last2 = Pemmasani | first2 = Giridhar\n | last3 = Skiena | first3 = Steven\n | last4 = Sumazin | first4 = Pavel\n | contribution = Finding least common ancestors in directed acyclic graphs\n | contribution-url = http://dl.acm.org/citation.cfm?id=365411.365795\n | isbn = 0-89871-490-7\n | location = Philadelphia, PA, USA\n | pages = 845–854\n | publisher = Society for Industrial and Applied Mathematics\n | title = Proceedings of the Twelfth Annual ACM-SIAM Symposium on Discrete Algorithms (SODA '01)\n | year = 2001}}.</ref>\n\nFor the same reason, the version history of a [[distributed revision control]] system generally has the structure of a directed acyclic graph, in which there is a vertex for each revision and an edge connecting pairs of revisions that were directly derived from each other. These are not trees in general due to merges.<ref>{{citation|title=Architecture and Methods for Flexible Content Management in Peer-to-Peer Systems|first=Udo|last=Bartlang|publisher=Springer|year=2010|isbn=978-3-8348-9645-2|page=59|url=https://books.google.com/books?id=vXdEAAAAQBAJ&pg=PA59}}.</ref>\n\nIn many [[randomization|randomized]] [[algorithm]]s in [[computational geometry]], the algorithm maintains a ''history DAG'' representing the version history of a geometric structure over the course of a sequence of changes to the structure. For instance in a [[Randomized algorithm#Randomized incremental constructions in geometry|randomized incremental]] algorithm for [[Delaunay triangulation]], the triangulation changes by replacing one triangle by three smaller triangles when each point is added, and by \"flip\" operations that replace pairs of triangles by a different pair of triangles. The history DAG for this algorithm has a vertex for each triangle constructed as part of the algorithm, and edges from each triangle to the two or three other triangles that replace it. This structure allows [[point location]] queries to be answered efficiently: to find the location of a query point {{mvar|q}} in the Delaunay triangulation, follow a path in the history DAG, at each step moving to the replacement triangle that contains {{mvar|q}}. The final triangle reached in this path must be the Delaunay triangle that contains {{mvar|q}}.<ref>{{citation|title=Combinatorial Geometry and Its Algorithmic Applications: The Alcalá Lectures|volume=152|series=Mathematical surveys and monographs|first1=János|last1=Pach|author1-link=János Pach|first2=Micha|last2=Sharir|author2-link=Micha Sharir|publisher=American Mathematical Society|isbn=978-0-8218-7533-9|pages=93–94|url=https://books.google.com/books?id=-fguzNaYoqcC&pg=PA93}}.</ref>\n\n=== Citation graphs ===\nIn a [[citation graph]] the vertices are documents with a single publication date. The edges represent the citations from the bibliography of one document to other necessarily earlier documents. The classic example comes from the citations between academic papers as pointed out in the 1965 article \"Networks of Scientific Papers\"<ref>{{citation | last = Price | first = Derek J. de Solla | date = July 30, 1965 | doi = 10.1126/science.149.3683.510 | issue = 3683 | journal = [[Science (journal)|Science]] | pages = 510–515 | pmid = 14325149 | title = Networks of Scientific Papers | url = http://garfield.library.upenn.edu/papers/pricenetworks1965.pdf | volume = 149}}.</ref> by [[Derek J. de Solla Price]].  In this case the [[Citation impact|citation count]] of a paper is just the in-degree of the corresponding vertex of the citation network. This is an important measure in [[citation analysis]]. [[Judgment (law)|Court judgements]] provide another example as judges support their conclusions in one case by recalling other earlier decisions made in previous cases. A final example is provided by patents which must refer to earlier [[prior art]], earlier patents which are relevant to the current patent claim. By taking the special properties of directed acyclic graphs into account, one can analyse these graphs with techniques not available when analysing the general graphs considered in many studies in [[Network Science|network analysis]]. For instance [[#Transitive closure and transitive reduction|transitive reduction]] gives a new insights into the citation distributions found in different applications highlighting clear differences in the mechanisms creating citations networks in different contexts.<ref>{{citation | last1 = Clough | first1 = James R. | last2 = Gollings | first2 = Jamie | last3 = Loach | first3 = Tamar V. | last4 = Evans | first4 = Tim S. | doi = 10.1093/comnet/cnu039 | issue = 2 | journal = Journal of Complex Networks | pages = 189–203 | title = Transitive reduction of citation networks | volume = 3}}.</ref> Another technique is [[main path analysis]], which traces the citation links and suggests the most significant citation chains in a given [[citation graph]].\n\n=== Data compression ===\nDirected acyclic graphs may also be used as a [[data compression|compact representation]] of a collection of sequences. In this type of application, one finds a DAG in which the paths form the given sequences. When many of the sequences share the same subsequences, these shared subsequences can be represented by a shared part of the DAG, allowing the representation to use less space than it would take to list out all of the sequences separately. For example, the [[Deterministic acyclic finite state automaton|directed acyclic word graph]] is a [[data structure]] in computer science formed by a directed acyclic graph with a single source and with edges labeled by letters or symbols; the paths from the source to the sinks in this graph represent a set of [[String (computer science)|strings]], such as English words.<ref>{{citation | first1=Maxime | last1=Crochemore | first2=Renaud | last2=Vérin | contribution=Direct construction of compact directed acyclic word graphs | series=Lecture Notes in Computer Science | publisher=Springer | title=Combinatorial Pattern Matching | year=1997 | pages=116–129 | doi=10.1007/3-540-63220-4_55 }}.</ref> Any set of sequences can be represented as paths in a tree, by forming a tree vertex for every prefix of a sequence and making the parent of one of these vertices represent the sequence with one fewer element; the tree formed in this way for a set of strings is called a [[trie]]. A directed acyclic word graph saves space over a trie by allowing paths to diverge and rejoin, so that a set of words with the same possible suffixes can be represented by a single tree vertex.<ref>{{citation|title=Applied Combinatorics on Words|volume=105|series=Encyclopedia of Mathematics and its Applications|first=M.|last=Lothaire|authorlink=M. Lothaire|publisher=Cambridge University Press|year=2005|isbn=9780521848022|page=18|url=https://books.google.com/books?id=fpLUNkj1T1EC&pg=PA18}}.</ref>\n\nThe same idea of using a DAG to represent a family of paths occurs in the [[binary decision diagram]],<ref>{{citation|first=C. Y.|last=Lee|title=Representation of switching circuits by binary-decision programs|journal=Bell System Technical Journal|volume=38|pages=985–999|year=1959|doi=10.1002/j.1538-7305.1959.tb01585.x}}.</ref><ref>{{citation|first=Sheldon B.|last=Akers|doi=10.1109/TC.1978.1675141|title=Binary decision diagrams|journal=IEEE Transactions on Computers|volume=C-27|issue=6|pages=509–516|year=1978}}.</ref> a DAG-based data structure for representing binary functions. In a binary decision diagram, each non-sink vertex is labeled by the name of a binary variable, and each sink and each edge is labeled by a 0 or 1. The function value for any [[truth assignment]] to the variables is the value at the sink found by following a path, starting from the single source vertex, that at each non-sink vertex follows the outgoing edge labeled with the value of that vertex's variable. Just as directed acyclic word graphs can be viewed as a compressed form of tries, binary decision diagrams can be viewed as compressed forms of [[decision tree]]s that save space by allowing paths to rejoin when they agree on the results of all remaining decisions.<ref>{{citation\n | last1 = Friedman | first1 = S. J.\n | last2 = Supowit | first2 = K. J.\n | contribution = Finding the optimal variable ordering for binary decision diagrams\n | doi = 10.1145/37888.37941\n | isbn = 0-8186-0781-5\n | location = New York, NY, USA\n | pages = 348–356\n | publisher = ACM\n | title = Proc. 24th ACM/IEEE Design Automation Conference (DAC '87)\n | year = 1987}}.</ref>\n\n== References ==\n{{reflist|30em}}\n\n== External links ==\n{{commons category|directed acyclic graphs}}\n* {{MathWorld | urlname=AcyclicDigraph | title=Acyclic Digraph}}\n\n[[Category:Directed graphs]]\n\n[[de:Graph_(Graphentheorie)#Teilgraphen.2C_Wege_und_Zyklen]]",
            "slug": "directed-acyclic-graph",
            "date_updated": 1518062087644,
            "imported": "https://en.wikipedia.org/wiki/Directed_acyclic_graph"
        }
    ]
}