{
    "article": [
        {
            "title": "Mutual exclusion",
            "text": "{{For|the concept in logic and probability theory|Mutual exclusivity}}\n[[File:Mutual exclusion example with linked list.png|thumb|Two nodes, ''i'' and ''i'' + 1, being removed simultaneously results in node ''i'' + 1 not being removed.]]\nIn [[computer science]], '''mutual exclusion''' is a property of [[concurrency control]], which is instituted for the purpose of preventing [[race condition]]s; it is the requirement that one [[thread (computing)|thread of execution]] never enter its [[critical section]] at the same time that another [[Concurrent computing|concurrent]] thread of execution enters its own critical section.{{efn|Here, ''critical section'' refers to an interval of time during which a thread of execution accesses a shared resource, such as [[Shared memory (interprocess communication)|shared memory]].}}\n\nThe requirement of mutual exclusion was first identified and solved by [[Edsger W. Dijkstra]] in his seminal 1965 paper titled ''Solution of a problem in concurrent programming control'',<ref>{{cite journal|last=Dijkstra|first=E. W.|title=Solution of a problem in concurrent programming control|journal=Communications of the ACM|volume=8|issue=9|pages=569|doi=10.1145/365559.365617|year=1965}}</ref><ref name=\"Taubenfeld:2004\">Taubenfeld, [http://www.cs.tau.ac.il/~afek/gadi.pdf The Black-White Bakery Algorithm]. In Proc. Distributed Computing, 18th international conference, DISC 2004. Vol 18, 56-70, 2004</ref> which is credited as the first topic in the study of [[concurrent algorithm]]s.<ref>{{Citation | url=http://www.podc.org/influential/2002.html | title=PODC Influential Paper Award: 2002 | work=ACM Symposium on Principles of Distributed Computing | accessdate=2009-08-24}}</ref>\n\nA simple example of why mutual exclusion is important in practice can be visualized using a [[singly linked list]] of four items, where the second and third are to be removed. The removal of a node that sits between 2 other nodes is performed by changing the ''next'' pointer of the previous node to point to the next node (in other words, if node ''i'' is being removed, then the ''next'' pointer of node ''i'' − 1 is changed to point to node ''i'' + 1, thereby removing from the linked list any reference to node ''i''). When such a linked list is being shared between multiple threads of execution, two threads of execution may attempt to remove two different nodes simultaneously, one thread of execution changing the ''next'' pointer of node ''i'' − 1 to point to node ''i'' + 1, while another thread of execution changes the ''next'' pointer of node ''i'' to point to node ''i'' + 2. Although both removal operations complete successfully, the desired state of the linked list is not achieved: node ''i'' + 1 remains in the list, because the ''next'' pointer of node ''i'' − 1 points to node ''i'' + 1.\n\nThis problem (called a ''race condition'') can be avoided by using the requirement of mutual exclusion to ensure that simultaneous updates to the same part of the list cannot occur.\n\nThe term mutual exclusion is also used in reference to the simultaneous writing of a memory address by one thread while the aforementioned memory address is being manipulated or read by another thread or other threads.\n\n==Problem description==\n\nThe problem which mutual exclusion addresses is a problem of resource sharing: how can a software system control multiple processes' access to a shared resource, when each process needs exclusive control of that resource while doing its work? The mutual-exclusion solution to this makes the shared resource available only while the process is in a specific code segment called the [[critical section]]. It controls access to the shared resource by controlling each mutual execution of that part of its program where the resource would be used.\n\nA successful solution to this problem must have at least these two properties:\n* It must implement ''mutual exclusion'': only one process can be in the critical section at a time.\n* It must be free of ''[[deadlock|deadlocks]]'': if processes are trying to enter the critical section, one of them must eventually be able to do so successfully, provided no process stays in the critical section permanently.\n\nDeadlock freedom can be expanded to implement one or both of these properties:\n* ''Lockout-freedom'' guarantees that any process wishing to enter the critical section will be able to do so eventually. This is distinct from deadlock avoidance, which requires that ''some'' waiting process be able to get access to the critical section, but does not require that every process gets a turn. If two processes continually trade a resource between them, a third process could be locked out and experience [[starvation (computer science)|resource starvation]], even though the system is not in deadlock. If a system is free of lockouts, it ensures that every process can get a turn at some point in the future.\n* A ''k-bounded waiting property'' gives a more precise commitment than lockout-freedom. Lockout-freedom ensures every process can access the critical section eventually: it gives no guarantee about how long the wait will be. In practice, a process could be overtaken an arbitrary or unbounded number of times by other higher-priority processes before it gets its turn. Under a ''k''-bounded waiting property, each process has a finite maximum wait time. This works by setting a limit to the number of times other processes can cut in line, so that no process can enter the critical section more than ''k'' times while another is waiting.<ref name=\"Distributed computing: fundamentals, simulations, and advanced topics\">{{cite book|last1=Attiya|first1=Hagit|last2=Welch|first2=Jennifer|title=Distributed computing: fundamentals, simulations, and advanced topics|date=Mar 25, 2004|publisher=John Wiley & Sons, Inc.|isbn=978-0-471-45324-6|url=http://ca.wiley.com/WileyCDA/WileyTitle/productCd-0471453242.html}}</ref>\n\nEvery process' program can be partitioned into four sections, resulting in four states. Program execution cycles through these four states in order:<ref>{{Citation | url=http://research.microsoft.com/en-us/um/people/lamport/pubs/mutual2.pdf | last=Lamport | first=Leslie | title = The Mutual Exclusion Problem Part II: Statement and Solutions |date = June 26, 2000}}</ref>\n[[File:State graph.png|thumb|the cycle of sections of a single process]]\n\n;Non-Critical Section: Operation is outside the critical section; the process is not using or requesting the shared resource.\n\n;Trying: The process attempts to enter the critical section.\n\n;Critical Section: The process is allowed to access the shared resource in this section.\n\n;Exit: The process leaves the critical section and makes the shared resource available to other processes.\n\nIf a process wishes to enter the critical section, it must first execute the trying section and wait until it acquires access to the critical section. After the process has executed its critical section and is finished with the shared resources, it needs to execute the exit section to release them for other processes' use. The process then returns to its non-critical section.\n\n==Enforcing mutual exclusion==\nThere are both software and hardware solutions for enforcing mutual exclusion. Some different solutions are discussed below.\n\n===Hardware solutions===\nOn [[uniprocessor]] systems, the simplest solution to achieve mutual exclusion is to disable [[interrupt]]s during a process's critical section. This will prevent any [[interrupt service routine]]s from running (effectively preventing a process from being [[Preemption (computing)|preempted]]). Although this solution is effective, it leads to many problems. If a critical section is long, then the [[system clock]] will drift every time a critical section is executed because the timer interrupt is no longer serviced, so tracking time is impossible during the critical section. Also, if a process halts during its critical section, control will never be returned to another process, effectively halting the entire system. A more elegant method for achieving mutual exclusion is the [[busy-wait]].\n\nBusy-waiting is effective for both uniprocessor and [[multiprocessor]] systems. The use of shared memory and an [[Linearizability|atomic]] [[test-and-set]] instruction provide the mutual exclusion. A process can test-and-set on a location in shared memory, and since the operation is atomic, only one process can set the flag at a time. Any process that is unsuccessful in setting the flag can either go on to do other tasks and try again later, release the processor to another process and try again later, or continue to loop while checking the flag until it is successful in acquiring it. [[Preemption (computing)|Preemption]] is still possible, so this method allows the system to continue to function—even if a process halts while holding the lock.\n\nSeveral other atomic operations can be used to provide mutual exclusion of data structures; most notable of these is [[compare-and-swap]] (CAS). CAS can be used to achieve [[wait-free]] mutual exclusion for any shared data structure by creating a linked list where each node represents the desired operation to be performed. CAS is then used to change the pointers in the linked list<ref>https://timharris.uk/papers/2001-disc.pdf</ref> during the insertion of a new node. Only one process can be successful in its CAS; all other processes attempting to add a node at the same time will have to try again. Each process can then keep a local copy of the data structure, and upon traversing the linked list, can perform each operation from the list on its local copy.\n\n===Software solutions===\nBeside hardware-supported solutions, some software solutions exist that use [[busy waiting]] to achieve mutual exclusion. Examples of these include the following:\n* [[Dekker's algorithm]];\n* [[Peterson's algorithm]];\n* [[Lamport's bakery algorithm]];<ref>{{cite journal|last=Lamport|first=Leslie|title=A new solution of Dijkstra's concurrent programming problem|journal=Communications of the ACM|date=August 1974|volume=17|issue=8|pages=453–455|doi=10.1145/361082.361093}}</ref>\n* [[Szymanski's algorithm]];\n* Taubenfeld's black-white bakery algorithm.<ref name=\"Taubenfeld:2004\" />\n\nThese algorithms do not work if [[out-of-order execution]] is used on the platform that executes them. Programmers have to specify strict ordering on the memory operations within a thread.<ref>{{cite journal|last=Holzmann|first=Gerard J.|author2=Bosnacki, Dragan|title=The Design of a Multicore Extension of the SPIN Model Checker|journal=IEEE Transactions on Software Engineering|date=1 October 2007|volume=33|issue=10|pages=659–674|doi=10.1109/TSE.2007.70724}}</ref>\n\nIt is often preferable to use synchronization facilities provided by an operating system's multithreading library, which will take advantage of hardware solutions if possible but will use software solutions if no hardware solutions exist. For example, when the operating system's [[lock (computer science)|lock]] library is used and a thread tries to acquire an already acquired lock, the operating system could suspend the thread using a [[context switch]] and swap it out with another thread that is ready to be run, or could put that processor into a low power state if there is no other thread that can be run. Therefore, most modern mutual exclusion methods attempt to reduce [[Latency (engineering)|latency]] and busy-waits by using queuing and context switches. However, if the time that is spent suspending a thread and then restoring it can be proven to be always more than the time that must be waited for a thread to become ready to run after being blocked in a particular situation, then [[spinlock]]s are an acceptable solution (for that situation only).{{citation needed|date=August 2015}}\n\n==Bound on the mutual exclusion problem==\n\nOne binary test&set register is sufficient to provide the deadlock-free solution to the mutual exclusion problem. But a solution built with a test&set register can possibly lead to the starvation of some processes which become caught in the trying section.<ref name=\"Distributed computing: fundamentals, simulations, and advanced topics\"/> In fact, <math>\\Omega(\\sqrt{n})</math> distinct memory states are required to avoid lockout. To avoid unbounded waiting, ''n'' distinct memory states are required.<ref>{{Citation | url=http://research.microsoft.com/en-us/um/people/lamport/pubs/mutual2.pdf | last=Burns |first=James E. |author2 = Paul Jackson, Nancy A. Lynch| title =Data Requirements for Implementation of N-Process Mutual Exclusion Using a Single Shared Variable  |date = January 1982}}</ref>\n\n==Recoverable mutual exclusion==\nMost algorithms for mutual exclusion are designed with the assumption that no failure occurs while a process is running inside the critical section. However, in reality such failures may be commonplace. For example, a sudden loss of power or faulty interconnect might cause a process in a critical section to experience an unrecoverable error or otherwise be unable to continue. If such a failure occurs, conventional, non-failure-tolerant mutual exclusion algorithms may deadlock or otherwise fail key liveness properties. To deal with this problem, several solutions using crash-recovery mechanisms have been proposed.<ref>{{Citation | url=http://dl.acm.org/citation.cfm?doid=2933057.2933087 | last=Golab|first=Wojciech|author2=Ramaraju, Aditya |title = Recoverable Mutual Exclusion|date = July 2016}}</ref>\n\n==Types of mutual exclusion devices==\nThe solutions explained above can be used to build the synchronization primitives below:\n* [[Lock (computer science)|locks]] (mutexes);\n* [[readers–writer lock]]s;\n* [[Reentrant mutex|recursive lock]]s;\n* [[Semaphore (programming)|semaphores]];\n* [[Monitor (synchronization)|monitors]];\n* [[message passing]];\n* [[tuple space]].\n\nMany forms of mutual exclusion have side-effects. For example, classic [[semaphore (programming)|semaphores]] permit [[deadlock]]s, in which one process gets a semaphore, another process gets a second semaphore, and then both wait till the other semaphore to be released. Other common side-effects include [[Resource starvation|starvation]], in which a process never gets sufficient resources to run to completion; [[priority inversion]], in which a higher priority thread waits for a lower-priority thread; and high latency, in which response to interrupts is not prompt.\n\nMuch research is aimed at eliminating the above effects, often with the goal of guaranteeing [[Non-blocking synchronization|non-blocking progress]]. No perfect scheme is known. Blocking system calls used to sleep an entire process. Until such calls became [[Thread safety|threadsafe]], there was no proper mechanism for sleeping a single thread within a process (see [[polling (computer science)|polling]]).{{citation needed|date=May 2016}}\n\n==See also==\n* [[Atomicity (programming)]]\n* [[Concurrency control]]\n* [[Exclusive or]]\n* [[Mutually exclusive events]]\n* [[Semaphore (programming)|Semaphore]]\n* [[Dining philosophers problem]]\n* [[Reentrant mutex]]\n* [[Spinlock]]\n\n==Notes==\n{{notelist}}\n\n== References ==\n{{reflist}}\n\n==Further reading==\n* Michel Raynal: ''Algorithms for Mutual Exclusion'', MIT Press, {{ISBN|0-262-18119-3}}\n* Sunil R. Das, Pradip K. Srimani: ''Distributed Mutual Exclusion Algorithms'', IEEE Computer Society, {{ISBN|0-8186-3380-8}}\n* Thomas W. Christopher, George K. Thiruvathukal: ''High-Performance Java Platform Computing'', Prentice Hall, {{ISBN|0-13-016164-0}}\n* Gadi Taubenfeld, ''Synchronization Algorithms and Concurrent Programming'', Pearson/Prentice Hall, {{ISBN|0-13-197259-6}}\n\n==External links==\n* Article [http://cprogramscollege.blogspot.in/2013/03/mutex-simple-c-code.html A Simple Mutex Program]\n* [http://www.ibm.com/developerworks/library/l-posix2/ Common threads: POSIX threads explained - The little things called mutexes]\" by [[Daniel Robbins (computer programmer)|Daniel Robbins]]\n* {{webarchive |url=https://web.archive.org/web/20160602235210/http://cs.adelaide.edu.au/users/esser/mutual.html |title=Mutual Exclusion Petri Net}}\n* [http://www.thinkingparallel.com/2006/09/09/mutual-exclusion-with-locks-an-introduction/ Mutual Exclusion with Locks - an Introduction]\n* [http://www.thinkingparallel.com/2006/08/21/scoped-locking-vs-critical-in-openmp-a-personal-shootout/ Mutual exclusion variants in OpenMP]\n* [http://www.faculty.idc.ac.il/gadi/Publications.htm The Black-White Bakery Algorithm]\n{{Use dmy dates|date=December 2010}}\n\n{{Edsger Dijkstra}}\n\n[[Category:Concurrency control]]\n[[Category:Edsger W. Dijkstra]]",
            "slug": "mutual-exclusion",
            "date_updated": 1520462540705,
            "imported": "https://en.wikipedia.org/wiki/Mutual_exclusion"
        }
    ]
}