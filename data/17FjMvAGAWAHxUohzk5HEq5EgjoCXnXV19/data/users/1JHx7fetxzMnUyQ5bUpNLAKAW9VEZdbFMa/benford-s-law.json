{
    "article": [
        {
            "title": "Benford's law",
            "text": "{{distinguish|text=the unrelated adage [[Benford's law of controversy]]}}\n[[File:Rozklad benforda.svg|thumb|alt=A sequence of decreasing blue bars against a light gray grid background|The distribution of first digits, according to Benford's law. Each bar represents a digit, and the height of the bar is the percentage of numbers that start with that digit.]]\n[[File:Benford-physical.svg|thumb|Frequency of first significant digit of physical constants plotted against Benford's law]]\n{{Use dmy dates|date=June 2013}}\n\n'''Benford's law''', also called '''Newcomb-Benford's law''', '''law of anomalous numbers''', and '''first-digit law''', is an observation about the [[frequency distribution]] of leading digits in many real-life sets of numerical [[data]]. The law states that in many naturally occurring collections of numbers, the leading [[significant digit]] is likely to be small.<ref name=BergerHill2011/> For example, in sets that obey the law, the number {{formatnum:1}} appears as the most significant digit about 30% of the time, while {{formatnum:9}} appears as the most significant digit less than 5% of the time. If the digits were distributed uniformly, they would each occur about 11.1% of the time.<ref>{{cite web | url=http://mathworld.wolfram.com/BenfordsLaw.html|author = Weisstein, Eric W.| title=Benford's Law | website = MathWorld, A Wolfram web resource |access-date = 7 June 2015}}</ref> Benford's law also makes predictions about the distribution of second digits, third digits, digit combinations, and so on.\n\nIt has been shown that this result applies to a wide variety of data sets, including electricity bills, street addresses, stock prices, house prices, population numbers, death rates, lengths of rivers, [[physical constant|physical]] and [[mathematical constant]]s,<ref>Paul H. Kvam, Brani Vidakovic, ''Nonparametric Statistics with Applications to Science and Engineering'', p. 158</ref> and processes described by [[power law]]s (which are very common in nature). It tends to be most accurate when values are distributed across multiple [[Order of magnitude|orders of magnitude]].\n\nThe graph here shows Benford's law for [[Decimal|base 10]]. There is a generalization of the law to numbers expressed in other bases (for example, [[hexadecimal|base 16]]), and also a generalization from leading 1 digit to leading ''n'' digits.\n\nIt is named after physicist [[Frank Benford]], who stated it in 1938 in a paper titled ''The Law of Anomalous Numbers'',<ref name=Benford>{{Cite journal | author = Frank Benford | author-link = Frank Benford | title = The law of anomalous numbers | journal = [[Proc. Am. Philos. Soc.]] | volume = 78 | issue = 4 |url=https://www.scribd.com/document/209534421/The-Law-of-Anomalous-Numbers|date=March 1938 | pages = 551–572 | jstor=984802}} (subscription required)</ref> although it had been previously stated by [[Simon Newcomb]] in 1881.<ref name=Newcomb /><ref name=Formann2010 />\n\n==Definition==\n[[File:Logarithmic scale.png|thumb|upright=1.5|alt=Rectangle with offset bolded axis in lower left, and light gray lines representing logarithms|A [[logarithmic scale]] bar. Picking a random ''x'' position [[Uniform distribution (continuous)|uniformly]] on this number line, roughly 30% of the time the first digit of the number will be 1.]]\nA set of numbers is said to satisfy Benford's law if the leading digit&nbsp;{{mvar|d}} ({{math|{{var|d}}&nbsp;∈&nbsp;{{mset|1,&nbsp;...,&nbsp;9}}}}) occurs with [[probability]]\n: <math>P(d)=\\log_{10}(d+1)-\\log_{10}(d)=\\log_{10} \\left(\\frac{d+1}{d}\\right)=\\log_{10} \\left(1+\\frac{1}{d}\\right)</math>\n\nThe leading digits in such a set thus have the following distribution:\n{| class=\"wikitable\"\n|-\n! {{nobold|{{mvar|d}}}} !! {{tmath|P(d)}} !! Relative size of {{tmath|P(d)}}\n|-\n| 1 || style=\"text-align:right;\"| {{bartable|30.1|%|10}}\n|-\n| 2 || style=\"text-align:right;\"| {{bartable|17.6|%|10}}\n|-\n| 3 || style=\"text-align:right;\"| {{bartable|12.5|%|10}}\n|-\n| 4 || style=\"text-align:right;\"| {{bartable| 9.7|%|10}}\n|-\n| 5 || style=\"text-align:right;\"| {{bartable| 7.9|%|10}}\n|-\n| 6 || style=\"text-align:right;\"| {{bartable| 6.7|%|10}}\n|-\n| 7 || style=\"text-align:right;\"| {{bartable| 5.8|%|10}}\n|-\n| 8 || style=\"text-align:right;\"| {{bartable| 5.1|%|10}}\n|-\n| 9 || style=\"text-align:right;\"| {{bartable| 4.6|%|10}}\n|}\nThe quantity {{tmath|P(d)}} is proportional to the space between {{mvar|d}} and {{math|{{var|d}}&nbsp;+&nbsp;1}} on a [[logarithmic scale]]. Therefore, this is the distribution expected if the [[significand|mantissae]] of the ''logarithms'' of the numbers (but not the numbers themselves) are [[Uniform distribution (continuous)|uniformly and randomly distributed]].\n\nFor example, a number {{mvar|x}}, constrained to lie between 1 and 10, starts with the digit 1 if {{math|1&nbsp;≤&nbsp;{{var|x}}&nbsp;<&nbsp;2}}, and starts with the digit 9 if {{math|9&nbsp;≤&nbsp;{{var|x}}&nbsp;<&nbsp;10}}. Therefore,  {{mvar|x}} starts with the digit 1 if {{math|log&nbsp;1&nbsp;≤&nbsp;log&nbsp; {{var|x}}&nbsp;<&nbsp;log&nbsp;2}}, or starts with 9 if {{math|log&nbsp;9&nbsp;≤&nbsp;log&nbsp;''x''&nbsp;<&nbsp;log&nbsp;10}}. The interval {{math|[log&nbsp;1,&nbsp;log&nbsp;2]}} is much wider than the interval {{math|[log&nbsp;9,&nbsp;log&nbsp;10]}} (0.30 and 0.05 respectively); therefore if log {{mvar|x}} is uniformly and randomly distributed, it is much more likely to fall into the wider interval than the narrower interval, i.e. more likely to start with 1 than with 9; the probabilities are proportional to the interval widths, giving the equation above (as well as the generalization to other bases besides decimal).\n\nBenford's law is sometimes stated in a stronger form, asserting that the [[fractional part]] of the logarithm of data is typically close to uniformly distributed between 0 and 1; from this, the main claim about the distribution of first digits can be derived.\n\n===Benford's law in other bases===\n[[File:Benford_law_bases.svg|thumb|200px|Graphs of ''P''&thinsp;(''d''&thinsp;) for initial digit ''d'' in various bases.<ref>They should strictly be bars but are shown as lines for clarity.</ref> The dotted line shows ''P''&thinsp;(''d''&thinsp;) were the distribution uniform. In [http://upload.wikimedia.org/wikipedia/commons/1/14/Benford_law_bases.svg the SVG image], hover over a graph to show the value for each point.]]\nAn extension of Benford's law predicts the distribution of first digits in other [[radix|bases]] besides [[decimal]]; in fact, any base {{math|''b''&nbsp;≥&nbsp;1}}. The general form is:\n: <math>P(d)=\\log_{b}(d+1)-\\log_{b}(d)=\\log_{b} \\left(1+\\tfrac{1}{d}\\right).</math>\nFor {{math|1=''b''&nbsp;=&nbsp;2}} (the [[Binary numeral system|binary number system]]), Benford's law is true but trivial: All binary numbers (except for 0) start with the digit 1. (On the other hand, the [[#Generalization to digits beyond the first|generalization of Benford's law to second and later digits]] is not trivial, even for binary numbers.)\n\n==Example==\n[[File:Benfords law illustrated by world's countries population.png|Distribution of first digits (in %, red bars) in the [[List of countries by population|population of the 237 countries]] of the world as of July 2010. Black dots indicate the distribution predicted by Benford's law.|thumb|right]]\nExamining a list of the heights of the [[List of tallest buildings and structures in the world#Tallest structure by category|60 tallest structures in the world by category]] shows that 1 is by far the most common leading digit, ''irrespective of the unit of measurement'' (cf. \"scale invariance\", below):\n{| class=\"wikitable\"\n|-\n! rowspan=\"2\" style=\"width:17%;\"| Leading digit\n! colspan=2 | meters\n! colspan=2 | feet\n! rowspan=\"2\" style=\"width:17%;\"| In Benford's law\n|-\n! style=\"width:16%;\"| Count\n! style=\"width:17%;\"| %\n! style=\"width:16%;\"| Count\n! style=\"width:17%;\"| %\n|-\n| 1\n| 26\n| 43.3%\n| 18\n| 30.0%\n| 30.1%\n|-\n| 2\n| 7\n| 11.7%\n| 8\n| 13.3%\n| 17.6%\n|-\n| 3\n| 9\n| 15.0%\n| 8\n| 13.3%\n| 12.5%\n|-\n| 4\n| 6\n| 10.0%\n| 6\n| 10.0%\n| 9.7%\n|-\n| 5\n| 4\n| 6.7%\n| 10\n| 16.7%\n| 7.9%\n|-\n| 6\n| 1\n| 1.7%\n| 5\n| 8.3%\n| 6.7%\n|-\n| 7\n| 2\n| 3.3%\n| 2\n| 3.3%\n| 5.8%\n|-\n| 8\n| 5\n| 8.3%\n| 1\n| 1.7%\n| 5.1%\n|-\n| 9\n| 0\n| 0.0%\n| 2\n| 3.3%\n| 4.6%\n|}\n\nAnother example is the leading digit of {{math|2<sup>''n''</sup>}}:\n\n:1, 2, 4, 8, 1, 3, 6, 1, 2, 5, 1, 2, 4, 8, 1, 3, 6, 1... {{OEIS|A008952}}\n\n==History==\nThe discovery of Benford's law goes back to 1881, when the American astronomer [[Simon Newcomb]] noticed that in [[logarithm]] tables the earlier pages (that started with 1) were much more worn than the other pages.<ref name=Newcomb>{{Cite journal | author = Simon Newcomb | author-link = Simon Newcomb | title = Note on the frequency of use of the different digits in natural numbers | journal = [[American Journal of Mathematics]] | volume = 4 | issue = 1/4 | year = 1881 | pages = 39–40 | doi = 10.2307/2369148 | publisher = American Journal of Mathematics, Vol. 4, No. 1 | jstor = 2369148}} (subscription required)</ref> Newcomb's published result is the first known instance of this observation and includes a distribution on the second digit, as well. Newcomb proposed a law that the probability of a single number ''N'' being the first digit of a number was equal to log(''N''&nbsp;+&nbsp;1)&nbsp;−&nbsp;log(''N'').\n\nThe phenomenon was again noted in 1938 by the physicist [[Frank Benford]],<ref name=Benford/> who tested it on data from 20 different domains and was credited for it. His data set included the surface areas of 335 rivers, the sizes of 3259 US populations, 104 [[physical constant]]s, 1800 [[molecular weight]]s, 5000 entries from a mathematical handbook, 308 numbers contained in an issue of ''[[Reader's Digest]]'', the street addresses of the first 342 persons listed in ''American Men of Science'' and 418 death rates. The total number of observations used in the paper was 20,229. This discovery was later named after Benford (making it an example of [[Stigler's Law]]).\n\nIn 1995, [[Ted Hill (mathematician)|Ted Hill]] proved the result about mixed distributions mentioned [[#Multiple probability distributions|below]].<ref name=Hill1995/>\n\n==Examples and explanations==\nLike other general principles about natural data—for example the fact that many data sets are well approximated by a [[normal distribution]]—there are illustrative examples and explanations that cover many of the cases where Benford's law applies, though there are many other cases where Benford's law applies that do not fall under any of the explanations below.<ref name=BergerHill2011>Arno Berger and Theodore P Hill, [http://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1074&context=rgp_rsr Benford's Law Strikes Back:  No Simple Explanation in Sight for Mathematical Gem, 2011]</ref>\n\n===Prevalence===\nBenford's law tends to apply most accurately to data that are distributed uniformly across several orders of magnitude. As a rule of thumb, the more orders of magnitude that the data evenly covers, the more accurately Benford's law applies. For instance, one can expect that Benford's law would apply to a list of numbers representing the populations of UK settlements, or representing the values of small insurance claims. But if a \"village\" is defined as a settlement with population between 300 and 999, or a \"small insurance claim\" is defined as a claim between $50 and $99, then Benford's law will not apply.<ref name=\"dspguide\">{{cite web|url=http://www.dspguide.com/ch34.htm |title=The Scientist and Engineer's Guide to Digital Signal Processing, chapter 34, Explaining Benford's Law |author=Steven W. Smith |accessdate=15 December 2012}} (especially [http://www.dspguide.com/ch34/10.htm section 10]).</ref><ref name=\"fewster\">{{Cite journal|first=R. M. |last=Fewster |title=A simple explanation of Benford's Law |journal=The American Statistician |year=2009 |volume=63 |issue=1 |pages=26–32 |doi=10.1198/tast.2009.0005 |postscript=<!--None--> |url=https://www.stat.auckland.ac.nz/~fewster/RFewster_Benford.pdf }}</ref>\n\nConsider the probability distributions shown below, referenced to a [[log scale]].<ref name=\"logscale\">This section discusses and plots probability distributions of the logarithms of a variable. This is not the same as taking a regular probability distribution of a variable, and simply plotting it on a log scale. Instead, one multiplies the distribution by a certain function. The log scale distorts the horizontal distances, so the height has to be changed also, in order for the area under each section of the curve to remain true to the original distribution. See, for example, [http://www.dspguide.com/ch34/4.htm]. Specifically: <math>P(\\log x) d(\\log x) = (1/x) P(\\log x) dx</math>.</ref>\nIn each case, the total area in red is the relative probability that the first digit is 1, and the total area in blue is the relative probability that the first digit is 8.\n\n{|\n[[File:BenfordBroad.gif|thumb|left|300px|A broad probability distribution of the log of a variable, shown on a log scale.<ref name=logscale/>]]\n|\n[[File:BenfordNarrow.gif|thumb|left|300px|A narrow probability distribution of the log of a variable, shown on a log scale<ref name=logscale/>]]\n|}\n\nFor the left distribution, the size of the ''areas'' of red and blue are approximately proportional to the ''widths'' of each red and blue bar. Therefore, the numbers drawn from this distribution will approximately follow Benford's law. On the other hand, for the right distribution, the ratio of the areas of red and blue is very different from the ratio of the widths of each red and blue bar. Rather, the relative areas of red and blue are determined more by the ''height'' of the bars than the widths. Accordingly, the first digits in this distribution do not satisfy Benford's law at all.<ref name=fewster />\n\nThus, real-world distributions that span several [[orders of magnitude]] rather uniformly (e.g. populations of villages / towns / cities, stock-market prices), are likely to satisfy Benford's law to a very high accuracy. On the other hand, a distribution that is mostly or entirely within one order of magnitude (e.g. heights of human adults, or IQ scores) is unlikely to satisfy Benford's law very accurately, or at all.<ref name=dspguide /><ref name=fewster /> However, it is not a sharp line: As the distribution gets narrower, the discrepancies from Benford's law ''typically'' increase gradually.\n\nIn terms of conventional [[probability density]] (referenced to a linear scale rather than log scale, i.e. P(x)dx rather than P(log x) d(log x)), the equivalent criterion is that Benford's law will be very accurately satisfied when P(x) is approximately proportional to 1/x over several orders-of-magnitude variation in x.<ref name=\"logscale\" />\n\nThis discussion is not a ''full'' explanation of Benford's law, because we have not explained ''why'' we so often come across data-sets that, when plotted as a probability distribution of the logarithm of the variable, are relatively uniform over several orders of magnitude.<ref name=BergerHillExplain>Arno Berger and Theodore P Hill, [http://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1074&context=rgp_rsr Benford's Law Strikes Back:  No Simple Explanation in Sight for Mathematical Gem, 2011]. The authors describe this argument, but say it \"still leaves open the question of why it is reasonable to assume that the logarithm of the spread, as opposed to the spread itself—or, say, the log log spread—should be large.\" Moreover, they say: \"assuming large spread on a logarithmic scale is ''equivalent'' to assuming an approximate conformance with [Benford's law]\" (italics added), something which they say lacks a \"simple explanation\".</ref>\n\n===Multiplicative fluctuations===\nMany real-world examples of Benford's law arise from multiplicative fluctuations.<ref name=Pietronero>{{cite journal|title=Explaining the uneven distribution of numbers in nature: the laws of Benford and Zipf |author=L. Pietronero |author2=E. Tosatti |author3=V. Tosatti|author4=A. Vespignani |journal=Physica A |year=2001 |volume=293 |pages=297–304 |doi=10.1016/S0378-4371(00)00633-6|bibcode = 2001PhyA..293..297P |url=https://arxiv.org/pdf/cond-mat/9808305v2.pdf |arxiv=cond-mat/9808305 }}</ref> For example, if a stock price starts at $100, and then each day it gets multiplied by a randomly chosen factor between 0.99 and 1.01, then over an extended period the probability distribution of its price satisfies Benford's law with higher and higher accuracy.\n\nThe reason is that the ''logarithm'' of the stock price is undergoing a [[random walk]], so over time its probability distribution will get more and more broad and smooth (see [[#Overview|above]]).<ref name=Pietronero/> (More technically, the [[central limit theorem]] says that multiplying more and more random variables will create a [[log-normal distribution]] with larger and larger variance, so eventually it covers many orders of magnitude almost uniformly.) To be sure of approximate agreement with Benford's Law, the distribution has to be approximately invariant when scaled up by any factor up to 10; a [[lognormal]]ly distributed data set with wide dispersion would have this approximate property.\n\nUnlike multiplicative fluctuations, ''additive'' fluctuations do not lead to Benford's law: They lead instead to [[normal probability distribution]]s (again by the [[central limit theorem]]), which do not satisfy Benford's law. For example, the \"number of heartbeats that I experience on a given day\" can be written as the ''sum'' of many random variables (e.g. the sum of heartbeats per minute over all the minutes of the day), so this quantity is ''unlikely'' to follow Benford's law. By contrast, that hypothetical stock price described above can be written as the ''product'' of many random variables (i.e. the price change factor for each day), so is ''likely'' to follow Benford's law quite well.\n\n===Multiple probability distributions===\n[[Anton Formann|Formann]] provided an alternative explanation by directing attention to the interrelation between the [[Probability distribution|distribution]] of the significant digits and the distribution of the [[dependent variable|observed variable]]. He showed in a simulation study that long right-tailed distributions of a [[random variable]] are compatible with the Newcomb-Benford law, and that for distributions of the ratio of two random variables the fit generally improves.<ref>Formann, A. K. (2010). The Newcomb-Benford law in its relation to some common distributions. ''PLoS ONE, 5,'' e10541.</ref> For numbers drawn from certain distributions (IQ scores, human heights) the Law fails to hold because these variates obey a normal distribution which is known not to satisfy Benford's law,<ref name=Formann2010>{{Cite journal\n| last1 = Formann | first1 = A. K.\n| title = The Newcomb-Benford Law in Its Relation to Some Common Distributions\n| doi = 10.1371/journal.pone.0010541\n| journal = PLoS ONE\n| volume = 5\n| issue = 5\n| pages = e10541\n| year = 2010\n| pmid = 20479878\n| pmc = 2866333\n| editor1-last = Morris\n| editor1-first = Richard James\n|bibcode = 2010PLoSO...510541F }}</ref> since normal distributions can't span several orders of magnitude and the [[Significand|mantissae]] of their logarithms will not be (even approximately) uniformly distributed.\nHowever, if one \"mixes\" numbers from those distributions, for example by taking numbers from newspaper articles, Benford's law reappears. This can also be proven mathematically: if one repeatedly \"randomly\" chooses a [[probability distribution]] (from an uncorrelated set) and then randomly chooses a number according to that distribution, the resulting list of numbers will obey Benford's Law.<ref name=Hill1995>{{Cite journal\n | author = Theodore P. Hill\n | author-link = Theodore P. Hill\n | title = A Statistical Derivation of the Significant-Digit Law\n | journal = Statistical Science\n | volume = 10\n | pages = 354–363\n | year = 1995\n | url = http://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1042&context=rgp_rsr\n | doi = 10.1214/ss/1177009869\n | mr = 1421567\n|format=PDF}}</ref><ref name=Hill1998>{{Cite journal\n | author = Theodore P. Hill\n | author-link = Theodore P. Hill\n | title = The first digit phenomenon\n | journal = [[American Scientist]]\n | volume = 86\n |date=July–August 1998\n | page = 358\n | url = http://people.math.gatech.edu/~hill/publications/PAPER%20PDFS/TheFirstDigitPhenomenonAmericanScientist1996.pdf\n|format=PDF\n | bibcode = 1998AmSci..86..358H\n | doi = 10.1511/1998.4.358\n | issue = 4}}</ref> A similar probabilistic explanation for the appearance of Benford's Law in everyday-life numbers has been advanced by showing that it arises naturally when one considers mixtures of uniform distributions.<ref>Élise Janvresse and Thierry de la Rue (2004), \"From Uniform Distributions to Benford's Law\", ''Journal of Applied Probability'', 41 1203–1210 {{doi|10.1239/jap/1101840566}} {{MR|2122815}} [http://lmrs.univ-rouen.fr/Persopage/Delarue/Publis/PDF/uniform_distribution_to_Benford_law.pdf preprint]</ref>\n\n===Scale invariance===\nIf there is a list of lengths, the distribution of first digits of numbers in the list may be generally similar regardless of whether all the lengths are expressed in metres, or yards, or feet, or inches, etc.\n\nThis is not ''always'' the case. For example, the height of adult humans almost always starts with a 1 or 2 when measured in meters, and almost always starts with 4, 5, 6, or 7 when measured in feet.\n\nBut consider a list of lengths that is spread evenly over many orders of magnitude. For example, a list of 1000 lengths mentioned in scientific papers will include the measurements of molecules, bacteria, plants, and galaxies. If one writes all those lengths in meters, or writes them all in feet, it is reasonable to expect that the distribution of first digits should be the same on the two lists.\n\nIn these situations, where the distribution of first digits of a data set is [[scale invariant]] (or independent of the units that the data are expressed in), the distribution of first digits is always given by Benford's Law.<ref name=Pinkham>Roger S. Pinkham, [http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoms/1177704862 On the Distribution of First Significant Digits], Ann. Math. Statist. Volume 32, Number 4 (1961), 1223-1230.</ref><ref name=wolfram>[http://mathworld.wolfram.com/BenfordsLaw.html MathWorld – Benford's Law]</ref>\n\nFor example, the first (non-zero) digit on this list of lengths should have the same distribution whether the unit of measurement is feet or yards. But there are three feet in a yard, so the probability that the first digit of a length in yards is 1 must be the same as the probability that the first digit of a length in feet is 3, 4, or&nbsp;5; similarly the probability that the first digit of a length in yards is 2 must be the same as the probability that the first digit of a length in feet is 6, 7, or&nbsp;8.  Applying this to all possible measurement scales gives the logarithmic distribution of Benford's law.\n\n==Applications==\n\n===Accounting fraud detection===\nIn 1972, [[Hal Varian]] suggested that the law could be used to detect possible [[fraud]] in lists of socio-economic data submitted in support of public planning decisions. Based on the plausible assumption that people who make up figures tend to distribute their digits fairly uniformly, a simple comparison of first-digit frequency distribution from the data with the expected distribution according to Benford's Law ought to show up any anomalous results.<ref>{{Cite journal|first=Hal |last=Varian |authorlink=Hal Varian |title=Benford's Law (Letters to the Editor) |journal=[[The American Statistician]]|year=1972 |issue=3 |volume=26 |page=65 |doi=10.1080/00031305.1972.10478934 }}</ref> Following this idea, [[Mark Nigrini]] showed that Benford's Law could be used in [[forensic accounting]] and [[audit]]ing as an indicator of accounting and expenses fraud.<ref name=Nigrini>{{Cite journal| first = Mark J. |last=Nigrini | title = I've Got Your Number:How a mathematical phenomenon can help CPAs uncover fraud and other irregulaities | journal = Journal of Accountancy |date=May 1999 | url = http://www.journalofaccountancy.com/Issues/1999/May/nigrini}}</ref> In practice, applications of Benford's Law for [[fraud detection]] routinely use more than the first digit.<ref name=Nigrini/>\n\n===Legal status===\nIn the United States, evidence based on Benford's law has been admitted in criminal cases at the federal, state, and local levels.<ref>{{cite episode| url = http://www.wnyc.org/shows/radiolab/episodes/2009/10/09/segments/137643| title =From Benford to Erdös | series = Radio Lab | serieslink = Radio Lab | airdate = 2009-09-30 | season = | number = 2009-10-09}}</ref>\n\n===Election data===\nBenford's Law has been invoked as evidence of fraud in the [[Iranian presidential election, 2009|2009 Iranian elections]],<ref>Stephen Battersby [https://www.newscientist.com/article/mg20227144.000-statistics-hint-at-fraud-in-iranian-election.html Statistics hint at fraud in Iranian election] ''New Scientist'' 24 June 2009</ref> and also used to analyze other election results. However, other experts consider Benford's Law essentially useless as a statistical indicator of election fraud in general.<ref>Joseph Deckert, Mikhail Myagkov and Peter C. Ordeshook, (2010) ''[http://vote.caltech.edu/sites/default/files/benford_pdf_4b97cc5b5b.pdf The Irrelevance of Benford’s Law for Detecting Fraud in Elections] {{webarchive |url=https://web.archive.org/web/20140517120934/http://vote.caltech.edu/sites/default/files/benford_pdf_4b97cc5b5b.pdf |date=17 May 2014 }}'', Caltech/MIT Voting Technology Project Working Paper No. 9</ref><ref>Charles R. Tolle, Joanne L. Budzien, and Randall A. LaViolette (2000)  ''[[:doi:10.1063/1.166498|Do dynamical systems follow Benford?s Law?]]'', Chaos 10, 2, pp.331–336 (2000); {{doi|10.1063/1.166498}}</ref>\n\n===Macroeconomic data===\nSimilarly, the macroeconomic data the Greek government reported to the European Union before entering the [[eurozone]] was shown to be probably fraudulent using Benford's law, albeit years after the country joined.<ref>Müller, Hans Christian: ''[https://www.forbes.com/sites/timworstall/2011/09/12/greece-was-lying-about-its-budget-numbers/ Greece Was Lying About Its Budget Numbers]''. ''[[Forbes]]''. 12 September 2011.</ref>\n\n=== Price digit analysis ===\nBenford's law as a benchmark for the investigation of price digits has been successfully introduced into the context of pricing research. The importance of this benchmark for detecting irregularities in prices was first demonstrated in a Europe-wide study<ref>{{Cite journal|last=Sehity|first=Tarek el|last2=Hoelzl|first2=Erik|last3=Kirchler|first3=Erich|date=2005-12-01|title=Price developments after a nominal shock: Benford's Law and psychological pricing after the euro introduction|url=http://www.sciencedirect.com/science/article/pii/S0167811605000522|journal=International Journal of Research in Marketing|volume=22|issue=4|pages=471–480|doi=10.1016/j.ijresmar.2005.09.002}}</ref> which investigated consumer price digits before and after the euro introduction for price adjustments. The introduction of the euro in 2002, with its various exchange rates, distorted existing nominal price patterns while at the same time retaining real prices. While the first digits of [[Real versus nominal value (economics)|nominal prices]] distributed according to Benford's Law, the study showed a clear deviation from this benchmark for the second and third digits in nominal market prices with a clear trend towards [[psychological pricing]] after the nominal shock of the euro introduction.\n\n===Genome data===\nThe number of [[open reading frame]]s and their relationship to genome size differs between [[eukaryote]]s and [[prokaryote]]s with the former showing a log-linear relationship and the latter a linear relationship. Benford's law has been used to test this observation with an excellent fit to the data in both cases.<ref name=Friar2012>{{cite journal | last1 = Friar | first1 = JL | last2 = Goldman | first2 = T | last3 = Pérez-Mercader | first3 = J | year = 2012 | title = Genome sizes and the benford distribution | journal = PLOS ONE | volume = 7 | issue = 5| page = e36624 | doi = 10.1371/journal.pone.0036624 |arxiv = 1205.6512 |bibcode = 2012PLoSO...736624F | pmid=22629319 | pmc=3356352}}</ref>\n\n===Scientific fraud detection===\nA test of regression coefficients in published papers showed agreement with Benford's law.<ref name=Diekmann2007>Diekmann A (2007) Not the First Digit! Using Benford's Law to detect fraudulent scientific data. J Appl Stat 34 (3) 321–329, {{doi|10.1080/02664760601004940}}</ref> As a comparison group subjects were asked to fabricate statistical estimates. The fabricated results failed to obey Benford's law.\n\n==Statistical tests==\nAlthough the [[chi square]]d test has been used to test for compliance with Benford's law it has low statistical power when used with small samples.\n\nThe [[Kolmogorov–Smirnov test]] and the [[Kuiper test]] are more powerful when the sample size is small particularly when Stephens's corrective factor is used.<ref name=Stephens1970>{{cite journal |last=Stephens |first=M. A. |year=1970 |title=Use of the Kolmogorov–Smirnov, Cramér–Von Mises and Related Statistics without Extensive Tables |journal=[[Journal of the Royal Statistical Society, Series B]] |volume=32 |issue=1 |pages=115–122 |url=}}</ref> These tests may be overly conservative when applied to discrete distributions. Values for the Benford test have been generated by Morrow.<ref name=Morrow2010>Morrow, J. (2010) [http://www.johnmorrow.info/projects/benford/benfordMain.pdf \"Benford’s Law, Families of Distributions and a test basis\"], UW-Madison</ref> The critical values of the test statistics are shown below:\n\n{| class=\"wikitable\"\n|-\n! {{diagonal split header|Test|''&alpha;''}}\n! 0.10\n! 0.05\n! 0.01\n|-\n| Kuiper Test\n| 1.191\n| 1.321\n| 1.579\n|-\n| Kolmogorov–Smirnov\n| 1.012\n| 1.148\n| 1.420\n|}\n\nThese critical values provide the minimum test statistic values required to reject the hypothesis of compliance with Benford's law at the given [[significance level]]s.\n\nTwo alternative tests specific to this law have been published: first, the max (''m'') statistic<ref name=Leemis2000>{{cite journal |last1=Leemis |first1=L. M. |last2=Schmeiser |first2=B. W. |last3=Evans |first3=D. L. |year=2000 |title=Survival distributions satisfying Benford's Law |journal=The Amererican Statistician |volume=54 |issue=4|pages=236–241 |doi=10.1080/00031305.2000.10474554}}</ref> is given by\n:<math>m = \\sqrt{N}\\cdot\\operatorname*\\max_{i=1}^{9} \\Big\\{|\\Pr (X \\text{ has FSD}=i)-\\log_{10}(1+1/i)| \\Big\\}\\,</math>\nand secondly, the distance (''d'') statistic<ref name=Cho2007>{{cite journal |last1=Cho |first1=W. K. T. |last2=Gaines |first2=B. J. |year=2007 |title=Breaking the (Benford) law: Statistical fraud detection in campaign finance |journal=The Amererican Statistician |volume=61 |pages=218–223 |doi=10.1198/000313007X223496 |issue=3}}</ref> is given by\n:<math>d= \\sqrt{N \\cdot \\sum_{i=1}^{9}\\Big[\\Pr ( X \\text{ has FSD}=i ) - \\log_{10}(1+1/i) \\Big]^{2}},</math>\nwhere FSD is the First Significant Digit and {{mvar|N}} is the sample size. Morrow has determined the critical values for both these statistics, which are shown below:<ref name=\"Morrow2010\" />\n\n{| class=\"wikitable\"\n|-\n! {{diagonal split header|Statistic|''&#9082;''}}\n! 0.10\n! 0.05\n! 0.01\n|-\n| Leemis' ''m''\n| 0.851\n| 0.967\n| 1.212\n|-\n| Cho–Gaines' ''d''\n| 1.212\n| 1.330\n| 1.569\n|}\n\nNigrini<ref name=Nigrini1996>{{cite journal |last=Nigrini |first=M. |year=1996 |title=A taxpayer compliance application of Benford's Law |journal=J Amer Tax Assoc |volume=18 |pages=72–91}}</ref> has suggested the use of a [[Z statistic|''z'' statistic]]\n\n: <math> z = \\frac { \\, | p_o - p_e | - \\frac{1}{2n} \\, }  { s_i } </math>\nwith\n: <math> s_i =  \\left[ \\frac { p_e ( 1 - p_e ) }  { n } \\right]^{1/2}, </math>\n\nwhere |''x''| is the absolute value of ''x'', ''n'' is the sample size, {{sfrac|1|2''n''}} is a continuity correction factor, ''p''<sub>e</sub> is the proportion expected from Benford's law and ''p''<sub>o</sub> is the observed proportion in the sample.\n\nMorrow has also shown that for any random variable ''X'' (with a continuous pdf) divided by its standard deviation (''σ''), a value ''A'' can be found such that the probability of the distribution of the first significant digit of the random variable ({{sfrac|''X''|''σ''}})<sup>''A''</sup> will differ from Benford's Law by less than ''ε'' > 0.<ref name=\"Morrow2010\" /> The value of ''A'' depends on the value of ''ε'' and the distribution of the random variable.\n\nA method of accounting fraud detection based on bootstrapping and regression has been proposed.<ref name=Suh2011>{{cite journal |last1=Suh |first1=I. S. |last2=Headrick |first2=T. C. |last3=Minaburo |first3=S. |year=2011 |title=An effective and efficient analytic technique: A bootstrap regression procedure and Benford's Law |journal=J Forensic & Investigative Accounting |volume=3 |issue=3}}</ref>\n\nIf the goal is to conclude agreement with the Benford's law rather than disagreement, then the [[goodness-of-fit test]]s mentioned above are inappropriate. In this case the specific [[Equivalence test|tests for equivalence]] should be applied. An empirical distribution is called equivalent to the Benford's law if a distance  (for example total variation distance or the usual Euclidean distance) between the probability mass functions is sufficiently small. This method of testing with application to Benford's law is described in Ostrovski (2017).<ref>{{cite journal|last1=Ostrovski|first1=Vladimir|date=May 2017|title=Testing equivalence of multinomial distributions|ssrn=2907258|journal=Statistics & Probability Letters|volume=124|pages=77–82|doi=10.1016/j.spl.2017.01.004|via=}}</ref>\n\n==Generalization to digits beyond the first==\n[[File:Benford_law_log_log_graph.svg|thumb|300px|Log-log graph of the probability that a number starts with the digit(s) ''n'', for a distribution satisfying Benford's law. The points show the exact formula, P(n)=log<sub>10</sub>(1+1/n). The graph tends towards the dashed asymptote passing through {{nobr|(1, log<sub>10&thinsp;</sub>''e'')}} with slope &minus;1 in log-log scale. The example in yellow shows that the probability of a number starts with 314 is around 0.00138. The dotted lines show the probabilities for a uniform distribution for comparison. In [http://upload.wikimedia.org/wikipedia/commons/1/14/Benford_law_log_log_graph.svg the SVG image], hover over a point to show its values.]]\nIt is possible to extend the law to digits beyond the first.<ref name=Hill1995sigdig>[[Theodore P. Hill]], \"The Significant-Digit Phenomenon\", The American Mathematical Monthly, Vol. 102, No. 4, (Apr., 1995), pp. 322–327. [https://www.jstor.org/stable/2974952 Official web link (subscription required)]. [http://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1041&context=rgp_rsr Alternate, free web link].</ref> In particular, the probability of encountering a number starting with the string of digits ''n'' is given by:\n\n:<math> \\log_{ 10 } \\left( n + 1 \\right )- \\log_{ 10 } \\left( n \\right ) = \\log_{ 10 } \\left( 1 + \\frac{ 1 }{ n } \\right)</math>\n\nFor example, the probability that a number starts with the digits 3,&nbsp;1,&nbsp;4 is {{math|log<sub>10</sub>(1&nbsp;+&nbsp;1/314)&nbsp;≈&nbsp;0.00138}}, as in the figure on the right.\n\nThis result can be used to find the probability that a particular digit occurs at a given position within a number. For instance, the probability that a \"2\" is encountered as the second digit is<ref name=Hill1995sigdig />\n\n:<math> \\log_{ 10 } \\left( 1 + \\frac{ 1 }{ 12 } \\right ) + \\log_{ 10 } \\left( 1 + \\frac{ 1 }{ 22 } \\right )+ \\cdots + \\log_{ 10 } \\left( 1 + \\frac{ 1 }{ 92 } \\right) \\approx 0.109 </math>\n\nAnd the probability that ''d'' (''d''&nbsp;=&nbsp;0,&nbsp;1,&nbsp;...,&nbsp;9) is encountered as the ''n''-th (''n''&nbsp;>&nbsp;1) digit is\n\n:<math> \\sum_{ k = 10^{ n - 2 } }^{ 10^{ n - 1 } - 1 } \\log_{ 10 } \\left( 1 + \\frac{ 1 }{ 10k + d } \\right )</math>\n\nThe distribution of the ''n''-th digit, as ''n'' increases, rapidly approaches a uniform distribution with 10% for each of the ten digits, as shown below.<ref name=Hill1995sigdig /> Four digits is often enough to assume a uniform distribution of 10% as '0' appears 10.0176% of the time in the fourth digit while '9' appears 9.9824% of the time.\n{| class=\"wikitable\"\n!Digit\n!0\n!1\n!2\n!3\n!4\n!5\n!6\n!7\n!8\n!9\n|-\n!1st\n| {{N/A}}\n|30.1%\n|17.6%\n|12.5%\n|9.7%\n|7.9%\n|6.7%\n|5.8%\n|5.1%\n|4.6%\n|-\n!2nd\n|12%\n|11.4%\n|10.9%\n|10.4%\n|10%\n|9.7%\n|9.3%\n|9%\n|8.8%\n|8.5%\n|-\n!3rd\n|10.2%\n|10.1%\n|10.1%\n|10.1%\n|10%\n|10%\n|9.9%\n|9.9%\n|9.9%\n|9.8%\n|}\n\n==Tests with common distributions==\nBenford's law was empirically tested against the numbers (up to the 10th digit) generated by a number of important distributions, including the [[uniform distribution (discrete)|uniform distribution]], the [[exponential distribution]], the [[half-normal distribution]], the [[Truncated normal distribution|right-truncated normal]], the [[normal distribution]], the [[chi square distribution]] and the [[log normal distribution]].<ref name=Formann2010 /> In addition to these the [[ratio distribution]] of two uniform distributions, the ratio distribution of two exponential distributions, the ratio distribution of two half-normal distributions, the ratio distribution of two right-truncated normal distributions, the ratio distribution of two chi-square distributions (the [[F distribution]]) and the [[log normal]] distribution were tested.\n\nThe uniform distribution as might be expected does not obey Benford's law. In contrast, the ratio distribution of two uniform distributions is well described by Benford's law. Benford's law also describes the exponential distribution and the ratio distribution of two exponential distributions well. Although the half-normal distribution does not obey Benford's law, the ratio distribution of two half-normal distributions does. Neither the right-truncated normal distribution nor the ratio distribution of two right-truncated normal distributions are well described by Benford's law. This is not surprising as this distribution is weighted towards larger numbers. Neither the normal distribution nor the ratio distribution of two normal distributions (the [[Cauchy distribution]]) obey Benford's law. The fit of chi square distribution depends on the [[degrees of freedom (statistics)|degrees of freedom]] (df) with good agreement with df = 1 and decreasing agreement as the df increases. The F distribution is fitted well for low degrees of freedom. With increasing dfs the fit decreases but much more slowly than the chi square distribution. The fit of the log-normal distribution depends on the [[mean]] and the [[variance]] of the distribution. The variance has a much greater effect on the fit than does the mean. Larger values of both parameters result in better agreement with the law. The ratio of two log normal distributions is a log normal so this distribution was not examined.\n\nOther distributions that have been examined include the [[Muth distribution]], [[Gompertz distribution]], [[Weibull distribution]], [[gamma distribution]], [[log-logistic distribution]] and the [[exponential power distribution]] all of which show reasonable agreement with the law.<ref name=Leemis2000 /><ref name=\"Dümbgen2008\">{{cite journal | last1 = Dümbgen | first1 = L | last2 = Leuenberger | first2 = C | year = 2008 | title = Explicit bounds for the approximation error in Benford's Law | url = | journal = Elect Comm in Probab | volume = 13 | issue = | pages = 99–112 | doi = 10.1214/ECP.v13-1358 | arxiv = 0705.4488 }}</ref> The [[Gumbel distribution]] – a density increases with increasing value of the random variable – does not show agreement with this law.<ref name=\"Dümbgen2008\"/>\n\n==Distributions known to obey Benford's law==\nSome well-known infinite [[integer sequence]]s {{not a typo|provably}} satisfy Benford's Law exactly (in the [[asymptotic limit]] as more and more terms of the sequence are included). Among these are the [[Fibonacci number]]s,<ref>{{cite journal | last1 = Washington | first1 = L. C. | year = 1981 | title = Benford's Law for Fibonacci and Lucas Numbers | url = | journal = [[The Fibonacci Quarterly]] | volume = 19 | issue = 2| pages = 175–177 }}</ref><ref>{{cite journal | last1 = Duncan | first1 = R. L. | year = 1967 | title = An Application of Uniform Distribution to the Fibonacci Numbers | url = | journal = [[The Fibonacci Quarterly]] | volume = 5 | issue = | pages = 137–140 }}</ref> the [[factorial]]s,<ref>{{cite journal | last1 = Sarkar | first1 = P. B. | year = 1973 | title = An Observation on the Significant Digits of Binomial Coefficients and Factorials | url = | journal = [[Sankhya]] B | volume = 35 | issue = | pages = 363–364 }}</ref> the powers of&nbsp;2,<ref name=powers>In general, the sequence ''k''<sup>1</sup>, ''k''<sup>2</sup>, ''k''<sup>3</sup>, etc., satisfies Benford's Law exactly, under the condition that log<sub>10</sub> ''k'' is an [[irrational number]]. This is a straightforward consequence of the [[equidistribution theorem]].</ref><ref>That the first 100 powers of&nbsp;2 approximately satisfy Benford's Law is mentioned by Ralph Raimi. {{cite journal | last1 = Raimi | first1 = Ralph A. | year = 1976 | title = The First Digit Problem | url = | journal = [[American Mathematical Monthly]] | volume = 83 | issue = 7| pages = 521–538 | doi=10.2307/2319349}}</ref> and the powers of ''almost'' any other number.<ref name=powers />\n\nLikewise, some continuous processes satisfy Benford's Law exactly (in the asymptotic limit as the process continues through time). One is an [[exponential growth]] or [[exponential decay|decay]] process: If a quantity is exponentially increasing or decreasing in time, then the percentage of time that it has each first digit satisfies Benford's Law asymptotically (i.e. increasing accuracy as the process continues through time).\n\n==Distributions known to disobey Benford's law==\nSquare roots and reciprocals do not obey this law.<ref name=Raimi1976>{{cite journal |last=Raimi |first=Ralph A. |date=Aug–Sep 1976 |title=The first digit problem |url= |journal=[[American Mathematical Monthly]] |volume=83 |issue=7 |pages=521–538 |doi=10.2307/2319349}}</ref> Also, Benford's law does not apply to [[Unary numeral system|unary systems]] such as [[tally marks]].  Telephone directories violate Benford's law because the numbers have a mostly fixed length and do not have the initial digit 1.<ref>The [[North American Numbering Plan]] uses 1 as a long distance prefix, and much of the rest of the world reserves it to begin special 3-digit numbers like [[112 (emergency telephone number)]].</ref>  Benford's law is violated by the populations of all places with population at least 2500 from five US states according to the 1960 and 1970 censuses, where only 19% began with digit 1 but 20% began with digit 2, for the simple reason that the truncation at 2500 introduces statistical bias.<ref name=Raimi1976/> The terminal digits in pathology reports violate Benford's law due to rounding, and the fact that terminal digits are never expected to follow Benford's law in the first place.<ref name=Beer2009>{{cite journal |last=Beer |first1=Trevor W. |year=2009 |title=Terminal digit preference: beware of Benford's Law |url= |journal=[[J. Clin. Pathol.]] |volume=62 |issue=2 |page=192 |doi=10.1136/jcp.2008.061721}}</ref>\n\n==Criteria for distributions expected and not expected to obey Benford's Law==\nA number of criteria—applicable particularly to accounting data—have been suggested where Benford's Law can be expected to apply and not to apply.<ref name=Durtschi2004>{{cite journal | last1 = Durtschi | first1 = C | last2 = Hillison | first2 = W | last3 = Pacini | first3 = C | year = 2004 | title = The effective use of Benford's Law to assist in detecting fraud in accounting data | url = | journal = J Forensic Accounting | volume = 5 | issue = | pages = 17–34 }}</ref>\n\n;Distributions that can be expected to obey Benford's Law:\n* When the mean is greater than the median and the skew is positive\n* Numbers that result from mathematical combination of numbers: e.g. quantity × price\n* Transaction level data: e.g. disbursements, sales\n* Numbers produced when doing any multiplicative calculations with an Oughtred slide rule, since the answers naturally fall into the right logarithmic distribution.\n\n;Distributions that would not be expected to obey Benford's Law:\n* Where numbers are assigned sequentially: e.g. check numbers, invoice numbers\n* Where numbers are influenced by human thought: e.g. prices set by psychological thresholds ($1.99)\n* Accounts with a large number of firm-specific numbers: e.g. accounts set up to record $100 refunds\n* Accounts with a built-in minimum or maximum\n* Where no transaction is recorded\n\n==Moments==\nMoments of random variables for the digits 1 to 9 following this law have been calculated:<ref name=Scott2001>Scott, P.D.; Fasli, M. (2001) [http://dces.essex.ac.uk/technical-reports/2001/CSM-349.pdf \"Benford’s Law: An empirical investigation and a novel explanation\"]. ''CSM Technical Report'' 349, Department of Computer Science, Univ. Essex</ref>\n* [[mean]] 3.440\n* [[variance]] 6.057\n* [[skewness]] 0.796\n* [[kurtosis]] −0.548\n\nFor the first and second digit distribution these values are also known:<ref name=Suh2010>{{cite journal | last1 = Suh | first1 = I.S. | last2 = Headrick | first2 = T.C. | year = 2010 | title = A comparative analysis of the bootstrap versus traditional statistical procedures applied to digital analysis based on Benford's Law | url = http://www.bus.lsu.edu/accounting/faculty/lcrumbley/jfia/Articles/Abstracts/abs_2010v2n2a7.pdf | format = PDF | journal = Journal of Forensic and Investigative Accounting | volume = 2 | issue = 2| pages = 144–175 }}</ref>\n* [[mean]] 38.590\n* [[variance]] 621.832\n* [[skewness]] 0.772\n* [[kurtosis]] −0.547\n\nA table of the exact probabilities for the joint occurrence of the first two digits according to Benford's law is available,<ref name=Suh2010/> as is the population correlation between the first and second digits:<ref name=Suh2010/> {{nowrap|1=''ρ'' = 0.0561 }}.\n\n==See also==\n* [[Predictive analytics#Fraud detection|Fraud detection in predictive analytics]]\n* [[Zipf's law]]\n\n==References==\n{{Reflist|30em}}\n\n==Further reading==\n{{Refbegin}}\n* {{Cite journal\n |author1=Arno Berger  |author2=Theodore P. Hill\n | title =What is…Benford's Law?\n | journal = Notices of the AMS\n | volume = 64\n | issue = 2\n | year = 2017\n | pages = 132–134\n | url = http://www.ams.org/publications/journals/notices/201702/rnoti-p132.pdf\n | doi=10.1090/noti1477\n}}\n* {{Cite book\n |author1=Arno Berger  |author2=Theodore P. Hill\n  |lastauthoramp=yes | title = An Introduction to Benford's Law\n | publisher = Princeton University Press\n | year = 2015\n | isbn = 978-0-691-16306-2\n}}\n* Alex Ely Kossovsky. ''[http://www.worldscientific.com/worldscibooks/10.1142/9089 Benford's Law: Theory, the General Law of Relative Quantities, and Forensic Fraud Detection Applications]'', 2014, World Scientific Publishing. {{ISBN|978-981-4583-68-8}}.\n* {{cite web|url=http://mathworld.wolfram.com/BenfordsLaw.html |title=Benford's Law – from Wolfram MathWorld |publisher=Mathworld.wolfram.com |date=14 June 2012 |accessdate=2012-06-26}}\n* {{Cite book\n | author = Mark J. Nigrini\n | title = Benford's Law: Applications for Forensic Accounting, Auditing, and Fraud Detection\n | publisher = John Wiley & Sons\n | year = 2012\n | page = 330\n | isbn = 978-1-118-15285-0\n}}\n* {{Cite journal\n | author = Alessandro Gambini\n | title = Probability of digits by dividing random numbers: A ψ and ζ functions approach\n | journal = Expositiones Mathematicae\n | volume = 30\n | year = 2012\n | pages = 223–238\n | doi = 10.1016/j.exmath.2012.03.001\n | last2 = Hoelzl\n | first2 = E\n | last3 = Kirchler\n | first3 = E\n | display-authors = 1\n | issue = 4\n}}\n* {{Cite journal\n | author = Sehity\n | title = Price developments after a nominal shock: Benford's Law and psychological pricing after the euro introduction\n | journal = International Journal of Research in Marketing\n | volume = 22\n | year = 2005\n | pages = 471–480\n | doi = 10.1016/j.ijresmar.2005.09.002\n | last2 = Hoelzl\n | first2 = Erik\n | last3 = Kirchler\n | first3 = Erich\n  | author3-link=Erich Kirchler\n| issue = 4\n}}\n* {{Cite journal\n | year = 2011\n | title =  Scatter and regularity implies Benford's Law...and more\n | journal = Zenil: Randomness through computation: some answers, more questions\n | volume = {{ISBN|9814327751}}\n | issue = \n | pages = 58–69\n | doi = 10.1142/9789814327756_0004\n|author1 = Nicolas Gauvrit|author2 = Jean-Paul Delahaye| authorlink2 =  Jean-Paul Delahaye\n | bibcode =  2009arXiv0910.1359G\n | arxiv =  0910.1359\n }}\n* {{Cite journal\n | author = Bernhard Rauch\n | author2 = Max Göttsche\n | author3 = Gernot Brähler\n | author4 = Stefan Engel\n |date=August 2011\n | title = Fact and Fiction in EU-Governmental Economic Data\n | journal = [[German Economic Review]]\n | volume = 12\n | issue = 3\n | pages = 243–255\n | doi = 10.1111/j.1468-0475.2011.00542.x\n}}\n* {{Cite journal\n |author1=Wendy Cho  |author2=Brian Gaines\n  |lastauthoramp=yes |date=August 2007\n | title = Breaking the (Benford) Law: statistical fraud detection in campaign finance\n | journal = [[The American Statistician]]\n | volume = 61\n | issue = 3\n | pages = 218–223\n | doi = 10.1198/000313007X223496\n}}\n* {{cite journal | title = The Law of Harmony in Statistics: An Investigation of the Metrical Interdependence of Social Phenomena. by L. V. Furlan |  last1 = Geiringer | first1 = Hilda | journal = Journal of the American Statistical Association | year = 1948 | volume = 43 | pages = 325–328 | publisher = American Statistical Association | jstor = 2280379 | doi = 10.2307/2280379 | last2 = Furlan | first2 = L. V. | issue = 242 |  authorlink1 = Hilda Geiringer }}\n\n{{Refend}}\n\n==External links==\n{{commons category}}\n\n===General audience===\n* [http://www.benfordonline.net/ Benford Online Bibliography], an online bibliographic database on Benford's Law.\n* [http://www.nigrini.com/benfordslaw.htm Companion website for Benford's Law by Mark Nigrini] Website includes 15 data sets, 10 Excel templates, photos, documents, and other miscellaneous items related to Benford's Law\n* [http://www.rexswain.com/benford.html Following Benford's Law, or Looking Out for No. 1], 1998 article from ''[[The New York Times]]''.\n* [https://web.archive.org/web/20121112200403/http://www.bbc.co.uk/radio4/science/further5.shtml A further five numbers: number 1 and Benford's law], [[BBC]] radio segment by [[Simon Singh]]\n* [http://www.wnyc.org/shows/radiolab/episodes/2009/10/09/segments/137643 From Benford to Erdös], Radio segment from the [[Radiolab]] program\n* [http://plus.maths.org/issue9/features/benford/index-gifd.html Looking out for number one] by Jon Walthoe, Robert Hunt and Mike Pearson, ''Plus Magazine'', September 1999\n* [http://www.kirix.com/blog/2008/07/22/fun-and-fraud-detection-with-benfords-law/ Video showing Benford's Law applied to Web Data (incl. Minnesota Lakes, US Census Data and Digg Statistics)]\n* [https://web.archive.org/web/20110514041058/https://mpi-inf.mpg.de/~fietzke/benford.html An illustration of Benford's Law], showing first-digit distributions of various sequences evolve over time, interactive.\n* [http://blog.iharder.net/2010/11/10/benford-how-to-generate-your-own-benfords-law-numbers/ Generate your own Benford numbers] A script for generating random numbers compliant with Benford's Law.\n* [http://testingbenfordslaw.com/ Testing Benford's Law] An open source project showing Benford's Law in action against publicly available datasets.\n* [http://www.metrica-bi.de/fraud-analysis-with-ssas-benfords-law-test-in-olap-cubes/ Testing Benford’s Law in OLAP Cubes] Implementation with Microsoft Analysis Services.\n* {{cite web|last=Mould|first=Steve|title=Number 1 and Benford's Law|url=http://www.numberphile.com/videos/benfords_law.html|work=Numberphile|publisher=[[Brady Haran]]}}\n* [https://www.independent.co.uk/property/property-news-roundup-a-third-of-property-values-begin-with-a-1-9154071.html A third of property values begin with a 1] An example of Benford's Law appearing in house price data.\n* [https://www.youtube.com/watch?v=4iz4EHriYz0 Benford's Very Strange Law - Professor John D. Barrow], lecture on Benford's Law.\n* Interactive graphic: [http://www.math.wm.edu/~leemis/chart/UDR/UDR.html Univariate Distribution Relationships]\n\n===More mathematical===\n* {{MathWorld | urlname=BenfordsLaw | title=Benford's Law}}\n* [http://terrytao.wordpress.com/2009/07/03/benfords-law-zipfs-law-and-the-pareto-distribution/ Benford’s law, Zipf’s law, and the Pareto distribution] by [[Terence Tao]]\n* [http://demonstrations.wolfram.com/CountryDataAndBenfordsLaw/ Country Data and Benford's Law], [http://demonstrations.wolfram.com/BenfordsLawFromRatiosOfRandomNumbers/ Benford's Law from Ratios of Random Numbers] at [[Wolfram Demonstrations Project]].\n* [http://www.dspguide.com/CH34.PDF Benford's Law Solved with Digital Signal Processing]\n* {{arxiv|1612.04200}} - Few more Comments on Benford's Law\n{{ProbDistributions|discrete-finite}}\n\n{{DEFAULTSORT:Benford's Law}}\n[[Category:Statistical laws]]\n[[Category:Theory of probability distributions]]\n[[Category:Eponymous scientific concepts]]",
            "slug": "benford-s-law",
            "date_updated": 1533067531100,
            "imported": "https://en.wikipedia.org/wiki/Benford's_law"
        },
        {
            "title": "Benford's law",
            "text": "{{distinguish|text=the unrelated adage [[Benford's law of controversy]]}}\n[[File:Rozklad benforda.svg|thumb|alt=A sequence of decreasing blue bars against a light gray grid background|The distribution of first digits, according to Benford's law. Each bar represents a digit, and the height of the bar is the percentage of numbers that start with that digit.]]\n[[File:Benford-physical.svg|thumb|Frequency of first significant digit of physical constants plotted against Benford's law]]\n{{Use dmy dates|date=June 2013}}\n\n'''Benford's law''', also called '''Newcomb-Benford's law''', '''law of anomalous numbers''', and '''first-digit law''', is an observation about the [[frequency distribution]] of leading digits in many real-life sets of numerical [[data]]. The law states that in many naturally occurring collections of numbers, the leading [[significant digit]] is likely to be small.<ref name=BergerHill2011/> For example, in sets that obey the law, the number {{formatnum:1}} appears as the most significant digit about 30% of the time, while {{formatnum:9}} appears as the most significant digit less than 5% of the time. If the digits were distributed uniformly, they would each occur about 11.1% of the time.<ref>{{cite web | url=http://mathworld.wolfram.com/BenfordsLaw.html|author = Weisstein, Eric W.| title=Benford's Law | website = MathWorld, A Wolfram web resource |access-date = 7 June 2015}}</ref> Benford's law also makes predictions about the distribution of second digits, third digits, digit combinations, and so on.\n\nIt has been shown that this result applies to a wide variety of data sets, including electricity bills, street addresses, stock prices, house prices, population numbers, death rates, lengths of rivers, [[physical constant|physical]] and [[mathematical constant]]s,<ref>Paul H. Kvam, Brani Vidakovic, ''Nonparametric Statistics with Applications to Science and Engineering'', p. 158</ref> and processes described by [[power law]]s (which are very common in nature). It tends to be most accurate when values are distributed across multiple [[Order of magnitude|orders of magnitude]].\n\nThe graph here shows Benford's law for [[Decimal|base 10]]. There is a generalization of the law to numbers expressed in other bases (for example, [[hexadecimal|base 16]]), and also a generalization from leading 1 digit to leading ''n'' digits.\n\nIt is named after physicist [[Frank Benford]], who stated it in 1938 in a paper titled ''The Law of Anomalous Numbers'',<ref name=Benford>{{Cite journal | author = Frank Benford | author-link = Frank Benford | title = The law of anomalous numbers | journal = [[Proc. Am. Philos. Soc.]] | volume = 78 | issue = 4 |url=https://www.scribd.com/document/209534421/The-Law-of-Anomalous-Numbers|date=March 1938 | pages = 551–572 | jstor=984802}} (subscription required)</ref> although it had been previously stated by [[Simon Newcomb]] in 1881.<ref name=Newcomb /><ref name=Formann2010 />\n\n==Definition==\n[[File:Logarithmic scale.png|thumb|upright=1.5|alt=Rectangle with offset bolded axis in lower left, and light gray lines representing logarithms|A [[logarithmic scale]] bar. Picking a random ''x'' position [[Uniform distribution (continuous)|uniformly]] on this number line, roughly 30% of the time the first digit of the number will be 1.]]\nA set of numbers is said to satisfy Benford's law if the leading digit&nbsp;{{mvar|d}} ({{math|{{var|d}}&nbsp;∈&nbsp;{{mset|1,&nbsp;...,&nbsp;9}}}}) occurs with [[probability]]\n: <math>P(d)=\\log_{10}(d+1)-\\log_{10}(d)=\\log_{10} \\left(\\frac{d+1}{d}\\right)=\\log_{10} \\left(1+\\frac{1}{d}\\right)</math>\n\nThe leading digits in such a set thus have the following distribution:\n{| class=\"wikitable\"\n|-\n! {{nobold|{{mvar|d}}}} !! {{tmath|P(d)}} !! Relative size of {{tmath|P(d)}}\n|-\n| 1 || style=\"text-align:right;\"| {{bartable|30.1|%|10}}\n|-\n| 2 || style=\"text-align:right;\"| {{bartable|17.6|%|10}}\n|-\n| 3 || style=\"text-align:right;\"| {{bartable|12.5|%|10}}\n|-\n| 4 || style=\"text-align:right;\"| {{bartable| 9.7|%|10}}\n|-\n| 5 || style=\"text-align:right;\"| {{bartable| 7.9|%|10}}\n|-\n| 6 || style=\"text-align:right;\"| {{bartable| 6.7|%|10}}\n|-\n| 7 || style=\"text-align:right;\"| {{bartable| 5.8|%|10}}\n|-\n| 8 || style=\"text-align:right;\"| {{bartable| 5.1|%|10}}\n|-\n| 9 || style=\"text-align:right;\"| {{bartable| 4.6|%|10}}\n|}\nThe quantity {{tmath|P(d)}} is proportional to the space between {{mvar|d}} and {{math|{{var|d}}&nbsp;+&nbsp;1}} on a [[logarithmic scale]]. Therefore, this is the distribution expected if the [[significand|mantissae]] of the ''logarithms'' of the numbers (but not the numbers themselves) are [[Uniform distribution (continuous)|uniformly and randomly distributed]].\n\nFor example, a number {{mvar|x}}, constrained to lie between 1 and 10, starts with the digit 1 if {{math|1&nbsp;≤&nbsp;{{var|x}}&nbsp;<&nbsp;2}}, and starts with the digit 9 if {{math|9&nbsp;≤&nbsp;{{var|x}}&nbsp;<&nbsp;10}}. Therefore,  {{mvar|x}} starts with the digit 1 if {{math|log&nbsp;1&nbsp;≤&nbsp;log&nbsp; {{var|x}}&nbsp;<&nbsp;log&nbsp;2}}, or starts with 9 if {{math|log&nbsp;9&nbsp;≤&nbsp;log&nbsp;''x''&nbsp;<&nbsp;log&nbsp;10}}. The interval {{math|[log&nbsp;1,&nbsp;log&nbsp;2]}} is much wider than the interval {{math|[log&nbsp;9,&nbsp;log&nbsp;10]}} (0.30 and 0.05 respectively); therefore if log {{mvar|x}} is uniformly and randomly distributed, it is much more likely to fall into the wider interval than the narrower interval, i.e. more likely to start with 1 than with 9; the probabilities are proportional to the interval widths, giving the equation above (as well as the generalization to other bases besides decimal).\n\nBenford's law is sometimes stated in a stronger form, asserting that the [[fractional part]] of the logarithm of data is typically close to uniformly distributed between 0 and 1; from this, the main claim about the distribution of first digits can be derived.\n\n===Benford's law in other bases===\n[[File:Benford_law_bases.svg|thumb|200px|Graphs of ''P''&thinsp;(''d''&thinsp;) for initial digit ''d'' in various bases.<ref>They should strictly be bars but are shown as lines for clarity.</ref> The dotted line shows ''P''&thinsp;(''d''&thinsp;) were the distribution uniform. In [http://upload.wikimedia.org/wikipedia/commons/1/14/Benford_law_bases.svg the SVG image], hover over a graph to show the value for each point.]]\nAn extension of Benford's law predicts the distribution of first digits in other [[radix|bases]] besides [[decimal]]; in fact, any base {{math|''b''&nbsp;≥&nbsp;1}}. The general form is:\n: <math>P(d)=\\log_{b}(d+1)-\\log_{b}(d)=\\log_{b} \\left(1+\\tfrac{1}{d}\\right).</math>\nFor {{math|1=''b''&nbsp;=&nbsp;2}} (the [[Binary numeral system|binary number system]]), Benford's law is true but trivial: All binary numbers (except for 0) start with the digit 1. (On the other hand, the [[#Generalization to digits beyond the first|generalization of Benford's law to second and later digits]] is not trivial, even for binary numbers.)\n\n==Example==\n[[File:Benfords law illustrated by world's countries population.png|Distribution of first digits (in %, red bars) in the [[List of countries by population|population of the 237 countries]] of the world as of July 2010. Black dots indicate the distribution predicted by Benford's law.|thumb|right]]\nExamining a list of the heights of the [[List of tallest buildings and structures in the world#Tallest structure by category|60 tallest structures in the world by category]] shows that 1 is by far the most common leading digit, ''irrespective of the unit of measurement'' (cf. \"scale invariance\", below):\n{| class=\"wikitable\"\n|-\n! rowspan=\"2\" style=\"width:17%;\"| Leading digit\n! colspan=2 | meters\n! colspan=2 | feet\n! rowspan=\"2\" style=\"width:17%;\"| In Benford's law\n|-\n! style=\"width:16%;\"| Count\n! style=\"width:17%;\"| %\n! style=\"width:16%;\"| Count\n! style=\"width:17%;\"| %\n|-\n| 1\n| 26\n| 43.3%\n| 18\n| 30.0%\n| 30.1%\n|-\n| 2\n| 7\n| 11.7%\n| 8\n| 13.3%\n| 17.6%\n|-\n| 3\n| 9\n| 15.0%\n| 8\n| 13.3%\n| 12.5%\n|-\n| 4\n| 6\n| 10.0%\n| 6\n| 10.0%\n| 9.7%\n|-\n| 5\n| 4\n| 6.7%\n| 10\n| 16.7%\n| 7.9%\n|-\n| 6\n| 1\n| 1.7%\n| 5\n| 8.3%\n| 6.7%\n|-\n| 7\n| 2\n| 3.3%\n| 2\n| 3.3%\n| 5.8%\n|-\n| 8\n| 5\n| 8.3%\n| 1\n| 1.7%\n| 5.1%\n|-\n| 9\n| 0\n| 0.0%\n| 2\n| 3.3%\n| 4.6%\n|}\n\nAnother example is the leading digit of {{math|2<sup>''n''</sup>}}:\n\n:1, 2, 4, 8, 1, 3, 6, 1, 2, 5, 1, 2, 4, 8, 1, 3, 6, 1... {{OEIS|A008952}}\n\n==History==\nThe discovery of Benford's law goes back to 1881, when the American astronomer [[Simon Newcomb]] noticed that in [[logarithm]] tables the earlier pages (that started with 1) were much more worn than the other pages.<ref name=Newcomb>{{Cite journal | author = Simon Newcomb | author-link = Simon Newcomb | title = Note on the frequency of use of the different digits in natural numbers | journal = [[American Journal of Mathematics]] | volume = 4 | issue = 1/4 | year = 1881 | pages = 39–40 | doi = 10.2307/2369148 | publisher = American Journal of Mathematics, Vol. 4, No. 1 | jstor = 2369148}} (subscription required)</ref> Newcomb's published result is the first known instance of this observation and includes a distribution on the second digit, as well. Newcomb proposed a law that the probability of a single number ''N'' being the first digit of a number was equal to log(''N''&nbsp;+&nbsp;1)&nbsp;−&nbsp;log(''N'').\n\nThe phenomenon was again noted in 1938 by the physicist [[Frank Benford]],<ref name=Benford/> who tested it on data from 20 different domains and was credited for it. His data set included the surface areas of 335 rivers, the sizes of 3259 US populations, 104 [[physical constant]]s, 1800 [[molecular weight]]s, 5000 entries from a mathematical handbook, 308 numbers contained in an issue of ''[[Reader's Digest]]'', the street addresses of the first 342 persons listed in ''American Men of Science'' and 418 death rates. The total number of observations used in the paper was 20,229. This discovery was later named after Benford (making it an example of [[Stigler's Law]]).\n\nIn 1995, [[Ted Hill (mathematician)|Ted Hill]] proved the result about mixed distributions mentioned [[#Multiple probability distributions|below]].<ref name=Hill1995/>\n\n==Examples and explanations==\nLike other general principles about natural data—for example the fact that many data sets are well approximated by a [[normal distribution]]—there are illustrative examples and explanations that cover many of the cases where Benford's law applies, though there are many other cases where Benford's law applies that do not fall under any of the explanations below.<ref name=BergerHill2011>Arno Berger and Theodore P Hill, [http://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1074&context=rgp_rsr Benford's Law Strikes Back:  No Simple Explanation in Sight for Mathematical Gem, 2011]</ref>\n\n===Prevalence===\nBenford's law tends to apply most accurately to data that are distributed uniformly across several orders of magnitude. As a rule of thumb, the more orders of magnitude that the data evenly covers, the more accurately Benford's law applies. For instance, one can expect that Benford's law would apply to a list of numbers representing the populations of UK settlements, or representing the values of small insurance claims. But if a \"village\" is defined as a settlement with population between 300 and 999, or a \"small insurance claim\" is defined as a claim between $50 and $99, then Benford's law will not apply.<ref name=\"dspguide\">{{cite web|url=http://www.dspguide.com/ch34.htm |title=The Scientist and Engineer's Guide to Digital Signal Processing, chapter 34, Explaining Benford's Law |author=Steven W. Smith |accessdate=15 December 2012}} (especially [http://www.dspguide.com/ch34/10.htm section 10]).</ref><ref name=\"fewster\">{{Cite journal|first=R. M. |last=Fewster |title=A simple explanation of Benford's Law |journal=The American Statistician |year=2009 |volume=63 |issue=1 |pages=26–32 |doi=10.1198/tast.2009.0005 |postscript=<!--None--> |url=https://www.stat.auckland.ac.nz/~fewster/RFewster_Benford.pdf }}</ref>\n\nConsider the probability distributions shown below, referenced to a [[log scale]].<ref name=\"logscale\">This section discusses and plots probability distributions of the logarithms of a variable. This is not the same as taking a regular probability distribution of a variable, and simply plotting it on a log scale. Instead, one multiplies the distribution by a certain function. The log scale distorts the horizontal distances, so the height has to be changed also, in order for the area under each section of the curve to remain true to the original distribution. See, for example, [http://www.dspguide.com/ch34/4.htm]. Specifically: <math>P(\\log x) d(\\log x) = (1/x) P(\\log x) dx</math>.</ref>\nIn each case, the total area in red is the relative probability that the first digit is 1, and the total area in blue is the relative probability that the first digit is 8.\n\n{|\n[[File:BenfordBroad.gif|thumb|left|300px|A broad probability distribution of the log of a variable, shown on a log scale.<ref name=logscale/>]]\n|\n[[File:BenfordNarrow.gif|thumb|left|300px|A narrow probability distribution of the log of a variable, shown on a log scale<ref name=logscale/>]]\n|}\n\nFor the left distribution, the size of the ''areas'' of red and blue are approximately proportional to the ''widths'' of each red and blue bar. Therefore, the numbers drawn from this distribution will approximately follow Benford's law. On the other hand, for the right distribution, the ratio of the areas of red and blue is very different from the ratio of the widths of each red and blue bar. Rather, the relative areas of red and blue are determined more by the ''height'' of the bars than the widths. Accordingly, the first digits in this distribution do not satisfy Benford's law at all.<ref name=fewster />\n\nThus, real-world distributions that span several [[orders of magnitude]] rather uniformly (e.g. populations of villages / towns / cities, stock-market prices), are likely to satisfy Benford's law to a very high accuracy. On the other hand, a distribution that is mostly or entirely within one order of magnitude (e.g. heights of human adults, or IQ scores) is unlikely to satisfy Benford's law very accurately, or at all.<ref name=dspguide /><ref name=fewster /> However, it is not a sharp line: As the distribution gets narrower, the discrepancies from Benford's law ''typically'' increase gradually.\n\nIn terms of conventional [[probability density]] (referenced to a linear scale rather than log scale, i.e. P(x)dx rather than P(log x) d(log x)), the equivalent criterion is that Benford's law will be very accurately satisfied when P(x) is approximately proportional to 1/x over several orders-of-magnitude variation in x.<ref name=\"logscale\" />\n\nThis discussion is not a ''full'' explanation of Benford's law, because we have not explained ''why'' we so often come across data-sets that, when plotted as a probability distribution of the logarithm of the variable, are relatively uniform over several orders of magnitude.<ref name=BergerHillExplain>Arno Berger and Theodore P Hill, [http://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1074&context=rgp_rsr Benford's Law Strikes Back:  No Simple Explanation in Sight for Mathematical Gem, 2011]. The authors describe this argument, but say it \"still leaves open the question of why it is reasonable to assume that the logarithm of the spread, as opposed to the spread itself—or, say, the log log spread—should be large.\" Moreover, they say: \"assuming large spread on a logarithmic scale is ''equivalent'' to assuming an approximate conformance with [Benford's law]\" (italics added), something which they say lacks a \"simple explanation\".</ref>\n\n===Multiplicative fluctuations===\nMany real-world examples of Benford's law arise from multiplicative fluctuations.<ref name=Pietronero>{{cite journal|title=Explaining the uneven distribution of numbers in nature: the laws of Benford and Zipf |author=L. Pietronero |author2=E. Tosatti |author3=V. Tosatti|author4=A. Vespignani |journal=Physica A |year=2001 |volume=293 |pages=297–304 |doi=10.1016/S0378-4371(00)00633-6|bibcode = 2001PhyA..293..297P |url=https://arxiv.org/pdf/cond-mat/9808305v2.pdf |arxiv=cond-mat/9808305 }}</ref> For example, if a stock price starts at $100, and then each day it gets multiplied by a randomly chosen factor between 0.99 and 1.01, then over an extended period the probability distribution of its price satisfies Benford's law with higher and higher accuracy.\n\nThe reason is that the ''logarithm'' of the stock price is undergoing a [[random walk]], so over time its probability distribution will get more and more broad and smooth (see [[#Overview|above]]).<ref name=Pietronero/> (More technically, the [[central limit theorem]] says that multiplying more and more random variables will create a [[log-normal distribution]] with larger and larger variance, so eventually it covers many orders of magnitude almost uniformly.) To be sure of approximate agreement with Benford's Law, the distribution has to be approximately invariant when scaled up by any factor up to 10; a [[lognormal]]ly distributed data set with wide dispersion would have this approximate property.\n\nUnlike multiplicative fluctuations, ''additive'' fluctuations do not lead to Benford's law: They lead instead to [[normal probability distribution]]s (again by the [[central limit theorem]]), which do not satisfy Benford's law. For example, the \"number of heartbeats that I experience on a given day\" can be written as the ''sum'' of many random variables (e.g. the sum of heartbeats per minute over all the minutes of the day), so this quantity is ''unlikely'' to follow Benford's law. By contrast, that hypothetical stock price described above can be written as the ''product'' of many random variables (i.e. the price change factor for each day), so is ''likely'' to follow Benford's law quite well.\n\n===Multiple probability distributions===\n[[Anton Formann|Formann]] provided an alternative explanation by directing attention to the interrelation between the [[Probability distribution|distribution]] of the significant digits and the distribution of the [[dependent variable|observed variable]]. He showed in a simulation study that long right-tailed distributions of a [[random variable]] are compatible with the Newcomb-Benford law, and that for distributions of the ratio of two random variables the fit generally improves.<ref>Formann, A. K. (2010). The Newcomb-Benford law in its relation to some common distributions. ''PLoS ONE, 5,'' e10541.</ref> For numbers drawn from certain distributions (IQ scores, human heights) the Law fails to hold because these variates obey a normal distribution which is known not to satisfy Benford's law,<ref name=Formann2010>{{Cite journal\n| last1 = Formann | first1 = A. K.\n| title = The Newcomb-Benford Law in Its Relation to Some Common Distributions\n| doi = 10.1371/journal.pone.0010541\n| journal = PLoS ONE\n| volume = 5\n| issue = 5\n| pages = e10541\n| year = 2010\n| pmid = 20479878\n| pmc = 2866333\n| editor1-last = Morris\n| editor1-first = Richard James\n|bibcode = 2010PLoSO...510541F }}</ref> since normal distributions can't span several orders of magnitude and the [[Significand|mantissae]] of their logarithms will not be (even approximately) uniformly distributed.\nHowever, if one \"mixes\" numbers from those distributions, for example by taking numbers from newspaper articles, Benford's law reappears. This can also be proven mathematically: if one repeatedly \"randomly\" chooses a [[probability distribution]] (from an uncorrelated set) and then randomly chooses a number according to that distribution, the resulting list of numbers will obey Benford's Law.<ref name=Hill1995>{{Cite journal\n | author = Theodore P. Hill\n | author-link = Theodore P. Hill\n | title = A Statistical Derivation of the Significant-Digit Law\n | journal = Statistical Science\n | volume = 10\n | pages = 354–363\n | year = 1995\n | url = http://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1042&context=rgp_rsr\n | doi = 10.1214/ss/1177009869\n | mr = 1421567\n|format=PDF}}</ref><ref name=Hill1998>{{Cite journal\n | author = Theodore P. Hill\n | author-link = Theodore P. Hill\n | title = The first digit phenomenon\n | journal = [[American Scientist]]\n | volume = 86\n |date=July–August 1998\n | page = 358\n | url = http://people.math.gatech.edu/~hill/publications/PAPER%20PDFS/TheFirstDigitPhenomenonAmericanScientist1996.pdf\n|format=PDF\n | bibcode = 1998AmSci..86..358H\n | doi = 10.1511/1998.4.358\n | issue = 4}}</ref> A similar probabilistic explanation for the appearance of Benford's Law in everyday-life numbers has been advanced by showing that it arises naturally when one considers mixtures of uniform distributions.<ref>Élise Janvresse and Thierry de la Rue (2004), \"From Uniform Distributions to Benford's Law\", ''Journal of Applied Probability'', 41 1203–1210 {{doi|10.1239/jap/1101840566}} {{MR|2122815}} [http://lmrs.univ-rouen.fr/Persopage/Delarue/Publis/PDF/uniform_distribution_to_Benford_law.pdf preprint]</ref>\n\n===Scale invariance===\nIf there is a list of lengths, the distribution of first digits of numbers in the list may be generally similar regardless of whether all the lengths are expressed in metres, or yards, or feet, or inches, etc.\n\nThis is not ''always'' the case. For example, the height of adult humans almost always starts with a 1 or 2 when measured in meters, and almost always starts with 4, 5, 6, or 7 when measured in feet.\n\nBut consider a list of lengths that is spread evenly over many orders of magnitude. For example, a list of 1000 lengths mentioned in scientific papers will include the measurements of molecules, bacteria, plants, and galaxies. If one writes all those lengths in meters, or writes them all in feet, it is reasonable to expect that the distribution of first digits should be the same on the two lists.\n\nIn these situations, where the distribution of first digits of a data set is [[scale invariant]] (or independent of the units that the data are expressed in), the distribution of first digits is always given by Benford's Law.<ref name=Pinkham>Roger S. Pinkham, [http://projecteuclid.org/DPubS?service=UI&version=1.0&verb=Display&handle=euclid.aoms/1177704862 On the Distribution of First Significant Digits], Ann. Math. Statist. Volume 32, Number 4 (1961), 1223-1230.</ref><ref name=wolfram>[http://mathworld.wolfram.com/BenfordsLaw.html MathWorld – Benford's Law]</ref>\n\nFor example, the first (non-zero) digit on this list of lengths should have the same distribution whether the unit of measurement is feet or yards. But there are three feet in a yard, so the probability that the first digit of a length in yards is 1 must be the same as the probability that the first digit of a length in feet is 3, 4, or&nbsp;5; similarly the probability that the first digit of a length in yards is 2 must be the same as the probability that the first digit of a length in feet is 6, 7, or&nbsp;8.  Applying this to all possible measurement scales gives the logarithmic distribution of Benford's law.\n\n==Applications==\n\n===Accounting fraud detection===\nIn 1972, [[Hal Varian]] suggested that the law could be used to detect possible [[fraud]] in lists of socio-economic data submitted in support of public planning decisions. Based on the plausible assumption that people who make up figures tend to distribute their digits fairly uniformly, a simple comparison of first-digit frequency distribution from the data with the expected distribution according to Benford's Law ought to show up any anomalous results.<ref>{{Cite journal|first=Hal |last=Varian |authorlink=Hal Varian |title=Benford's Law (Letters to the Editor) |journal=[[The American Statistician]]|year=1972 |issue=3 |volume=26 |page=65 |doi=10.1080/00031305.1972.10478934 }}</ref> Following this idea, [[Mark Nigrini]] showed that Benford's Law could be used in [[forensic accounting]] and [[audit]]ing as an indicator of accounting and expenses fraud.<ref name=Nigrini>{{Cite journal| first = Mark J. |last=Nigrini | title = I've Got Your Number:How a mathematical phenomenon can help CPAs uncover fraud and other irregulaities | journal = Journal of Accountancy |date=May 1999 | url = http://www.journalofaccountancy.com/Issues/1999/May/nigrini}}</ref> In practice, applications of Benford's Law for [[fraud detection]] routinely use more than the first digit.<ref name=Nigrini/>\n\n===Legal status===\nIn the United States, evidence based on Benford's law has been admitted in criminal cases at the federal, state, and local levels.<ref>{{cite episode| url = http://www.wnyc.org/shows/radiolab/episodes/2009/10/09/segments/137643| title =From Benford to Erdös | series = Radio Lab | serieslink = Radio Lab | airdate = 2009-09-30 | season = | number = 2009-10-09}}</ref>\n\n===Election data===\nBenford's Law has been invoked as evidence of fraud in the [[Iranian presidential election, 2009|2009 Iranian elections]],<ref>Stephen Battersby [https://www.newscientist.com/article/mg20227144.000-statistics-hint-at-fraud-in-iranian-election.html Statistics hint at fraud in Iranian election] ''New Scientist'' 24 June 2009</ref> and also used to analyze other election results. However, other experts consider Benford's Law essentially useless as a statistical indicator of election fraud in general.<ref>Joseph Deckert, Mikhail Myagkov and Peter C. Ordeshook, (2010) ''[http://vote.caltech.edu/sites/default/files/benford_pdf_4b97cc5b5b.pdf The Irrelevance of Benford’s Law for Detecting Fraud in Elections] {{webarchive |url=https://web.archive.org/web/20140517120934/http://vote.caltech.edu/sites/default/files/benford_pdf_4b97cc5b5b.pdf |date=17 May 2014 }}'', Caltech/MIT Voting Technology Project Working Paper No. 9</ref><ref>Charles R. Tolle, Joanne L. Budzien, and Randall A. LaViolette (2000)  ''[[:doi:10.1063/1.166498|Do dynamical systems follow Benford?s Law?]]'', Chaos 10, 2, pp.331–336 (2000); {{doi|10.1063/1.166498}}</ref>\n\n===Macroeconomic data===\nSimilarly, the macroeconomic data the Greek government reported to the European Union before entering the [[eurozone]] was shown to be probably fraudulent using Benford's law, albeit years after the country joined.<ref>Müller, Hans Christian: ''[https://www.forbes.com/sites/timworstall/2011/09/12/greece-was-lying-about-its-budget-numbers/ Greece Was Lying About Its Budget Numbers]''. ''[[Forbes]]''. 12 September 2011.</ref>\n\n=== Price digit analysis ===\nBenford's law as a benchmark for the investigation of price digits has been successfully introduced into the context of pricing research. The importance of this benchmark for detecting irregularities in prices was first demonstrated in a Europe-wide study<ref>{{Cite journal|last=Sehity|first=Tarek el|last2=Hoelzl|first2=Erik|last3=Kirchler|first3=Erich|date=2005-12-01|title=Price developments after a nominal shock: Benford's Law and psychological pricing after the euro introduction|url=http://www.sciencedirect.com/science/article/pii/S0167811605000522|journal=International Journal of Research in Marketing|volume=22|issue=4|pages=471–480|doi=10.1016/j.ijresmar.2005.09.002}}</ref> which investigated consumer price digits before and after the euro introduction for price adjustments. The introduction of the euro in 2002, with its various exchange rates, distorted existing nominal price patterns while at the same time retaining real prices. While the first digits of [[Real versus nominal value (economics)|nominal prices]] distributed according to Benford's Law, the study showed a clear deviation from this benchmark for the second and third digits in nominal market prices with a clear trend towards [[psychological pricing]] after the nominal shock of the euro introduction.\n\n===Genome data===\nThe number of [[open reading frame]]s and their relationship to genome size differs between [[eukaryote]]s and [[prokaryote]]s with the former showing a log-linear relationship and the latter a linear relationship. Benford's law has been used to test this observation with an excellent fit to the data in both cases.<ref name=Friar2012>{{cite journal | last1 = Friar | first1 = JL | last2 = Goldman | first2 = T | last3 = Pérez-Mercader | first3 = J | year = 2012 | title = Genome sizes and the benford distribution | journal = PLOS ONE | volume = 7 | issue = 5| page = e36624 | doi = 10.1371/journal.pone.0036624 |arxiv = 1205.6512 |bibcode = 2012PLoSO...736624F | pmid=22629319 | pmc=3356352}}</ref>\n\n===Scientific fraud detection===\nA test of regression coefficients in published papers showed agreement with Benford's law.<ref name=Diekmann2007>Diekmann A (2007) Not the First Digit! Using Benford's Law to detect fraudulent scientific data. J Appl Stat 34 (3) 321–329, {{doi|10.1080/02664760601004940}}</ref> As a comparison group subjects were asked to fabricate statistical estimates. The fabricated results failed to obey Benford's law.\n\n==Statistical tests==\nAlthough the [[chi square]]d test has been used to test for compliance with Benford's law it has low statistical power when used with small samples.\n\nThe [[Kolmogorov–Smirnov test]] and the [[Kuiper test]] are more powerful when the sample size is small particularly when Stephens's corrective factor is used.<ref name=Stephens1970>{{cite journal |last=Stephens |first=M. A. |year=1970 |title=Use of the Kolmogorov–Smirnov, Cramér–Von Mises and Related Statistics without Extensive Tables |journal=[[Journal of the Royal Statistical Society, Series B]] |volume=32 |issue=1 |pages=115–122 |url=}}</ref> These tests may be overly conservative when applied to discrete distributions. Values for the Benford test have been generated by Morrow.<ref name=Morrow2010>Morrow, J. (2010) [http://www.johnmorrow.info/projects/benford/benfordMain.pdf \"Benford’s Law, Families of Distributions and a test basis\"], UW-Madison</ref> The critical values of the test statistics are shown below:\n\n{| class=\"wikitable\"\n|-\n! {{diagonal split header|Test|''&alpha;''}}\n! 0.10\n! 0.05\n! 0.01\n|-\n| Kuiper Test\n| 1.191\n| 1.321\n| 1.579\n|-\n| Kolmogorov–Smirnov\n| 1.012\n| 1.148\n| 1.420\n|}\n\nThese critical values provide the minimum test statistic values required to reject the hypothesis of compliance with Benford's law at the given [[significance level]]s.\n\nTwo alternative tests specific to this law have been published: first, the max (''m'') statistic<ref name=Leemis2000>{{cite journal |last1=Leemis |first1=L. M. |last2=Schmeiser |first2=B. W. |last3=Evans |first3=D. L. |year=2000 |title=Survival distributions satisfying Benford's Law |journal=The Amererican Statistician |volume=54 |issue=4|pages=236–241 |doi=10.1080/00031305.2000.10474554}}</ref> is given by\n:<math>m = \\sqrt{N}\\cdot\\operatorname*\\max_{i=1}^{9} \\Big\\{|\\Pr (X \\text{ has FSD}=i)-\\log_{10}(1+1/i)| \\Big\\}\\,</math>\nand secondly, the distance (''d'') statistic<ref name=Cho2007>{{cite journal |last1=Cho |first1=W. K. T. |last2=Gaines |first2=B. J. |year=2007 |title=Breaking the (Benford) law: Statistical fraud detection in campaign finance |journal=The Amererican Statistician |volume=61 |pages=218–223 |doi=10.1198/000313007X223496 |issue=3}}</ref> is given by\n:<math>d= \\sqrt{N \\cdot \\sum_{i=1}^{9}\\Big[\\Pr ( X \\text{ has FSD}=i ) - \\log_{10}(1+1/i) \\Big]^{2}},</math>\nwhere FSD is the First Significant Digit and {{mvar|N}} is the sample size. Morrow has determined the critical values for both these statistics, which are shown below:<ref name=\"Morrow2010\" />\n\n{| class=\"wikitable\"\n|-\n! {{diagonal split header|Statistic|''&#9082;''}}\n! 0.10\n! 0.05\n! 0.01\n|-\n| Leemis' ''m''\n| 0.851\n| 0.967\n| 1.212\n|-\n| Cho–Gaines' ''d''\n| 1.212\n| 1.330\n| 1.569\n|}\n\nNigrini<ref name=Nigrini1996>{{cite journal |last=Nigrini |first=M. |year=1996 |title=A taxpayer compliance application of Benford's Law |journal=J Amer Tax Assoc |volume=18 |pages=72–91}}</ref> has suggested the use of a [[Z statistic|''z'' statistic]]\n\n: <math> z = \\frac { \\, | p_o - p_e | - \\frac{1}{2n} \\, }  { s_i } </math>\nwith\n: <math> s_i =  \\left[ \\frac { p_e ( 1 - p_e ) }  { n } \\right]^{1/2}, </math>\n\nwhere |''x''| is the absolute value of ''x'', ''n'' is the sample size, {{sfrac|1|2''n''}} is a continuity correction factor, ''p''<sub>e</sub> is the proportion expected from Benford's law and ''p''<sub>o</sub> is the observed proportion in the sample.\n\nMorrow has also shown that for any random variable ''X'' (with a continuous pdf) divided by its standard deviation (''σ''), a value ''A'' can be found such that the probability of the distribution of the first significant digit of the random variable ({{sfrac|''X''|''σ''}})<sup>''A''</sup> will differ from Benford's Law by less than ''ε'' > 0.<ref name=\"Morrow2010\" /> The value of ''A'' depends on the value of ''ε'' and the distribution of the random variable.\n\nA method of accounting fraud detection based on bootstrapping and regression has been proposed.<ref name=Suh2011>{{cite journal |last1=Suh |first1=I. S. |last2=Headrick |first2=T. C. |last3=Minaburo |first3=S. |year=2011 |title=An effective and efficient analytic technique: A bootstrap regression procedure and Benford's Law |journal=J Forensic & Investigative Accounting |volume=3 |issue=3}}</ref>\n\nIf the goal is to conclude agreement with the Benford's law rather than disagreement, then the [[goodness-of-fit test]]s mentioned above are inappropriate. In this case the specific [[Equivalence test|tests for equivalence]] should be applied. An empirical distribution is called equivalent to the Benford's law if a distance  (for example total variation distance or the usual Euclidean distance) between the probability mass functions is sufficiently small. This method of testing with application to Benford's law is described in Ostrovski (2017).<ref>{{cite journal|last1=Ostrovski|first1=Vladimir|date=May 2017|title=Testing equivalence of multinomial distributions|ssrn=2907258|journal=Statistics & Probability Letters|volume=124|pages=77–82|doi=10.1016/j.spl.2017.01.004|via=}}</ref>\n\n==Generalization to digits beyond the first==\n[[File:Benford_law_log_log_graph.svg|thumb|300px|Log-log graph of the probability that a number starts with the digit(s) ''n'', for a distribution satisfying Benford's law. The points show the exact formula, P(n)=log<sub>10</sub>(1+1/n). The graph tends towards the dashed asymptote passing through {{nobr|(1, log<sub>10&thinsp;</sub>''e'')}} with slope &minus;1 in log-log scale. The example in yellow shows that the probability of a number starts with 314 is around 0.00138. The dotted lines show the probabilities for a uniform distribution for comparison. In [http://upload.wikimedia.org/wikipedia/commons/1/14/Benford_law_log_log_graph.svg the SVG image], hover over a point to show its values.]]\nIt is possible to extend the law to digits beyond the first.<ref name=Hill1995sigdig>[[Theodore P. Hill]], \"The Significant-Digit Phenomenon\", The American Mathematical Monthly, Vol. 102, No. 4, (Apr., 1995), pp. 322–327. [https://www.jstor.org/stable/2974952 Official web link (subscription required)]. [http://digitalcommons.calpoly.edu/cgi/viewcontent.cgi?article=1041&context=rgp_rsr Alternate, free web link].</ref> In particular, the probability of encountering a number starting with the string of digits ''n'' is given by:\n\n:<math> \\log_{ 10 } \\left( n + 1 \\right )- \\log_{ 10 } \\left( n \\right ) = \\log_{ 10 } \\left( 1 + \\frac{ 1 }{ n } \\right)</math>\n\nFor example, the probability that a number starts with the digits 3,&nbsp;1,&nbsp;4 is {{math|log<sub>10</sub>(1&nbsp;+&nbsp;1/314)&nbsp;≈&nbsp;0.00138}}, as in the figure on the right.\n\nThis result can be used to find the probability that a particular digit occurs at a given position within a number. For instance, the probability that a \"2\" is encountered as the second digit is<ref name=Hill1995sigdig />\n\n:<math> \\log_{ 10 } \\left( 1 + \\frac{ 1 }{ 12 } \\right ) + \\log_{ 10 } \\left( 1 + \\frac{ 1 }{ 22 } \\right )+ \\cdots + \\log_{ 10 } \\left( 1 + \\frac{ 1 }{ 92 } \\right) \\approx 0.109 </math>\n\nAnd the probability that ''d'' (''d''&nbsp;=&nbsp;0,&nbsp;1,&nbsp;...,&nbsp;9) is encountered as the ''n''-th (''n''&nbsp;>&nbsp;1) digit is\n\n:<math> \\sum_{ k = 10^{ n - 2 } }^{ 10^{ n - 1 } - 1 } \\log_{ 10 } \\left( 1 + \\frac{ 1 }{ 10k + d } \\right )</math>\n\nThe distribution of the ''n''-th digit, as ''n'' increases, rapidly approaches a uniform distribution with 10% for each of the ten digits, as shown below.<ref name=Hill1995sigdig /> Four digits is often enough to assume a uniform distribution of 10% as '0' appears 10.0176% of the time in the fourth digit while '9' appears 9.9824% of the time.\n{| class=\"wikitable\"\n!Digit\n!0\n!1\n!2\n!3\n!4\n!5\n!6\n!7\n!8\n!9\n|-\n!1st\n| {{N/A}}\n|30.1%\n|17.6%\n|12.5%\n|9.7%\n|7.9%\n|6.7%\n|5.8%\n|5.1%\n|4.6%\n|-\n!2nd\n|12%\n|11.4%\n|10.9%\n|10.4%\n|10%\n|9.7%\n|9.3%\n|9%\n|8.8%\n|8.5%\n|-\n!3rd\n|10.2%\n|10.1%\n|10.1%\n|10.1%\n|10%\n|10%\n|9.9%\n|9.9%\n|9.9%\n|9.8%\n|}\n\n==Tests with common distributions==\nBenford's law was empirically tested against the numbers (up to the 10th digit) generated by a number of important distributions, including the [[uniform distribution (discrete)|uniform distribution]], the [[exponential distribution]], the [[half-normal distribution]], the [[Truncated normal distribution|right-truncated normal]], the [[normal distribution]], the [[chi square distribution]] and the [[log normal distribution]].<ref name=Formann2010 /> In addition to these the [[ratio distribution]] of two uniform distributions, the ratio distribution of two exponential distributions, the ratio distribution of two half-normal distributions, the ratio distribution of two right-truncated normal distributions, the ratio distribution of two chi-square distributions (the [[F distribution]]) and the [[log normal]] distribution were tested.\n\nThe uniform distribution as might be expected does not obey Benford's law. In contrast, the ratio distribution of two uniform distributions is well described by Benford's law. Benford's law also describes the exponential distribution and the ratio distribution of two exponential distributions well. Although the half-normal distribution does not obey Benford's law, the ratio distribution of two half-normal distributions does. Neither the right-truncated normal distribution nor the ratio distribution of two right-truncated normal distributions are well described by Benford's law. This is not surprising as this distribution is weighted towards larger numbers. Neither the normal distribution nor the ratio distribution of two normal distributions (the [[Cauchy distribution]]) obey Benford's law. The fit of chi square distribution depends on the [[degrees of freedom (statistics)|degrees of freedom]] (df) with good agreement with df = 1 and decreasing agreement as the df increases. The F distribution is fitted well for low degrees of freedom. With increasing dfs the fit decreases but much more slowly than the chi square distribution. The fit of the log-normal distribution depends on the [[mean]] and the [[variance]] of the distribution. The variance has a much greater effect on the fit than does the mean. Larger values of both parameters result in better agreement with the law. The ratio of two log normal distributions is a log normal so this distribution was not examined.\n\nOther distributions that have been examined include the [[Muth distribution]], [[Gompertz distribution]], [[Weibull distribution]], [[gamma distribution]], [[log-logistic distribution]] and the [[exponential power distribution]] all of which show reasonable agreement with the law.<ref name=Leemis2000 /><ref name=\"Dümbgen2008\">{{cite journal | last1 = Dümbgen | first1 = L | last2 = Leuenberger | first2 = C | year = 2008 | title = Explicit bounds for the approximation error in Benford's Law | url = | journal = Elect Comm in Probab | volume = 13 | issue = | pages = 99–112 | doi = 10.1214/ECP.v13-1358 | arxiv = 0705.4488 }}</ref> The [[Gumbel distribution]] – a density increases with increasing value of the random variable – does not show agreement with this law.<ref name=\"Dümbgen2008\"/>\n\n==Distributions known to obey Benford's law==\nSome well-known infinite [[integer sequence]]s {{not a typo|provably}} satisfy Benford's Law exactly (in the [[asymptotic limit]] as more and more terms of the sequence are included). Among these are the [[Fibonacci number]]s,<ref>{{cite journal | last1 = Washington | first1 = L. C. | year = 1981 | title = Benford's Law for Fibonacci and Lucas Numbers | url = | journal = [[The Fibonacci Quarterly]] | volume = 19 | issue = 2| pages = 175–177 }}</ref><ref>{{cite journal | last1 = Duncan | first1 = R. L. | year = 1967 | title = An Application of Uniform Distribution to the Fibonacci Numbers | url = | journal = [[The Fibonacci Quarterly]] | volume = 5 | issue = | pages = 137–140 }}</ref> the [[factorial]]s,<ref>{{cite journal | last1 = Sarkar | first1 = P. B. | year = 1973 | title = An Observation on the Significant Digits of Binomial Coefficients and Factorials | url = | journal = [[Sankhya]] B | volume = 35 | issue = | pages = 363–364 }}</ref> the powers of&nbsp;2,<ref name=powers>In general, the sequence ''k''<sup>1</sup>, ''k''<sup>2</sup>, ''k''<sup>3</sup>, etc., satisfies Benford's Law exactly, under the condition that log<sub>10</sub> ''k'' is an [[irrational number]]. This is a straightforward consequence of the [[equidistribution theorem]].</ref><ref>That the first 100 powers of&nbsp;2 approximately satisfy Benford's Law is mentioned by Ralph Raimi. {{cite journal | last1 = Raimi | first1 = Ralph A. | year = 1976 | title = The First Digit Problem | url = | journal = [[American Mathematical Monthly]] | volume = 83 | issue = 7| pages = 521–538 | doi=10.2307/2319349}}</ref> and the powers of ''almost'' any other number.<ref name=powers />\n\nLikewise, some continuous processes satisfy Benford's Law exactly (in the asymptotic limit as the process continues through time). One is an [[exponential growth]] or [[exponential decay|decay]] process: If a quantity is exponentially increasing or decreasing in time, then the percentage of time that it has each first digit satisfies Benford's Law asymptotically (i.e. increasing accuracy as the process continues through time).\n\n==Distributions known to disobey Benford's law==\nSquare roots and reciprocals do not obey this law.<ref name=Raimi1976>{{cite journal |last=Raimi |first=Ralph A. |date=Aug–Sep 1976 |title=The first digit problem |url= |journal=[[American Mathematical Monthly]] |volume=83 |issue=7 |pages=521–538 |doi=10.2307/2319349}}</ref> Also, Benford's law does not apply to [[Unary numeral system|unary systems]] such as [[tally marks]].  Telephone directories violate Benford's law because the numbers have a mostly fixed length and do not have the initial digit 1.<ref>The [[North American Numbering Plan]] uses 1 as a long distance prefix, and much of the rest of the world reserves it to begin special 3-digit numbers like [[112 (emergency telephone number)]].</ref>  Benford's law is violated by the populations of all places with population at least 2500 from five US states according to the 1960 and 1970 censuses, where only 19% began with digit 1 but 20% began with digit 2, for the simple reason that the truncation at 2500 introduces statistical bias.<ref name=Raimi1976/> The terminal digits in pathology reports violate Benford's law due to rounding, and the fact that terminal digits are never expected to follow Benford's law in the first place.<ref name=Beer2009>{{cite journal |last=Beer |first1=Trevor W. |year=2009 |title=Terminal digit preference: beware of Benford's Law |url= |journal=[[J. Clin. Pathol.]] |volume=62 |issue=2 |page=192 |doi=10.1136/jcp.2008.061721}}</ref>\n\n==Criteria for distributions expected and not expected to obey Benford's Law==\nA number of criteria—applicable particularly to accounting data—have been suggested where Benford's Law can be expected to apply and not to apply.<ref name=Durtschi2004>{{cite journal | last1 = Durtschi | first1 = C | last2 = Hillison | first2 = W | last3 = Pacini | first3 = C | year = 2004 | title = The effective use of Benford's Law to assist in detecting fraud in accounting data | url = | journal = J Forensic Accounting | volume = 5 | issue = | pages = 17–34 }}</ref>\n\n;Distributions that can be expected to obey Benford's Law:\n* When the mean is greater than the median and the skew is positive\n* Numbers that result from mathematical combination of numbers: e.g. quantity × price\n* Transaction level data: e.g. disbursements, sales\n* Numbers produced when doing any multiplicative calculations with an Oughtred slide rule, since the answers naturally fall into the right logarithmic distribution.\n\n;Distributions that would not be expected to obey Benford's Law:\n* Where numbers are assigned sequentially: e.g. check numbers, invoice numbers\n* Where numbers are influenced by human thought: e.g. prices set by psychological thresholds ($1.99)\n* Accounts with a large number of firm-specific numbers: e.g. accounts set up to record $100 refunds\n* Accounts with a built-in minimum or maximum\n* Where no transaction is recorded\n\n==Moments==\nMoments of random variables for the digits 1 to 9 following this law have been calculated:<ref name=Scott2001>Scott, P.D.; Fasli, M. (2001) [http://dces.essex.ac.uk/technical-reports/2001/CSM-349.pdf \"Benford’s Law: An empirical investigation and a novel explanation\"]. ''CSM Technical Report'' 349, Department of Computer Science, Univ. Essex</ref>\n* [[mean]] 3.440\n* [[variance]] 6.057\n* [[skewness]] 0.796\n* [[kurtosis]] −0.548\n\nFor the first and second digit distribution these values are also known:<ref name=Suh2010>{{cite journal | last1 = Suh | first1 = I.S. | last2 = Headrick | first2 = T.C. | year = 2010 | title = A comparative analysis of the bootstrap versus traditional statistical procedures applied to digital analysis based on Benford's Law | url = http://www.bus.lsu.edu/accounting/faculty/lcrumbley/jfia/Articles/Abstracts/abs_2010v2n2a7.pdf | format = PDF | journal = Journal of Forensic and Investigative Accounting | volume = 2 | issue = 2| pages = 144–175 }}</ref>\n* [[mean]] 38.590\n* [[variance]] 621.832\n* [[skewness]] 0.772\n* [[kurtosis]] −0.547\n\nA table of the exact probabilities for the joint occurrence of the first two digits according to Benford's law is available,<ref name=Suh2010/> as is the population correlation between the first and second digits:<ref name=Suh2010/> {{nowrap|1=''ρ'' = 0.0561 }}.\n\n==See also==\n* [[Predictive analytics#Fraud detection|Fraud detection in predictive analytics]]\n* [[Zipf's law]]\n\n==References==\n{{Reflist|30em}}\n\n==Further reading==\n{{Refbegin}}\n* {{Cite journal\n |author1=Arno Berger  |author2=Theodore P. Hill\n | title =What is…Benford's Law?\n | journal = Notices of the AMS\n | volume = 64\n | issue = 2\n | year = 2017\n | pages = 132–134\n | url = http://www.ams.org/publications/journals/notices/201702/rnoti-p132.pdf\n | doi=10.1090/noti1477\n}}\n* {{Cite book\n |author1=Arno Berger  |author2=Theodore P. Hill\n  |lastauthoramp=yes | title = An Introduction to Benford's Law\n | publisher = Princeton University Press\n | year = 2015\n | isbn = 978-0-691-16306-2\n}}\n* Alex Ely Kossovsky. ''[http://www.worldscientific.com/worldscibooks/10.1142/9089 Benford's Law: Theory, the General Law of Relative Quantities, and Forensic Fraud Detection Applications]'', 2014, World Scientific Publishing. {{ISBN|978-981-4583-68-8}}.\n* {{cite web|url=http://mathworld.wolfram.com/BenfordsLaw.html |title=Benford's Law – from Wolfram MathWorld |publisher=Mathworld.wolfram.com |date=14 June 2012 |accessdate=2012-06-26}}\n* {{Cite book\n | author = Mark J. Nigrini\n | title = Benford's Law: Applications for Forensic Accounting, Auditing, and Fraud Detection\n | publisher = John Wiley & Sons\n | year = 2012\n | page = 330\n | isbn = 978-1-118-15285-0\n}}\n* {{Cite journal\n | author = Alessandro Gambini\n | title = Probability of digits by dividing random numbers: A ψ and ζ functions approach\n | journal = Expositiones Mathematicae\n | volume = 30\n | year = 2012\n | pages = 223–238\n | doi = 10.1016/j.exmath.2012.03.001\n | last2 = Hoelzl\n | first2 = E\n | last3 = Kirchler\n | first3 = E\n | display-authors = 1\n | issue = 4\n}}\n* {{Cite journal\n | author = Sehity\n | title = Price developments after a nominal shock: Benford's Law and psychological pricing after the euro introduction\n | journal = International Journal of Research in Marketing\n | volume = 22\n | year = 2005\n | pages = 471–480\n | doi = 10.1016/j.ijresmar.2005.09.002\n | last2 = Hoelzl\n | first2 = Erik\n | last3 = Kirchler\n | first3 = Erich\n  | author3-link=Erich Kirchler\n| issue = 4\n}}\n* {{Cite journal\n | year = 2011\n | title =  Scatter and regularity implies Benford's Law...and more\n | journal = Zenil: Randomness through computation: some answers, more questions\n | volume = {{ISBN|9814327751}}\n | issue = \n | pages = 58–69\n | doi = 10.1142/9789814327756_0004\n|author1 = Nicolas Gauvrit|author2 = Jean-Paul Delahaye| authorlink2 =  Jean-Paul Delahaye\n | bibcode =  2009arXiv0910.1359G\n | arxiv =  0910.1359\n }}\n* {{Cite journal\n | author = Bernhard Rauch\n | author2 = Max Göttsche\n | author3 = Gernot Brähler\n | author4 = Stefan Engel\n |date=August 2011\n | title = Fact and Fiction in EU-Governmental Economic Data\n | journal = [[German Economic Review]]\n | volume = 12\n | issue = 3\n | pages = 243–255\n | doi = 10.1111/j.1468-0475.2011.00542.x\n}}\n* {{Cite journal\n |author1=Wendy Cho  |author2=Brian Gaines\n  |lastauthoramp=yes |date=August 2007\n | title = Breaking the (Benford) Law: statistical fraud detection in campaign finance\n | journal = [[The American Statistician]]\n | volume = 61\n | issue = 3\n | pages = 218–223\n | doi = 10.1198/000313007X223496\n}}\n* {{cite journal | title = The Law of Harmony in Statistics: An Investigation of the Metrical Interdependence of Social Phenomena. by L. V. Furlan |  last1 = Geiringer | first1 = Hilda | journal = Journal of the American Statistical Association | year = 1948 | volume = 43 | pages = 325–328 | publisher = American Statistical Association | jstor = 2280379 | doi = 10.2307/2280379 | last2 = Furlan | first2 = L. V. | issue = 242 |  authorlink1 = Hilda Geiringer }}\n\n{{Refend}}\n\n==External links==\n{{commons category}}\n\n===General audience===\n* [http://www.benfordonline.net/ Benford Online Bibliography], an online bibliographic database on Benford's Law.\n* [http://www.nigrini.com/benfordslaw.htm Companion website for Benford's Law by Mark Nigrini] Website includes 15 data sets, 10 Excel templates, photos, documents, and other miscellaneous items related to Benford's Law\n* [http://www.rexswain.com/benford.html Following Benford's Law, or Looking Out for No. 1], 1998 article from ''[[The New York Times]]''.\n* [https://web.archive.org/web/20121112200403/http://www.bbc.co.uk/radio4/science/further5.shtml A further five numbers: number 1 and Benford's law], [[BBC]] radio segment by [[Simon Singh]]\n* [http://www.wnyc.org/shows/radiolab/episodes/2009/10/09/segments/137643 From Benford to Erdös], Radio segment from the [[Radiolab]] program\n* [http://plus.maths.org/issue9/features/benford/index-gifd.html Looking out for number one] by Jon Walthoe, Robert Hunt and Mike Pearson, ''Plus Magazine'', September 1999\n* [http://www.kirix.com/blog/2008/07/22/fun-and-fraud-detection-with-benfords-law/ Video showing Benford's Law applied to Web Data (incl. Minnesota Lakes, US Census Data and Digg Statistics)]\n* [https://web.archive.org/web/20110514041058/https://mpi-inf.mpg.de/~fietzke/benford.html An illustration of Benford's Law], showing first-digit distributions of various sequences evolve over time, interactive.\n* [http://blog.iharder.net/2010/11/10/benford-how-to-generate-your-own-benfords-law-numbers/ Generate your own Benford numbers] A script for generating random numbers compliant with Benford's Law.\n* [http://testingbenfordslaw.com/ Testing Benford's Law] An open source project showing Benford's Law in action against publicly available datasets.\n* [http://www.metrica-bi.de/fraud-analysis-with-ssas-benfords-law-test-in-olap-cubes/ Testing Benford’s Law in OLAP Cubes] Implementation with Microsoft Analysis Services.\n* {{cite web|last=Mould|first=Steve|title=Number 1 and Benford's Law|url=http://www.numberphile.com/videos/benfords_law.html|work=Numberphile|publisher=[[Brady Haran]]}}\n* [https://www.independent.co.uk/property/property-news-roundup-a-third-of-property-values-begin-with-a-1-9154071.html A third of property values begin with a 1] An example of Benford's Law appearing in house price data.\n* [https://www.youtube.com/watch?v=4iz4EHriYz0 Benford's Very Strange Law - Professor John D. Barrow], lecture on Benford's Law.\n* Interactive graphic: [http://www.math.wm.edu/~leemis/chart/UDR/UDR.html Univariate Distribution Relationships]\n\n===More mathematical===\n* {{MathWorld | urlname=BenfordsLaw | title=Benford's Law}}\n* [http://terrytao.wordpress.com/2009/07/03/benfords-law-zipfs-law-and-the-pareto-distribution/ Benford’s law, Zipf’s law, and the Pareto distribution] by [[Terence Tao]]\n* [http://demonstrations.wolfram.com/CountryDataAndBenfordsLaw/ Country Data and Benford's Law], [http://demonstrations.wolfram.com/BenfordsLawFromRatiosOfRandomNumbers/ Benford's Law from Ratios of Random Numbers] at [[Wolfram Demonstrations Project]].\n* [http://www.dspguide.com/CH34.PDF Benford's Law Solved with Digital Signal Processing]\n* {{arxiv|1612.04200}} - Few more Comments on Benford's Law\n{{ProbDistributions|discrete-finite}}\n\n{{DEFAULTSORT:Benford's Law}}\n[[Category:Statistical laws]]\n[[Category:Theory of probability distributions]]\n[[Category:Eponymous scientific concepts]]",
            "slug": "benford-s-law",
            "date_updated": 1533067532700,
            "imported": "https://en.wikipedia.org/wiki/Benford's_law"
        }
    ]
}