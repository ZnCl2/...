{
    "article": [
        {
            "title": "tensor product",
            "text": "In [[mathematics]], the '''tensor product''' {{math|''V'' ⊗ ''W''}} of two vector spaces {{math|''V''}} and {{math|''W''}} (over the same [[Field_(mathematics)|field]]) is itself a vector space, together with an operation of [[Bilinear map|bilinear composition]], denoted by {{math|⊗}}, from ordered pairs in the [[Cartesian product]] {{math|''V'' × ''W''}} into {{math|V ⊗ W}}, in a way that generalizes the [[outer product]].  The tensor product of {{math|''V''}} and {{math|''W''}} is the vector space generated by the symbols {{math|''v'' ⊗ ''w''}}, with {{math|''v'' ∈ ''V''}} and {{math|''w'' ∈ ''W''}}, in which the relations of bilinearity are imposed for the product operation {{math|⊗}}, ''and no other relations'' are assumed to hold.  The tensor product space is thus the \"[[free object|freest]]\" (or most general) such vector space, in the sense of having the fewest constraints.\n\nThe tensor product of (finite dimensional) vector spaces has dimension equal to the product of the dimensions of the two factors:\n:<math>\\dim(V\\otimes W) = \\dim V \\times \\dim W.</math>\nIn particular, this distinguishes the tensor product from the [[direct sum]] vector space, whose dimension is the sum of the dimensions of the two summands:\n:<math>\\dim(V\\oplus W) = \\dim V + \\dim W.</math>\n\nMore generally, the tensor product can be extended to other [[category (mathematics)|categories]] of mathematical objects in addition to vector spaces, such as to  [[matrix (mathematics)|matrices]], [[tensors]], [[algebra over a field|algebras]], [[topological vector spaces]], and [[module (mathematics)|modules]].  In each such case the tensor product is characterized by a similar [[#Universal property|universal property]]: it is the freest [[bilinear operator|bilinear operation]].  The general concept of a \"tensor product\" is captured by [[monoidal category|monoidal categories]]; that is, the class of all things that have a tensor product is a monoidal category.\n\n==Tensor product of vector spaces==\nThe tensor product of two [[vector space]]s {{math|''V''}} and {{math|''W''}} over a [[field (mathematics)|field]] {{math|''K''}} is another vector space over {{math|''K''}}. It is denoted {{math|''V'' ⊗<sub>''K''</sub> ''W''}}, or {{math|''V'' ⊗ ''W''}} when the underlying field {{math|''K''}} is understood.\n\nIf <math>V</math> has a basis <math>e_1,\\dots,e_m</math> and <math>W</math> has a basis <math>f_1,\\dots,f_n</math>, then the tensor product <math>V\\otimes W</math> can be taken to be a vector space spanned by a basis consisting of all pair-wise products of elements from the two bases; each such basis element of <math>V\\otimes W</math> is denoted <math>e_i\\otimes f_j</math>.  For any vectors <math>v = \\sum\\nolimits_i v_i e_i \\in V</math> and <math>w = \\sum\\nolimits_j w_j f_j \\in W,</math> there is a corresponding product vector <math>v\\otimes w</math> in <math>V\\otimes W</math> given by <math>\\sum\\nolimits_{ij} v_i w_j (e_i\\otimes f_j) \\in V\\otimes W.</math>  This product operation <math>\\otimes : V \\times W \\rightarrow V\\otimes W</math> is quickly verified to be bilinear.\n\nAs an example, letting <math>V = W = \\mathbb{R}^3</math> (considered as a vector space over the field of real numbers) and considering the standard basis set <math>\\{\\hat{x},\\hat{y},\\hat{z}\\}</math> for each, the tensor product <math>V\\otimes W</math> is spanned by the nine basis vectors <math>\\{\\hat{x}\\otimes\\hat{x},\\hat{x}\\otimes\\hat{y},\\hat{x}\\otimes\\hat{z},\\hat{y}\\otimes\\hat{x},\\hat{y}\\otimes\\hat{y},\\hat{y}\\otimes\\hat{z},\\hat{z}\\otimes\\hat{x},\\hat{z}\\otimes\\hat{y},\\hat{z}\\otimes\\hat{z}\\},</math> and is isomorphic to <math>\\mathbb{R}^9.</math>  For vectors <math>v=(1,2,3), w=(1,0,0)\\in \\mathbb{R}^3,</math> the tensor product <math>v\\otimes w = \\hat{x}\\otimes\\hat{x} + 2\\hat{y}\\otimes\\hat{x} + 3\\hat{z}\\otimes\\hat{x}.</math>\n\nThe above definition relies on a choice of basis, which can not be done canonically for a generic vector space.  However, any two choices of basis lead to isomorphic tensor product spaces (c.f. the universal property described below).  Alternatively, the tensor product may be defined in an expressly basis-independent manner as a quotient space of a free vector space over {{math|''V'' × ''W''}}.  This approach is described below.\n\n===The free vector space===\nThe definition of {{math|⊗}} requires the notion of the [[free vector space]] {{math|''F''(''S'')}} on some [[set (mathematics)|set]] {{math|''S''}}, a vector space whose basis is [[Index set|indexed]] by {{math|''S''}}. {{math|''F''(''S'')}} is defined as the set of all functions {{math|''g''}} from {{math|''S''}} to a given field {{math|''K''}} that have [[finite support]]; i.e.,  {{math|''g''}} is identically zero outside some finite subset of {{math|''S''}}. It is a vector space over {{math|''K''}} with the usual addition and scalar multiplication of functions. It has a basis parameterized by {{math|''S''}}. Indeed, for each {{math|''s''}} in {{math|''S''}} we define<ref>In a fancier language, {{math|''δ<sub>s</sub>''}} is [[Dirac's delta function]] with point mass at {{math|''s''}} when {{math|''S''}} is viewed as a discrete space.</ref>\n\n:<math>\\begin{cases} \\delta_s : S \\to K \\\\ \\delta_s(t) =  \\begin{cases} 1 & t =s \\\\ 0 & t \\neq s \\end{cases} \\end{cases} </math>\n\nThen {{math|{''δ<sub>s</sub>'' {{!}} ''s'' ∈ ''S''} }} is a basis for {{math|''F''(''S'')}}, since each element {{math|''g''}} of {{math|''F''(''S'')}} can be uniquely written as a linear combination of {{math|''δ<sub>s</sub>''}}, and because of the restriction that {{math|''g''}} has finite support, this linear combination consists of finitely many terms. Because of this explicit expression, an element of {{math|''F''(''S'')}} is often called a [[formal sum]] of symbols in {{math|''S''}}.\n\nBy construction, the (possibly infinite) [[dimension (vector space)|dimension]] of the vector space {{math|''F''(''S'')}} equals the cardinality of the set {{math|''S''}}.\n\n===Definition===\nLet us first consider a special case: let us say {{math|''V'', ''W''}} are free vector spaces for the sets {{math|''S'', ''T''}} respectively. That is, {{math|''V'' {{=}} ''F''(''S''), ''W'' {{=}} ''F''(''T'')}}. In this special case, the tensor product is defined as {{math|''F''(''S'') ⊗ ''F''(''T'') {{=}} ''F''(''S'' × ''T'')}}. In most typical cases, any vector space can be immediately understood as the free vector space for some set, so this definition suffices. However, there is also an explicit way of constructing the tensor product directly from {{math|''V'', ''W''}}, without appeal to {{math|''S'', ''T''}}.\n\nIn general, given two vector spaces {{math|''V''}} and {{math|''W''}} over a field {{math|''K''}}, the tensor product {{math|''U''}} of {{math|''V''}} and {{math|''W''}}, denoted as {{math|''U'' {{=}} ''V'' ⊗ ''W''}} is defined as the vector space whose elements and operations are constructed as follows:\n\nFrom the [[Cartesian product]] {{math|''V'' × ''W''}}, the free vector space {{math|''F''(''V'' × ''W'')}} over {{math|''K''}} is formed. The vectors of {{math|''V'' ⊗ ''W''}} are then defined to be the [[equivalence class]]es of the [[congruence relation|congruence]] generated by the following relations on {{math|''F''(''V'' × ''W'')}}:\n\n:<math>\\begin{align}\n&\\forall v, v_1, v_2 \\in V, \\forall w, w_1, w_2 \\in W, \\forall c \\in K:\\\\\n&(v_1,w) + (v_2,w) \\sim (v_1 + v_2,w),\\\\\n&(v,w_1) + (v,w_2) \\sim (v,w_1+w_2),\\\\\n&c(v,w) \\sim (cv,w),\\\\\n&c(v,w) \\sim (v,cw).\n\\end{align}</math>\n\nThe operations of {{math|''V'' ⊗ ''W''}}, i.e. the map of vector addition {{math|+ : ''U'' × ''U'' → ''U''}} and scalar multiplication {{math|⋅ : ''K'' × ''U'' → ''U''}} are defined to be the respective operations {{math|+<sub>''F''</sub>}} and {{math|⋅<sub>''F''</sub>}} from {{math|''F''(''V'' × ''W'')}}, acting on ''any'' representatives\n:<math>\\tilde u_1, \\tilde u_2</math>\nin the involved equivalence classes outputting the one equivalence class of the result.\n\n:<math>\\tilde u_1 \\in u_1 , \\tilde u_2 \\in u_2 \\Rightarrow (+): (u_1,u_2) \\mapsto [\\tilde u_1 +_F \\tilde u_2]</math>\n:<math>\\tilde u_1 \\in u_1 \\Rightarrow (\\cdot): (c,u_1) \\mapsto [c \\cdot_F \\tilde u_1]</math>\n\nThe result can be proven to be independent of which representatives of the involved classes have been chosen. In other words, the operations are well-defined.\n\nIn other words, the tensor product {{math|''V'' ⊗ ''W''}} is defined as the [[quotient space (linear algebra)|quotient space]] {{math|''F''(''V'' × ''W'')/''N''}}, where {{math|''N''}} is the subspace of {{math|''F''(''V'' × ''W'')}} consisting of the equivalence class of the zero element, {{math|''N'' {{=}} [∅]}}, {{math|∅ ∈ ''F''(''V'' × ''W'')}}, under the equivalence relation of above.  In this way, because it is a quotient of the free vector space by the subspace generated by the relations, it is the ''freest'' such vector space.<ref>Keith Conrad [http://www.math.uconn.edu/~kconrad/blurbs/linmultialg/tensorprod.pdf Tensor products] University of Connecticut, lecture notes </ref><ref>{{citation|first=David|last=Eisenbud|authorlink=David Eisenbud | title=Commutative algebra with a view to algebraic geometry|publisher=Springer}}</ref>  For this reason, the tensor product <math>V\\otimes W</math> can also be characterised by a [[#Universal property|universal property]].\n\nThe following expression explicitly gives the subspace {{math|''N''}}:<ref>{{citation|last = Lee|first = J. M.|title=Introduction to Smooth manifolds|year=2003|publisher=|series=Springer Graduate Texts in Mathematics|isbn=0-387-95448-1|volume=218|postscript=<!--none-->}}</ref> \n\n:<math>\\begin{align}\nN = \\operatorname{span}(\\{ u \\in F(V \\times W) \\,|\\, & \\exists v,v_1,v_2 \\in V , \\exists w,w_1,w_2 \\in W , \\exists c \\in K :\\\\\n&u = (v_1,w) + (v_2,w) - (v_1 + v_2,w) \\lor\\\\\n&u = (v,w_1) + (v,w_2) - (v,w_1+w_2) \\lor\\\\\n&u = c(v,w) - (cv,w) \\lor\\\\\n&u = c(v,w) - (v,cw) \\}).\n\\end{align}</math>\n\nIn the quotient, where {{math|''N''}} is mapped to the zero vector, the following equalities,\n:<math>\\begin{align}\n(v_1,w) + (v_2,w) &= (v_1 + v_2,w),\\\\\n(v,w_1) + (v,w_2) &= (v,w_1+w_2),\\\\\nc(v,w) &= (cv,w),\\\\\nc(v,w) &= (v,cw)\n\\end{align}</math>\nall ''hold'' (unlike in {{math|''F''(''V'' × ''W'')}}), which is exactly what is desired. In these latter expressions, the {{math|(''v''<sub>1</sub>, ''w'')}}, etc., are images in the quotient of vectors in the free product under the quotient map. Usually, some other notation is employed for them, see below.\n\n===Notation===\nElements of {{math|''V'' ⊗ ''W''}} are often referred to as ''tensors'', although this term refers to many other related concepts as well.<ref>See [[Tensor]] or [[Tensor (intrinsic definition)]].</ref> If {{math|''v''}} belongs to {{math|''V''}} and {{math|''w''}} belongs to {{math|''W''}}, then the equivalence class of {{math|(''v'', ''w'')}} is denoted by {{math|''v'' ⊗ ''w''}}, which is called the tensor product of {{math|''v''}} with {{math|''w''}}. In physics and engineering, this use of the {{math| \"⊗\"}} symbol refers specifically to the [[outer product]] operation; the result of the outer product {{math|''v'' ⊗ ''w''}} is one of the standard ways of representing the equivalence class {{math|''v'' ⊗ ''w''}}.<ref>This similar to how [[Modulo operation|the engineering use]] of \"<math>\\pmod n</math>\" specifically returns the remainder, one of the many elements of the <math>\\pmod n</math> equivalence class.</ref> An element of {{math|''V'' ⊗ ''W''}} that can be written in the form {{math|''v'' ⊗ ''w''}} is called a ''pure'' or ''[[simple tensor]]''.  In general, an element of the tensor product space is not a pure tensor, but rather a finite linear combination of pure tensors.  For example, if {{math|''v''<sub>1</sub>}} and {{math|''v''<sub>2</sub>}} are [[linearly independent]], and {{math|''w''<sub>1</sub>}} and {{math|''w''<sub>2</sub>}} are also linearly independent, then {{math|''v''<sub>1</sub> ⊗ ''w''<sub>1</sub> + ''v''<sub>2</sub> ⊗ ''w''<sub>2</sub>}} cannot be written as a pure tensor. The number of simple tensors required to express an element of a tensor product is called the [[tensor rank]] (not to be confused with [[tensor order]], which is the number of spaces one has taken the product of, in this case 2; in notation, the number of indices), and for linear operators or matrices, thought of as {{math|(1, 1)}} tensors (elements of the space {{math|''V'' ⊗ ''V''<sup>∗</sup>}}), it agrees with [[matrix rank]].\n\n===Dimension===\nGiven bases {{math|{''v<sub>i</sub>''} }} and {{math|{''w<sub>j</sub>''} }} for {{math|''V''}} and {{math|''W''}} respectively, the tensors {{math|{''v<sub>i</sub>'' ⊗ ''w<sub>j</sub>''}<nowiki/>}} form a basis for {{math|''V'' ⊗ ''W''}}. Therefore, if {{math|''V''}} and {{math|''W''}} are finite-dimensional, the dimension of the tensor product is the product of dimensions of the original spaces; for instance {{math|'''R'''<sup>''m''</sup> ⊗ '''R'''<sup>''n''</sup>}} is isomorphic to {{math|'''R'''<sup>''mn''</sup>}}.\n\n===Tensor product of linear maps===\nThe tensor product also operates on [[linear map]]s between vector spaces. Specifically, given two linear maps {{math|''S'' : ''V'' → ''X''}} and {{math|''T'' : ''W'' → ''Y''}} between vector spaces, the ''tensor product of the two linear maps'' {{math|''S''}} and {{math|''T''}} is a linear map\n:<math>S\\otimes T:V\\otimes W\\to X\\otimes Y</math>\ndefined by\n:<math>(S\\otimes T)(v\\otimes w)=S(v)\\otimes T(w).</math>\n\nIn this way, the tensor product becomes a [[bifunctor]] from the category of vector spaces to itself, [[Functor#Covariance and contravariance|covariant]] in both arguments.<ref>{{cite book| last1=Hazewinkel|first1=Michiel|last2=Gubareni|first2=Nadezhda Mikhaĭlovna| last3=Gubareni|first3=Nadiya|last4=Kirichenko|first4=Vladimir V.|title=Algebras, rings and modules|page=100|\npublisher=Springer|year=2004|isbn=978-1-4020-2690-4}}</ref>\n\nIf {{math|''S''}} and {{math|''T''}} are both injective, surjective, or continuous then {{math|''S'' ⊗ ''T''}} is, respectively, injective, surjective, continuous.\n\nBy choosing bases of all vector spaces involved, the linear maps {{math|''S''}} and {{math|''T''}} can be represented by [[matrix (mathematics)|matrices]]. Then, the matrix describing the tensor product {{math|''S'' ⊗ ''T''}} is the [[Kronecker product]] of the two matrices. For example, if {{math|''V'', ''X'', ''W''}}, and {{math|''Y''}} above are all two-dimensional and bases have been fixed for all of them, and {{math|''S''}} and {{math|''T''}} are given by the matrices\n\n:<math>\\begin{bmatrix}\n    a_{1,1} & a_{1,2} \\\\\n    a_{2,1} & a_{2,2} \\\\\n  \\end{bmatrix}, \\qquad \\begin{bmatrix}\n    b_{1,1} & b_{1,2} \\\\\n    b_{2,1} & b_{2,2} \\\\\n  \\end{bmatrix}, </math>\n\nrespectively, then the tensor product of these two matrices is\n\n:<math>\n  \\begin{bmatrix}\n    a_{1,1} & a_{1,2} \\\\\n    a_{2,1} & a_{2,2} \\\\\n  \\end{bmatrix}\n\\otimes\n  \\begin{bmatrix}\n    b_{1,1} & b_{1,2} \\\\\n    b_{2,1} & b_{2,2} \\\\\n  \\end{bmatrix}\n=\n  \\begin{bmatrix}\n    a_{1,1}  \\begin{bmatrix}\n              b_{1,1} & b_{1,2} \\\\\n              b_{2,1} & b_{2,2} \\\\\n            \\end{bmatrix} & a_{1,2}  \\begin{bmatrix}\n                                      b_{1,1} & b_{1,2} \\\\\n                                      b_{2,1} & b_{2,2} \\\\\n                                    \\end{bmatrix} \\\\\n     & \\\\\n    a_{2,1}  \\begin{bmatrix}\n              b_{1,1} & b_{1,2} \\\\\n              b_{2,1} & b_{2,2} \\\\\n            \\end{bmatrix} & a_{2,2}  \\begin{bmatrix}\n                                      b_{1,1} & b_{1,2} \\\\\n                                      b_{2,1} & b_{2,2} \\\\\n                                    \\end{bmatrix} \\\\\n  \\end{bmatrix}\n=\n  \\begin{bmatrix}\n    a_{1,1} b_{1,1} & a_{1,1} b_{1,2} & a_{1,2} b_{1,1} & a_{1,2} b_{1,2} \\\\\n    a_{1,1} b_{2,1} & a_{1,1} b_{2,2} & a_{1,2} b_{2,1} & a_{1,2} b_{2,2} \\\\\n    a_{2,1} b_{1,1} & a_{2,1} b_{1,2} & a_{2,2} b_{1,1} & a_{2,2} b_{1,2} \\\\\n    a_{2,1} b_{2,1} & a_{2,1} b_{2,2} & a_{2,2} b_{2,1} & a_{2,2} b_{2,2} \\\\\n  \\end{bmatrix}.\n</math>\n\nThe resultant rank is at most 4, and thus the resultant dimension is 4. Here rank denotes the [[tensor rank]] (number of requisite indices), while the [[matrix rank]] counts the number of degrees of freedom in the resulting array.\n\nA [[dyadic product]] is the special case of the tensor product between two vectors of the same dimension.\n\n===Universal property===\n[[File:Another universal tensor prod.svg|right|thumb|200px|This [[commutative diagram]] presents the universal property of tensor product. Here <math>\\varphi</math> and <math>h</math> are bilinear, whereas <math>\\tilde{h}</math> is linear.]]\n\nIn the context of vector spaces, the tensor product <math>V \\otimes W</math> and the associated bilinear map <math>\\varphi: V \\times W \\to V \\otimes W</math> are characterized up to isomorphism by a [[universal property]] regarding [[bilinear map|bilinear maps]]. (Recall that a bilinear map is a function that is ''separately'' linear in each of its arguments.) Informally, <math>\\varphi</math> is the most general bilinear map out of <math>V \\times W</math>.\n\n{{gbq|\nThe vector space <math>V \\otimes W</math> and the associated bilinear map <math>\\varphi: V \\times W \\to V \\otimes W</math> have the property that any bilinear map <math>h: V \\times W \\to Z</math> from <math>V \\times W</math> to any vector space <math>Z</math> factors through <math>\\varphi</math> uniquely. By saying \"<math>h</math> factors through <math>\\varphi</math> uniquely,\" we mean that there is a unique linear map <math>\\tilde{h}: V \\otimes W \\to Z</math> such that <math>h = \\tilde{h} \\circ \\varphi</math>.\n}}\n\nThis characterization can simplify proofs about the tensor product. For example, the tensor product is symmetric, meaning there is a [[canonical isomorphism]]:\n:<math>V \\otimes W \\cong W \\otimes V.</math>\nTo construct, say, a map from <math>V \\otimes W</math> to <math>W \\otimes V</math>, it suffices to give a bilinear map <math>h: V \\times W \\to W \\otimes V</math> that maps <math>(v,w)</math> to <math>w \\otimes v</math>. Then the universal property of <math>V \\otimes W</math> means <math>h</math> factors into a map <math>\\tilde{h}:V \\otimes W \\to W \\otimes V</math>.\nA map <math>\\tilde{g}:W \\otimes V \\to V \\otimes W</math> in the opposite direction is similarly defined, and one checks that the two linear maps <math>\\tilde{h}</math> and <math>\\tilde{g}</math> are inverse to one another by again using their universal properties.\n\nSimilar reasoning can be used to show that the tensor product is associative, that is, there are natural isomorphisms\n:<math>V_1\\otimes(V_2\\otimes V_3)\\cong (V_1\\otimes V_2)\\otimes V_3.</math>\nTherefore, it is customary to omit the parentheses and write <math>V_1 \\otimes V_2 \\otimes V_3</math>.\n\nThe category of vector spaces with tensor product is an example of a [[symmetric monoidal category]].\n\nThe universal-property definition of a tensor product is valid in more categories that just the category of vector spaces. Instead of using multilinear (bilinear) maps, the general tensor product definition uses multimorphisms.<ref>https://ncatlab.org/nlab/show/tensor+product{{user-generated source|date=September 2017}}</ref>\n\n===Tensor powers and braiding===\nLet {{math|''n''}} be a non-negative integer.  The {{math|''n''}}th '''tensor power''' of the vector space {{math|''V''}} is the {{math|''n''}}-fold tensor product of {{math|''V''}} with itself.  That is\n:<math>V^{\\otimes n} \\;\\overset{\\mathrm{def}}{=}\\; \\underbrace{V\\otimes\\cdots\\otimes V}_{n}.</math>\n\nA [[permutation]] {{math|''σ''}} of the set {{math|{1, 2, ..., ''n''} }} determines a mapping of the {{math|''n''}}th Cartesian power of {{math|''V''}} as follows:\n\n:<math>\\begin{cases} \\sigma \\colon V^n\\to V^n \\\\ \\sigma(v_1,v_2,\\cdots,v_n) = \\left (v_{\\sigma(1)}, v_{\\sigma(2)},\\cdots,v_{\\sigma(n)} \\right ) \\end{cases}</math>\n\nLet\n:<math>\\varphi \\colon V^n \\to V^{\\otimes n}</math>\nbe the natural multilinear embedding of the Cartesian power of {{math|''V''}} into the tensor power of {{math|''V''}}.  Then, by the universal property, there is a unique isomorphism\n:<math>\\tau_\\sigma \\colon V^{\\otimes n} \\to V^{\\otimes n}</math>\nsuch that\n:<math>\\varphi\\circ\\sigma = \\tau_\\sigma\\circ\\varphi.</math>\n\nThe isomorphism {{math|''τ<sub>σ</sub>''}} is called the '''braiding map''' associated to the permutation {{math|''σ''}}.\n\n==Product of tensors==\n{{See also|Classical treatment of tensors}}\nFor non-negative integers {{math|''r''}} and {{math|''s''}} a type {{math|(''r'',''s'')}} [[tensor]] on a vector space {{math|''V''}} is an element of\n:<math> T^r_s(V) = \\underbrace{ V\\otimes \\dots \\otimes V}_{r} \\otimes \\underbrace{ V^*\\otimes \\dots \\otimes V^*}_{s} = V^{\\otimes r}\\otimes V^{*\\otimes s}.</math>\nHere {{math|''V''<sup>∗</sup>}} is the [[dual vector space]] (which consists of all [[linear map]]s {{math|''f''}} from {{math|''V''}} to the ground field {{math|''K''}}).\n\nThere is a product map, called the ''(tensor) product of tensors''{{refn|{{harvp|Bourbaki|1989|p=244}} defines the usage \"tensor product of ''x'' and ''y''\", elements of the respective modules.}}\n:<math>T^r_s (V) \\otimes_K T^{r'}_{s'} (V) \\to T^{r+r'}_{s+s'}(V).</math>\nIt is defined by grouping all occurring \"factors\" {{math|''V''}} together: writing {{math|''v''<sub>''i''</sub>}} for an element of {{math|''V''}} and {{math|''f''<sub>''i''</sub>}} for elements of the dual space,\n:<math>(v_1 \\otimes f_1) \\otimes (v'_1) = v_1 \\otimes v'_1 \\otimes f_1.</math>\n\nPicking a basis of {{math|''V''}} and the corresponding [[dual basis]] of {{math|''V''<sup>∗</sup>}} naturally induces a basis for {{math|''T''{{su|b=''s''|p=''r''}}(''V'')}} (this basis is described in the [[Kronecker product#Relation to the abstract tensor product|article on Kronecker products]]). In terms of these bases, the [[Coordinate vector|components]] of a (tensor) product of two (or more) [[tensor]]s can be computed. For example, if {{math|''F''}} and {{math|''G''}} are two [[covariance and contravariance of vectors|covariant]] tensors of rank {{math|''m''}} and {{math|''n''}} respectively (i.e. {{math|''F'' ∈ ''T''{{su|b=''m''|p= 0}}}}, and {{math|''G'' ∈ ''T''{{su|b=''n''|p= 0}}}}), then the components of their tensor product are given by\n:<math>(F\\otimes G)_{i_1i_2\\ldots i_{m+n}} = F_{i_{1}i_{2}\\ldots i_{m}}G_{i_{m+1}i_{m+2}i_{m+3}\\ldots i_{m+n}}.</math>\n<ref>Analogous formulas also hold for [[covariance and contravariance of vectors|contravariant]] tensors, as well as tensors of mixed variance.  Although in many cases such as when there is an [[inner product]] defined, the distinction is irrelevant.</ref>\nThus, the components of the tensor product of two tensors are the ordinary product of the components of each tensor. Another example: let {{math|'''U'''}} be a tensor of type {{math|(1, 1)}} with components {{math|''U<sup>α</sup><sub>β</sub>''}}, and let {{math|'''V'''}} be a tensor of type {{math|(1, 0)}} with components {{math|''V'' <sup>''γ''</sup>}}.  Then\n:<math> U^\\alpha {}_\\beta V^\\gamma = (U \\otimes V)^\\alpha {}_\\beta {}^\\gamma </math>\nand\n:<math> V^\\mu U^\\nu {}_\\sigma = (V \\otimes U)^{\\mu \\nu} {}_\\sigma. </math>\n\n==Relation to dual space==\nA particular example is the tensor product of some vector space {{math|''V''}} with its [[dual vector space]] {{math|''V''<sup>∗</sup>}} (which consists of all [[linear map]]s {{math|''f''}} from {{math|''V''}} to the ground field {{math|''K''}}). In this case, there is a canonical '''evaluation map'''\n:<math>V \\otimes V^* \\to K</math>\nwhich on elementary tensors is defined by\n:<math>v \\otimes f \\mapsto f(v).</math>\nThe resulting map\n:<math>T^r_s (V) \\to T^{r-1}_{s-1}(V)</math>\nis called [[tensor contraction]] (for {{math|''r'', ''s'' > 0}}).\n\nOn the other hand, if {{math|''V''}} is ''finite-dimensional'', there is a canonical map in the other direction (called the '''coevaluation map''')\n:<math>K \\to V \\otimes V^*, \\lambda \\mapsto \\sum_i \\lambda v_i \\otimes v^*_i.</math>\nwhere {{math|''v''<sub>1</sub>, ..., ''v''<sub>''n''</sub>}} is any basis of {{math|''V''}}, and {{math|''v''<sub>''i''</sub><sup>∗</sup>}} is its dual basis. Surprisingly, this map does not depend on our choice of basis.<ref>{{Cite web|url=https://unapologetic.wordpress.com/2008/11/13/the-coevaluation-on-vector-spaces/|title=The Coevaluation on Vector Spaces|date=2008-11-13|website=The Unapologetic Mathematician|access-date=2017-01-26}}</ref>\n\nThe interplay of evaluation and coevaluation map can be used to characterize finite-dimensional vector spaces without referring to bases.<ref>See [[Compact closed category]].</ref>\n\n===Tensor product vs. Hom===\nGiven two finite dimensional vector spaces {{math|''U''}}, {{math|''V''}}, denote the [[dual space]] of {{math|''U''}} as {{math|''U*''}}, we have the following relation: \n:<math> U^* \\otimes V  \\cong \\mathrm{Hom} (U, V),</math>\nan isomorphism can be defined by <math>\\alpha: U^* \\otimes V \\rightarrow  \\mathrm{Hom} (U, V)</math>, when acting on pure tensors \n:<math> u^* \\otimes v  \\mapsto (u^* \\otimes v)(u)  = u^*(u) v,</math> \nits \"inverse\" can be defined in a similar manner as [[Tensor product#Relation to dual space|above (Relation to dual space)]] using [[dual basis]] <math>\\{u^*_i\\}</math>, \n:<math> \\mathrm{Hom} (U,V) \\to U^* \\otimes V, \\quad f(\\cdot) \\mapsto \\sum_i u^*_i \\otimes f(u_i).</math>\nThis result implies \n:<math> \\dim( U \\otimes V ) =\\dim(U)\\dim(V)</math>\nwhich automatically gives the important fact that <math>\\{u_i\\otimes v_j\\} </math> forms a basis for  <math>U \\otimes V</math> where <math> \\{u_i\\}, \\{v_j\\} </math> are bases of {{math|''U''}} and {{math|''V''}}.\n\nFurthermore, given three vector spaces {{math|''U''}}, {{math|''V''}}, {{math|''W''}} the tensor product is linked to the vector space of ''all'' linear maps, as follows:\n:<math> \\mathrm{Hom} (U \\otimes V, W) \\cong \\mathrm{Hom} (U, \\mathrm{Hom}(V, W)).</math>\nHere {{math|Hom(-,-)}} denotes the {{math|''K''}}-vector space of all linear maps. This is an example of [[adjoint functor]]s: the tensor product is \"left adjoint\" to Hom.\n\n===Adjoint representation===\nThe tensor <math> \\scriptstyle T^r_s(V) </math> may be naturally viewed as a module for the [[Lie algebra]] {{math|End(''V'')}} by means of the diagonal action: for simplicity let us assume {{math|1=''r'' = ''s'' = 1}}, then, for each {{math|''u'' ∈ End(''V'')}},\n:<math> u(a \\otimes b)  = u(a) \\otimes b - a \\otimes u^*(b),</math>\n\nwhere {{math|''u''<sup>∗</sup>}} in {{math|End(''V''<sup>∗</sup>)}} is the [[transpose]] of {{math|''u''}}, that is, in terms of the obvious pairing on {{math|''V'' ⊗ ''V''<sup>∗</sup>}},\n:<math>\\langle u(a), b \\rangle = \\langle a, u^*(b) \\rangle</math>.\n\nThere is a canonical isomorphism <math>\\scriptstyle T^1_1(V) \\rightarrow \\mathrm{End}(V) </math> given by\n:<math>(a \\otimes b)(x) = \\langle x, b \\rangle a. </math>\n\nUnder this isomorphism, every {{math|''u''}} in {{math|End(''V'')}} may be first viewed as an endomorphism of <math>\\scriptstyle T^1_1(V)</math> and then viewed as an endomorphism of {{math|End(''V'')}}. In fact it is the [[Adjoint representation of a Lie algebra|adjoint representation]] {{math|ad(''u'')}} of {{math|End(''V'')}}.\n\n==Tensor products of modules over a ring==\n{{main article|Tensor product of modules}}\nThe tensor product of two [[module (mathematics)|modules]] {{math|''A''}} and {{math|''B''}} over a ''[[commutative ring|commutative]]'' [[ring (mathematics)|ring]] {{math|''R''}} is defined in exactly the same way as the tensor product of vector spaces over a field:\n:<math>A \\otimes_R B := F (A \\times B) / G</math>\nwhere now {{math|''F''(''A'' × ''B'')}} is the [[free module|free {{math|''R''}}-module]] generated by the cartesian product and {{math|''G''}} is the {{math|''R''}}-module generated by [[Tensor product#Definition|the same relations as above]].\n\nMore generally, the tensor product can be defined even if the ring is non-commutative ({{math|''ab'' ≠ ''ba''}}). In this case {{math|''A''}} has to be a right-{{math|''R''}}-module and {{math|''B''}} is a left-{{math|''R''}}-module, and instead of the last two relations above, the relation\n:<math>(ar,b)-(a,rb)</math>\nis imposed. If {{math|''R''}} is non-commutative, this is no longer an {{math|''R''}}-module, but just an [[abelian group]].\n\nThe universal property also carries over, slightly modified: the map {{math|''φ'' : ''A'' × ''B'' → ''A'' ⊗<sub>''R''</sub> ''B''}} defined by {{math|(''a'', ''b'') ↦ ''a'' ⊗ ''b''}} is a [[Tensor product of modules#Balanced product|middle linear map]] (referred to as \"the canonical middle linear map\".<ref>\n{{cite book|last=Hungerford|first=Thomas W.|title=Algebra|\npublisher=Springer|year=1974|isbn=0-387-90518-9}}</ref>); that is,<ref name=chen>\n{{citation|last=Chen|first=Jungkai Alfred|title=Advanced Algebra II|chapter=Tensor product|\nchapter-url=http://www.math.ntu.edu.tw/~jkchen/S04AA/S04AAL10.pdf|\ntype=lecture notes|date=Spring 2004|place=National Taiwan University}}</ref> it satisfies:\n\n:<math> \\begin{align}\n\\phi(a+a',b)=\\phi(a,b)+\\phi(a',b) \\\\\n\\phi(a,b+b')=\\phi(a,b)+\\phi(a,b') \\\\\n\\phi(ar,b)=\\phi(a,rb)\n\\end{align} </math>\n\nThe first two properties make {{math|''φ''}} a bilinear map of the [[abelian group]] {{math|''A'' × ''B''}}. For any middle linear map {{math|''ψ''}} of {{math|''A'' × ''B''}}, a unique group homomorphism {{math|''f''}} of {{math|''A'' ⊗<sub>''R''</sub> ''B''}} satisfies {{math|1=''ψ'' = ''f'' ∘ ''φ''}}, and this property determines <math> \\phi </math> within group isomorphism. See the [[tensor product of modules|main article]] for details.\n\n===Tensor product of modules over a non-commutative ring===\n\nLet A be a right R-module and B be a left R-module B. Then the tensor product of A and B is an abelian group defined by\n:<math>A \\otimes_R B := F (A \\times B) / G</math>\nwhere <math>F (A \\times B)</math> is a [[free abelian group]] over <math>A \\times B </math> and G is a subgroup of <math>F (A \\times B)</math> generated by relations\n:<math>\\begin{align}\n&\\forall a, a_1, a_2 \\in A, \\forall b, b_1, b_2 \\in B, \\forall r \\in R:\\\\\n&(a_1,b) + (a_2,b) - (a_1 + a_2,b),\\\\\n&(a,b_1) + (a,b_2) - (a,b_1+b_2),\\\\\n&(ar,b) - (a,rb).\\\\\n\\end{align}</math>\n\nThe universal property can be stated as follows.\nLet G be an abelian group with a map <math>q:A\\times B \\rightarrow G</math> which is bilinear, in the sense that\n:<math>\\begin{align}\n&q(a_1+a_2,b)=q(a_1,b)+q(a_2,b),\\\\\n&q(a,b_1+b_2)=q(a,b_1)+q(a,b_2),\\\\\n&q(ar,b)=q(a,rb).\n\\end{align}</math>\nThen there is a unique map <math>\\overline{q}:A\\otimes B \\rightarrow G</math> such that <math>\\overline{q}(a\\otimes b)=q(a,b)</math> for every <math>a\\in A, b\\in B</math>.\n\nFurthermore, we can give <math>A \\otimes_R B</math> a module structure under some extra conditions.\n:1) If A was a (S,R)-bimodule, then <math>A \\otimes_R B</math> is a left S-module where <math>s(a\\otimes b):=(sa)\\otimes b</math>.\n:2) If B was a (R,S)-bimodule, then <math>A \\otimes_R B</math> is a right S-module where <math>(a\\otimes b)s:=a\\otimes (bs)</math>.\n:3) If R was a commutative ring, then A and B are (R,R)-bimodules where <math>ra:=ar</math> and <math>br:=rb</math>. By 1), <math>A \\otimes_R B</math> is a left R-module. By 2), <math>A \\otimes_R B</math> is a right R-module. So we can conclude <math>A \\otimes_R B</math> is a (R,R)-bimodule.\n\n===Computing the tensor product===\nFor vector spaces, the tensor product {{math|''V'' ⊗ ''W''}} is quickly computed since bases of {{math|''V''}} of {{math|''W''}} immediately determine a basis of {{math|''V'' ⊗ ''W''}}, as was mentioned above. For modules over a general (commutative) ring, not every module is free. For example, {{math|'''Z'''/''n'''''Z'''}} is not a free abelian group (= {{math|'''Z'''}}-module). The tensor product with {{math|'''Z'''/''n'''''Z'''}} is given by\n:<math>M \\otimes_\\mathbf Z \\mathbf Z/n\\mathbf Z = M/nM.</math>\nMore generally, given a [[presentation of a module|presentation]] of some {{math|''R''}}-module {{math|''M''}}, that is, a number of generators {{math|''m''<sub>''i''</sub> ∈ ''M'', ''i'' ∈ ''I''}} together with relations <math>\\sum_{j \\in J} a_{ji} m_i = 0</math>, with {{math|''a''<sub>''ji''</sub> ∈ ''R''}}, the tensor product can be computed as the following [[cokernel]]:\n:<math>M \\otimes_R N = \\operatorname{coker} (N^J \\rightarrow N^I)</math>\nHere {{math|1=''N''<sup>''J''</sup> := ⨁<sub>''j'' ∈ ''J''</sub> ''N''}} and the map is determined by sending some {{math|''n'' ∈ ''N''}} in the {{math|''j''}}th copy of {{math|''N''<sup>''J''</sup>}} to {{math|''a''<sub>''ji''</sub>''n''}} (in {{math|''N''<sup>''I''</sup>}}). Colloquially, this may be rephrased by saying that a presentation of {{math|''M''}} gives rise to a presentation of {{math|''M'' ⊗<sub>''R''</sub> ''N''}}. This is referred to by saying that the tensor product is a [[right exact functor]]. It is not in general left exact, that is, given an injective map of {{math|''R''}}-modules {{math|''M''<sub>1</sub> → ''M''<sub>2</sub>}}, the tensor product\n:<math>M_1 \\otimes_R N \\to M_2 \\otimes_R N</math>\nis not usually injective. For example, tensoring the (injective) map given by multiplication with {{math|''n''}}, {{math|''n'' : '''Z''' → '''Z'''}} with {{math|'''Z'''/''n'''''Z'''}} yields the zero map {{math|0 : '''Z'''/''n'''''Z''' → '''Z'''/''n'''''Z'''}}, which is not injective. Higher [[Tor functor]]s measure the defect of the tensor product being not left exact. All higher Tor functors are assembled in the [[derived tensor product]].\n\n==Tensor product of algebras==\n{{main article|Tensor product of algebras}}\nLet {{math|''R''}} be a commutative ring. The tensor product of {{math|''R''}}-modules applies, in particular, if {{math|''A''}} and {{math|''B''}} are [[Algebra (ring theory)|{{math|''R''}}-algebras]]. In this case, the tensor product {{math|''A'' ⊗<sub>''R''</sub> ''B''}} is an {{math|''R''}}-algebra itself by putting\n:<math>(a_1 \\otimes b_1) \\cdot (a_2 \\otimes b_2) = (a_1 \\cdot a_2) \\otimes (b_1 \\cdot b_2).</math>\nFor example,\n:<math>R[x] \\otimes_R R[y] \\cong R[x, y].</math>\n\nA particular example is when {{math|''A''}} and {{math|''B''}} are fields containing a common subfield {{math|''R''}}. The [[tensor product of fields]] is closely related to [[Galois theory]]: if, say, {{math|1=''A'' = ''R''[''x''] / ''f''(''x'')}}, where {{math|''f''}} is some [[irreducible polynomial]] with coefficients in {{math|''R''}}, the tensor product can be calculated as\n:<math>A \\otimes_R B \\cong B[x] / f(x)</math>\nwhere now {{math|''f''}} is interpreted as the same polynomial, but with its coefficients regarded as elements of {{math|''B''}}. In the larger field {{math|''B''}}, the polynomial may become reducible, which brings in Galois theory. For example, if {{math|1=''A'' = ''B''}} is a [[Galois extension]] of {{math|''R''}}, then\n:<math>A \\otimes_R A \\cong A[x] / f(x)</math>\nis isomorphic (as an {{math|''A''}}-algebra) to the {{math|''A''<sup>deg(''f'')</sup>}}.\n\n==Eigenconfigurations of tensors==\nSquare [[Matrix (mathematics)|matrices]] {{math|''A''}} with entries in a [[Field (mathematics)|field]] {{math|''K''}} represent [[linear maps]] of [[vector spaces]], say <math>K^n \\to K^n</math>,  and thus linear maps <math>\\psi : \\mathbb{P}^{n-1} \\to \\mathbb{P}^{n-1}</math> of [[projective spaces]] over <math>K</math>. If {{math|''A''}} is [[Invertible matrix|nonsingular]] then <math>\\psi</math> is [[well-defined]] everywhere, and the [[Eigenvalues and eigenvectors|eigenvectors]] of <math>A</math> correspond to the fixed points of <math>\\psi</math>.  The ''eigenconfiguration'' of {{math|''A''}} consists of <math>n</math> points in <math>\\mathbb{P}^{n-1}</math>, provided <math>A</math> is generic and {{math|''K''}} is [[Algebraically closed field|algebraically closed]].   The fixed points of nonlinear maps are the eigenvectors of tensors.  \nLet <math>A = (a_{i_1 i_2 \\cdots i_d})</math> be a <math>d</math>-dimensional tensor of format <math>n \\times n \\times \\cdots \\times n</math> with entries <math>(a_{i_1 i_2 \\cdots i_d})</math>  lying in an algebraically closed field <math>K</math> of [[Characteristic (algebra)|characteristic]] zero.  Such a tensor <math>A \\in (K^{n})^{\\otimes d}</math> defines [[Morphism of algebraic varieties|polynomial maps]] <math>K^n \\to K^n</math> and <math>\\mathbb{P}^{n-1} \\to \\mathbb{P}^{n-1}</math> with coordinates \n:<math>\\psi_i(x_1, ..., x_n) = \\sum_{j_2=1}^n \\sum_{j_3=1}^n \\cdots \\sum_{j_d = 1}^n a_{i j_2 j_3 \\cdots j_d} x_{j_2} x_{j_3}\\cdots x_{j_d} \\;\\; \\mbox{for } i = 1,...,n </math>\nThus each of the <math>n</math> coordinates of <math> \\psi </math> is a [[homogeneous polynomial]] <math> \\psi_i </math> of degree <math> d - 1</math> in <math>\\mathbf{x} = (x_1, ..., x_n)</math>.  The eigenvectors of <math>A</math> are the solutions of the constraint \n:<math>\\mbox{rank} \\begin{pmatrix}x_1 & x_2 & \\cdots  & x_n \\\\ \\psi_1(\\mathbf{x}) & \\psi_2(\\mathbf{x}) & \\cdots & \\psi_n(\\mathbf{x}) \\end{pmatrix} \\leq 1 </math> \nand the eigenconfiguration is given by the [[Algebraic variety|variety]] of the <math>2 \\times 2</math> [[Minor (linear algebra)|minors]] of this matrix.<ref>Abo, H.; Seigal, A.; Sturmfels B. arXiv:1505.05729 [math.AG]</ref>\n\n==Other examples of tensor products==\n<!--- this section needs a clean-up? —- Taku --->\n===Tensor product of sheaves of modules===\n{{main article|Sheaf of modules}}\n\n===Tensor product of Hilbert spaces===\n{{main article|Tensor product of Hilbert spaces}}\n\n===Topological tensor product===\n{{main article|Topological tensor product}}\n\n===Tensor product of graded vector spaces===\n{{main article|Graded vector space#Operations on graded vector spaces}}\n\n===Tensor product of quadratic forms===\n{{main article|Tensor product of quadratic forms}}\n\n===Tensor product of multilinear forms===\nGiven two [[multilinear form]]s <math>\\scriptstyle f (x_1,\\dots,x_k)</math> and <math>\\scriptstyle g (x_1,\\dots, x_m)</math> on a vector space <math>V</math> over the field <math>K</math> their tensor product is the multilinear form \n:<math> (f \\otimes g) (x_1,\\dots,x_{k+m}) = f(x_1,\\dots,x_k) g(x_{k+1},\\dots,x_{k+m}).</math><ref name=\"An Introduction to Manifolds\">{{cite book |title=An Introduction to Manifolds | first=L. W. | last=Tu |series=Universitext |publisher=Springer | page=25 | isbn=978-1-4419-7399-3 | year=2010}}</ref>\n\nThis is a special case of the [[Tensor product#Product of tensors|product of tensors]] if they are seen as multilinear maps (see also [[Tensor#As multilinear maps|tensors as multilinear maps]]). Thus the components of the tensor product of multilinear forms can be computed by the [[Kronecker product]].\n\n===Tensor product of representations===\n{{main|Tensor product of representations}}\n\n===Tensor product of graphs===\n{{main article|Tensor product of graphs}}\nIt should be mentioned that, though called \"tensor product\", this is not a tensor product of graphs in the above sense; actually it is the [[Product (category theory)|category-theoretic product]] in the category of graphs and [[graph homomorphism]]s. However it is actually the [[Kronecker product|Kronecker tensor product]] of the [[adjacency matrix|adjacency matrices]] of the graphs. Compare also the section [[tensor product#Tensor product of linear maps|Tensor product of linear maps]] above.\n\n===Monoidal categories===\n\nA general context for tensor product is that of a [[monoidal category]].\n\n==Applications==\n\n===Exterior and symmetric algebra===\n{{Main|Exterior algebra|Symmetric algebra}}\n\nTwo notable constructions in linear algebra can be constructed as quotients of the tensor product: the exterior algebra and the symmetric algebra. For example, given a vector space {{math|''V''}}, the exterior product\n:<math>V \\wedge V</math>\nis defined as\n:<math>V \\otimes V/(v\\otimes v \\text{ for all } v\\in V).</math>\nNote that when the underlying field of {{math|''V''}} does not have characteristic 2, then this definition is equivalent to\n:<math>V \\otimes V / (v_1 \\otimes v_2 + v_2 \\otimes v_1 \\text{ for all } v_1, v_2 \\in V).</math>\nThe image of <math>v_1 \\otimes v_2</math> in the exterior product is usually denoted <math>v_1 \\wedge v_2</math> and satisfies, by construction, <math>v_1 \\wedge v_2 = - v_2 \\wedge v_1</math>. Similar constructions are possible for <math>V \\otimes \\dots \\otimes V</math> ({{math|''n''}} factors), giving rise to <math>\\Lambda^n V</math>, the {{math|''n''}}th [[exterior power]] of {{math|''V''}}. The latter notion is the basis of [[differential form|differential {{math|''n''}}-forms]].\n\nThe symmetric algebra is constructed in a similar manner:\n:<math>\\operatorname{Sym}^n V := \\underbrace{V \\otimes \\dots \\otimes V}_n / (\\dots \\otimes v_i \\otimes v_{i+1} \\otimes \\dots - \\dots \\otimes v_{i+1} \\otimes v_{i} \\otimes \\dots)</math>\nThat is, in the symmetric algebra two adjacent vectors (and therefore all of them) can be interchanged. The resulting objects are called symmetric tensors.\n\n===Tensor product of line bundles===\n{{main article|Vector bundle#Operations on vector bundles}}\n\n{{See also|tensor product bundle}}\n\n==Tensor product in programming==\n\n===Array programming languages===\n[[Array programming languages]] may have this pattern built in.  For example, in [[APL programming language|APL]] the tensor product is expressed as <code>○.×</code> (for example <code>A ○.× B</code> or <code>A ○.× B ○.× C</code>).  In [[J programming language|J]] the tensor product is the dyadic form of <code>*/</code> (for example <code>a */ b</code> or <code>a */ b */ c</code>).\n\nNote that J's treatment also allows the representation of some tensor fields, as <code>a</code> and <code>b</code> may be functions instead of constants. This product of two functions is a derived function, and if <code>a</code> and <code>b</code> are [[Differentiable function|differentiable]], then <code>a */ b</code> is differentiable.\n\nHowever, these kinds of notation are not universally present in array languages.  Other array languages may require explicit treatment of indices (for example, [[MATLAB]]), and/or may not support [[higher-order function]]s such as the [[Jacobian matrix and determinant|Jacobian derivative]] (for example, [[Fortran]]/APL).\n\n==See also==\n{{wiktionary}}\n*[[Dyadic product]]\n*[[Extension of scalars]]\n*[[Tensor algebra]]\n*[[Tensor contraction]]\n*[[Topological tensor product]]\n*[[Monoidal category]]\n\n==Notes==\n{{Reflist}}\n\n==References==\n* {{cite book |first = Nicolas|last=Bourbaki|authorlink=Nicolas Bourbaki | title = Elements of mathematics, Algebra I| publisher = Springer-Verlag | year = 1989|isbn=3-540-64243-9}}\n* {{cite book |first=Pierre A.|last=Grillet|title=Abstract Algebra|year=2007|publisher=Springer Science+Business Media, LLC|isbn=0387715673}}\n* {{cite book |authorlink=Paul Halmos|first=Paul|last=Halmos|title=Finite dimensional vector spaces|year=1974|publisher=Springer|isbn=0-387-90093-4}}\n* {{cite book |first=Thomas W.|last=Hungerford|authorlink=Thomas W. Hungerford|title=Algebra|year=2003|publisher=Springer|isbn=0387905189}}\n* {{Lang Algebra|edition=3r}}\n* {{cite book |first1=S.|last1=Mac Lane|authorlink1=Saunders Mac Lane|authorlink2=Garrett Birkhoff|last2=Birkhoff|first2=G.|title=Algebra|publisher=AMS Chelsea|year=1999|isbn=0-8218-1646-2}}\n* {{cite book |first1=M.|last1=Aguiar|first2=S.|last2=Mahajan| title = Monoidal functors, species and Hopf algebras|publisher = CRM Monograph Series Vol 29 |year=2010|isbn=0-8218-4776-7}}\n* {{cite web |url=http://pages.bangor.ac.uk/~mas010/nonabtens.html |title=Bibliography on the nonabelian tensor product of groups }}\n\n{{tensors}}\n\n{{DEFAULTSORT:Tensor Product}}\n[[Category:Binary operations]]\n[[Category:Bilinear operators]]",
            "slug": "tensor-product",
            "date_updated": 1517732354688,
            "imported": "https://en.wikipedia.org/wiki/tensor product"
        },
        {
            "title": "Tensor product",
            "text": "In [[mathematics]], the '''tensor product''' {{math|''V'' ⊗ ''W''}} of two vector spaces {{math|''V''}} and {{math|''W''}} (over the same [[Field_(mathematics)|field]]) is itself a vector space, together with an operation of [[Bilinear map|bilinear composition]], denoted by {{math|⊗}}, from ordered pairs in the [[Cartesian product]] {{math|''V'' × ''W''}} into {{math|V ⊗ W}}, in a way that generalizes the [[outer product]].  The tensor product of {{math|''V''}} and {{math|''W''}} is the vector space generated by the symbols {{math|''v'' ⊗ ''w''}}, with {{math|''v'' ∈ ''V''}} and {{math|''w'' ∈ ''W''}}, in which the relations of bilinearity are imposed for the product operation {{math|⊗}}, ''and no other relations'' are assumed to hold.  The tensor product space is thus the \"[[free object|freest]]\" (or most general) such vector space, in the sense of having the fewest constraints.\n\nThe tensor product of (finite dimensional) vector spaces has dimension equal to the product of the dimensions of the two factors:\n:<math>\\dim(V\\otimes W) = \\dim V \\times \\dim W.</math>\nIn particular, this distinguishes the tensor product from the [[direct sum]] vector space, whose dimension is the sum of the dimensions of the two summands:\n:<math>\\dim(V\\oplus W) = \\dim V + \\dim W.</math>\n\nMore generally, the tensor product can be extended to other [[category (mathematics)|categories]] of mathematical objects in addition to vector spaces, such as to  [[matrix (mathematics)|matrices]], [[tensors]], [[algebra over a field|algebras]], [[topological vector spaces]], and [[module (mathematics)|modules]].  In each such case the tensor product is characterized by a similar [[#Universal property|universal property]]: it is the freest [[bilinear operator|bilinear operation]].  The general concept of a \"tensor product\" is captured by [[monoidal category|monoidal categories]]; that is, the class of all things that have a tensor product is a monoidal category.\n\n==Tensor product of vector spaces==\nThe tensor product of two [[vector space]]s {{math|''V''}} and {{math|''W''}} over a [[field (mathematics)|field]] {{math|''K''}} is another vector space over {{math|''K''}}. It is denoted {{math|''V'' ⊗<sub>''K''</sub> ''W''}}, or {{math|''V'' ⊗ ''W''}} when the underlying field {{math|''K''}} is understood.\n\nIf <math>V</math> has a basis <math>e_1,\\dots,e_m</math> and <math>W</math> has a basis <math>f_1,\\dots,f_n</math>, then the tensor product <math>V\\otimes W</math> can be taken to be a vector space spanned by a basis consisting of all pair-wise products of elements from the two bases; each such basis element of <math>V\\otimes W</math> is denoted <math>e_i\\otimes f_j</math>.  For any vectors <math>v = \\sum\\nolimits_i v_i e_i \\in V</math> and <math>w = \\sum\\nolimits_j w_j f_j \\in W,</math> there is a corresponding product vector <math>v\\otimes w</math> in <math>V\\otimes W</math> given by <math>\\sum\\nolimits_{ij} v_i w_j (e_i\\otimes f_j) \\in V\\otimes W.</math>  This product operation <math>\\otimes : V \\times W \\rightarrow V\\otimes W</math> is quickly verified to be bilinear.\n\nAs an example, letting <math>V = W = \\mathbb{R}^3</math> (considered as a vector space over the field of real numbers) and considering the standard basis set <math>\\{\\hat{x},\\hat{y},\\hat{z}\\}</math> for each, the tensor product <math>V\\otimes W</math> is spanned by the nine basis vectors <math>\\{\\hat{x}\\otimes\\hat{x},\\hat{x}\\otimes\\hat{y},\\hat{x}\\otimes\\hat{z},\\hat{y}\\otimes\\hat{x},\\hat{y}\\otimes\\hat{y},\\hat{y}\\otimes\\hat{z},\\hat{z}\\otimes\\hat{x},\\hat{z}\\otimes\\hat{y},\\hat{z}\\otimes\\hat{z}\\},</math> and is isomorphic to <math>\\mathbb{R}^9.</math>  For vectors <math>v=(1,2,3), w=(1,0,0)\\in \\mathbb{R}^3,</math> the tensor product <math>v\\otimes w = \\hat{x}\\otimes\\hat{x} + 2\\hat{y}\\otimes\\hat{x} + 3\\hat{z}\\otimes\\hat{x}.</math>\n\nThe above definition relies on a choice of basis, which can not be done canonically for a generic vector space.  However, any two choices of basis lead to isomorphic tensor product spaces (c.f. the universal property described below).  Alternatively, the tensor product may be defined in an expressly basis-independent manner as a quotient space of a free vector space over {{math|''V'' × ''W''}}.  This approach is described below.\n\n===The free vector space===\nThe definition of {{math|⊗}} requires the notion of the [[free vector space]] {{math|''F''(''S'')}} on some [[set (mathematics)|set]] {{math|''S''}}, a vector space whose basis is [[Index set|indexed]] by {{math|''S''}}. {{math|''F''(''S'')}} is defined as the set of all functions {{math|''g''}} from {{math|''S''}} to a given field {{math|''K''}} that have [[finite support]]; i.e.,  {{math|''g''}} is identically zero outside some finite subset of {{math|''S''}}. It is a vector space over {{math|''K''}} with the usual addition and scalar multiplication of functions. It has a basis parameterized by {{math|''S''}}. Indeed, for each {{math|''s''}} in {{math|''S''}} we define<ref>In a fancier language, {{math|''δ<sub>s</sub>''}} is [[Dirac's delta function]] with point mass at {{math|''s''}} when {{math|''S''}} is viewed as a discrete space.</ref>\n\n:<math>\\begin{cases} \\delta_s : S \\to K \\\\ \\delta_s(t) =  \\begin{cases} 1 & t =s \\\\ 0 & t \\neq s \\end{cases} \\end{cases} </math>\n\nThen {{math|{''δ<sub>s</sub>'' {{!}} ''s'' ∈ ''S''} }} is a basis for {{math|''F''(''S'')}}, since each element {{math|''g''}} of {{math|''F''(''S'')}} can be uniquely written as a linear combination of {{math|''δ<sub>s</sub>''}}, and because of the restriction that {{math|''g''}} has finite support, this linear combination consists of finitely many terms. Because of this explicit expression, an element of {{math|''F''(''S'')}} is often called a [[formal sum]] of symbols in {{math|''S''}}.\n\nBy construction, the (possibly infinite) [[dimension (vector space)|dimension]] of the vector space {{math|''F''(''S'')}} equals the cardinality of the set {{math|''S''}}.\n\n===Definition===\nLet us first consider a special case: let us say {{math|''V'', ''W''}} are free vector spaces for the sets {{math|''S'', ''T''}} respectively. That is, {{math|''V'' {{=}} ''F''(''S''), ''W'' {{=}} ''F''(''T'')}}. In this special case, the tensor product is defined as {{math|''F''(''S'') ⊗ ''F''(''T'') {{=}} ''F''(''S'' × ''T'')}}. In most typical cases, any vector space can be immediately understood as the free vector space for some set, so this definition suffices. However, there is also an explicit way of constructing the tensor product directly from {{math|''V'', ''W''}}, without appeal to {{math|''S'', ''T''}}.\n\nIn general, given two vector spaces {{math|''V''}} and {{math|''W''}} over a field {{math|''K''}}, the tensor product {{math|''U''}} of {{math|''V''}} and {{math|''W''}}, denoted as {{math|''U'' {{=}} ''V'' ⊗ ''W''}} is defined as the vector space whose elements and operations are constructed as follows:\n\nFrom the [[Cartesian product]] {{math|''V'' × ''W''}}, the free vector space {{math|''F''(''V'' × ''W'')}} over {{math|''K''}} is formed. The vectors of {{math|''V'' ⊗ ''W''}} are then defined to be the [[equivalence class]]es of the [[congruence relation|congruence]] generated by the following relations on {{math|''F''(''V'' × ''W'')}}:\n\n:<math>\\begin{align}\n&\\forall v, v_1, v_2 \\in V, \\forall w, w_1, w_2 \\in W, \\forall c \\in K:\\\\\n&(v_1,w) + (v_2,w) \\sim (v_1 + v_2,w),\\\\\n&(v,w_1) + (v,w_2) \\sim (v,w_1+w_2),\\\\\n&c(v,w) \\sim (cv,w),\\\\\n&c(v,w) \\sim (v,cw).\n\\end{align}</math>\n\nThe operations of {{math|''V'' ⊗ ''W''}}, i.e. the map of vector addition {{math|+ : ''U'' × ''U'' → ''U''}} and scalar multiplication {{math|⋅ : ''K'' × ''U'' → ''U''}} are defined to be the respective operations {{math|+<sub>''F''</sub>}} and {{math|⋅<sub>''F''</sub>}} from {{math|''F''(''V'' × ''W'')}}, acting on ''any'' representatives\n:<math>\\tilde u_1, \\tilde u_2</math>\nin the involved equivalence classes outputting the one equivalence class of the result.\n\n:<math>\\tilde u_1 \\in u_1 , \\tilde u_2 \\in u_2 \\Rightarrow (+): (u_1,u_2) \\mapsto [\\tilde u_1 +_F \\tilde u_2]</math>\n:<math>\\tilde u_1 \\in u_1 \\Rightarrow (\\cdot): (c,u_1) \\mapsto [c \\cdot_F \\tilde u_1]</math>\n\nThe result can be proven to be independent of which representatives of the involved classes have been chosen. In other words, the operations are well-defined.\n\nIn other words, the tensor product {{math|''V'' ⊗ ''W''}} is defined as the [[quotient space (linear algebra)|quotient space]] {{math|''F''(''V'' × ''W'')/''N''}}, where {{math|''N''}} is the subspace of {{math|''F''(''V'' × ''W'')}} consisting of the equivalence class of the zero element, {{math|''N'' {{=}} [∅]}}, {{math|∅ ∈ ''F''(''V'' × ''W'')}}, under the equivalence relation of above.  In this way, because it is a quotient of the free vector space by the subspace generated by the relations, it is the ''freest'' such vector space.<ref>Keith Conrad [http://www.math.uconn.edu/~kconrad/blurbs/linmultialg/tensorprod.pdf Tensor products] University of Connecticut, lecture notes </ref><ref>{{citation|first=David|last=Eisenbud|authorlink=David Eisenbud | title=Commutative algebra with a view to algebraic geometry|publisher=Springer}}</ref>  For this reason, the tensor product <math>V\\otimes W</math> can also be characterised by a [[#Universal property|universal property]].\n\nThe following expression explicitly gives the subspace {{math|''N''}}:<ref>{{citation|last = Lee|first = J. M.|title=Introduction to Smooth manifolds|year=2003|publisher=|series=Springer Graduate Texts in Mathematics|isbn=0-387-95448-1|volume=218|postscript=<!--none-->}}</ref> \n\n:<math>\\begin{align}\nN = \\operatorname{span}(\\{ u \\in F(V \\times W) \\,|\\, & \\exists v,v_1,v_2 \\in V , \\exists w,w_1,w_2 \\in W , \\exists c \\in K :\\\\\n&u = (v_1,w) + (v_2,w) - (v_1 + v_2,w) \\lor\\\\\n&u = (v,w_1) + (v,w_2) - (v,w_1+w_2) \\lor\\\\\n&u = c(v,w) - (cv,w) \\lor\\\\\n&u = c(v,w) - (v,cw) \\}).\n\\end{align}</math>\n\nIn the quotient, where {{math|''N''}} is mapped to the zero vector, the following equalities,\n:<math>\\begin{align}\n(v_1,w) + (v_2,w) &= (v_1 + v_2,w),\\\\\n(v,w_1) + (v,w_2) &= (v,w_1+w_2),\\\\\nc(v,w) &= (cv,w),\\\\\nc(v,w) &= (v,cw)\n\\end{align}</math>\nall ''hold'' (unlike in {{math|''F''(''V'' × ''W'')}}), which is exactly what is desired. In these latter expressions, the {{math|(''v''<sub>1</sub>, ''w'')}}, etc., are images in the quotient of vectors in the free product under the quotient map. Usually, some other notation is employed for them, see below.\n\n===Notation===\nElements of {{math|''V'' ⊗ ''W''}} are often referred to as ''tensors'', although this term refers to many other related concepts as well.<ref>See [[Tensor]] or [[Tensor (intrinsic definition)]].</ref> If {{math|''v''}} belongs to {{math|''V''}} and {{math|''w''}} belongs to {{math|''W''}}, then the equivalence class of {{math|(''v'', ''w'')}} is denoted by {{math|''v'' ⊗ ''w''}}, which is called the tensor product of {{math|''v''}} with {{math|''w''}}. In physics and engineering, this use of the {{math| \"⊗\"}} symbol refers specifically to the [[outer product]] operation; the result of the outer product {{math|''v'' ⊗ ''w''}} is one of the standard ways of representing the equivalence class {{math|''v'' ⊗ ''w''}}.<ref>This similar to how [[Modulo operation|the engineering use]] of \"<math>\\pmod n</math>\" specifically returns the remainder, one of the many elements of the <math>\\pmod n</math> equivalence class.</ref> An element of {{math|''V'' ⊗ ''W''}} that can be written in the form {{math|''v'' ⊗ ''w''}} is called a ''pure'' or ''[[simple tensor]]''.  In general, an element of the tensor product space is not a pure tensor, but rather a finite linear combination of pure tensors.  For example, if {{math|''v''<sub>1</sub>}} and {{math|''v''<sub>2</sub>}} are [[linearly independent]], and {{math|''w''<sub>1</sub>}} and {{math|''w''<sub>2</sub>}} are also linearly independent, then {{math|''v''<sub>1</sub> ⊗ ''w''<sub>1</sub> + ''v''<sub>2</sub> ⊗ ''w''<sub>2</sub>}} cannot be written as a pure tensor. The number of simple tensors required to express an element of a tensor product is called the [[tensor rank]] (not to be confused with [[tensor order]], which is the number of spaces one has taken the product of, in this case 2; in notation, the number of indices), and for linear operators or matrices, thought of as {{math|(1, 1)}} tensors (elements of the space {{math|''V'' ⊗ ''V''<sup>∗</sup>}}), it agrees with [[matrix rank]].\n\n===Dimension===\nGiven bases {{math|{''v<sub>i</sub>''} }} and {{math|{''w<sub>j</sub>''} }} for {{math|''V''}} and {{math|''W''}} respectively, the tensors {{math|{''v<sub>i</sub>'' ⊗ ''w<sub>j</sub>''}<nowiki/>}} form a basis for {{math|''V'' ⊗ ''W''}}. Therefore, if {{math|''V''}} and {{math|''W''}} are finite-dimensional, the dimension of the tensor product is the product of dimensions of the original spaces; for instance {{math|'''R'''<sup>''m''</sup> ⊗ '''R'''<sup>''n''</sup>}} is isomorphic to {{math|'''R'''<sup>''mn''</sup>}}.\n\n===Tensor product of linear maps===\nThe tensor product also operates on [[linear map]]s between vector spaces. Specifically, given two linear maps {{math|''S'' : ''V'' → ''X''}} and {{math|''T'' : ''W'' → ''Y''}} between vector spaces, the ''tensor product of the two linear maps'' {{math|''S''}} and {{math|''T''}} is a linear map\n:<math>S\\otimes T:V\\otimes W\\to X\\otimes Y</math>\ndefined by\n:<math>(S\\otimes T)(v\\otimes w)=S(v)\\otimes T(w).</math>\n\nIn this way, the tensor product becomes a [[bifunctor]] from the category of vector spaces to itself, [[Functor#Covariance and contravariance|covariant]] in both arguments.<ref>{{cite book| last1=Hazewinkel|first1=Michiel|last2=Gubareni|first2=Nadezhda Mikhaĭlovna| last3=Gubareni|first3=Nadiya|last4=Kirichenko|first4=Vladimir V.|title=Algebras, rings and modules|page=100|\npublisher=Springer|year=2004|isbn=978-1-4020-2690-4}}</ref>\n\nIf {{math|''S''}} and {{math|''T''}} are both injective, surjective, or continuous then {{math|''S'' ⊗ ''T''}} is, respectively, injective, surjective, continuous.\n\nBy choosing bases of all vector spaces involved, the linear maps {{math|''S''}} and {{math|''T''}} can be represented by [[matrix (mathematics)|matrices]]. Then, the matrix describing the tensor product {{math|''S'' ⊗ ''T''}} is the [[Kronecker product]] of the two matrices. For example, if {{math|''V'', ''X'', ''W''}}, and {{math|''Y''}} above are all two-dimensional and bases have been fixed for all of them, and {{math|''S''}} and {{math|''T''}} are given by the matrices\n\n:<math>\\begin{bmatrix}\n    a_{1,1} & a_{1,2} \\\\\n    a_{2,1} & a_{2,2} \\\\\n  \\end{bmatrix}, \\qquad \\begin{bmatrix}\n    b_{1,1} & b_{1,2} \\\\\n    b_{2,1} & b_{2,2} \\\\\n  \\end{bmatrix}, </math>\n\nrespectively, then the tensor product of these two matrices is\n\n:<math>\n  \\begin{bmatrix}\n    a_{1,1} & a_{1,2} \\\\\n    a_{2,1} & a_{2,2} \\\\\n  \\end{bmatrix}\n\\otimes\n  \\begin{bmatrix}\n    b_{1,1} & b_{1,2} \\\\\n    b_{2,1} & b_{2,2} \\\\\n  \\end{bmatrix}\n=\n  \\begin{bmatrix}\n    a_{1,1}  \\begin{bmatrix}\n              b_{1,1} & b_{1,2} \\\\\n              b_{2,1} & b_{2,2} \\\\\n            \\end{bmatrix} & a_{1,2}  \\begin{bmatrix}\n                                      b_{1,1} & b_{1,2} \\\\\n                                      b_{2,1} & b_{2,2} \\\\\n                                    \\end{bmatrix} \\\\\n     & \\\\\n    a_{2,1}  \\begin{bmatrix}\n              b_{1,1} & b_{1,2} \\\\\n              b_{2,1} & b_{2,2} \\\\\n            \\end{bmatrix} & a_{2,2}  \\begin{bmatrix}\n                                      b_{1,1} & b_{1,2} \\\\\n                                      b_{2,1} & b_{2,2} \\\\\n                                    \\end{bmatrix} \\\\\n  \\end{bmatrix}\n=\n  \\begin{bmatrix}\n    a_{1,1} b_{1,1} & a_{1,1} b_{1,2} & a_{1,2} b_{1,1} & a_{1,2} b_{1,2} \\\\\n    a_{1,1} b_{2,1} & a_{1,1} b_{2,2} & a_{1,2} b_{2,1} & a_{1,2} b_{2,2} \\\\\n    a_{2,1} b_{1,1} & a_{2,1} b_{1,2} & a_{2,2} b_{1,1} & a_{2,2} b_{1,2} \\\\\n    a_{2,1} b_{2,1} & a_{2,1} b_{2,2} & a_{2,2} b_{2,1} & a_{2,2} b_{2,2} \\\\\n  \\end{bmatrix}.\n</math>\n\nThe resultant rank is at most 4, and thus the resultant dimension is 4. Here rank denotes the [[tensor rank]] (number of requisite indices), while the [[matrix rank]] counts the number of degrees of freedom in the resulting array.\n\nA [[dyadic product]] is the special case of the tensor product between two vectors of the same dimension.\n\n===Universal property===\n[[File:Another universal tensor prod.svg|right|thumb|200px|This [[commutative diagram]] presents the universal property of tensor product. Here <math>\\varphi</math> and <math>h</math> are bilinear, whereas <math>\\tilde{h}</math> is linear.]]\n\nIn the context of vector spaces, the tensor product <math>V \\otimes W</math> and the associated bilinear map <math>\\varphi: V \\times W \\to V \\otimes W</math> are characterized up to isomorphism by a [[universal property]] regarding [[bilinear map|bilinear maps]]. (Recall that a bilinear map is a function that is ''separately'' linear in each of its arguments.) Informally, <math>\\varphi</math> is the most general bilinear map out of <math>V \\times W</math>.\n\n{{gbq|\nThe vector space <math>V \\otimes W</math> and the associated bilinear map <math>\\varphi: V \\times W \\to V \\otimes W</math> have the property that any bilinear map <math>h: V \\times W \\to Z</math> from <math>V \\times W</math> to any vector space <math>Z</math> factors through <math>\\varphi</math> uniquely. By saying \"<math>h</math> factors through <math>\\varphi</math> uniquely,\" we mean that there is a unique linear map <math>\\tilde{h}: V \\otimes W \\to Z</math> such that <math>h = \\tilde{h} \\circ \\varphi</math>.\n}}\n\nThis characterization can simplify proofs about the tensor product. For example, the tensor product is symmetric, meaning there is a [[canonical isomorphism]]:\n:<math>V \\otimes W \\cong W \\otimes V.</math>\nTo construct, say, a map from <math>V \\otimes W</math> to <math>W \\otimes V</math>, it suffices to give a bilinear map <math>h: V \\times W \\to W \\otimes V</math> that maps <math>(v,w)</math> to <math>w \\otimes v</math>. Then the universal property of <math>V \\otimes W</math> means <math>h</math> factors into a map <math>\\tilde{h}:V \\otimes W \\to W \\otimes V</math>.\nA map <math>\\tilde{g}:W \\otimes V \\to V \\otimes W</math> in the opposite direction is similarly defined, and one checks that the two linear maps <math>\\tilde{h}</math> and <math>\\tilde{g}</math> are inverse to one another by again using their universal properties.\n\nSimilar reasoning can be used to show that the tensor product is associative, that is, there are natural isomorphisms\n:<math>V_1\\otimes(V_2\\otimes V_3)\\cong (V_1\\otimes V_2)\\otimes V_3.</math>\nTherefore, it is customary to omit the parentheses and write <math>V_1 \\otimes V_2 \\otimes V_3</math>.\n\nThe category of vector spaces with tensor product is an example of a [[symmetric monoidal category]].\n\nThe universal-property definition of a tensor product is valid in more categories that just the category of vector spaces. Instead of using multilinear (bilinear) maps, the general tensor product definition uses multimorphisms.<ref>https://ncatlab.org/nlab/show/tensor+product{{user-generated source|date=September 2017}}</ref>\n\n===Tensor powers and braiding===\nLet {{math|''n''}} be a non-negative integer.  The {{math|''n''}}th '''tensor power''' of the vector space {{math|''V''}} is the {{math|''n''}}-fold tensor product of {{math|''V''}} with itself.  That is\n:<math>V^{\\otimes n} \\;\\overset{\\mathrm{def}}{=}\\; \\underbrace{V\\otimes\\cdots\\otimes V}_{n}.</math>\n\nA [[permutation]] {{math|''σ''}} of the set {{math|{1, 2, ..., ''n''} }} determines a mapping of the {{math|''n''}}th Cartesian power of {{math|''V''}} as follows:\n\n:<math>\\begin{cases} \\sigma \\colon V^n\\to V^n \\\\ \\sigma(v_1,v_2,\\cdots,v_n) = \\left (v_{\\sigma(1)}, v_{\\sigma(2)},\\cdots,v_{\\sigma(n)} \\right ) \\end{cases}</math>\n\nLet\n:<math>\\varphi \\colon V^n \\to V^{\\otimes n}</math>\nbe the natural multilinear embedding of the Cartesian power of {{math|''V''}} into the tensor power of {{math|''V''}}.  Then, by the universal property, there is a unique isomorphism\n:<math>\\tau_\\sigma \\colon V^{\\otimes n} \\to V^{\\otimes n}</math>\nsuch that\n:<math>\\varphi\\circ\\sigma = \\tau_\\sigma\\circ\\varphi.</math>\n\nThe isomorphism {{math|''τ<sub>σ</sub>''}} is called the '''braiding map''' associated to the permutation {{math|''σ''}}.\n\n==Product of tensors==\n{{See also|Classical treatment of tensors}}\nFor non-negative integers {{math|''r''}} and {{math|''s''}} a type {{math|(''r'',''s'')}} [[tensor]] on a vector space {{math|''V''}} is an element of\n:<math> T^r_s(V) = \\underbrace{ V\\otimes \\dots \\otimes V}_{r} \\otimes \\underbrace{ V^*\\otimes \\dots \\otimes V^*}_{s} = V^{\\otimes r}\\otimes V^{*\\otimes s}.</math>\nHere {{math|''V''<sup>∗</sup>}} is the [[dual vector space]] (which consists of all [[linear map]]s {{math|''f''}} from {{math|''V''}} to the ground field {{math|''K''}}).\n\nThere is a product map, called the ''(tensor) product of tensors''{{refn|{{harvp|Bourbaki|1989|p=244}} defines the usage \"tensor product of ''x'' and ''y''\", elements of the respective modules.}}\n:<math>T^r_s (V) \\otimes_K T^{r'}_{s'} (V) \\to T^{r+r'}_{s+s'}(V).</math>\nIt is defined by grouping all occurring \"factors\" {{math|''V''}} together: writing {{math|''v''<sub>''i''</sub>}} for an element of {{math|''V''}} and {{math|''f''<sub>''i''</sub>}} for elements of the dual space,\n:<math>(v_1 \\otimes f_1) \\otimes (v'_1) = v_1 \\otimes v'_1 \\otimes f_1.</math>\n\nPicking a basis of {{math|''V''}} and the corresponding [[dual basis]] of {{math|''V''<sup>∗</sup>}} naturally induces a basis for {{math|''T''{{su|b=''s''|p=''r''}}(''V'')}} (this basis is described in the [[Kronecker product#Relation to the abstract tensor product|article on Kronecker products]]). In terms of these bases, the [[Coordinate vector|components]] of a (tensor) product of two (or more) [[tensor]]s can be computed. For example, if {{math|''F''}} and {{math|''G''}} are two [[covariance and contravariance of vectors|covariant]] tensors of rank {{math|''m''}} and {{math|''n''}} respectively (i.e. {{math|''F'' ∈ ''T''{{su|b=''m''|p= 0}}}}, and {{math|''G'' ∈ ''T''{{su|b=''n''|p= 0}}}}), then the components of their tensor product are given by\n:<math>(F\\otimes G)_{i_1i_2\\ldots i_{m+n}} = F_{i_{1}i_{2}\\ldots i_{m}}G_{i_{m+1}i_{m+2}i_{m+3}\\ldots i_{m+n}}.</math>\n<ref>Analogous formulas also hold for [[covariance and contravariance of vectors|contravariant]] tensors, as well as tensors of mixed variance.  Although in many cases such as when there is an [[inner product]] defined, the distinction is irrelevant.</ref>\nThus, the components of the tensor product of two tensors are the ordinary product of the components of each tensor. Another example: let {{math|'''U'''}} be a tensor of type {{math|(1, 1)}} with components {{math|''U<sup>α</sup><sub>β</sub>''}}, and let {{math|'''V'''}} be a tensor of type {{math|(1, 0)}} with components {{math|''V'' <sup>''γ''</sup>}}.  Then\n:<math> U^\\alpha {}_\\beta V^\\gamma = (U \\otimes V)^\\alpha {}_\\beta {}^\\gamma </math>\nand\n:<math> V^\\mu U^\\nu {}_\\sigma = (V \\otimes U)^{\\mu \\nu} {}_\\sigma. </math>\n\n==Relation to dual space==\nA particular example is the tensor product of some vector space {{math|''V''}} with its [[dual vector space]] {{math|''V''<sup>∗</sup>}} (which consists of all [[linear map]]s {{math|''f''}} from {{math|''V''}} to the ground field {{math|''K''}}). In this case, there is a canonical '''evaluation map'''\n:<math>V \\otimes V^* \\to K</math>\nwhich on elementary tensors is defined by\n:<math>v \\otimes f \\mapsto f(v).</math>\nThe resulting map\n:<math>T^r_s (V) \\to T^{r-1}_{s-1}(V)</math>\nis called [[tensor contraction]] (for {{math|''r'', ''s'' > 0}}).\n\nOn the other hand, if {{math|''V''}} is ''finite-dimensional'', there is a canonical map in the other direction (called the '''coevaluation map''')\n:<math>K \\to V \\otimes V^*, \\lambda \\mapsto \\sum_i \\lambda v_i \\otimes v^*_i.</math>\nwhere {{math|''v''<sub>1</sub>, ..., ''v''<sub>''n''</sub>}} is any basis of {{math|''V''}}, and {{math|''v''<sub>''i''</sub><sup>∗</sup>}} is its dual basis. Surprisingly, this map does not depend on our choice of basis.<ref>{{Cite web|url=https://unapologetic.wordpress.com/2008/11/13/the-coevaluation-on-vector-spaces/|title=The Coevaluation on Vector Spaces|date=2008-11-13|website=The Unapologetic Mathematician|access-date=2017-01-26}}</ref>\n\nThe interplay of evaluation and coevaluation map can be used to characterize finite-dimensional vector spaces without referring to bases.<ref>See [[Compact closed category]].</ref>\n\n===Tensor product vs. Hom===\nGiven two finite dimensional vector spaces {{math|''U''}}, {{math|''V''}}, denote the [[dual space]] of {{math|''U''}} as {{math|''U*''}}, we have the following relation: \n:<math> U^* \\otimes V  \\cong \\mathrm{Hom} (U, V),</math>\nan isomorphism can be defined by <math>\\alpha: U^* \\otimes V \\rightarrow  \\mathrm{Hom} (U, V)</math>, when acting on pure tensors \n:<math> u^* \\otimes v  \\mapsto (u^* \\otimes v)(u)  = u^*(u) v,</math> \nits \"inverse\" can be defined in a similar manner as [[Tensor product#Relation to dual space|above (Relation to dual space)]] using [[dual basis]] <math>\\{u^*_i\\}</math>, \n:<math> \\mathrm{Hom} (U,V) \\to U^* \\otimes V, \\quad f(\\cdot) \\mapsto \\sum_i u^*_i \\otimes f(u_i).</math>\nThis result implies \n:<math> \\dim( U \\otimes V ) =\\dim(U)\\dim(V)</math>\nwhich automatically gives the important fact that <math>\\{u_i\\otimes v_j\\} </math> forms a basis for  <math>U \\otimes V</math> where <math> \\{u_i\\}, \\{v_j\\} </math> are bases of {{math|''U''}} and {{math|''V''}}.\n\nFurthermore, given three vector spaces {{math|''U''}}, {{math|''V''}}, {{math|''W''}} the tensor product is linked to the vector space of ''all'' linear maps, as follows:\n:<math> \\mathrm{Hom} (U \\otimes V, W) \\cong \\mathrm{Hom} (U, \\mathrm{Hom}(V, W)).</math>\nHere {{math|Hom(-,-)}} denotes the {{math|''K''}}-vector space of all linear maps. This is an example of [[adjoint functor]]s: the tensor product is \"left adjoint\" to Hom.\n\n===Adjoint representation===\nThe tensor <math> \\scriptstyle T^r_s(V) </math> may be naturally viewed as a module for the [[Lie algebra]] {{math|End(''V'')}} by means of the diagonal action: for simplicity let us assume {{math|1=''r'' = ''s'' = 1}}, then, for each {{math|''u'' ∈ End(''V'')}},\n:<math> u(a \\otimes b)  = u(a) \\otimes b - a \\otimes u^*(b),</math>\n\nwhere {{math|''u''<sup>∗</sup>}} in {{math|End(''V''<sup>∗</sup>)}} is the [[transpose]] of {{math|''u''}}, that is, in terms of the obvious pairing on {{math|''V'' ⊗ ''V''<sup>∗</sup>}},\n:<math>\\langle u(a), b \\rangle = \\langle a, u^*(b) \\rangle</math>.\n\nThere is a canonical isomorphism <math>\\scriptstyle T^1_1(V) \\rightarrow \\mathrm{End}(V) </math> given by\n:<math>(a \\otimes b)(x) = \\langle x, b \\rangle a. </math>\n\nUnder this isomorphism, every {{math|''u''}} in {{math|End(''V'')}} may be first viewed as an endomorphism of <math>\\scriptstyle T^1_1(V)</math> and then viewed as an endomorphism of {{math|End(''V'')}}. In fact it is the [[Adjoint representation of a Lie algebra|adjoint representation]] {{math|ad(''u'')}} of {{math|End(''V'')}}.\n\n==Tensor products of modules over a ring==\n{{main article|Tensor product of modules}}\nThe tensor product of two [[module (mathematics)|modules]] {{math|''A''}} and {{math|''B''}} over a ''[[commutative ring|commutative]]'' [[ring (mathematics)|ring]] {{math|''R''}} is defined in exactly the same way as the tensor product of vector spaces over a field:\n:<math>A \\otimes_R B := F (A \\times B) / G</math>\nwhere now {{math|''F''(''A'' × ''B'')}} is the [[free module|free {{math|''R''}}-module]] generated by the cartesian product and {{math|''G''}} is the {{math|''R''}}-module generated by [[Tensor product#Definition|the same relations as above]].\n\nMore generally, the tensor product can be defined even if the ring is non-commutative ({{math|''ab'' ≠ ''ba''}}). In this case {{math|''A''}} has to be a right-{{math|''R''}}-module and {{math|''B''}} is a left-{{math|''R''}}-module, and instead of the last two relations above, the relation\n:<math>(ar,b)-(a,rb)</math>\nis imposed. If {{math|''R''}} is non-commutative, this is no longer an {{math|''R''}}-module, but just an [[abelian group]].\n\nThe universal property also carries over, slightly modified: the map {{math|''φ'' : ''A'' × ''B'' → ''A'' ⊗<sub>''R''</sub> ''B''}} defined by {{math|(''a'', ''b'') ↦ ''a'' ⊗ ''b''}} is a [[Tensor product of modules#Balanced product|middle linear map]] (referred to as \"the canonical middle linear map\".<ref>\n{{cite book|last=Hungerford|first=Thomas W.|title=Algebra|\npublisher=Springer|year=1974|isbn=0-387-90518-9}}</ref>); that is,<ref name=chen>\n{{citation|last=Chen|first=Jungkai Alfred|title=Advanced Algebra II|chapter=Tensor product|\nchapter-url=http://www.math.ntu.edu.tw/~jkchen/S04AA/S04AAL10.pdf|\ntype=lecture notes|date=Spring 2004|place=National Taiwan University}}</ref> it satisfies:\n\n:<math> \\begin{align}\n\\phi(a+a',b)=\\phi(a,b)+\\phi(a',b) \\\\\n\\phi(a,b+b')=\\phi(a,b)+\\phi(a,b') \\\\\n\\phi(ar,b)=\\phi(a,rb)\n\\end{align} </math>\n\nThe first two properties make {{math|''φ''}} a bilinear map of the [[abelian group]] {{math|''A'' × ''B''}}. For any middle linear map {{math|''ψ''}} of {{math|''A'' × ''B''}}, a unique group homomorphism {{math|''f''}} of {{math|''A'' ⊗<sub>''R''</sub> ''B''}} satisfies {{math|1=''ψ'' = ''f'' ∘ ''φ''}}, and this property determines <math> \\phi </math> within group isomorphism. See the [[tensor product of modules|main article]] for details.\n\n===Tensor product of modules over a non-commutative ring===\n\nLet A be a right R-module and B be a left R-module B. Then the tensor product of A and B is an abelian group defined by\n:<math>A \\otimes_R B := F (A \\times B) / G</math>\nwhere <math>F (A \\times B)</math> is a [[free abelian group]] over <math>A \\times B </math> and G is a subgroup of <math>F (A \\times B)</math> generated by relations\n:<math>\\begin{align}\n&\\forall a, a_1, a_2 \\in A, \\forall b, b_1, b_2 \\in B, \\forall r \\in R:\\\\\n&(a_1,b) + (a_2,b) - (a_1 + a_2,b),\\\\\n&(a,b_1) + (a,b_2) - (a,b_1+b_2),\\\\\n&(ar,b) - (a,rb).\\\\\n\\end{align}</math>\n\nThe universal property can be stated as follows.\nLet G be an abelian group with a map <math>q:A\\times B \\rightarrow G</math> which is bilinear, in the sense that\n:<math>\\begin{align}\n&q(a_1+a_2,b)=q(a_1,b)+q(a_2,b),\\\\\n&q(a,b_1+b_2)=q(a,b_1)+q(a,b_2),\\\\\n&q(ar,b)=q(a,rb).\n\\end{align}</math>\nThen there is a unique map <math>\\overline{q}:A\\otimes B \\rightarrow G</math> such that <math>\\overline{q}(a\\otimes b)=q(a,b)</math> for every <math>a\\in A, b\\in B</math>.\n\nFurthermore, we can give <math>A \\otimes_R B</math> a module structure under some extra conditions.\n:1) If A was a (S,R)-bimodule, then <math>A \\otimes_R B</math> is a left S-module where <math>s(a\\otimes b):=(sa)\\otimes b</math>.\n:2) If B was a (R,S)-bimodule, then <math>A \\otimes_R B</math> is a right S-module where <math>(a\\otimes b)s:=a\\otimes (bs)</math>.\n:3) If R was a commutative ring, then A and B are (R,R)-bimodules where <math>ra:=ar</math> and <math>br:=rb</math>. By 1), <math>A \\otimes_R B</math> is a left R-module. By 2), <math>A \\otimes_R B</math> is a right R-module. So we can conclude <math>A \\otimes_R B</math> is a (R,R)-bimodule.\n\n===Computing the tensor product===\nFor vector spaces, the tensor product {{math|''V'' ⊗ ''W''}} is quickly computed since bases of {{math|''V''}} of {{math|''W''}} immediately determine a basis of {{math|''V'' ⊗ ''W''}}, as was mentioned above. For modules over a general (commutative) ring, not every module is free. For example, {{math|'''Z'''/''n'''''Z'''}} is not a free abelian group (= {{math|'''Z'''}}-module). The tensor product with {{math|'''Z'''/''n'''''Z'''}} is given by\n:<math>M \\otimes_\\mathbf Z \\mathbf Z/n\\mathbf Z = M/nM.</math>\nMore generally, given a [[presentation of a module|presentation]] of some {{math|''R''}}-module {{math|''M''}}, that is, a number of generators {{math|''m''<sub>''i''</sub> ∈ ''M'', ''i'' ∈ ''I''}} together with relations <math>\\sum_{j \\in J} a_{ji} m_i = 0</math>, with {{math|''a''<sub>''ji''</sub> ∈ ''R''}}, the tensor product can be computed as the following [[cokernel]]:\n:<math>M \\otimes_R N = \\operatorname{coker} (N^J \\rightarrow N^I)</math>\nHere {{math|1=''N''<sup>''J''</sup> := ⨁<sub>''j'' ∈ ''J''</sub> ''N''}} and the map is determined by sending some {{math|''n'' ∈ ''N''}} in the {{math|''j''}}th copy of {{math|''N''<sup>''J''</sup>}} to {{math|''a''<sub>''ji''</sub>''n''}} (in {{math|''N''<sup>''I''</sup>}}). Colloquially, this may be rephrased by saying that a presentation of {{math|''M''}} gives rise to a presentation of {{math|''M'' ⊗<sub>''R''</sub> ''N''}}. This is referred to by saying that the tensor product is a [[right exact functor]]. It is not in general left exact, that is, given an injective map of {{math|''R''}}-modules {{math|''M''<sub>1</sub> → ''M''<sub>2</sub>}}, the tensor product\n:<math>M_1 \\otimes_R N \\to M_2 \\otimes_R N</math>\nis not usually injective. For example, tensoring the (injective) map given by multiplication with {{math|''n''}}, {{math|''n'' : '''Z''' → '''Z'''}} with {{math|'''Z'''/''n'''''Z'''}} yields the zero map {{math|0 : '''Z'''/''n'''''Z''' → '''Z'''/''n'''''Z'''}}, which is not injective. Higher [[Tor functor]]s measure the defect of the tensor product being not left exact. All higher Tor functors are assembled in the [[derived tensor product]].\n\n==Tensor product of algebras==\n{{main article|Tensor product of algebras}}\nLet {{math|''R''}} be a commutative ring. The tensor product of {{math|''R''}}-modules applies, in particular, if {{math|''A''}} and {{math|''B''}} are [[Algebra (ring theory)|{{math|''R''}}-algebras]]. In this case, the tensor product {{math|''A'' ⊗<sub>''R''</sub> ''B''}} is an {{math|''R''}}-algebra itself by putting\n:<math>(a_1 \\otimes b_1) \\cdot (a_2 \\otimes b_2) = (a_1 \\cdot a_2) \\otimes (b_1 \\cdot b_2).</math>\nFor example,\n:<math>R[x] \\otimes_R R[y] \\cong R[x, y].</math>\n\nA particular example is when {{math|''A''}} and {{math|''B''}} are fields containing a common subfield {{math|''R''}}. The [[tensor product of fields]] is closely related to [[Galois theory]]: if, say, {{math|1=''A'' = ''R''[''x''] / ''f''(''x'')}}, where {{math|''f''}} is some [[irreducible polynomial]] with coefficients in {{math|''R''}}, the tensor product can be calculated as\n:<math>A \\otimes_R B \\cong B[x] / f(x)</math>\nwhere now {{math|''f''}} is interpreted as the same polynomial, but with its coefficients regarded as elements of {{math|''B''}}. In the larger field {{math|''B''}}, the polynomial may become reducible, which brings in Galois theory. For example, if {{math|1=''A'' = ''B''}} is a [[Galois extension]] of {{math|''R''}}, then\n:<math>A \\otimes_R A \\cong A[x] / f(x)</math>\nis isomorphic (as an {{math|''A''}}-algebra) to the {{math|''A''<sup>deg(''f'')</sup>}}.\n\n==Eigenconfigurations of tensors==\nSquare [[Matrix (mathematics)|matrices]] {{math|''A''}} with entries in a [[Field (mathematics)|field]] {{math|''K''}} represent [[linear maps]] of [[vector spaces]], say <math>K^n \\to K^n</math>,  and thus linear maps <math>\\psi : \\mathbb{P}^{n-1} \\to \\mathbb{P}^{n-1}</math> of [[projective spaces]] over <math>K</math>. If {{math|''A''}} is [[Invertible matrix|nonsingular]] then <math>\\psi</math> is [[well-defined]] everywhere, and the [[Eigenvalues and eigenvectors|eigenvectors]] of <math>A</math> correspond to the fixed points of <math>\\psi</math>.  The ''eigenconfiguration'' of {{math|''A''}} consists of <math>n</math> points in <math>\\mathbb{P}^{n-1}</math>, provided <math>A</math> is generic and {{math|''K''}} is [[Algebraically closed field|algebraically closed]].   The fixed points of nonlinear maps are the eigenvectors of tensors.  \nLet <math>A = (a_{i_1 i_2 \\cdots i_d})</math> be a <math>d</math>-dimensional tensor of format <math>n \\times n \\times \\cdots \\times n</math> with entries <math>(a_{i_1 i_2 \\cdots i_d})</math>  lying in an algebraically closed field <math>K</math> of [[Characteristic (algebra)|characteristic]] zero.  Such a tensor <math>A \\in (K^{n})^{\\otimes d}</math> defines [[Morphism of algebraic varieties|polynomial maps]] <math>K^n \\to K^n</math> and <math>\\mathbb{P}^{n-1} \\to \\mathbb{P}^{n-1}</math> with coordinates \n:<math>\\psi_i(x_1, ..., x_n) = \\sum_{j_2=1}^n \\sum_{j_3=1}^n \\cdots \\sum_{j_d = 1}^n a_{i j_2 j_3 \\cdots j_d} x_{j_2} x_{j_3}\\cdots x_{j_d} \\;\\; \\mbox{for } i = 1,...,n </math>\nThus each of the <math>n</math> coordinates of <math> \\psi </math> is a [[homogeneous polynomial]] <math> \\psi_i </math> of degree <math> d - 1</math> in <math>\\mathbf{x} = (x_1, ..., x_n)</math>.  The eigenvectors of <math>A</math> are the solutions of the constraint \n:<math>\\mbox{rank} \\begin{pmatrix}x_1 & x_2 & \\cdots  & x_n \\\\ \\psi_1(\\mathbf{x}) & \\psi_2(\\mathbf{x}) & \\cdots & \\psi_n(\\mathbf{x}) \\end{pmatrix} \\leq 1 </math> \nand the eigenconfiguration is given by the [[Algebraic variety|variety]] of the <math>2 \\times 2</math> [[Minor (linear algebra)|minors]] of this matrix.<ref>Abo, H.; Seigal, A.; Sturmfels B. arXiv:1505.05729 [math.AG]</ref>\n\n==Other examples of tensor products==\n<!--- this section needs a clean-up? —- Taku --->\n===Tensor product of sheaves of modules===\n{{main article|Sheaf of modules}}\n\n===Tensor product of Hilbert spaces===\n{{main article|Tensor product of Hilbert spaces}}\n\n===Topological tensor product===\n{{main article|Topological tensor product}}\n\n===Tensor product of graded vector spaces===\n{{main article|Graded vector space#Operations on graded vector spaces}}\n\n===Tensor product of quadratic forms===\n{{main article|Tensor product of quadratic forms}}\n\n===Tensor product of multilinear forms===\nGiven two [[multilinear form]]s <math>\\scriptstyle f (x_1,\\dots,x_k)</math> and <math>\\scriptstyle g (x_1,\\dots, x_m)</math> on a vector space <math>V</math> over the field <math>K</math> their tensor product is the multilinear form \n:<math> (f \\otimes g) (x_1,\\dots,x_{k+m}) = f(x_1,\\dots,x_k) g(x_{k+1},\\dots,x_{k+m}).</math><ref name=\"An Introduction to Manifolds\">{{cite book |title=An Introduction to Manifolds | first=L. W. | last=Tu |series=Universitext |publisher=Springer | page=25 | isbn=978-1-4419-7399-3 | year=2010}}</ref>\n\nThis is a special case of the [[Tensor product#Product of tensors|product of tensors]] if they are seen as multilinear maps (see also [[Tensor#As multilinear maps|tensors as multilinear maps]]). Thus the components of the tensor product of multilinear forms can be computed by the [[Kronecker product]].\n\n===Tensor product of representations===\n{{main|Tensor product of representations}}\n\n===Tensor product of graphs===\n{{main article|Tensor product of graphs}}\nIt should be mentioned that, though called \"tensor product\", this is not a tensor product of graphs in the above sense; actually it is the [[Product (category theory)|category-theoretic product]] in the category of graphs and [[graph homomorphism]]s. However it is actually the [[Kronecker product|Kronecker tensor product]] of the [[adjacency matrix|adjacency matrices]] of the graphs. Compare also the section [[tensor product#Tensor product of linear maps|Tensor product of linear maps]] above.\n\n===Monoidal categories===\n\nA general context for tensor product is that of a [[monoidal category]].\n\n==Applications==\n\n===Exterior and symmetric algebra===\n{{Main|Exterior algebra|Symmetric algebra}}\n\nTwo notable constructions in linear algebra can be constructed as quotients of the tensor product: the exterior algebra and the symmetric algebra. For example, given a vector space {{math|''V''}}, the exterior product\n:<math>V \\wedge V</math>\nis defined as\n:<math>V \\otimes V/(v\\otimes v \\text{ for all } v\\in V).</math>\nNote that when the underlying field of {{math|''V''}} does not have characteristic 2, then this definition is equivalent to\n:<math>V \\otimes V / (v_1 \\otimes v_2 + v_2 \\otimes v_1 \\text{ for all } v_1, v_2 \\in V).</math>\nThe image of <math>v_1 \\otimes v_2</math> in the exterior product is usually denoted <math>v_1 \\wedge v_2</math> and satisfies, by construction, <math>v_1 \\wedge v_2 = - v_2 \\wedge v_1</math>. Similar constructions are possible for <math>V \\otimes \\dots \\otimes V</math> ({{math|''n''}} factors), giving rise to <math>\\Lambda^n V</math>, the {{math|''n''}}th [[exterior power]] of {{math|''V''}}. The latter notion is the basis of [[differential form|differential {{math|''n''}}-forms]].\n\nThe symmetric algebra is constructed in a similar manner:\n:<math>\\operatorname{Sym}^n V := \\underbrace{V \\otimes \\dots \\otimes V}_n / (\\dots \\otimes v_i \\otimes v_{i+1} \\otimes \\dots - \\dots \\otimes v_{i+1} \\otimes v_{i} \\otimes \\dots)</math>\nThat is, in the symmetric algebra two adjacent vectors (and therefore all of them) can be interchanged. The resulting objects are called symmetric tensors.\n\n===Tensor product of line bundles===\n{{main article|Vector bundle#Operations on vector bundles}}\n\n{{See also|tensor product bundle}}\n\n==Tensor product in programming==\n\n===Array programming languages===\n[[Array programming languages]] may have this pattern built in.  For example, in [[APL programming language|APL]] the tensor product is expressed as <code>○.×</code> (for example <code>A ○.× B</code> or <code>A ○.× B ○.× C</code>).  In [[J programming language|J]] the tensor product is the dyadic form of <code>*/</code> (for example <code>a */ b</code> or <code>a */ b */ c</code>).\n\nNote that J's treatment also allows the representation of some tensor fields, as <code>a</code> and <code>b</code> may be functions instead of constants. This product of two functions is a derived function, and if <code>a</code> and <code>b</code> are [[Differentiable function|differentiable]], then <code>a */ b</code> is differentiable.\n\nHowever, these kinds of notation are not universally present in array languages.  Other array languages may require explicit treatment of indices (for example, [[MATLAB]]), and/or may not support [[higher-order function]]s such as the [[Jacobian matrix and determinant|Jacobian derivative]] (for example, [[Fortran]]/APL).\n\n==See also==\n{{wiktionary}}\n*[[Dyadic product]]\n*[[Extension of scalars]]\n*[[Tensor algebra]]\n*[[Tensor contraction]]\n*[[Topological tensor product]]\n*[[Monoidal category]]\n\n==Notes==\n{{Reflist}}\n\n==References==\n* {{cite book |first = Nicolas|last=Bourbaki|authorlink=Nicolas Bourbaki | title = Elements of mathematics, Algebra I| publisher = Springer-Verlag | year = 1989|isbn=3-540-64243-9}}\n* {{cite book |first=Pierre A.|last=Grillet|title=Abstract Algebra|year=2007|publisher=Springer Science+Business Media, LLC|isbn=0387715673}}\n* {{cite book |authorlink=Paul Halmos|first=Paul|last=Halmos|title=Finite dimensional vector spaces|year=1974|publisher=Springer|isbn=0-387-90093-4}}\n* {{cite book |first=Thomas W.|last=Hungerford|authorlink=Thomas W. Hungerford|title=Algebra|year=2003|publisher=Springer|isbn=0387905189}}\n* {{Lang Algebra|edition=3r}}\n* {{cite book |first1=S.|last1=Mac Lane|authorlink1=Saunders Mac Lane|authorlink2=Garrett Birkhoff|last2=Birkhoff|first2=G.|title=Algebra|publisher=AMS Chelsea|year=1999|isbn=0-8218-1646-2}}\n* {{cite book |first1=M.|last1=Aguiar|first2=S.|last2=Mahajan| title = Monoidal functors, species and Hopf algebras|publisher = CRM Monograph Series Vol 29 |year=2010|isbn=0-8218-4776-7}}\n* {{cite web |url=http://pages.bangor.ac.uk/~mas010/nonabtens.html |title=Bibliography on the nonabelian tensor product of groups }}\n\n{{tensors}}\n\n{{DEFAULTSORT:Tensor Product}}\n[[Category:Binary operations]]\n[[Category:Bilinear operators]]",
            "slug": "tensor-product",
            "date_updated": 1517737189673,
            "imported": "https://en.wikipedia.org/wiki/Tensor product"
        }
    ]
}