{
	"next_comment_id": 5,
	"comment": [
		{
			"comment_id": 1,
			"body": "There's no difference between amd64 and x86_64",
			"post_id": 20,
			"date_added": 1449758846
		},
		{
			"comment_id": 2,
			"body": "as others already noted, there are already some attempts for index sites like ZeroSearch. I think we need a more decentralized solution.",
			"post_id": 14,
			"date_added": 1449758974
		},
		{
			"comment_id": 3,
			"body": "> [cgm616](#comment_6_1KcPohxmuqiNShTaAzJZLndm5aWtBZLuJn): Yeah, that's been my general line of thinking. ZeroSearch is good, but there's no way to find any content that you don't know you want to find. The same is true to a certain extent on the normal web, but it's a lot easier to browse with the centralized structure.\n\nThe normal web crawlers use links between sites to build their index. We can of course have same thing here. What I mean is that it would be better if we don't have a centralized index site at all.\n\nMaybe if the nodes could somehow automatically report to each-other what sites they are seeding, it would be possible for each node to query the network and build an index if necessary.",
			"post_id": 14,
			"date_added": 1449834186
		},
		{
			"comment_id": 4,
			"body": "> [cgm616](#comment_7_1KcPohxmuqiNShTaAzJZLndm5aWtBZLuJn): Yeah, that would work. As new sites get created, they get added to a per-node client side list. The same mechanism would be useful for reply notifications on comments.\n> What happens when a site is stopped being seeded by anyone? I know the goal of this network is to not have that happen, but it will eventually. Should the sites just stay in the client side list?\n\nIf a site is in a peer list, then it is being seeded (unless it was explicitly paused). If no one is  seeding a site, and if it is not in your list, then, there is no way to reach that content anyways, so no sense in querying it.\n",
			"post_id": 14,
			"date_added": 1449905438
		}
	],
	"comment_vote": {},
	"topic_vote": {}
}