{
	"title": "Infonesy.Blog",
	"description": "Мысли по проекту децентрализованной социальной системы. И вообще по p2p-социальным сетям.",
	"links": "* Wiki с инфо: [Infonesy](/17yiPtXkxqJY6RDyxfh1ZYYWhdq92tbQpE/)\n* [Balancer's Blog](/1MaQ4W5D6G52TpBfPACU9k9QcB1DxvHZ5v/)\n* Форум по p2p: [Infonesy.Talk](/1F4WVHDpQYxuJL6xEY3EZTYkZds9TTjVHC/)",
	"next_post_id": 35,
	"demo": false,
	"modified": 1540545950,
	"post": [
		{
			"post_id": 33,
			"title": "PixelFed",
			"date_published": 1540312857.125,
			"body": "Опять немного сегодня поковырялся с PixelFed (кто пропустил — это ранняя альфа федеративной фотогалереи на ActivePub). Сумел зарегистрироваться и запостить пару картинок. Но у Laravel какое-то полное безумие с определением HTTPS и роутингом. Я уже как только потроха вручную не патчил (перепробовав все штатные нагугленные методы), но до сих пор дофига ресурсов пытается грузиться по http, из-за чего на https-страница не работает. Не понимаю, как можно было нагородить такую кривь.\n\n![2018-10-23_19-40-21.jpg (977x507)](data/img/post_33_2018-10-23_19-40-21.jpg)"
		},
		{
			"post_id": 32,
			"title": "IPFS-cluster",
			"date_published": 1540301587.664,
			"body": "Я уже несколько раз писал про сабж. Пора вынести в отдельную заметку. Основная идея проста и изящна — связываем несколько IPFS-нод воедино инструментом распределения pin'ов. Чтобы можно было пинить файлы на разных нодах и они с нужными параметрами реплицировались на других узлах кластера.\n\nГлавная проблема была и есть в том, что IPFS-кластер, вешается на все доступные интерфейсы и это никак не регулируется. На жирном сервере с полудюжиной LXC и десятком-других Docker'ов IPFS-кластер получает эти же десятки адресов. Он их передаёт другим участникам кластера. Они потом безрезультатно пытаются достучаться до других узлов по липовым адресам и, через небольшой период времени, не достигнув успеха, завершают работу не найдя других участников.\n\nПроблему удалось побороть, сделав `Restart=always` в  `ipfs-cluster.service`. Теперь нода, даже вылетая, перезапускается снова и снова, пока, наконец, не достучится хоть до кого-то. Через некоторое время кластер благополучно собирается и работает уже безотказно :)\n\nВот только ноды кластера подозрительно медленно работают даже на десятках/сотнях пинов. Надо бы загнать туда сотню-другую гигабайт форумных аттачей и посмотреть, выживет оно или нет :)"
		},
		{
			"post_id": 31,
			"title": "И об атмосфере",
			"date_published": 1538321986,
			"body": "Во! Кто-то помнит, может, как я [в прошлом году писал про типичную аудиторию разных распределённых соцсетей](/1GQkPB8mFgxH7GQQbkNPJtvRaZZpVi65u1/?Post:26:Особенности+контингента+разных+распределённых+соцсетей). Писал я и про агрессивных пацифистов в SSB Patchwork. На днях снова начал щупать этот движок, что там поменялось и запостил сегодня в #military фотки МиГ-31\\. Реакция мгновенная: `Blocked [мой ID] for glorifying the military` :)"
		},
		{
			"post_id": 30,
			"title": "Скрипт для быстрой заливки картинки в IPFS",
			"date_published": 1527668841.75,
			"body": "Скрипт из командной строки принимает имя файла или ссылку на файл, если нужно, делает превью 800x, кладёт всё в IPFS и даёт Markdown-код итоговой картинки.\n\nПример:\n\n```\n┌─( ✔ 11:36:07 +00:00:07.498):~/Изображения/Export/экспорт-1511-4\n└balancer@home-server─> ipfs-add-md 20140519-1729-img_8955.jpg\n[![](https://gateway.ipfs.io/ipfs/QmezLi4DX7z5wYGP1VWUiamJFcdGiraHLvVKL4fNPFAoif/20140519-1729-img_8955-800x.jpg)](https://gateway.ipfs.io/ipfs/QmbhCfcffn5Ub8SBcA6Te8sPrbqFHZaEn5bXgxabECnYLb/20140519-1729-img_8955.jpg)\n```\n\nРезультат:\n\n[![](https://gateway.ipfs.io/ipfs/QmezLi4DX7z5wYGP1VWUiamJFcdGiraHLvVKL4fNPFAoif/20140519-1729-img_8955-800x.jpg)](https://gateway.ipfs.io/ipfs/QmbhCfcffn5Ub8SBcA6Te8sPrbqFHZaEn5bXgxabECnYLb/20140519-1729-img_8955.jpg)\n\n* * *\n\n```\n#!/bin/bash\n\nSWARM=`ipfs swarm peers`\n#GATE=https://gw-ipfs.tk/ipfs\nGATE=https://gateway.ipfs.io/ipfs\n\nif [[ ! $SWARM ]]; then\n        echo \"IPFS not running\"\n        exit\nfi\n\nif [[ \"$1\" =~ ^https?: ]]; then\n    BASE=$(basename \"$1\")\n    EXT=\"${BASE##*.}\"\n    FILE=$(tempfile --suffix=.$EXT)\n    wget -q \"$1\" -O \"$FILE\"\n    UNLINK=1\nelse\n    FILE=\"$1\"\n    UNLINK=0\nfi\n\nBASENAME=`basename \"$FILE\"`\n\nID=$(ipfs add -qw \"$FILE\" | tail -n1)\n\nWIDTH=`identify -format %W \"$FILE\"`\nID=$(ipfs add -qw \"$FILE\" | tail -n1)\n\nif [[ \"$ID\" != \"\" ]]; then\n        echo $ID > /var/sync/Infonesy/Infonesy-balancer-commands/pin-add-$ID\nfi\n\nif [[ $WIDTH -gt 800 ]]; then\n        THUMB=\"$(echo \"$FILE\" | sed -re 's/(\\.[a-z]+)$/-800x\\1/i')\"\n\n        if [[ \"$THUMB\" == \"$FILE\" ]]; then\n                echo Can not get thumbnail name for $FILE\n                exit\n        fi\n\n        convert \"$FILE\" -geometry 800x \"$THUMB\"\n\n        THUMB_ID=$(ipfs add -qw \"$THUMB\" | tail -n1)\n\n        echo \"[![]($GATE/${THUMB_ID}/`basename \"$THUMB\"`)]($GATE/${ID}/${BASENAME})\"\n\n        if [[ \"$THUMB_ID\" != \"\" ]]; then\n                echo $THUMB_ID > /var/sync/Infonesy/Infonesy-balancer-commands/pin-add-$THUMB_ID\n        fi\n\n        unlink \"$THUMB\"\nelse\n        echo \"![]($GATE/${ID}/${BASENAME})\"\nfi\n\nif [[ \"$UNLINK\" == \"1\" ]]; then\n    unlink \"$FILE\"\nfi\n```"
		},
		{
			"post_id": 29,
			"title": "Закат солнца вручную. Георепликация и Round Robin (черновик)",
			"date_published": 1522841929.454,
			"body": "> У нас было 2 мешка травы, 75 таблеток мескалина, 5 марок мощнейшей кислоты, полсолонки кокаина и гора возбудителей, успокоительных и всего такого, всех цветов, а ещё литр текилы, литр рома, ящик пива, пол-литра эфира и две дюжины амила. Не то, чтобы это всё было нужно в поездке, но раз начал коллекционировать наркоту, то иди в своём увлечении до конца. Единственное, что меня беспокоило — это эфир. В мире нет никого более беспомощного, безответственного и безнравственного, чем человек в эфирном запое. И я знал, что довольно скоро мы в это окунёмся.\n\nКак я ранее писал, разочарование в IPFS заставило искать иные способы георепликации. Плюс к этому — глюки Cloudflare, из-за которых пришлось отказаться от их кеширования, что привело к росту нагрузки на сервер и необходимости растаскивать нагрузку по нескольким серверам. Очевидное решение — Round Robin DNS. Но вылезает несколько мелких проблем:\n\n*   Файлы, которые аплоадятся только на одну ноду, не появляются мгновенно на других при использовании любых средств синхронизации.\n*   Автоматика получения и обновления сертификатов Let's Encrypt на Round Robin начинает буксовать.\n\nИтак, _у нас было_ три сервера:\n\n* * *\n\n*   Быстрый, основной, на Hetzner, с древними HDD, которых не хватает на высокую нагрузку\n*   Быстрый, новый, на Scaleway. С SSD, но с малым объёмом диска, куда все аттачи тупо не влезут.\n*   Тормозной, очень медленный VPS у Time4VPS, но с самым дешёвым терабайтом места.\n\n_​​​​​​​**тут я замечу, что это [пока ещё?] не статья с точными инструкциями, а что-то типа блог-записи с мыслями.** Может быть, со временем, доведу и до уровня статьи._\n\nЗадача.\n\n*   Ссылки древнего формата вида [https://files.balancer.ru/forums/attaches/f3/84/f384b2063aecac75502dced21ca339e5.jpg](https://files.balancer.ru/forums/attaches/f3/84/f384b2063aecac75502dced21ca339e5.jpg) отправить на общий архив, типа [https://archive.attaches.forums.a0z.ru/f3/84/f384b2063aecac75502dced21ca339e5.jpg](https://archive.attaches.forums.a0z.ru/f3/84/f384b2063aecac75502dced21ca339e5.jpg)\n*   Ссылки типа [https://files.balancer.ru/forums/attaches/2018/02/24-5978257-admiral-kuznetsov-063.jpg](https://files.balancer.ru/forums/attaches/2018/02/24-5978257-admiral-kuznetsov-063.jpg) — на [https://2018.f.a0z.ru/02/24-5978257-admiral-kuznetsov-063.jpg](https://2018.f.a0z.ru/02/24-5978257-admiral-kuznetsov-063.jpg)\n\nЭто позволит раскидать нагрузку по разным серверам и задействовать Round Robin DNS, когда одному доменному имени отвечают несколько IP.\n\nЭто решается, конечно, элементарно. Например, на NginX:\n\n```conf\nlocation ~ ^/forums/attaches/(\\w\\w/\\w\\w.*)$ {\n    rewrite ^/forums/attaches/(\\w\\w/\\w\\w.*)$ https://archive.attaches.forums.a0z.ru/$1 permanent;\n}\n\nlocation ~ ^/forums/attaches/((\\d\\d\\d\\d).*)$ {\n    rewrite ^/forums/attaches/(\\d\\d\\d\\d)/(.+)$ https://$1.f.a0z.ru/$2 permanent;\n}\n```\n\nВот дальше было хитрее.\n\nВо-первых, синхронизация файлов между серверами. Я задействовал для этого `Syncthing`. Хотя он и тормозит при пересканировании, но его можно поставить очень редким (оставив свежее обновление по `syncthing-inotify`).\n\nВо-вторых, syncthing даже при хорошей работе срабатывает не мгновенно. Задержка синхронизации бывает от секунд до десятков секунд. В это время обращения к серверам, куда файл ещё не пришёл, будет возвращать 404-ю ошибку.\n\nЭто проблему я решил NginX-проксированием на вторичных серверах. Если файл существует, то он показывается. Если нет, то идёт прокси-запрос к мастер-серверу:\n\n```conf\nserver_name 2018.f.a0z.ru;\nlocation / {\n# ...\n    try_files $uri @htz;\n}\n\nlocation @htz {\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    proxy_set_header Host $host;\n    proxy_pass http://htz.wrk.ru;\n}\n\n# ...\n```\n\nТаким образом, с любого вторичного сервера файл доступе даже когда синхронизация ещё не произошла.\n\nДальше — вопрос сертификата Let's Encrypt при использовании Round Robin DNS. Тут пришлось много возиться и экспериментировать. Я опущу все промежуточные проблемы и эксперименты и поделюсь итоговым решением.\n\nНа всех вторичных серверах нужно направить запросы с подкаталогу `/.well-known/acme-challenge` на мастер-сервер:\n```conf\nlocation /.well-known/acme-challenge/ {\n    proxy_set_header    Host                $host;\n    proxy_pass          http://htz.wrk.ru;\n}\n```\n\nНа мастер-сервере отправляем отдачу этого подкаталога из конкретного места сервера:\n```conf\nlocation ^~ /.well-known/acme-challenge/ {\n    default_type \"text/plain\";\n    root /var/www/html/letsencrypt;\n}\n```\n\nПрописываем этот путь в настройках `/etc/letsencrypt/cli.ini`:\n```conf\nauthenticator = webroot\nwebroot-path = /var/www/html/letsencrypt\npost-hook = service nginx reload\ntext = True\n```\n\nТакже там же жёстко прописываем плагин аутентификации по умолчанию (webroot). Нужно убедиться, что данный каталог нормально отдаётся со вторичных серверов. Потом можно получать сертификаты:\n```bash\n./certbot-auto certonly -d 2016.f.a0z.ru\n```\n\n_(продолжение следует)_"
		},
		{
			"post_id": 28,
			"title": "IPFS: разочарование",
			"date_published": 1515121990.642,
			"body": "Продолжая тему [Проблемы с IPFS](/1GQkPB8mFgxH7GQQbkNPJtvRaZZpVi65u1/?Post:27:Проблемы+с+IPFS).\n\nРазочарован :-/\n\nСделал несколько экспериментов по раздаче сколь-нибудь больших репозиториев (десятки гигабайт) и не смог обуздать аппетиты к памяти и процессору. Сервер, типа 32Гб оперативки и i7-4770 начинает жрать LA больше 20, всё тормозит:\n\n![load-week-ipfs-on.png (497x280)](data/img/post_28_load-week-ipfs-on.png)\n\n![cpu-week-ipfs-on.png (497x376)](data/img/post_28_cpu-week-ipfs-on.png)\n\nПридётся искать для синхронизации файлов в Infonesy более традиционные методы :-/\n\n**Update 2018-2401**:\n\n> [anotherneko](#comment_2_1LvGFs28pbTRSvaM94DNRK1z1Z6CaoAFZ7): Оно течет, если рестаровать периодически то более-менее юзабельно.\n\nОно само крешиться и перезапускается, если память в контейнере урезать (зелёненькое):\n\n![docker_memory-day.png (497x424)](data/img/post_28_docker_memory-day.png)\n\nУвы, всё равно жрёт ресурсов чрезмерно по отношению к отдаче. При чём когда-то давно раньше такого явно не было. Хоть экспериментируй с откатами на старые версии :)"
		},
		{
			"post_id": 27,
			"title": "Проблемы с IPFS",
			"date_published": 1514311440.508,
			"body": "IPFS в последнее время что-то совсем вразнос пошла. Сперва памяти стала жрать как не в себя. При чём в нескольких версиях, в последних из которых прямо пишут, что уменьшили потребление памяти. Ага, щаз, на машине с 16Гб мгновенно выжирает 8Гб. На VPS с 1Гб выжирает 700Мб, отправляя в аут MySQL и PHP. Ладно, эту проблему решил, засунув Docker-конейнер. Теперь на одном из серверов (VPS, 2Гб) и только на нём непрерывно занимается дисковым чтением на 50..100Мб/с. При чём в сеть это всё не идёт, сетевой трафик измеряется десятками килобайт в секунду. Думал, сперва, мало ли, переиндексация какая-то или оптимизация — но нет, уже половина дня прошла..."
		},
		{
			"post_id": 26,
			"title": "Особенности контингента разных распределённых соцсетей (черновик)",
			"date_published": 1513651290.128,
			"body": "Затравка, буду понемногу расширять запись в рамках подхода «[блоги как сайты](/1PxNZqJ3R3aUt171foqtzbhgZZ6JaggaAi/?Post:15:На+чём+делать+зайты)».\n\n## Mastodon\n\nМного японских (и японоговорящих) анимешников. Говорят, таким способом уходят от японских возможных проблем с законом.\n\n## [RetroShare](/18i1Ra9wePfmwhMCyhmLXXShxcSha5YAns/?Post:2:RetroShare)\n\nОгромная масса параноиков. Каждый второй обвиняет друг друга в работе на ФСБ. Каждое четвёртое сообщение заканчивается припиской «товарищ майор, перелогиньтесь». Очень много мата и ругани. Правда, там есть функция игнора и после зачистки самых агрессивных пользователей, сеть становится заметно чище. Но и почти мёртвой. Хотя, поскольку это сеть f2f, можно формировать собственные круги друзей, «только для своих».\n\n## SSB Patchwork\n\nПользуюсь сетью мало. Но когда начал там размещать фотографии боевых самолётов, получил лёгкий наезд в духе «зачем Вы тут постите фотографии оружия — оно убивает людей, это не этично!». Иных, более активных конфликтов или культурных особенностей пока не встречал.\n\n**Update 2018-09-30**: почти год спустя полез посмотреть, чем живёт сеть. Запостил фотки МиГ-31 в #military. Реакция мгновенная: `Blocked [мой ID] for glorifying the military` :)\n\nПозже метко охарактеризовал аудиторию товарищ StaLeg `@BVc+1q3069UJ/CWqM7w41E6qE9gnCd/ka5K1T7dtnYY=.ed25519`: «_Здесь, в ссб, в основном соларпанки и природолюбы, а ще паще технари_». Действительно, я это заметил, но не сформулировал в голове классификацию. Очень «_зелёная_» публика :)\n\n## [ZeroNet](/18i1Ra9wePfmwhMCyhmLXXShxcSha5YAns/?Post:3:ZeroNet)\n\nАудитория в целом очень усреднённая, без заметных перекосов. Почему лично я её и предпочитаю :) В основном относительно культурный IT-шный контингент, чем-то похоже на старое FIDO. Исключение — очень много китайцев. Похоже, для них это хороший способ выбраться за GFW. Ну и их просто в абсолютных числах много. Вот у них с технической культурой не очень. Например, они так и не восприняли идею, что заводить в общем англоязычном ZeroTalk массовые темы на китайском — не хорошо :)\n\n## Ссылки\n\n*   [Активность разных социальных систем](/1PxNZqJ3R3aUt171foqtzbhgZZ6JaggaAi/?Post:11:Активность+разных+социальных+систем)"
		},
		{
			"post_id": 25,
			"title": "Для LOR'а о причинах непопулярности популярных p2p социальных сетей :)",
			"date_published": 1507361696.572,
			"body": "> **[shell-script](https://www.linux.org.ru/forum/admin/13720004?cid=13726977):**\n> Всякие разные децентрализаторы предлагают по сути вернуться к файлику hosts, оборачивая его всякими хешами и большими алгоритмами.\n> Поэтому и не взлетают пока все эти распределённые сети\n\n1.  В том же ZeroNet активно используется NameCoin :)\n2.  Доменные имена всерьёз никогда не способствовали популярности ресурса. Сперва был долгий период, когда ресурс просто нельзя было найти, не важно, с читаемым именем или нет, потом очень быстро наступил период, когда люди не помнят и не вводят вручную даже короткие доменные имена, кроме совсем очевидных случаев, типа vk.com или google.com :) Для продвинутых юзеров есть закладки, для основной массы — поисковая система в адресной строке браузера.\n3.  Практически про каждую современную p2p-систему можно сказать, что причины отсутствия её популярности связаны не с перечисленным и не с чем-то общим, а, чаще, с индивидуальными особенностями.\n\nВот, например, ZeroNet сейчас сдерживают отсутствие нормального поиска по сети (что нас отбрасывает в конец 1990-х годов, я писал раньше: [ZeroNet: повторение большого пути](/1MaQ4W5D6G52TpBfPACU9k9QcB1DxvHZ5v/?Post:27:ZeroNet:+повторение+большого+пути)) и отсутствие анонимной раздачи больших файлов (вот, буквально только что на днях выкатили BigFiles в протоколе и реализовали зайт [ZeroUp](/1uPLoaDwKzP6MCGoVzw48r4pxawRBdmQc/)), но это ещё очень сыро и с кучей родовых проблем.\n\n* * *\n\n**RetroShare** от роста популярности удерживает firend-to-friend система, совершенно убогий клиент с куцыми форумами, отсутствие нормальной обновляемой динамики и т.п. А хуже всего — отсутствие headless-серверной реализации, чтобы можно было поддерживать сеть не только с десктопной машины.\n\n**GNUSocial**, **Mastodon**, **Twister** и прочую компанию тормозит то, что это только микроблоги. А потребителей одним микроблогов не так много. При чём первые два федеративные, а второй — на блокчейне, который даже сейчас, в отсутствии большой популярности, весит уже гигабайт.\n\n**SSB Patchwork** просто не имеет каких-то особых киллерфич, чтобы заинтересовать много народа. При этом бедный по функционалу, и тяжёлый по базе данных и клиенту. И тоже нет серверной версии.\n\nЧто там ещё осталось для форумно-комментного общения? :) Я, в общем, оценивал разные p2p-системы в [Infonesy.Talk](/1F4WVHDpQYxuJL6xEY3EZTYkZds9TTjVHC/)...\n\n**Steemit**. Ну, это фиаско с точки зрения децентрализации. Сделали распределённую систему, которую огородили и централизовали по самое не могу. Но вот у неё, как раз, шанс взлететь есть. «Майнинг написанием постов» многих может привлечь. Но это — не децентрализация.\n\nА, ну да. **Movim**, **Diaspora**. Федеративные, а не децентрализованные. Только блоги. Разработчики Diaspora ещё и какие-то мутные :) Пиар был недолгий, быстро утихло, понемногу развиваются, но из-за отсутствия пиара не на слуху.\n\n**Pandora**. Идея была интересная. Но, если я правильно помню, задумка осталась в рамках одного разработчика, который так и не потянул систему в одиночку. А соратников такие системы обычно привлекают только когда уже есть что-то работающее и интересное."
		},
		{
			"post_id": 23,
			"title": "ZeroTalk → Infonesy",
			"date_published": 1505007303.815,
			"body": "Немного повозился с сабжем. Чтобы нормально разгребать структуру требуется не только транспорт сделать, но и абстрактное хранилище. Для удобства ручной работы — на файлах. Всё думал подключить в качестве такого бэкенда какой-нибудь flat-file форум, но всё, что пощупал, кривое и недоделанное. Плюнул, завелосипедил свой формат. Точнее, пока только рыбу формата.\n\nСейчас работает экспорт ZeroTalk в посты по топикам на файловой системе. Нужно привести в порядок все доступные поля и можно делать импорт этих данных в какой-нибудь из обычных Web-форумов. Например, в ту же Vanilla. И можно будет запустить начерно web-зеркало на манер www.zites.cf"
		},
		{
			"post_id": 22,
			"title": "Facebook → Infonesy",
			"date_published": 1503898047.682,
			"body": "Аналогично предыдущему драйверу Redmine делаю и более востребованный драйвер Facebook. Пока только для чтения. Стадия готовности очень ранняя. В свете последующих работ с драйвером Redmine, придётся ещё и интерфейсы немного править. Главная проблема — Facebook сильно лимитирует частоту обращений через API (200 в час), что требует много возни с групповой работой, чтобы одним запросом выдёргивать как можно больше. А это плохо ложится в унификацию интерфейсов. Пока делаю только чтение, но когда-то надо будет делать и запись, для двухстороннего синка.\n\nhttps://github.com/Balancer/infonesy-driver-facebook"
		},
		{
			"post_id": 21,
			"title": "Redmine → Infonesy",
			"date_published": 1503897572.319,
			"body": "Возникла тут задача отконвертировать данные от Redmine (issues+wiki) и Trac в [Phabricator](https://www.phacility.com/phabricator/). Готовых работающих решений не нашёл и пришлось писать своё :) Решил делать не прямую конвертацию одного в другое, а через промежуточное файловое сохранение. Ага, как раз в формате обмена данных Infonesy :)\n\n[https://github.com/Balancer/infonesy-driver-redmine](https://github.com/Balancer/infonesy-driver-redmine)\n\n* * *\n\nЭто пока не работающий ещё драйвер, а отработка. Но уже экспортирует issues и юзеров в файлы Infonesy. Например:\n\n```Markdown\n---\nTitle: 'Отображение классификатора для «Участника проекта»'\nUUID: ru.balancer.rm.issue.563\nAuthor:\n    Title: 'XXXXXXX'\n    EmailMD5: 69489xxx04219adbd75663218bda8ce1\n    UUID: ru.balancer.rm.user.1\nDate: 'Mon, 12 Jun 2017 13:40:57 +0300'\nType: Issue\nModify: 'Mon, 12 Jun 2017 16:26:34 +0300'\n---\n\n# Отображение классификатора для «Участника проекта»\n\n*Роль «Участник проекта»*\n\n1\\. Прошу, сделать таблицу в три колонки\n\n| Полное название (Псевдоним)| Идентификатор | Описание |\n\nПсевдоним – отображаем, разумеется, если он есть\n\n2\\. Убрать ссылки с названия объекта\n\n3\\. Добавить в название слово «Проектный»… должно быть «Проектный классификатор…»\n\n4\\. Добавить над таблицей, с выравниванием вправо текст «Всего объектов: (экспорт в XLS)»\n```\n\nВажно только правильно и единообразно согласовать, например, форматы полей пользователя. А то в разных системах есть много тонкостей (например, одни учитывают последний логин, другие — последний визит...).\n\nЗаодно отрабатываю единые интерфейсы для разнородных данных."
		},
		{
			"post_id": 20,
			"title": "Ход работ",
			"date_published": 1503203738.248,
			"body": "Сейчас основное у меня направление — это гейтование с ZeroNet. Как закончится — так всё это будет и в Интернете доступно :) Ну, разве что ещё гейтование Facebook → Infonesy приоритетно тоже.\n\nЯ ещё к началу лета сделал (благо, это не сложно) экспорт ZeroBlog в Infonesy-файловый синк. Но потом дело притормозилось из-за кучи других забот. Сейчас возвращаюсь к экспериментам.\n\nРешил совместить приятное с полезным — сделать из файлсинка импорт в HTMLy ([вот тут писал выше](/1GQkPB8mFgxH7GQQbkNPJtvRaZZpVi65u1/?Post:18:HTMLy+CMS+на+flat-file+Markdown)). Очень уж удобный формат «базы» блогов.\n\nПолезность же будет в том, что это будут «статические» блоги, которые смогут окучить поисковики. И контент ZeroNet появится в обычном Интернете. Легче будет искать.\n\nПод всякие мелочи и технические моменты завёл тему в ZeroTalk: [http://127.0.0.1:43110/1F4WVHDpQYxuJL6xEY3EZTYkZds9TTjVHC/?Topic:28_1PniNzyi8fygvwyBaLpA9oBDVWZ5fXuJUw/Infonesy](http://127.0.0.1:43110/1F4WVHDpQYxuJL6xEY3EZTYkZds9TTjVHC/?Topic:28_1PniNzyi8fygvwyBaLpA9oBDVWZ5fXuJUw/Infonesy)"
		},
		{
			"post_id": 18,
			"title": "HTMLy (CMS на flat-file Markdown)",
			"date_published": 1503070819.087,
			"body": "*В рамках [задуманной системы блогов как сайтов](/1PxNZqJ3R3aUt171foqtzbhgZZ6JaggaAi/?Post:15:На+чём+делать+зайты) — для затравки буду пописывать инфо по разным движкам с точки зрения целесообразности использования их в Infonesy.*\n\nHTMLy is an open source databaseless blogging platform. The Flat-File\nBlog and Flat-File CMS written in PHP.\n\n- https://www.htmly.com/\n- https://github.com/danpros/htmly (520, 12, 5m)\n- Composer, Comments(Disqus), Admin, Markdown, Multiuser, Plugins, Search, Themes\n- Demo: https://demo.htmly.com/2015/07/premature-optimization-is-the-root-of-all-evil#disqus_thread\n- Demo: http://demo-htmly.rhcloud.com/tag/image-post\n- Themes: https://www.htmly.com/download/themes\n\n---\n\nСобственные впечатления по первым тестам:\n\n- В редакторе есть превью. Но нет синтаксической подсветки, автоматизации ссылок и т.п.\n- Категории. Сделаны достаточно удобно.\n- Многопользовательская.\n- Есть аплоад изображений.\n- Много разных категорий сообщения. Изображения, цитаты, видео, статические страницы...\n\nЕсли сравнивать с Grav, то HTMLy легче и в целом из коробки много функциональнее. Фактически это сразу готовое к использованию решение с приличным видом. Grav нужно сильно допиливать и то не факт, что получится. Зато в Grav классный редактор. Метатеги в Markdown в нём сделаны по-человечески в виде YAML в шапке. А у HTMLy — в виде HTML-комментариев."
		},
		{
			"post_id": 17,
			"title": "Steemit & Golos.io cli",
			"date_published": 1502825728.522,
			"body": "Копилка инструментария для работы со Steemit и Golos.io из командной строки или API.\n\n## steemcli\n\nA command-line client for posting content to Steem (npm)\n\n*   [https://github.com/yamadapc/steemcli](https://github.com/yamadapc/steemcli)\n*   [https://steemit.com/steembin/@yamadapc/ad562e9780cd8392a1ee5c097a3a88897c94f89f78022daa37c7dc27fc1ba78a](https://steemit.com/steembin/@yamadapc/ad562e9780cd8392a1ee5c097a3a88897c94f89f78022daa37c7dc27fc1ba78a)\n\n## wordpress-golos-chain\n\nПриложение для импорта и синхронизации wordpress записей в golos.io. Позволяет настроить автопостинг в p2p-сети постов из WordPress (npm).\n\n*   [https://github.com/vikxx/wordpress-golos-chain](https://github.com/vikxx/wordpress-golos-chain)"
		},
		{
			"post_id": 16,
			"title": "Проблема идентификаторов UUID в Infonesy",
			"date_published": 1499495147.769,
			"body": "Одна из проблем, которую я до сих пор удовлетворительно не решил — проблема сохранения UUID при кросспостинге.\n\nПример. У нас налажена двухсторонняя трансляция Facebook <-> ZeroBlog. Пишем в Facebook, получаем копию в ZeroBlog. Пишем в ZeroBlog, получаем копию в Facebook. Что получается без всякого контроля.\n\n1.  Пишем сообщение в ZeroBlog.\n2.  Осуществляется кросспостинг записи ZeroBlog → Facebook.\n3.  Транслятор обнаруживает новую запись в Facebook и делает кросспостинг Facebook→ ZeroBlog. В ZeroBlog оказывается дубль.\n4.  Транслятор ZeroBlog → Facebook обнаруживает новую запись... Переход к пункту 2.\n\n* * *\n\nЧтобы такого не происходило, каждое сообщение должно не только идентифицироваться уникально своим UUID, но транслятор должен знать его оригинальный UUID. Чтобы мог проверить наличие такого в целевой системе и избежать дубля.\n\nПока транслятор единственный, это не проблема — можно хранить базу с соответствием ID сообщений в системах и их оригинальным UUID. Там Infonesy работает сейчас. Тем более, что сейчас двунаправленного обмена по-настоящему и нет ещё нигде.\n\nНо в общем случае могут возникать длинные цепочки со множеством потенциальных зацикливаний. Да и просто для надёжности хорошо бы иметь несколько трансляторов. Вот у меня, пока я в отпуске, отказал домашний сервер. Что там с ним происходит не знаю, он недоступен. И на нём отказала единственная точка трансляции из Твиттера и RSS на форумы.\n\nТаким образом, желательно, чтобы каждый транслятор знал об оригинальном UUID любого сообщения. И вот тут у меня проблема. Я вижу два решения (которые могут дополнять друг друга для надёжности), но они далеки от идеала:\n\n## Единая база UUID\n\nМожно реализовать её, например, на базе той же ZeroNet. Есть некий распределённый сервис, куда все пользователи могут писать свои пары ключ-значение с указанием связок оригинального UUID сообщения и ID сообщения в конечно системе. То есть каждый кросспостер сперва проверит, нет ли для UUID, который он пытается транслировать, в нашем примере, из ZeroBlog уже созданного ID в Facebook.\n\nМинусы:\n\n*   Система не будет работать, когда станет по-настоящему большой. Вероятно, миллионы записей от десятков тысяч пользователей — максимум, что она нормально потянет.\n*   На каждом трансляторе придётся тащить ещё и ZeroNet-ноду.\n\n## Сохранение UUID прямо в конце сообщения\n\nДописываем каждое сообщение неким уникальным идентификатором, где указываем оригинальный UUID (или хеш, например, md5). Например, `nfoidz: fceab9cef4dc9619add4f85602875f1c`\n\nМинусы:\n\n*   Сообщение «замусоривается»\n*   У микроблогов происходит потеря и без того ограниченной длины сообщения"
		},
		{
			"post_id": 15,
			"title": "ZeroBlog → Infonesy",
			"date_published": 1499444887.637,
			"body": "После долгих месяцев простоя сегодня вернулся к работе над драйвером ZeroBlog. На самом деле там по сути всё просто, всё время уходит только на согласование и унификацию протокола. Сейчас работает уже экспорт ZeroBlog в формат файлового транспорта Infonesy. Немного допилить, оформить прилично, выложить пакетом — и экспорт готов.\n\nВот с блог-импортом пока глухо, в смысле, нигде пока не используется :) Наверное, проще всего будет для начала сделать импорт на свой форум в формате топиков, благо там с потрохами никаких проблем.\n\nА так, хочется экспорт в Facebook сделать. При чём если сделать это отдельным сервисом, то можно универсальное решение для любых ZeroNet юзеров сделать.\n\n```php\n$zeroblog_storage = \\Infonesy\\Drivers\\ZeroBlogStorage::factory(ZERO_DATA_DIR.'/'.$zero_blog_id);\n\n$exporter = new \\Infonesy\\Transport\\ObjectExporter($infonesy_push_dir);\n\n$user = new \\Infonesy\\Drivers\\ZeroBlog('1PniNzyi8fygvwyBaLpA9oBDVWZ5fXuJUw');\n$user->set('title', 'Balancer');\n$user->set('email_md5', md5('balancer@balancer.ru'));\n\nforeach($zeroblog_storage->load_array(\\Infonesy\\Drivers\\ZeroBlog::class, []) as $post)\n{\n    $post->set('infonesy_user', $user);\n    $exporter->export_md($post);\n}\n```"
		},
		{
			"post_id": 14,
			"title": "Снова о p2p-хранении и транспорте",
			"date_published": 1494299604.398,
			"body": "На LOR'е очередная тема [Сколько осталось до Интернетов в IPFS и когда мы побежим майнить Filecoinчики?](https://www.linux.org.ru/forum/talks/13405612). Я там отвечал, зафиксирую ответ и тут :)\n\n...\n\nЯ тоже делал очень большие ставки на IPFS в своих проектах, но сейчас отчасти разочарован.\n\n— IPFS в классическом виде плохо работает с большими объёмами данных. Я попробовал расшарить через него архив аттачей форума всего за год, около 100Гб и почти поставил сервер колом :) Очень высокая дисковая активность и миллион (образно, точно было не посчитать) мелких файликов в его базе, которые делают под ext4 работу с .ipfs почти невозможной.\n\n---\n\n— IPFS в классическом виде приводит к удваиванию занимаемой информации, если с ней нужно работать и локально. Расшариваешь библиотеку фильмов — тебе нужно или отказаться от её хранения локально и оставить только в IPFS, или придётся хранить и там, и там.\n\n— Недавно, наконец, была добавлена возможность расшаривания файлов из внешнего каталога. Я молчу о том, что это возможно только в пределах родительского для .ipfs каталога, это переживается хоть симлинками, хоть правкой исходников. Но в таком случае у раздаваемых файлов меняются хеши! А как же пресловутая адресуемость по контенту? Я хотел те же аттачи из первого пункта перевести на файловое хранение и почистить запиненные в базе файлы, но фигушки — хеши теперь другие!\n\n— Как было сказано выше, IPFS не годится для анонимного распространения контента. Если и есть надежда, что IPFS в будущем наберёт популярность, то для раздачи тех же коллекций фильмов и музыки он не пойдёт. Он сразу же сдаст их первоисточник :)\n\nЕдинственное, для чего я нашёл сперва, было, удобным применение IPFS — это для раздачи картинок в блогах ZeroNet и на сторонних форумах. Но потом картинки в блогах ZeroNet стали поддерживаться нативно и я подумал — какого фига, в IPFS (в отличие от ZeroNet) нужно раздачу файлов поддерживать искусственно. Ушёл владелец первичной информации из сети (потерял интерес, умер, сел в тюрьму...) — его файлы в IPFS могут быстро исчезнуть. В то время, как в ZeroNet они будут оставаться столько времени, сколько к ним будет существовать интерес. И хотя ZeroNet гораздо хуже служит для раздачи больших файлов, зато хранение хотя бы картинок в нём получается более надёжным и монолитным.\n\nИсключение составляет видео. Но и тут я стал больше ориентироваться на Tahoe-LAFS. Раз уж всё равно приходится поддерживать раздачу файлов искусственно и обращаться к гейтам, то удобнее делать это в системе, где контроль файлов более гибкий. Хочешь — адресуешь по контенту, хочешь — по ключу с модификациями. И хорошо видно, кто хранит какие данные, кого подменить после выбывания из сети... Кстати, даже с точки зрения легальности бонус — не смотря на явность, открытость и ограниченность сети, никто не хранит весь файл целиком. А за раздачу фрагментов файлов привлечь уже, по-моему, гораздо сложнее :)\n\nВ общем, сейчас я для p2p-хранения предпочитаю использовать ZeroNet+Tahoe-LAFS. А IPFS годен для простой и быстрой p2p-передачи файлов. Тут он, действительно, хорош. Добавил на одной ноде файл, получил хеш, отправил его в сеть и участники сети гарантированно этот файл по хешу получить могут, пусть и с какой-то задержкой. В то время, как ZeroNet требует предварительной загрузки всего зайта, а Tahoe-LAFS требует работы с конкретными нодами сети."
		},
		{
			"post_id": 13,
			"title": "IPFS 0.4.8",
			"date_published": 1493354512.081,
			"body": "Вышла (хе-хе, уже месяц как) версия 0.4.8\n\n[https://github.com/ipfs/go-ipfs/blob/master/CHANGELOG.md](https://github.com/ipfs/go-ipfs/blob/master/CHANGELOG.md)\n\nКакое-то ключевое изменение с directory sharding. Не понял навскидку, что делает, но судя по анонсу, что-то круто в плане оптимизации работы с большими деректориями. Нарезает на куски, что ли?\n\nПоявились базовые команды для работы с файловым хранилищем.\n\nПонял причины ошибки `Error: cannot add filestore references outside ipfs root`. Добавлять файлы можно только из home, где запущен ipfs. Наверное, как-то можно обойти эту настройку, пока не нашёл как. Сейчас можно в home сделать подкаталог и кидать туда симлинки на расшаривемые каталоги. В таком виде — работает. Вот пример сохранения ролика, удалённого с YouTube:\n\n<video controls=\"\" style=\"max-width: 100%\"><source data-cke-saved-src=\"https://gateway.ipfs.io/ipfs/QmdTvfJSGNNTkigu64qwM4qnwGyx6uhPGHTr11gUWUe2fZ/?title=icebreaker.mp4\" src=\"https://gateway.ipfs.io/ipfs/QmdTvfJSGNNTkigu64qwM4qnwGyx6uhPGHTr11gUWUe2fZ/?title=icebreaker.mp4\" type=\"video/mp4\">Your browser does not support the video element.</video>\n\n**Update:** Однако, есть проблемы:\n\n1. Хеши файлов, добавляемых из файлового хранилища не совпадают с обычными хешами. Т.е. перенести уже добавленные десятки гигабайт в нормальный вид с сохранением работающих хешей не получится.\n\n2. Если уже есть добавленный из файлового хранилища файл и добавляется обычный таким же путём, дублирование не отлавливается. Новый файл добавляется в репо `.ipfs`, а `ipfs filestore dups` ничего не отлавливает."
		},
		{
			"post_id": 12,
			"title": "Ещё о сравнении подходов",
			"date_published": 1492685825.148,
			"body": "Сейчас стараюсь время от времени одинаковые посты размещать в разные системы и сравниваю какие-то технические тонкости, реакцию сообщества и т.п.\n\nНачал размещать [только что написанный текст](/1GQkPB8mFgxH7GQQbkNPJtvRaZZpVi65u1/?Post:11:%D0%A1%D0%BE%D1%86%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D0%B0%D1%8F+%D1%81%D0%BF%D0%B5%D1%86%D0%B8%D0%B0%D0%BB%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F+p2p-%D1%81%D0%B5%D1%82%D0%B5%D0%B9) с иллюстрацией о разном восприятии коммьюнити разных сетей. Сперва — в **Quitter** ([**GNU Social**](/1F4WVHDpQYxuJL6xEY3EZTYkZds9TTjVHC/?Topic:13_1PniNzyi8fygvwyBaLpA9oBDVWZ5fXuJUw/GNU+Social)): [https://quitter.no/notice/3879872](https://quitter.no/notice/3879872) . Но туда не добавляется картинка. Молча не пишет причины, «не могу сохранить» и всё тут. Ладно, отложим. Пробуем новорекламированный **Mastodon**...\n\n* * *\n\nС ним всё ок. Выложилось сразу и без проблем: [https://mastodon.blue/@Balancer/231535](https://mastodon.blue/@Balancer/231535)\n\nОк, думаю, тогда в Quitter можно поместить только одну ссылку на фото. Но, вот незадача. Сразу возникает мысль — а если эта нода Мастодонта завтра ляжет? Картинки, размещённые на нём станут недоступны. Это очевидный недостаток федеративных сетей, типа GNU Social. Пока тебя читают оперативно, то читатели с других нод получат информацию и смогут её увидеть, даже если оригинальная нода упадёт. Но все остальные по фиксированной ссылке, пермалинку, получить информацию не смогут. То есть такой подход позволяет только обеспечить доступ к оперативной информации, но не позволяет зафиксировать её долговременно.\n\nВарианты p2p-сетей со специализированными клиентами, типа [**RetroShare**](/1F4WVHDpQYxuJL6xEY3EZTYkZds9TTjVHC/?Topic:14_1PniNzyi8fygvwyBaLpA9oBDVWZ5fXuJUw/RetroShare) или того же [**SSB Patchwork**](/1F4WVHDpQYxuJL6xEY3EZTYkZds9TTjVHC/?Topic:1_1BkgWBWWN9CoXNeEmyyuagid7roJruBVjz/Scuttlebutt) не подходят в принципе. На них невозможно дать ссылку. Кроме того, в RS ещё и ограничено время хранения данных.\n\n[**ZeroNet**](http://zeronet.a0z.ru/). Вот тут всё почти прекрасно :) Каждый материал имеет уникальный ID, который позволит предоставить доступ из внешнего Интернета даже если прокси, ссылку через который предоставят станет недоступным. Ну и, естественно, доступность материала никак не ограничена работоспособностью исходной ноды, если этот материал хранится хоть у одного читателя, находящегося в онлайне.\n\nПравда, сразу проблема. В ZeroTalk оригинальной модификации невозможно поместить картинку в сообщение. Это неприятно. Но можно написать отдельное сообщение в блог и поделится ссылкой. Что и было сделано :)\n\nЕщё сравнительный бонус. Прекрасная система публикации блога. Писать можно долго, внося исправления, сохраняя, но не публикуя сообщение. При этом локальность работы гарантирует беспроблемное сохранение неопубликованного черновика независимо от наличия связи с Интернет. После публикации материал можно в любое время отредактировать, исправить опечатки, дополнить... Подобная возможность отсутствует во всех остальных известных мне p2p-социальных системах.\n\n...\n\n**Update:** Но текущее впечатление — больше всего шансов взлететь у StatusNet (Diaspora/GNU Social/Mastodon). Не смотря на массу технических и идеологических недостатков у них больше шансов привлечь широкую публику. Примерно как это сделал Twitter :) Людям обычно нужно бегло потрещать, а не генерировать контент. Так что такие сети подходят тут идеально. Сам же я буду активнее развивать присутствие в ZeroNet, где сохранность, долговечность контента и его создание наиболее удобные :)"
		},
		{
			"post_id": 11,
			"title": "Социальная специализация p2p-сетей",
			"date_published": 1492685201.247,
			"body": "Думаю, этот блог можно посвятить не только Infonesy, по которой всё равно мало материала, а, вообще, p2p-сетям. Благо, тематика близкая. Так что...\n\nПока нерепрезентативно, но складывается впечатление, что Patchwork тоже отличается от других p2p-сетей «своеобразием». Если, например, RetroShare содержит много хамов-либералов-параноиков, в ZeroNet больше простые технари, чуждые политике, то в Patchwork стали попадаться агрессивные пацифисты :) Пример общения в канале #military :) Ещё и в приват стучат, типа, «одумайся, не пости военные фото, могут быть проблемы!» :D\n\n![patchwork-no-war.jpg (0x0)](data/img/post_11_patchwork-no-war.jpg)​​​​​​​"
		},
		{
			"post_id": 10,
			"title": "Неожиданные способы использования ZeroNet в рамках Infonesy",
			"date_published": 1491881852.004,
			"body": "> [biodamage](#comment_1_1J49x4BArT9m7BA7RWJcoGnP64xCmnUsFN): здравствуй balancer73 давно читаю тебя, меня интересует вопрос , нашел ли ты замену ipfs. мне не очень нравится закрытый btsync.\n\n_В какой-то степени это продолжение мыслей с <http://vanilla.infonesy.wrk.ru/discussion/13/infonesy-i-zeronet>_\n\nIPFS и BTSync, всё же, не прямые аналоги. Только в контексте подобных Infonesy и то, и другое, может работать как транспорт для данных. И то с натяжкой :)\n\nДля IPFS в качестве альтернативы я внезапно нашёл... использование собственно ZeroNet :) Заводим отдельный зайт для данных, выкладываем файлы, также, как в IPFS получаем из обычного Интернет, доступ по хешу/имени и гейту (например, основной gateway.ipfs.io), так и тут, в ZeroNet, можно иметь доступ к файлу по хешу/имени и прокси — разница только в том, что в ZeroNet отсутствует один центральный прокси. Ну и, конечно, в ZeroNet нет автоматической распределённости файлов, адресации по контенту и т.п. Зато, в отличие от IPFS, если кто-то хочет поддержать раздачу файлов, не нужно пинить их по одному, в ZeroNet «пинятся» целиком зайты.\n\n* * *\n\nВ качестве транспорта команд/мелких данных альтернативой для BTSync может служить или близкий аналог, Syncthing, или, опять же, ZeroNet. С Syncthing всё понятно, почти то же самое, только раздача не через публичные ключи, а через включение компьютеров в сеть, а в ZeroNet можно раздавать через публикацию файлов на зайтах. Что самое интересное, можно в рамках одного зайта множество разных участников сети могут раздавать свои подписанные файлы. Такая возможность отсутствует в btsync или аналогах. Там мне приходится иметь по R/O ключу для каждого источника и раздавать этот ключ всем приёмникам. Которые, в свою очередь, для передачи от себя, тоже шлют тебе свои R/O ключи. Получается много лишних сущностей. А в ZeroNet можно иметь один зайт, куда все будут писать, но никто не сможет написать от чужого имени.\n\nВ общем, у ZeroNet внезапно оказывается больше вариантов применения, чем просто p2p-сеть для общения :)"
		},
		{
			"post_id": 9,
			"title": "Файловый обмен: атачи",
			"date_published": 1488427480.436,
			"body": "Для распространения аттачей я делал большую ставку на **IPFS**, но она, похоже, не оправдывается :-/ Это прекрасный протокол обмена данными, по плюсам которого я много писал, но у него есть существенные недостатки:\n\n*   У IPFS очень плохо с контролем файловой системы. Да, можно получить список пинов... и всё. Нельзя разделить файлы по категориям, разнеся их хранение по разным нодам, нельзя получить списки файлов по тем или иным критериям, нельзя почистить кеши.... вообще, ничего нельзя, кроме как получить файл по хешу.\n*   На реальных системах нужно хранить по два экземпляра файлов. Один для IPFS, один для работы в локальной ФС. Эту проблему озвучивали не раз и я в том числе. Она становится злободневной при больших объёмах.\n*   С IPFS-хранилищем ноды очень, очень медленно получается работать на загруженных машинах. На своём основном сервере я даже объём `~/.ipfs/blocks` посчитать не могу! За 3-4 часа работы `du -hs` процесс так и не завершается, хотя сервер при этом аж тормозит от дисковой активности. Там что-то порядка 515+ подкаталогов по 15 тысяч файлов в каждом. Для ext на старом забитом разделе на нагруженном сервере это ад. Открытие одного каталога может занимать несколько минут(!). Легко понять, что вычисление всего размера в этом случае займёт десятки часов. По моим подсчётам, `du -hs` должен занять более двух суток! Кроме того, `ipfs pin ls` тоже может длится часами.\n*   IPFS никак не контролирует трафик. Я сижу за ноутбуком с серым IP. IPFS тут стоит только для удобства выгрузки файлов. Я делаю на ноуте `ipfs add`, а потом по полученному хешу — `ipfs pin add` на основном сервере. Так вот, на ноуте IPFS постоянно активна, жрёт в больших количествах процессор и трафик. Она выступает в роли транзитного узла для других нод. Серая машина с тормозным Wi-Fi! У меня канал затыкается на этом! И транзитный трафик никак не отключить штатными средствами!\n\nТак что же на замену?\n\n* * *\n\n### Файловый синк (BTSync/Rslsync/Syncthing)\n\n#### Плюсы\n\n*   Всё хранение в обычных файлах. Как храним, там и отдаём. Соответственно, полностью контролируем работу с файлами.\n*   Легко подключать новые машины для раздачи.\n*   Система как R/O, так и R/W. Файлы можно менять.\n*   Рядом с файлами можно хранить их описание. В IPFS никак по хешу файла не найти, откуда он и что с ним.\n\n#### Минусы\n\n*   Дублирование файлов.\n*   Невозможность получить файл на сторонней ноде, пока она всё не выкачает. В IPFS можно запросить файл по хешу и, пусть и с задержкой, он обязательно будет отдан. Здесь пока ноды не засинхронизируются, файл просто отсутствует.\n*   Невозможность делать транзитные ноды, выходные узлы. Нода должна хранить все файлы.\n\n### ZeroNet\n\nВ основном плюсы и минусы как у файлового синка, так как это, фактически, вариант такого синка. Но дополнительно:\n\n#### Плюсы\n\n*   Репозитории могут быть готовыми к отдаче зайтами.\n*   Изначальные ноды могут прятаться за Tor, что полезно для борьбы с блокировками.\n\n#### Минусы\n\n*   Tor (в случае «прятаться») плохо рассчитан на большой трафик в начале синка\n*   ZeroNet плохо смотрит на зайты в десятки гигабайт размером :) Можно (и нужно), конечно, нарезать хранилище по дате/теме, но всё равно получатся гигабайты на зайт.\n\n### Tahoe-LAFS\n\nПлюсы-минусы тут близки к IPFS и частично пересекаются с файловым синком. Поэтому некоторые из них.\n\n#### Плюсы\n\n*   Контент можно модифицировать.\n*   Можно работать с тематическими каталогами.\n*   Можно создавать выходные ноды без хранения на них всего контента.\n\n#### Минусы\n\n*   Как и у IPFS — отсутствие раздачи прямо с ФС. Только из своего хранилища.\n*   Жёсткая структура связки нод — любой желающий не может подключиться на раздачу.\n\n## Выводы\n\nВ первом приближении сейчас думаю задействовать файловый синк через BTSync/Rslsync. Создам десятки раздач по датам/темам. В протоколе передачи данных буду указывать ID ноды и путь к файлу."
		},
		{
			"post_id": 8,
			"title": "Тысячи сайтов темной паутины – Dark Web – оказались недоступны из-за атаки",
			"date_published": 1487004844.284,
			"body": "_Она вывела из строя до 20% всего анонимного интернета_\n\nВ результате кибератаки на хостинг Freedom Hosting II в пятницу тысячи сайтов темной паутины были выведены из строя и оставались неработоспособными как минимум до конца понедельника.\n\n---\n\nТемной паутиной называют сеть серверов, построенных на защищенной программной платформе Tor, обеспечивающей анонимность участников. Этой сетью пользуются многие общественные активисты, лица, желающие скрыть свою личность, а также преступники, распространяющие запрещенный контент вроде детской порнографии и средств для осуществления кибератак. Так, онлайновая торговая площадка Silk Road использовала серверы темной паутины, желая избежать преследования со стороны правоохранителей, но в 2013 г. была ликвидирована федеральными властями США в результате уголовного расследования.\n\nПо словам независимого исследователя Сары Джейми Льюис, ранее работавшей инженером по безопасности в Amazon.com, атака вывела из строя около 20% всех сайтов темной паутины. Организаторы атаки затем опубликовали информацию из баз данных на серверах Freedom Hosting II. Льюис отмечает, что Freedom Hosting II был крупнейшим хостингом анонимных сайтов. В числе прочего хакеры опубликовали переписку участников форумов, посвященных детской порнографии, а также коды для серверов, управлявших взломанной сетью.\n\nДругой независимый исследователь, Крис Монтейро, проанализировавший опубликованные хакерами данные с Freedom Hosting II, также обнаружил в них материалы, связанные с детской порнографией, и идентификаторы и пароли пользователей. Еще один исследователь, Трой Хант, отмечает, что среди этих материалов были обсуждения порнографического контента, но собственно порнографические изображения оттуда были удалены. «Сайты такого рода по понятным причинам заинтересованы в сохранении анонимности», – говорит Хант. Пока неясно, кто управляет хостингом Freedom Hosting II, информации о его владельцах в публичном доступе нет.\n\nХотя анонимная система Tor приспособлена для сокрытия личности и местоположения пользователей, частные сообщения, передаваемые в сети Freedom Hosting II, могут содержать данные, которые позволяют установить личности участников обмена, в том числе телефонные номера и адреса электронной почты. В сервисах же вроде Gmail не применяются «анонимайзеры» (средства для скрытия информации о пользователе). Правоохранители могут использовать эти данные в ходе расследований, вместе с тем нарушение работы столь крупного хостинг-провайдера может и помешать уже начатым расследованиям, поскольку нарушители закона, вероятно, поспешат перенести свою деятельность на другую онлайн-площадку. ФБР в понедельник отказалось комментировать ситуацию.\n\nЛица, называющие себя организаторами атаки на Freedom Hosting II, сообщают свой адрес электронной почты, но отказываются предоставить информацию о себе. Льюис отмечает, что, хотя атакой были затронуты около 10 000 сайтов, большинство из них не использовались активно. Многие сайты содержали анонимные блоги, посвященные политике.\n\n// Перевел Александр Силонов\n// http://www.vedomosti.ru/technology/articles/2017/02/09/676782-temnoi-pautini"
		},
		{
			"post_id": 7,
			"title": "TT-RSS транспорт",
			"date_published": 1480179930.297,
			"body": "Поток (пока начерно — нет тегов, точно не показываются авторы и т.п.) пошёл: http://www.wrk.ru/forums/viewforum.php?id=221\n\nПосмотреть, как это выглядит на уровне данных можно в BTSync по ключу `BOEWZOVDW47TYM22WMQXDGULCNWLGRQFC`."
		},
		{
			"post_id": 6,
			"title": "Интеграция с Tiny Tiny RSS",
			"date_published": 1480126306.938,
			"body": "Начерно слепил экспорт в унифицированном формате из ссылок, опубликованных в Tiny Tiny RSS. С виду как живые :) Давно собирался, но всё замахивался на крутую обработку ссылок и взяться за реализацию всё не получалось. Сейчас предельно упростил задачу и процесс пошёл.\n\n- TT-RSS конвертируется в Markdown, пока с картинками с их реальными адресами\n- Результат складируется в Post-формате (Markdown+YAML)\n- Всё это выглядит как поток сообщений на форуме, соответственно, может импортироваться для обсуждения любым форумом в Infonesy."
		},
		{
			"post_id": 5,
			"title": "Каталоги в IPFS",
			"date_published": 1477241243.841,
			"body": "Хеш каталога не зависит от его имени, только от содержимого. Таким образом для раздачи файла с сохранением имени достаточно отдавать его в любом каталоге любое количество раз, засорения хранилища не будет. Главное, чтобы файл оставался с одним названием. Если его поменять, то хеш файла останется тем же, а вот хеш каталога с ним — уже нет.\n\n![Game of Thrones: Hold door](https://ipfs.io/ipfs/QmVFuq4TUed4FYBtfW5GMtrTVMNRWjMuB6ckzjzfwz9kAX/Game-of-Thrones--Hold-door.jpg)\n"
		},
		{
			"post_id": 3,
			"title": "IPFS в Infonesy",
			"date_published": 1476197454.657,
			"body": "У меня долго дело стопорилось из-за того, что при раздаче файлов теряются их имена и расширения. Что в случае аттачей достаточно неприятно.\n\nИ только сегодня допёр, что раздавать можно не тупо файлами, а файлами, положенными в каталоги. В таком случае раздаётся хеш имени каталога + имя файла. Например:\n\n```\nhttps://gateway.ipfs.io/ipfs/QmaoxkD2rBfqJRJqrwkstPkxPAVtX8EU1dWrCFpUh9RqNJ/2016-0828-1825-img_9402-002-калина-макро.jpg\n```\n\nБолее того, раздачи можно оформлять во вполне приличном виде каталогов, типа:\n\nhttps://gateway.ipfs.io/ipfs/QmaoxkD2rBfqJRJqrwkstPkxPAVtX8EU1dWrCFpUh9RqNJ/\n\nНадо бы продумать логику работы с IPNS (там главный затык — наличие только одной модифицируемой переменной на ноду) и таким образом можно организовать хоть всеобщую раздачу всех аттачей форумов одной кучей :)\n\nПридётся поковыряться с реализацией, но результат будет интересный.\n\n// кросспостинг с http://www.balancer.ru/g/p4313121"
		}
	]
}