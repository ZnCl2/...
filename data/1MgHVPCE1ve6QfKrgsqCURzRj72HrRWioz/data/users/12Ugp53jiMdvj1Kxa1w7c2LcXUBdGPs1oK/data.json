{"next_paste_id":3,"next_comment_id":0,"paste":[{"paste_id":0,"description":"","body":"python zeronet.py --use_openssl True --db_mode speed --fileserver_port 10088  --stream_downloads True \n","language":"text/x-sh","encrypted":false,"added":1496063922},{"paste_id":1,"description":"","body":"本着先来后到的原则，笔者先来介绍进程组：\n顾名思义，进程组就是一系列相互关联的进程集合，系统中的每一个进程也必须从属于某一个进程组；\n每个进程组中都会有一个唯一的 ID(process group id)，简称 PGID；PGID 一般等同于进程组的创建进程的 Process ID，而这个进进程一般也会被称为进程组先导(process group leader)，同一进程组中除了进程组先导外的其他进程都是其子孙；\n进程组的存在，方便了系统对多个相关进程执行某些统一的操作，例如，我们可以一次性发送一个信号量给同一进程组中的所有进程。","language":"text/plain","encrypted":false,"added":1496072540},{"paste_id":2,"description":"","body":"#!/usr/bin/env python\n# -*- encoding: utf-8 -*-\n# Created on 2016-03-25 00:59:45\n# Project: taobaomm\n\nfrom pyspider.libs.base_handler import *\n\nPAGE_START = 1\nPAGE_END = 30\nDIR_PATH = '/var/py/mm'\n\n\nclass Handler(BaseHandler):\n    crawl_config = {\n    }\n\n    def __init__(self):\n        self.base_url = 'https://mm.taobao.com/json/request_top_list.htm?is_coment=false&page='\n        self.page_num = PAGE_START\n        self.total_num = PAGE_END\n        self.deal = Deal()\n\n    def on_start(self):\n        while self.page_num <= self.total_num:\n            url = self.base_url + str(self.page_num)\n            self.crawl(url, callback=self.index_page)\n            self.page_num += 1\n\n    def index_page(self, response):\n        for each in response.doc('.lady-name').items():\n            self.crawl(each.attr.href, callback=self.detail_page, fetch_type='js')\n\n    def detail_page(self, response):\n        domain = response.doc('.mm-p-domain-info li > span').text()\n        if domain:\n            page_url = 'https:' + domain\n            self.crawl(page_url, callback=self.domain_page)\n\n    def domain_page(self, response):\n        name = response.doc('.mm-p-model-info-left-top dd > a').text()\n        dir_path = self.deal.mkDir(name)\n        brief = response.doc('.mm-aixiu-content').text()\n        if dir_path:\n            imgs = response.doc('.mm-aixiu-content img').items()\n            count = 1\n            self.deal.saveBrief(brief, dir_path, name)\n            for img in imgs:\n                url = img.attr.src\n                if url:\n                    extension = self.deal.getExtension(url)\n                    file_name = name + str(count) + '.' + extension\n                    count += 1\n                    self.crawl(img.attr.src, callback=self.save_img,\n                               save={'dir_path': dir_path, 'file_name': file_name})\n\n    def save_img(self, response):\n        content = response.content\n        dir_path = response.save['dir_path']\n        file_name = response.save['file_name']\n        file_path = dir_path + '/' + file_name\n        self.deal.saveImg(content, file_path)\n\n\nimport os\n\nclass Deal:\n    def __init__(self):\n        self.path = DIR_PATH\n        if not self.path.endswith('/'):\n            self.path = self.path + '/'\n        if not os.path.exists(self.path):\n            os.makedirs(self.path)\n\n    def mkDir(self, path):\n        path = path.strip()\n        dir_path = self.path + path\n        exists = os.path.exists(dir_path)\n        if not exists:\n            os.makedirs(dir_path)\n            return dir_path\n        else:\n            return dir_path\n\n    def saveImg(self, content, path):\n        f = open(path, 'wb')\n        f.write(content)\n        f.close()\n\n    def saveBrief(self, content, dir_path, name):\n        file_name = dir_path + \"/\" + name + \".txt\"\n        f = open(file_name, \"w+\")\n        f.write(content.encode('utf-8'))\n\n    def getExtension(self, url):\n        extension = url.split('.')[-1]\n        return extension","language":"text/x-python","encrypted":false,"added":1496073483}],"comment":[]}