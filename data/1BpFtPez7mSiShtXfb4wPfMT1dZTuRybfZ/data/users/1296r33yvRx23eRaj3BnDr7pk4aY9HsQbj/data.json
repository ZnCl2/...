{
	"next_topic_id": 2,
	"topic": [
		{
			"topic_id": 1554656221,
			"title": "Принцип работы Zeronet",
			"body": "Хотелось бы поинтересоваться, может кто проясит. Каким образом заявляется работа форумов в Zeronet?   В IPFS, понятно, система в целом оперирует только файлами и нужна какая-то надстройка сверху...  В Zeronet заявляется подпись сайта владельцем. Получается, форум -- это чей-то сайт,  как в обычном виде?  А как же работает авторизация (вот я сейчас был вынужден авторизоваться, чтоб написать это сообщение) ?  Получается сообщения подписаны авторами.  Но технически, на более низком уровне -- чем является форум?  Всё тем же сайтом где в бэкенде стоит  база данных в которую валятся сообщения, и из которой выбираются при попытке показать страничику?  Или сообщения существуют независимо (от сайта на котором показываются), и сайт лишь имеет ссылки на файлы сообщений?\n\nКак я сказал выше, IPFS оперирует только файлами. И используя некую надстройку можно организовать поверх IPFS сеть типа форума, чата и т.п. Где каждое сообщение бы существовало независимо, а некая система бы только собирала сообщения из общей сети в единое целое. При этом процесс мог бы происходить у каждого пользователя в браузере независимо от некого центрального сайта, который мог бы быть нужен только лишь для загрузки \"веб-приложения\", которое в принципе можно грузить из разных источников или использовать ранее закешированное. Нужна только некоторая система, которая будет в общеизвестное место помещать идентификаторы новых сообщений-файлов, и способ логического деления сообщений (топики/треды, группы новостей, чаты, автор, дата/время), который мог бы использовать пользователь для выбора не всего подряд, а интересного ему. Наверное сообщение (верней его метаинформация, доступная без чтения самого сообщения) попросту могла бы нести в себе ограниченный набор ссылок на ряд других объектов, таких как другие сообщения (начальное сообщение форума, первое сообщение темы, сообщение на которое отвечают), люди (для выборки по автору),  и т.п.\n\nНо непонятно, что бы могло являться неким общеизвестным местом, куда бы попадала информация о существующих сообщениях. Очевидно, поток в пределе может быть весьма значительным, миллиарды ссылок на сообщения. Потому, что он общий на всю планету. Да, сообщения из будущего могут ссылаться на сообщения из прошлого, но не наоборот. Это проблема. Решение заключается в \"ассоциативной памяти\", когда можно найти данные по содержимому (метаинформации, содержащей только ссылки), а не по адресу. Т.е. когда были бы возможно запросы \"найти все записи ссылающиеся на такую-то запись\".  Сейчас IPFS, как я понимаю, такой функционал не предусматривает. Фактически же, он должен выполняться каждым сервером. И потом такая функция скорей подразумевает способность эффективно оперировать объектами малого (сотни байт) размера.\n\nА как дело обстоит в Zeronet?  Возможно ли потенциальное построение системы подобной описанной выше?",
			"added": 1554656220
		}
	],
	"topic_vote": {
		"1554656221_1296r33yvRx23eRaj3BnDr7pk4aY9HsQbj": 1
	},
	"next_comment_id": 4,
	"comment": {
		"1537644529_161s6hKbhaHsCo96nivkFpAQ1Ff2SDTEUk": [
			{
				"comment_id": 1,
				"body": "Как я понимаю, из простых мер -- PaleMoon.",
				"added": 1554656282
			}
		],
		"1554656221_1296r33yvRx23eRaj3BnDr7pk4aY9HsQbj": [
			{
				"comment_id": 2,
				"body": "Понятно. Почитал ещё про IPFS и IPLD. Понял окончательно. У них дерево хешей не в ту сторону растёт. Впрочем, понятно, что хеши в другую и не могут расти, они же хеши. Ссылка для понимания: https://hackernoon.com/ipfs-and-merkle-forest-a6b7f15f3537\n\nТ.е. они любой _новый_ набор данных могут слинковать с уже существующим и выстраивать таким образом деревья. Не совсем правда понятно зачем здесь хеширование хешей (кроме проверки аутентичности), достаточно просто дать список хешей источников на которые делаются ссылки. В принципе это работает как обычная гиперссылка в вебе.\n\nНо в вебе изначально не продумано было, что нужны ссылки в обратную сторону. Чтоб как в гугле, вводишь \"link:somesite.com\" и он тебе находит всех, кто ссылкается на заданный ресурс. Тоже дерево, но развёрнутое в противоположном направлении.\n\nПонятно, что такое дерево некому строить. Так и должно быть (см. последние абзацы), это правильно. Хотелось бы от ранее созданных ресурсов выходить к более новым на них ссылающимся, а не в обратную сторону. Но ранее созданный ресурс не мог знать, что кт-то в будущем на него станет ссылаться!  И не может в себе нести эту информацию. Да и не хочет может быть обновляться по поводу и без. \n\nЭто точно так же как в Git: из одного коммита может вырасти сколько угодно потомков. Только в случае семантически-связанной сети и родителей может быть больше одного, т.е. графы в итоге могут запросто содержать циклы, но это отдельная история. Важно, что родитель не имеет возможности найти своих потомков так просто, так же и в git, очень сложно для коммита найти всех потомков, а в обратную сторону запросто.\n\nТо что я хотел бы видеть, вот оно выше описано (см. также первое сообщение). \n\nЯ поэтому в первом сообщении и предположил, что \"коммит\" должен состоять не только из данных, но и из метаинформации ограниченного объёма, которую можно просмотреть в любой момент. И главное, которую можно искать/выбирать по-содержимому, для неё построен индекс. Точно так же как файлы можно выбирать по имени, например. И если в метаинформации содержаться ссылки на предков \"коммита\" (в принципе именно так Git и работает), то достаточно просто сделать запрос \"найти коммиты у которых предок такой-то\", если сама метаинформация проиндексирована по-содержимому. И повторять рекурсивно. В итоге можно построить дерево, или граф (коль число предков и потомков не ограничено) направленный в другую сторону. \n\nВ принципе сейчас похожий функционал уже реализован в файлообменных сетях типа eDonkey. Когда создаётся запрос на поиск файла по-имени, то создаётся волна, отправляющаяся близлежащим серверам, близким к ним серверам и так далее, пока не затухнет (из-за TTL).  И каждый сервер в своём индексе (где проиндексировано как раз по именам) ищет файлы, если находит то присылает ответ. По примерно такой же методике могла бы восстанавливаться связность от родителя к потомкам в IPFS-подобной сети. Понятно, это жутко медленно, потому, что каждая новая связь в цепочке -- новый поисковый запрос. Нужен какой-то способ ускорения, но не уверен, что он вообще возможен.\n\nНаличие подобной связности, от родителя к потомкам, даёт ключ к построению семантической сети, где отдельные понятия, закодированные в отдельных коммитах, могут быть связаны друг с другом. И могут добавляться *независимо* друг от друга, нет единого корня (как в IPLD). В обратную сторону может работать, понятно IPLD или попросту указание хешей родителей в метаинформации, не принципиально.\n\nЯ вообще больше думал о системе блогов, чатов, форумов. В них так или иначе есть семантическая связность: сообщение связано с конкретным автором (его блогом), связано с темой/топиком, является ответом на другое сообщение, может ссылаться на какие-либо сообщения, входит в какую-либо группу новостей и т.п. Вопрос как эту связность обеспечить на общемировом уровне без конкретных серверов, их владельцев, потенциальной цензуры, модерации и т.п.\n\nПонятно, что спам станет самой насущной проблемой, это отдельная сложная задача. Идеально, чтоб создание сообщений или новых узлов в сети было платным. Связано с криптовалютой например. Это отсекло бы большую часть спама.\n\nЕщё раз в чём разница с IPLD, дело в том что IPLD обеспечивает связь в обратную сторону, не от родителя к потомкам, а от потомка к родителю. Потенциально можно создать отдельный коммит содержащий информацию для поиска всех известных на данный момент потомков, но как мы узнаем о новых записях, если они будут сделаны позже, и самое главное, что за каждым коммитом неизбежно стоит человек или организация которые вольны добавлять или не добавлять отдельные коммиты в список. Т.е. это опять же централизация. А идея в том, чтоб единой точки, человека, сервера, организации, узла сети, способной влиять на работу сети в целом -- не существовало.\n\nМожет кто-то прокомментирует.",
				"added": 1554763320
			}
		],
		"1562004913_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di": [
			{
				"comment_id": 3,
				"body": "Если сеть требует управления -- ничем хорошим это не кончится. Сеть превратилась в то же самое, чем является \"Вконтакт\" им. Дурова.\n\nЗначит нужна другая сеть. Более того, предложенный выше вариант ХУЖЕ чем когда всё находится в руках одного человека. По сути делёжка власти УЖЕ началась. Кое-кто, не будем показывать пальцем, хочет отжать у @nofish кое что. И даже не завуалированно так начал. Консенсус, понятно, какой нужно будет достигнут ибо в ЦК партии будут только нужные люди через непродолжительное время.\n\nЯ не знаю зачем кому-то нужны ключи от чего. Для чего?  Каждый должен иметь ключи от своего ресурса, а не от, условно, общественного. ZeroHello, ZeroUpdate, ZeroMe, ZeroTalk -- это ресурсы принадлежащие @nofish, нужно это просто понимать. Ничем не будет лучше, если они будут принадлежать кому-то другому, более того, будет однозначно хуже, если круг этих лиц станет неопределённо большим.\n\nЧто касается ПО для доступа к сети то неплохо бы иметь несколько разных программ, не связанных между собой. Каждая конкретная программа, конечно, принадлежит какому-то конкретному автору, или коллективу авторов, и там нечем \"управлять\". \n\nДа, проблема ZeroNet ровно в двух местах:\n\n  1) Отсутствие документированное протокола/способа соединения с сетью, позволяющего реализовать полностью независимо свой набор ПО для этого (и постоянные изменения к тому же) -- это наиболее острая проблема в перспективе существования сети. Сеть не должна полагаться на какое-то конкретное ПО и конкретных людей занимающихся его поддержкой.\n\n  2)  Информационной единицей является \"сайт\" принадлежащий кому-либо. Сеть фрагментирована на эти \"сайты\", невозможно выстраивание общего семантически связного информационного пространства  (только через систему гиперссылок размещаемых на сайтах, чему владельцы сайтов могут противиться, кроме того сайты попросту могут быть удалены). См. мои комментарии ниже.\n\n  3) Для соединения с сетью нужно обращение к выделенным узлам, которые могут быть недоступны... данная проблема решена в таких сетях как eDonkey, и я думаю решения должны быть просто позаимствованы.\n\n  В идеале, на мой взгляд, информационной единицей должен являться, условно говоря, файл (запись, сообщение), не принадлежащий какому-либо сайту или владельцу, файл как сущность общая для сети в целом, части которой могут храниться на произвольных узлах сети (как в IPFS). Файл должен быть способен иметь как ссылки на ранее существовавшие файлы (явные, например идентификаторы или хеши этих файлов), так и возможность связи вновь создаваемых файлов с ранее созданными файлами в обратную сторону: возможность поиска, для заданного более раннего файла, файлов на него ссылающихся. Таким образом можно обеспечить семантическую связность из прошлого в будущее и обратно, в обе стороны. В IPFS сейчас связность возможна только в одну сторону, из будущего в прошлое, и, возможно только построение бесконечно ветвящегося дерева, но не сети. И в этом дереве нет способа найти узлы являющиеся листьями, можно от листа выйти к корню, но не наоборот. При наличии сети с двухсторонней связностью возникает возможность строить системы обмена сообщениями, блоги, форумы поверх этой сети. При этом не нужны некие централизованные \"сайты\" агрегирующие информацию, т.к. сеть самостоятельно может произвести поиск связанных материалов.",
				"added": 1562065200
			}
		]
	},
	"comment_vote": {}
}