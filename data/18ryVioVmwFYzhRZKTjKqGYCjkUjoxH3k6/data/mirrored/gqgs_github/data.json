{"cert_user_id": "gqgs@github", "next_topic_id": 5, "topic": [{"topic_id": 1604067012, "title": "Define \"Content-Encoding\" header for encoded files", "body": "If the file is encoded returns the _encoding_ in the [Content-Encoding](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) header to allow proper decoding in the browser.\r\n\r\nThis should make it easier to distribute compressed files in the network.", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1544278409, "modified": 1544375470, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1806", "source_type": "github"}, {"topic_id": 1604067943, "title": "Remove unnecessary debugger", "body": "It doesn't exist in the original `src/Ui/media/Wrapper.coffee` file.", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1589076322, "modified": 1589094487, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/2556", "source_type": "github"}, {"topic_id": 1604067945, "title": "UiWSGIHandler websocket error: TypeError: 'NoneType' object is not iterable", "body": "### Step 1: Please describe your environment\r\n\r\n  * ZeroNet version: 0.7.1 rev4486\r\n  * Web browser: Chrome\r\n\r\n### Step 2: Describe the problem:\r\n\r\n`UiWSGIHandler websocket error: TypeError: 'NoneType' object is not iterable in UiServer.py line 50 > pywsgi.py line 924 > __init__.py line 266`\r\n\r\n#### Steps to reproduce:\r\n\r\n1. Use the `BigfileUploadInit` command to upload a file using the protocol \"websocket\"\r\n\r\n#### Observed Results:\r\n\r\nThe file is uploaded correctly but the error above occurs after `actionBigfileUploadWebsocket` finishes processing the requests.\r\n\r\nIt seems `self.result` is still uninitialized when this method is being invoked but I didn't look too much into it.\r\nhttps://github.com/HelloZeroNet/ZeroNet/blob/eeb48fc72e14ae2055cb2608bb838bd77edf21c3/src/lib/gevent_ws/__init__.py#L263-L269\r\n\r\nIn the browser the websocket logs the following error:\r\n`One or more reserved bits are on: reserved1 = 0, reserved2 = 1, reserved3 = 1`\r\n\r\n#### Expected Results:\r\n\r\nThe command to be executed without errors.\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1589186803, "modified": 1589835737, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2557", "source_type": "github"}, {"topic_id": 1604067947, "title": "Avoid iterating in uninitialized result", "body": "Fixes #2557 ", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1589198447, "modified": 1589835894, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/2558", "source_type": "github"}], "next_comment_id": 6, "comment": {"1604067012_mirrored_gqgs_github": [{"comment_id": 1, "body": "@HelloZeroNet The main use case is compressing static assets.\r\nFor instance, with this modification it would be possible for a owner to compress the `all.css`/`all.js` files and using appropriate files names (i.e. `all.css.gz`/`all.js.gz`) the content would be decoded and interpreted correctly in the browser.\r\n\r\nFor sites there are updated frequently this would significantly decrease the size of the payload that is delivered to users after each update.\r\nOr am I missing something and a gzip compression for these cases is already happening somewhere else?", "added": 1544281891, "modified": 1544282187, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1806#issuecomment-445478545", "source_type": "github"}, {"comment_id": 2, "body": ">reach the packed files (.zip and .tar.gz) content\r\n\r\nThat hack does work. Thanks.\r\nWith that the result should be effectively the same.\r\n\r\nJust one last thing I didn't understand is how defining this header would affect the distribution of compressed files.\r\nI tested and fetching some `*.tar.gz` files as you mentioned and apparently everything behaved as expected.\r\nFor the browser it made no difference. I will just initialize a fileGet request / download dialog with the provided `*.tar.gz` filename.\r\n\r\nThe only difference I spotted is that, as expected, the `Content-Encoding: gzip` will now be returned in the request response.\r\n```\r\nAccept-Ranges: bytes\r\nCache-Control: no-cache, no-store, private, must-revalidate, max-age=0\r\nConnection: Keep-Alive\r\nContent-Encoding: gzip\r\nContent-Length: 11835546\r\nContent-Type: application/x-tar\r\nDate: Sun, 09 Dec 2018 15:51:04 GMT\r\nKeep-Alive: max=25, timeout=30\r\nVersion: HTTP/1.1\r\nX-Frame-Options: SAMEORIGIN\r\n```\r\n\r\nIn the master branch the content type being returned is the same.\r\n```\r\nAccept-Ranges: bytes\r\nCache-Control: no-cache, no-store, private, must-revalidate, max-age=0\r\nConnection: Keep-Alive\r\nContent-Length: 11835546\r\nContent-Type: application/x-tar\r\nDate: Sun, 09 Dec 2018 15:47:14 GMT\r\nKeep-Alive: max=25, timeout=30\r\nVersion: HTTP/1.1\r\nX-Frame-Options: SAMEORIGIN\r\n```\r\n\r\nIt seems to me the reply above could led to some ambiguity since there is nothing to distinguish between compressed and uncompressed files, e.g.\r\n```\r\n>>> mimetypes.guess_type(\"file.tar\")\r\n('application/x-tar', None)\r\n>>> mimetypes.guess_type(\"file.tar.gz\")\r\n('application/x-tar', 'gzip')\r\n```\r\n \r\n", "added": 1544370804, "modified": 1544370804, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1806#issuecomment-445561669", "source_type": "github"}, {"comment_id": 3, "body": "That's interesting. I was not expecting the browser unpacking the file to affect what is being stored by the node.\r\nStill the `Content-Type: application/x-tar` seems incorrect in this case.\r\nTrying to get the mime type from the file magic number (and then fall backing to the filename if the previous method failed) might be a more accurate way in order to yield the correct type.\r\nBut then I'm not sure if the browser would try decompressing it again in this case.\r\n\r\nEither way the `<script src=\"all.zip/all.js\">` hack should work fine for my use case. Appreciated.", "added": 1544375470, "modified": 1544375470, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1806#issuecomment-445567395", "source_type": "github"}], "1604067945_mirrored_gqgs_github": [{"comment_id": 4, "body": "@imachug It seems that is enough to fix it. Everything is working fine and without errors if I don't close the websocket.\r\nHowever, if I close it I'm getting another error after the first successful upload and the subsequent uploads get corrupted.\r\n`UiWSGIHandler websocket error: EOFError:  in UiServer.py line 50 > pywsgi.py line 923 > UiServer.py line 115 > UiRequest.py line 155 > Bigfile/BigfilePlugin.py line 92 > 101 > 318 > 294 > 268 > 88 > __init__.py line 92`\r\n\r\nAm I really expected to never manually close the connection?", "added": 1589192688, "modified": 1589193917, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2557#issuecomment-626699818", "source_type": "github"}, {"comment_id": 5, "body": "I don't think so. A new websocket object is being created for each file so I also think it's strange that they are interfering with each other. I will look into it.\r\n\r\nAnyway, I think #2558 should fix the original problem.", "added": 1589198568, "modified": 1589198568, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2557#issuecomment-626760335", "source_type": "github"}]}}