{"cert_user_id": "mx5kevin@github", "next_topic_id": 22, "topic": [{"topic_id": 1604067142, "title": "Large file download/resume and Zero Hello functional problems", "body": "### Step 1: Please describe your environment\r\n\r\n  * ZeroNet version: _____0.6.5 (rev 3852) and all previous version\r\n  * Operating system: _____windows\r\n  * Web browser: _____firefox\r\n  * Tor status: always\r\n  * Opened port: no\r\n  * Special configuration: Tor proxy for tracker connections\r\n\r\n### Step 2: Describe the problem:\r\n\r\nFiles downloading and seeding problems.The files download are not resume from browser request.The users are not get the files,only just part of them.The files are not added to Zero Hello Files menu if the file have no seeder.\r\n\r\n#### Steps to reproduce:\r\n\r\n  1. Downloading a large optional file from a website. (Without zites what have seed button)\r\n  2. Or setup a zite with large optional file more than 300MB testing are ideal.Using tests with offline and \r\n  online seeder.Closing the page.Restart ZeroNet client.And restart the PC.\r\n\r\n\r\n\r\n#### Observed Results:\r\n\r\nSelf made zites.Or zites which do not have +seed button the file download are not resume if i close the browser.Or if the seeder are offline the file are not starting to download.And not add in the ZeroHello files menu.Self made zites the users can not download the files.Or get only parts of them.Can not setup easy way (average user impossible) with self made zites to all files download are resume and finish from browser request if the browser are closed.Or the seeder are offline.If you a zite administrator and you setup a zite with big optional files the are no easy way to set up if a user want download a file always resume and finish the download.Smaler optional files under 10MB what can finish some lucky users goes fast offline.This lucky files have minimal seeder but later this files goes realy fast offline.\r\n\r\n#### Expected Results:\r\n\r\n**Downloadind problems**\r\n\r\nThe files are not downloaded or not resume from browser request.This makes more froblem with HTML5 embeded video files.The are no option in Zero Hello files menu to pause,contiune files download.And impossible to in Zero Hello files menu to resume the file (file are paused!).From browser request if the browser are closed or the seeder are offline the file download are not resume.And if the seeder are offline the file are not added the Zero Hello Files menu.Have the same problem with ZeroUp,KopyKate big which have +Seed button.The users are does not know what this seed button.The users are only know the files download are always failed!\r\n\r\n**Seeding problems**\r\n\r\nThe users are can not download the files or only get parts of them if the seeder are not 24/7 online.All users only download parts of the files.This way not possible with larger files to a downloader turn later to a seeder! More than 50 files are tested.The users downloaded always part of the files! Or failed to download files.With large files 0% of the users get the complete file! THE ZERO NET DOWNLOAD/SEED SYSTEM THIS POINT COMLETLY FAILED!\r\n\r\n#### Ideas to fix this problems:\r\n\r\n1. The most important: Always resume download all files default from browser request.And always add the file to the Zero Hello files menu.Even if the file have no seeder!\r\n\r\n2. Add to Zero Hello files menu to a pause,contiune download button.So if the user want more bandwidth she can stop and contiune the file.It would be especially useful with video files in sites like KopyKate or large video sharing zites.Optional way make a esy access to Zero Hello files without the user need to close the current zite page.Example open ZeroHelo files menu in the browser new tab.\r\n\r\n3. Seperate in Zero Hello files menu the files what are downloading but not finished and copletly downloaded files.\r\n\r\n4. Downloading priority from browser request (and not half finished files from browser request)\r\n\r\nIf a file get a browser request this pont that file get major priority.And another downloads this point are paused later when the browser request are not active the another files download are automatic way resume.With this setup all download are finished.And get fast all files from browser request.And the backround running downloads not make problems.\r\n\r\n5. Downloading priority with active files where can the user give more priority some files.\r\n\r\n\r\n\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1550733707, "modified": 1552830669, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1910", "source_type": "github"}, {"topic_id": 1604067303, "title": "Non stop 24/7 ZeroNet free seed server download system idea", "body": "****Why****\r\n\r\n-MORE ZERONET USERS AND ZITE ADMINISTRATORS.AND MORE QUALITY ZITES!\r\n\r\n-ZeroNet and similar platforms have a big problem.Especially large files and contents are many times are not avaiable.Or not immediately available. Users can't wait for this.And website owners goes elsewhere.\r\n\r\n-We can make a NON STOP FREE auto seed system.We have the techology.\r\n\r\n-ZeroNet have problems with large file sharing. Lot of large files are dead or low seeded.\r\n\r\n-The sytem will be more resistence for censorship.The site and file owners get more protection.Users get more bandwidth.\r\n\r\n-Site and file owners can reducte the server costs. The are no case it goes unnecessarily the server. Only whaste electricity without useful uploading.\r\n\r\n-Countries where ZeroNet are blocked there would be more chance this way to get the files.\r\nThe idea\r\n\r\nIf the site or file owner can upload the content automaticaly to another user without waiting for a downloader.If the file have only one seeder.Site or file owner can save electricity cost. And we can make a guarantated 24/7 seed for every file.\r\n\r\nExample we make a storage in a seperated folder in every ZeroNet client where the site or file owners can upload files to another users compjuter.Users who allow this option are get extra bandwidht from this storage.From every uploaded amount of data the user get the same Byte,MB,GB back wehen the user want download a single file.This option the site or file ownwrs are free.From another users are get extra bandwith and save time. If the user allow bigger disk space. She get faster more amount of data access from uploaded files.\r\n\r\n****How its works****\r\n\r\n******The users******\r\n\r\nThis is an allowable feature!\r\n\r\nThe zites and files are downloaded the same way from the uploader machine interaction automatically but seperated place (folder and in the client) from the another user (seed server) copjuter.\r\n\r\nExample credit minnig zites in seperated. Everything looks the same whay if the user download a file or zite. Only this is get a distinctive sign.And the files and zites are downloaded a seperated folder.\r\n\r\nThe user get from every uploaded data extra Byte,MB,GB (coins) from this storage.What he get back from this storage when he download files.\r\n\r\nIf the user allow too to daily automatic way upload files too she get more faster extra Byte,MB,GB (coins).\r\n\r\nFrom users the are two single button (Allow credit minning).And another button what allow auto upload If the file have only one seeder.Or not have 2.0 ratio.For much more extra and faster (file coins).\r\n\r\n****The site and file owners****\r\n\r\nThis is an allowable feature to site and file owners too!\r\n\r\nFrom the site or file owners in ZeroHello files menu/Files where are the ratio and zite name.And seperated the optional files we make a simple option.If the file have only one seeder.Or not have 2.0 ratio.The file are start autamatic way upload in the system.\r\nIf the file owner (not the zite owner) upload a file from another user zite.She can enable this function with the current file.\r\n\r\nIf a site owner have a veary large zite where another users upload large data.Optional large files can uploaded to another users. Example ZeroUp.So zites what allow from another users and not just the zite owner to upload files.It is possible to set up a limit.", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1559477945, "modified": 1585375578, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2039", "source_type": "github"}, {"topic_id": 1604067305, "title": "Signed content.json publish failed (if the changed zite are larger than 10MB)", "body": "### Step 1: Please describe your environment\r\n\r\n  * ZeroNet version: 0.6.5 (rev 3864)\r\n  * Operating system: Windows 10\r\n  * Web browser: Firefox 67.0\r\n  * Tor status: always\r\n  * Opened port: no\r\n  * Special configuration: Proxy forTracker connections goes tourgh Tor\r\n\r\n### The problem:\r\n\r\nIf the existing seeded by other users zite are under 10MB. And i completly update the zite. All files get updated. And its larger than 10MB. Content.json if i set up a larger limit than 10MB are accepted. And Signed. But when i try publish the zite are not getting updated. And when i try download the zite the outdated files are downloaded from another users. And its impossible to get the new usrs the updated files. Zeronet know the zite limite are highter when i try domwnload the zite. But the outdated content.json and files are downloaded from another users.The connection are OK. The proplem was another users client not accept the update. Under 10MB everything works fine.\r\n\r\n#### Steps to reproduce:\r\n\r\n  1. Make a zite with more files under 10MB (make shure its seeded many user important)\r\n  2. Update all files this time more largen than 10MB (Try 50MB)\r\n  3. Set up the limit\r\n  4. Sign content.json file \r\n  5. Publish the file\r\n\r\n#### Observed Results:\r\n\r\nThe outdated content.json and files are downloaded. ZeroNet accepted the highter zite limit when i tryed download the zite.But the zite are never get updated.\r\n\r\n#### Expected Results:\r\n\r\n Content.json sign are OK. Content publish failed error MSG. If i make a test download the old files are downloaded and never updated!\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1559479898, "modified": 1559480299, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2040", "source_type": "github"}, {"topic_id": 1604067307, "title": "Popup window to resumume large optional files download from browser request", "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nNot easy or some times impossible to download optional large files from zites without seed button.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA simple DOWNLOAD FILE popup when the opened page include optional file. Example embed HTML5 files and etc. This fuction works like the seed button and resume the download if nobody seed the current time the file.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nZeroNet currently use the +SEED button. This is not integrated by many website owners. And not easy to integrate. Download managers are failed! A popup window what give you the option to resume the file download are easy to use for every user!\r\n\r\n**Additional context**\r\n\r\n+SEED button not integrated by many website owners. Download managers are failed! if the users try download this files whit them. Currently there is no easy good working alternative. And larger files with thie current setup are all failed.\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1559481771, "modified": 1568662205, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2041", "source_type": "github"}, {"topic_id": 1604067347, "title": "Add to a VOIP Call sevice with a browser interface", "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nNot easy to find a good working VOIP service. And almost impossible what decentralized, protect the user anonymity, can use proxy, does not ask private data, easy to use. A VOIP service itself can attract many users. Easy to set up, works with x86 multiple platforms and older OS systems too. And a powerful social media tool with which ZeroNet can many new users can be obtained.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA VOIP Call sevice with a browser interface. As a service like ZeroMail, ZeroUp, ZeroMe.\r\nWith Video Call and standart call service, chat and file share option, in ideal way telephone book where people can search users. User online icon what only can see the accepted users. And a alert sytem when a user goes online, send MSG ETC. And important easy to use in mobile devices!\r\n\r\n**Describe alternatives you've considered**\r\n \r\nTested: WhatsApp, Skype, Viber, Talky, ooVoo, WeChat.\r\n\r\nMost of them are useless. Some of them without a mobile phone and phone adress unusable. And lot of them does not workig in serval platforms. Very much of them are use a centralized network. And imposible to set up a simple proxy. Asking too much sensitive private data like phone number. A simple good working platform like [Jami](https://jami.net/) will be ideal.\r\n\r\nZeroNet have the existing platform what currently solve many of this issues. What the most VOIP servieces does not have. And in this platform we can set up a powerful good quality VOIP service. ZeroNet are working multiple platform Phones!, Linux, and Windows systems.\r\n\r\n\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1562233854, "modified": 1569006279, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2070", "source_type": "github"}, {"topic_id": 1604067403, "title": "Keeping files online forewer using the Safe Network (chunk+copy) file storage technology", "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nFile Storage Problem:\r\n\r\n- I'ts not possible to keep online the files 24/7 without non stop running the compjuter.\r\n- Large (Optional Files) goes fast offline. But the system are indexed them forewer in the system.\r\n- If the file are not popular and have periodic downloads the bandwidth are limited.\r\n- Must wait all File/Zite owner to a downloader too keep the file online. Without this not possible to upload the files in the system. And reduce minimal the server electrocity costs.\r\n- Users must wait sometimes too long to get a file. Or the file are newer get downloaded\r\n- In clearnet all files 24/7 avaible. With high download speed.\r\n- Playing  problems with streamable HTML5 media files. Wheare users need to get the files directly, high download speed, with stable download process.\r\n- If a user have low upload speed. And sharing lot of files. Another users can download the files from other sources. So the bandwidth will be high an unlimited.\r\n\r\nSecurity issue:\r\n\r\n- Tourgh VPN, TOR ALWAYS MODE, or PROXY with test downloads i'ts possible to monitor the current user tracing back the download/upload traffic if only one people seed the current file. If tourgh 1 tunnel this data collected to serval users I'ts not so easy to track back the site or file owner.\r\n\r\n- Less visited optional files not resistence for censorship. If the owner are shooted down the file are dead. So with the current setup its possible to shoot down large sites. Wheare the zite have many visitors. But incude many optional files what have variable seeder. And wheare wee need minimum 1 seeder who have all files. If wee need too keep all files online. If we talk about large services the chance is getting bigger only the site owner have all files.\r\n\r\n**Describe the solution you'd like**\r\n\r\nDescription of the technology: https://www.youtube.com/watch?v=U1ffmf6z50E\r\n                                              And\r\n                                               https://www.youtube.com/watch?v=RdGH40oUVDY\r\n                                            \r\nA storage system where stored all files in chunks in a encrypted data storage. And multiple copies of the files. In the ZeroNet usrers compjuters. Distributed among themselves the data. And when a user need a file collect the pieces from another ZeroNet users. The users are store only chunks and not the full file. So their does not have to wory the are storing illegal content. And file owners can upload to this storage and does not have to wait a users who download the current file or zite and help to seed it. This is a secondary storage what helping and fix the issues with the current storage system.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nhttps://safenetwork.org/\r\n\r\nSimilar techology\r\n\r\nhttps://freenetproject.org/\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1564374820, "modified": 1564403043, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2113", "source_type": "github"}, {"topic_id": 1604067572, "title": "0Net HTML functional problems tourgh the browser", "body": "### Step 1: Please describe your environment\r\n\r\n  * ZeroNet version: 0.6.5 (Rev: 3866)\r\n  * Operating system: Windows 10\r\n  * Web browser: Firefox Quantum 69.0.3\r\n  * Tor status: always\r\n  * Opened port: no\r\n  * Special configuration: Trackers goes tourgh TOR\r\n\r\n### Step 2: Describe the problem:\r\n\r\nSome HTML problems when a user setup a single user site tourgh 0Net and open the current zite the browser.\r\n\r\n#### Steps to reproduce:\r\n\r\n1. 0hello Files page .mp4 files are not played (no supported mime video).But tourgh HTML5 player are working perfectly the same files.\r\n2.\thttp ://127.0.0.1:43110/site/folder /some video file.mp4 as link in a website not played\r\n3.\tImages and video and something\u00e9\u00e1\u00fc\u00f6.html files not accept special characters in HTML files Example:\r\n\r\nbnhm\u00e9\u0171o.jpg i get: \r\nServer error\r\nErr: UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position 4: ordinal not in range(128) in UiServer.py line 103 > UiRequest.py line 152 > UiConfigPlugin.py line 21 > ContentFilterPlugin.py line 193 > UiRequest.py line 371 > UiRequest.py line 470 > FilePackPlugin.py line 108 > SiteStorage.py line 349 > SiteStorage.py line 368\r\n4.\tOpening new site in a new tab using the target=\"_blank command are not loading the page.\r\n\r\n            <a href=\"http://127.0.0.1:43110/anotherzite\"  target=\"_blank\">Some zite open new tab</a>\r\n5.\tNot possible to automatic way easy download all optional large  files in a single user zite when the user download the site.So large files are not seeded.\r\n6.\t.SWF game or another files are not working.\r\n7.\tAll files only sows correctly with UTF-8 format. \r\n8.\tUser can not go back using the browser back button if he open another zite to the previous zite.\r\n9. Can not go back the previous page in zites when the user click the back button in the browser the user stuck in the same page.This can be a problem for larger pages.\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1571915371, "modified": 1573520371, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2241", "source_type": "github"}, {"topic_id": 1604067577, "title": "Download large files default way in single user zites, and make possible to upload/download extreme large files like 10GB or larger files too", "body": "**Is your feature request related to a problem? Please describe.**\r\nA clear and concise description of what the problem is. Ex. I'm always frustrated when [...]\r\n\r\nIn large (optional) files currently the are no way to automatic way download them when the user load a zite.And users can not know a optional file in a single user zite are how much big.Currently must enable in the right 0Net icon with a limit and a simple user he doesn't even know exactly what it is. All these is that there are files on a site which are not available.The site owners see the big files does not have seed this way but another files are correctly seeded.\r\n\r\n\r\n**Describe the solution you'd like**\r\nA clear and concise description of what you want to happen.\r\n\r\nCurrently all zite ask the users if the site lagen than 10MB.If we default way allow do download all optional files.And we make a button what this can Enable/disable when the zite are loading.Default way enable. Then those who do not know how to use computers, or 0Net than older or not pro  users.They could easily access the files rar,zip,mp4,mp3 etc.I heard the developers working a new setup. Started working on next big feature: [Content addressed data that should enable site-independent file storage and de-duplication](https://github.com/HelloZeroNet/ZeroNet/issues/2192).This can be made much more effective.We can make a option what show the total file size in a single zite.And we can keep the in the right 0Net icon but with a function what show the total files size in a zite.Example if a zite are loading show a button what default way enable to download all files larges and small files too without user interaction.If the user think the zite are too large can enable him to this button can turn off large files download.The zite ask the user when a zite larger than 10MB so that's not a problem.In this period I recommend show the large and small files size too.And this pint show a button which requires no user intervention if the user want all files.If he not want but later change his mind the are the right 0Net icon. And it would be easier for everyone to use the software.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nIn torrent clients the user can download all files what include the current torrent files.And all files are seeded.In torrent files extreme large 10-20-60GB or larger single files are working,in 0Net are not.Torrent clients resume the download.Utorrent web which you can play HTML5 files using the browser without completing the download resume the download and download all files default too.And if something a user doesn't want then picks out the check mark in the current file.For advanced users here on 0Net it could be solved in the same way.And who didn't know too much from this its the solution above the simplest.\r\n\r\n**Additional context**\r\n\r\nWith single files it would be would be [necessary a button what shows and allow resume the download when the user click a file without +seed button integratoin](https://github.com/HelloZeroNet/ZeroNet/issues/2041).This can works with multiple user sites and single sites too.With multiple user sites in the right 0Net icon  would be easier to show the total files too.It would be useful to allow multiple user sites to download not just the whole site files.But select some users too.\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1571947399, "modified": 1571994716, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2243", "source_type": "github"}, {"topic_id": 1604067670, "title": "Seeding the deleted but not owerwritted files, to get extra healt for the files  without wasting this resources", "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nWhen a user delete a file from a storage device HDD,SSD,Memory Cards ETC. Only the icon will be deleted, but the file is still available on the device until it is completely overwritten with another file. It is possible this way to seed deleted files and get extra health an existing unused one powerful resource without using extra another resources in any device. These files in many case are still available long time after deletion.From low storage capacity mobile, and high capacity devices we can double the seed capacity  this way.This is currently a wasted free huge storage.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA clear and concise description of what you want to happen.\r\nA seeded deleted files window,with a delete illegal malicious content button.And a button what only not use this seed function when the user delete a file because its illegal,virus.And simple  extra menu insaide the files menu seeded deleted files.Where correctly written this files are deleted from your disk,not use your disk space,seeded, and please only delete some files if the file malicious or illegal.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nFile restoring programs widely use this option.There are not many P2P programs like ZeroNet which could take advantage of this. With darknet programs like I2P,Freenet such an option can be problematic.Similar working P2P decentralized web hosting program as ZeroNet which could take advantage of this to my knowledge not exit yet. But on a similar decentralized P2P web hosting platform,who can take advantage of this gaining a significant advantage over its competitors.\r\n\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1573858478, "modified": 1573858478, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2315", "source_type": "github"}, {"topic_id": 1604067707, "title": "Allow a Prof Of Work download upload system in content.json (A correct blocklist which the owners can filter the Hit And Run Users)", "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\n[Hit And Run Wiki](https://en.wikipedia.org/wiki/Glossary_of_BitTorrent_terms#Hit-and-run)\r\n\r\n-To reduce and filter Hit And Run Users who do not want to seed back the files. \r\n\r\n-This will be work like a \"Bad Seeders\" 100% correct and decentralized blocklist for the site owners.\r\n(It does not offer any  solution to this problem the ZeroNet service.)\r\n\r\n-To get money easy way the site owners and seeders.\r\n\r\n-To get long seeded files.\r\n\r\n-Reducing the owners and seeders electricity costs\r\n\r\n-If the file are not popular but the owner seed the file then she can make more profit from it.\r\n\r\n-This way the owners can pay with this revenues with Paid Hosting Service.\r\n\r\n-Who are properly seeding files it would not cost them money.They could even make money with it.\r\n\r\n-Publishers can get fast seeders if we use the (first 4 user credit system) see below. And users can get money if they seed new files.\r\n\r\nUsers who just download but don't seed back the files they do harm for the owners. And the whole network.\r\n\r\n**Describe the solution you'd like**\r\n\r\nA simple setup If the user download a file she must pay 1Byte/Coin.When the same user seed back the file she earn 1Byte/Coin when the complete file are seeded back.This point the file are free from the user.When the user seed more the file she earn more coins.And **a simple setup in content.json \"ban_hit_and_run_users\" true, or false.** Using free updates when the user have the file.The coins are collecting in the user walet.\r\n\r\nExample: If the file are 1GB the user Must pay 1GB Coin.When the user seeded back the 1GB file he get back the coin.When he seed more than 1GB he earn coins.What can the user use it for other services and downloads.\r\n\r\nHow the users can get free credit,and the pulishers fast seed:\r\n\r\nAnd a extra to keep it free for new users.The first 4 downloader the file will be free after the last publication.So they can earn mony if they seed it back.The first 4 downloader after the file are published only get a minus credit, but the user can  download the file .So users get money if they download paid new files and seed it back more extra data than the current file.If the file are not new the user can download as much as he have in their walet, but the can not get credit.\r\n\r\n\r\n**Describe alternatives you've considered**\r\n\r\nIn all non public registration require torrent services. Users who regulary not seed back the content that they downloaded get banned.Many zite or file owners these Hit And Run users are only a problem.And it would be important to allow to block this users.In TPB lot uf user download the newly uploaded files.So the uploader doesn't have to run too much time their mashine to get enough seeder.\r\n\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1575672866, "modified": 1575852836, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2342", "source_type": "github"}, {"topic_id": 1604067776, "title": "0Net does not delete deleted optional files from site directory", "body": "### Step 1: Please describe your environment\r\n\r\n  * ZeroNet version: 0.7.1 (Rev:4399)\r\n  * Operating system: Windows 10\r\n  * Web browser: Firefox 72.0.2\r\n  * Tor status: always\r\n  * Opened port: no\r\n  \r\n\r\n### Step 2: Describe the problem:\r\n\r\nIn ZeroUp,KopyKate, and files menu i deleted some files.In the site directory still exit the picemap.msg and the deleted files too. This takes up space unnecessarily. The program does not want to delete them.Too much trash file collect this way the program.\r\n\r\n#### Steps to reproduce:\r\n\r\n  1. Upload a file to ZeroUp,KopyKate, etc.\r\n  2. Delete file from the site and files menu too.\r\n  \r\n#### Observed Results:\r\n\r\nIn the site directory/user folder the picemap.msg and files does not deleted!\r\n\r\n#### Expected Results:\r\n\r\nToo much trash file collect this way the program.Which cannot be separated from the seeded files if the user seed for many files.\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1580135411, "modified": 1585004832, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2407", "source_type": "github"}, {"topic_id": 1604067802, "title": "Too much time wait the client to resume file download if the seeders goes online", "body": "### Step 1: Please describe your environment\r\n\r\n  * ZeroNet version: 0.7.1 (rev4445)\r\n  * Operating system: Windows 10\r\n  * Web browser: Firefox 72.02\r\n  * Tor status: not always\r\n  * Opened port: no\r\n  * Special configuration:\r\n\r\nUsed 2 different wifi netwotks with 2 different internet provider. 150KB/s upload speed. 3GB of total files in cc 500 MB/ file.1 week period and the  computers serval times goes off and on. And not all 2 PC always active at the same time.\r\n\r\n### Step 2: Describe the problem:\r\n\r\nToo much time wait the client to resume file download if the seeders goes online. Without the user interaction using the refresh button and shows example 2000 file left. Too much time passes when the seeder goes online and the client start to download the files.This largely increases the time it takes for the files to be fully downloaded. 5piece cc 500-600MB  total 3 GB file about 1 week downloaded. Which is a lot of time.\r\n\r\n#### Steps to reproduce:\r\n\r\n1. Use 2 PC with 2 different internet provider what restarted, and behave like any other PC in the internet.\r\n\r\n#### Observed Results:\r\n\r\nWhen the seeder goes online too much time passes when the client start refresh the current page and download the files. Without the auto refreshing the page files will not downloading.About hours the client does not download the files even if the seeder are goes online.\r\n\r\n#### Expected Results:\r\n\r\nBetter detect it if the another client are online. About 1 week from 3GB of total files using 150KB/s upload speed it's a lot of time. And there was too much time to the 2 PC was the same time online and the client can download the file, but it didn't.\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1582113727, "modified": 1582553702, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2428", "source_type": "github"}, {"topic_id": 1604067804, "title": "Faild to startup ZeroNet from desktop at system startup (The system can not find the ZeroNet.exe file)", "body": "### Step 1: Please describe your environment\r\n\r\n \r\n\r\n  * ZeroNet version: 0.7.1 (rev4445)\r\n\r\n  * Operating system: Windows 10 Enterprise\r\n\r\n  * Web browser: Firefox 72.02\r\n\r\n  * Tor status: always\r\n\r\n  * Opened port: no\r\n\r\n  * Special configuration: Run ZeroNet client at sytem startup when windows start. And installed the ZeroNet folder to the desktop.\r\n\r\n \r\n\r\n### Step 2: Describe the problem:\r\n\r\n \r\n\r\nIn the Drive C ZeroNet works perfectly. In the desktop in startup i got a msg (the system can not find ZeroNet.exe file). If i start my self the file ZeroNet are running. When the system try to start at sytem startup i got this error msg.\r\n\r\n \r\n\r\n#### Steps to reproduce:\r\n\r\n \r\n\r\nExtract the complete ZeroNet folder to desktop. The current user directory cointans special characters \u00c1\u0150\u00da\u0170.Setup Start ZeroNet when Windows starts option. Reboot the computer.\r\n\r\n \r\n\r\n#### Observed Results:\r\n\r\n \r\n\r\nI got a error msg after system startup and ZeroNet faild to start. (The system can not find the ZeroNet.exe file.)\r\n\r\n \r\n\r\n#### Expected Results:\r\n\r\n \r\n\r\nOlder py 2 versions didn't have that problem. All py3 version this problem occurs. It worked well on the same computer for a long time.", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1582119029, "modified": 1582727096, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2429", "source_type": "github"}, {"topic_id": 1604067838, "title": "+ADD File menu  to easier download ZeroNet large optional files", "body": "+ADD File menu  to download ZeroNet files in the right menu and another in files menu too.  This works like a seed button for advanced users. When a user want download a file, simple copy and paste the file URL. And press the download button. If it is a valid file a green check mark appears. If not a red exclamation mark with a error msg. The same setup what use all download managers. The user copy the link, paste to the +ADD File menu to the link. It's always easily accessible. No problem if it is not integrated on the site the +Seed button. If the zite have Optional Files this option are shows too. Like the \"Help distribute added optional files\" menu. All browser have a good Copy/Paste option. And it's works fine with 0Net large files.\r\n\r\nThe [Popup window to resumume large optional files download from browser request](https://github.com/HelloZeroNet/ZeroNet/issues/2041) would be ideal for less experienced users.\r\n\r\n[A download manager  pause, contiune download button option It would be useful](https://github.com/HelloZeroNet/ZeroNet/issues/1910) in Zero Hello files menu.This would make the downloads easy to manage.\r\n\r\nAnd [Allow auto download optional files too when the zite are loading](https://github.com/HelloZeroNet/ZeroNet/issues/2243) it would make things a lot easier for less experienced users.\r\n\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1583411667, "modified": 1583873460, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2458", "source_type": "github"}, {"topic_id": 1604067966, "title": "Optional large file sharing/downloading major difficulties and problems", "body": "### Step 1: Please describe your environment\r\n\r\n  * ZeroNet version: 0.7.1 (rev4486) and all previous versions\r\n  * Operating system: Windows 10\r\n  * Web browser: Firefox 76.0.1\r\n  * Tor status: always\r\n  * Opened port: no\r\n\r\n\r\n### Step 2: Describe the problem:\r\n\r\n1. Auto download big file size limit 10MB preset value: Many files are larger than 10MB.A less knowledgeable user don't know what this feature is for. If the page contains 20MB 100MB 1GB file the user can not download it. The other problem is that the user does not know what size have the largest file on the page.From files under 10MB non optional files such as HTML can even total 1GB/site.And for files larger than 10MB optional files can even altogether 40MB in the same site.\r\n\r\n2. If in the content.json file not set the optional files then files what larger than 10MB they cannot be downloaded: A beginner website owner will not be able to set it.Users cannot download the files larger than 10MB.There are no easy-to-find detailed descriptions on how to set this up.\r\n\r\n3. When the page loads,large files which are larger than 10MB  cannot be downloaded automatically.These files doe not seeded correcly in single sites this way.And in many cases, users cannot download it.Very confusing because they are part of the website in the same way. It can greatly degrade the enjoyment value of pages.\r\n\r\n4. Can not resume files download without seed button: If nobody seed the file it cannot be set up easily to try to download the files the program later.\r\n\r\n5. Priority: It takes a lot of time for the pages to appear: HTML,CSS,Pictures,js should download first to load the pages faster.When the download of these files is complete.The other files will be loaded even later.Which are not displayed by the browser.\r\n\r\n\r\n#### Steps to reproduce:\r\n\r\nCreate a simple simple user website below and above 10MB mixed files.If the site contains 1GB under 10MB non optional files.And total 500GB mixed files 15-100MB files the problems are spectacular.But with a simple index.html and a 20MB file setup also given the problems.\r\n\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1590122340, "modified": 1590122340, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2566", "source_type": "github"}, {"topic_id": 1604067972, "title": "Paid and volunteer community projects to accelerate developments", "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe development of many things should be accelerated.There are zites which would require continuous improvement. Like ZeroUp,KopyKate Big,ZeroTalk,search services.I am thinking mainly of basic platforms what can clone and update users.Just for a well-designed search engine like Yacy need a development team.For Google and clearnet search egnies to index properly the zites it would also require serious development.More paid and voluntary developers are needed for a more serious level of development.We are too few for very serious improvements.For widespread use, it is no small exaggeration to say that it would require the same level of improvements as Windows or GTA games.\r\n\r\n**Describe the solution you'd like**\r\n\r\nIn the More Sites start page to Create a Page where volunteers can upload patches and codes,current softwares.About ZeroNet and zites too.In the case of Zites who wants what,bug reports.If a developer has free time, they can simply add it to the project.Eg interrupted zites development could be continued.Up to several directions at once can run a project.Website owners can find supported development softwares here.Such as ZeroTalk with file sharing,images,search function,embedded video player.And if another developer comes who thinks he could do an existing project better than can upload he own version.When a developer creates a zite software he can easily share it.Don\u2019t get permission from anyone or wait for anything else.\r\n\r\nDonate to using popular cryptocurrencies and not just bitcoin.Opening a common mining pool where the users can donate CPU and GPU mining with an easy-to-download preset software.Using a mining pool there is a high payout threshold which we can achieve regularly together.This could be a regular income for the project.Multiple users would go much further together.For donators vote on projects,collecting for specific purposes.It could be platform too like Patreon for regular sponsors.From the money raised,some paid developers could be entrusted with specific works.We can start joint projects later with which users and developers can make money.Like a decentralized 24/7 hosting,paid services and zites.\r\n\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1590845749, "modified": 1592785458, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2570", "source_type": "github"}, {"topic_id": 1604067995, "title": "Integrate freenet free decentralized storage system as optional secondary storage", "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nUsers cannot seed the files and zites 24/7,keeping files alive could be greatly improved if users could upload files to the system.Filecoin,Story,MaidSafe, which offer a solution to a similar problem of paid young systems which will not work in the near future.Freenet storage system are 100% free and has been operating for more than 15 years it is constantly being supported.Convenient to use without user intervention.It's not needed to be pay or mine if someone wants to store something in it.The problem is leaving no option for free content storage if we goes offline.There should also be a protection from a security point of view to test downloads it is easy to identify who the original owners of the content are.But if the content is loaded from multiple places then the original owner is still offline this not only protects the content from disappearing easily but also protects content owners.There would be a guaranteed free helper seeder for everyone who share something in 0Net.jSite plugin a correct well-functioning plugin for upload files.Similar systems are not ready yet and are designed to be paid.There will be no similar free working decentralized storage system.\r\n\r\nOffical site:\r\n\r\nhttps://freenetproject.org/pages/help.html\r\n\r\n**Describe the solution you'd like**\r\n\r\nIn plugins as an optional option.Disk space selection and a complete zite upload feature.And file upload feature in multi user zites like ZeroUp in Zero hello files menu.This could be extended later to other similar protocols like Filecoin,Story,which begin to appear.There could be an option if a file falls under a certain seed then it will be uploaded to the system automatically.If under a zite the files are uploaded to the freenet system one by one there is also no need to wait long for the files to upload.System can reboot serval times and the files could be conveniently uploaded.See jSite plugin but with the difference that uploading will resume automatically even if the computer restarts.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nFilecoin,Story,MaidSafe Similar P2P projects are all working on this solution but these are paid systems.IPFS it also bolts in support of two this storage systems.Later on,I think more of these storage technologies should be integrated in ZeroNet.And users could choose what they want to use as needed.The problem is that these systems are paid.Or you have to mine often with surreal requirements,or pay,but they do not work to provide a comfortable self-sustaining system.Freenet storage system the only one free system which has been working for a long time. There is no similar system,and no one works on a similar system which is free.Inevitably, following competing softwares,ZeroNet will also integrate these capabilities.Freenet is a long-established,developed,supported reliable system non buggy or rough-and-ready protocols would be integrated with it.\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1594513524, "modified": 1597818226, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2589", "source_type": "github"}, {"topic_id": 1604067998, "title": "Clearnet access for all pages using a central https://website.something/<hash> or https://<hash>.something", "body": "Is your feature request related to a problem? Please describe.**\r\n\r\nIPFS or Tor have a Tor2Web project.These projects allow pages running on a closed network to be available on the open web too.And the open web search engines Google,Yahoo,DuckDuckGo,etc index the content of the page.It would be important for open web crawlers to index the content of pages.Users should be encouraged when visit zites without zeronet software example a video,document etc and if the content is not available encourage them to download the ZeroNet software to get it later when the user or user or users who have the file goes online.\r\n\r\nThis is what an IPFS page looks like\r\n\r\nhttps://ipfs.io/ipfs/QmXoypizjW3WknFiJnKLwHCnL72vedxjQkDDP1mXWo6uco/wiki/\r\n\r\nThis is a Tor onion site looks like in clearnet\r\n\r\nhttps://xmh57jrzrnw6insl.onion.ws/\r\n\r\n**Describe the solution you'd like**\r\n\r\nIPFS uses a working solution the point is that there is a central link https : //ipfs.io/ipfs/hash> and all IPFS pages can be accessed from the open net using the link.If a page is running from large files, everything works on it.Previously indexed content is available for up to 24 hours even if the server on which the specific page runs is offline.The pages of the major search engines Google,Yahoo are index. What is not available can be added to the client and thus becomes available later. There is a similar option on the Tor network using the https: //<hash>.onion.to, onion.cab, onion.something extension.There used to be similar solutions for ZeroNet,but on different links https: //wibsite1.something /hash>, https: //wibsite2.something /hash> etc.And these servers shut down in a row often not available. Need a central link where all pages would be available.These could be found the simlpe clearnet serch egnies and browsers.A working solution would be important because people are interested in the sites available on the open internet.Zeronet.link it is good to recommend downloading the software but nothing in the content of the pages is indexed by the normal internet search engines.Need a solution where if the content is available then the content is available on a central link on the open web.If not available such as a large file or other should be offered to download the 0Net software to get the user it later when it becomes available.At this time,no content running on the 0net can be accessed from the open web.\r\n\r\nProblems with the current system\r\n\r\nhttps: //wibsite1.something /hash>, https: //wibsite2.something hash> often not available, there is no stable central link on which web pages can be indexed uniformly.\r\n\r\nCurrently,none of these links work out of many.\r\n\r\nThey cannot retrieve larger pages or files.\r\n\r\nThe HTML not appears correctly like title,description in the clearnet search engines.\r\n\r\n**Describe alternatives you've considered**\r\n\r\nIPFS,Tor2Web project.\r\n\r\nhttps://www.tor2web.org/\r\n\r\nOr see the IPFS decentralized Wikipedia\r\n\r\nhttps://blog.ipfs.io/24-uncensorable-wikipedia/\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1594516718, "modified": 1595249802, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2590", "source_type": "github"}, {"topic_id": 1604068000, "title": "Backward compatibility for download and share help seed zites using another torrent clients", "body": "Should have an option for pages and files like a save as zip to crate a torrent file from a complete zite with all files checking content.json and the existing files.Important an HTML file could be placed in the torrent file what the user can add the zite or file to ZeroNet client.And if ZeroNet not installed then this should be mentioned to use in the page.Tribler have https://www.tribler.org/ a onion based UDP anonymous protocoll.Using this,could also connect zeronet anonymously to any torrent client using DHT.\r\n\r\nWhat would be the goals whit this\r\n\r\n-Using a hash,simple magnet link,torrent file whit a simple torrent client or ZeroNet software users can share complete zites in the open web or anywhere else.\r\n\r\n-Users can seed zites with torrent clients,and when a user open a zite in ZeroNet can download zites from another torrent clients too not just ZeroNet clients.\r\n\r\n-Using the webtorrent protocoll users can share files and video files what avaible in ZeroNet in clearnet sites what support web torrent tourgh the ZeroNet client.\r\n\r\n-Anonymous torrenting  which would encourage even more users to use ZeroNet\r\n\r\n-The indexing method of the Tribler could be used to auto index torrent files,zites,files.There could be a indexing page where the torrent added to the client,if not private,would be automatically indexed here.We could collect files from other sites without having to download the pages.Or in content.json a option public site:True or Falshe auto index here the zites.See this on Tribler search option.The advantage would be that a lot of quality content would be automatically uploaded to the zeronet network without content producers.Quality content would automatically gather in one place.Example if a user download a game,video,software from clearnet this could be shared automatically by the system unless the user intends it to be private.\r\n\r\n-If ZeroNet are blocked but torrent are not then the pages would be available.\r\n\r\n-With a simple HTML file we can promote Zeronet and add zites and files to the ZeroNet client when the user download the torrent with a torrent client and does not have installed ZeroNet.\r\n\r\n-ZeroNet this way can use not just TCP but UDP connection.Tribler onion protocoll are use UDP not TCP.And with this working with the UDP based DHT protocoll without trackers.If the user not set ZeroNet as exit node using a insaide UDP proxy network it is also ideal for an internal proxy network that is more difficult to censor.So if both TOR and ZeroNet are blocked or all trackers this third option is still there.\r\n\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1594521239, "modified": 1594521239, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2591", "source_type": "github"}, {"topic_id": 1604068013, "title": "5 things that cause a serious problem in the operation of ZeroNet for several years", "body": "### Step 1: Please describe your environment\r\n\r\n  * ZeroNet version: 0.7.1 (rev 4496) and all previous versions\r\n  * Operating system: Windows 10\r\n  * Web browser: Firefox 79.0\r\n  * Tor status: not always\r\n  * Opened port: no\r\n  \r\n\r\n### Describe the problem:\r\n\r\nFor simple users a few things are too unnecessarily complicated which should be simplified because this things make the software unusable for many user about long time. Setting up websites and downloading files should be made much easier for simple users.\r\n\r\n### As website owner: \r\nSetting up websites should be made easier by copying and signing files to a folder.\r\n\r\n-1.UTF-8 encoding: All pages must be converted to UTF-8 otherwise, the characters will not be displayed correctly in the browser. This requires a separate program for several files, which is difficult to find on the Internet.\r\n\r\n-2.In content.json file, files larger than 10 mb are required as set as optional files or they cannot be downloaded. This is very inconvenient for site owners many times the larger files are part of the page. Not everyone can use the content.json commands. It would be simpler if no separate parameter is specified in content.json larger files would be downloaded in the same way as smaller files.\r\n\r\n-3.Special line in HTML files: `<base href=\"\" target=\"_top\" id=\"base\">` and `<meta charset=\"UTF-8\">`\r\nDon't have to setup the `<base href=\"\" target=\"_top\" id=\"base\">` line to navigate correctly the pages. Many people don\u2019t know to need to set it up and without it, you cannot navigate properly between pages.\r\n\r\n### As user: \r\nLarge files are not available on the network and this makes the use of the software unenjoyable. For simple users we should make it easy to download files. If it\u2019s not even available right away when he visit back can check it out. There should be no complicated options for this because these cannot be handled by users. Most users cannot handle a +SEED button and all they see is that they can\u2019t download anything.\r\n\r\n-4.Large file download in single user zites: Download all large files automatically with the website. For simple users don\u2019t have to worry about why the content (like larger fideo or etc files) isn\u2019t available and why not. Advanced users should have a button if they do not want to download larger files on the site then this can be turned off at the touch of a button.\r\n\r\n-5.Large file download in multiple user zites: If a user clicking a file always complete and resume the file download. If the file is not available in the default case,the program always try to download it later even if the computer restarts. If someone does not want this at the touch of a button, this can also be turned off. Semi-finished or finished files can be deleted at any time. I have been experiencing for years that that theory doesn\u2019t work that we are not downloading the entire file from browser request so as not to take up extra disk space. As a result, the files cannot spread and almost nothing is available, and it is thus useless, unenjoyable to many people. Added to that is the problem some multiple user sites like IFS are not use the +SEED button.\r\n\r\n**A small optimization would be important default setting ZeroNet run at system startup.To seed files this is very important.If not set the computer is active but users cannot seed the files.**\r\n\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1596668942, "modified": 1597938094, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2602", "source_type": "github"}, {"topic_id": 1604068016, "title": "Security issues with codes embedded in clearnet websites or Zites (it would be useful to have a own closed ZeroNet Tor browser)", "body": "### Step 1: Please describe your environment\r\n\r\n  * ZeroNet version: 0.7.1 (rev 4496)\r\n  * Operating system: Windows 10\r\n  * Web browser: Firefox 79.0\r\n  * Tor status: not available/always/disabled\r\n  * Opened port: No\r\n  \r\n\r\n### Step 2: Describe the problem:\r\n\r\nSecurity issue with particularly HTML scripts when the user visit a clearnet website, or a zite contain a HTML script they may leak sensitive information about the user. The problem lies in communicating with external sites. One problem is that possible to scan what zites a user stores on their machine. And possible to detect the IP address too using a simple HTML script. If the user use TOR browser to access ZeroNet service and allow the localhost access to ZeroNet. Then this access works through it as well. A lot thing is leaking through the browser. Involuntarily if someone copy a website from clearnet it may contain dangerous codes which can leak unwanted things about users to third parties. Not a good idea to allow localhost access in Tor browser because it is not only used for ZeroNet. The other problem is ZeroNet open Firefox browser and not the Tor browser.\r\n\r\n#### Steps to reproduce:\r\n\r\nhttp://127.0.0.1:43110/1ScanCY9fjmjanDt7NwvyNQCL16hqWnVM/\r\n\r\nThere are pages in ZeroNet that can be visited to extract the user's IP address with a simple HTML script.\r\n\r\nZites can communicate externial clearnet sites using simple HTML scripts without the user's knowledge.\r\n\r\n#### Expected Results:\r\n\r\nIn TOR always mode more security:\r\n\r\nA special browser would also be useful which would only work with ZeroNet. And this browser would launch ZeroNet. Could be a TOR browser modified for zeronet and connect the zeronet TOR network. And prevents IP address leakage. Allow only the localhost communication excluding the fact that security can be circumvented through the browser. And to rule out all access to ZeroNet through all another browsers. The default TOR browser is not a good solution, it opens a gate to ZeroNet since it is not only used the user for ZeroNet. It could be a noscript option which could be disabled for advanced users any unnecessary scripts. Currently, blocking scripts blocks the entire software. This could be a much safer way if someone use TOR always mode.\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1596678170, "modified": 1597659198, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2603", "source_type": "github"}], "next_comment_id": 41, "comment": {"1604067142_mirrored_mx5kevin_github": [{"comment_id": 1, "body": "> \r\n> \r\n> This is intentional: by default ZeroNet will only download file parts that are requested by your browser. This avoids downloading huge, unnecessary files in the background, the site can add a seed button if they want, that will trigger all the parts to be downloaded.\r\n\r\nThis is very complicated. Users can not know what this seed button. Special zites like IFS (Intergalactic File Server) use a coplicated special script to download all part of the current file by default from browser request.The IFS setup with a complicated script what force all files to completly download are working.The service have seeders.And the files are stay online with loonger time. Very hard way for a medium website administrator to integrate a special script or button.The are no option in Zero Hello files menu to resume the downloads for the users. I can not find simple script,and another tutorial how to fix this.The are no option in the Zero Hello/Files menu wheare the users can controll this process.The are a Delete and Pin button what does not help.Its not a user friendly setup.And how to make this seed button using a simple HTML code? Freenet have a simple option.If the file the current time not available the are a option which can always be later downloaded.You can easy way use it all time when you download a file does not need to find it in the program. This is included in the program. There is no need the website administrators for special coplicated integrations.What users may not understand what is that,and how to use.", "added": 1550747911, "modified": 1550749337, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1910#issuecomment-466015682", "source_type": "github"}, {"comment_id": 2, "body": "> \r\n> \r\n> This is intentional: by default ZeroNet will only download file parts that are requested by your browser. This avoids downloading huge, unnecessary files in the background, the site can add a seed button if they want, that will trigger all the parts to be downloaded.\r\n\r\nMaking a easy accessable intelligent window what if a user download a file.Or play a HTML5 media in a website embed player.Like a friendly popup,which can handle more downloads in ideal way.ZeroNet use esy popup windows.Can show a window when user play a media or download a file with a download button.What can work like the seed button.This change can make currently with minimal work.Like the  .json file change or add CDN,set website limit buttons in a popup window etc.I mean **user click a file or a player then came up a popup window with  (Download File) button and the file name.And this button works like the +SEED button**.It would be better simple for all users.And all site owners.This way can users get all part of the files.Or without it from browser request like Embed HTML5 Player in websites can download only parts of them.Or if the file not avaible they can get this way later.Users can access the function this way easy.The website owners this way does not need special integrations.What makes problems for everyone. The most beginner users can use the function. This way website owners can make more modern,bigger,more quality sites.The working setup are in the download managers and torrent clients.Zero Hello files menu need later a good working download interface.", "added": 1551282831, "modified": 1551283776, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1910#issuecomment-467985133", "source_type": "github"}, {"comment_id": 3, "body": "**Version 0.6.5 (rev3853) and the previous version.Another downloading bugs:**\r\n\r\nWith the written above configuration using Tor Always mode as server and cilent.If 1 user seed many files the sytem are crashed.Tested with windows 7 as cilent and windows 10 as server setup.Tested in a natural environment the 2 PC connected another internet provider.Used high speed internet connection.Tested ZeroUp Clone, KopyKate Big Clone, and selfmade test sites.\r\n\r\n**-1.  Download and help distribute all files does not start or stucked the download setted up high       2000MB downloads.Updating stucked X file left.With Zero Up and KopyKate clone happend this two.**\r\n\r\n**-2. Download and help distribute all files plus using the seed button,or without seed button using download manager or browser the file can not be downloaded.This happend with ZeroUp clone.**\r\n\r\n**-3. After turned off Download and help distribute all files the seed button or file downloading with download manager  or browser not worked.**\r\n\r\nIn the past, these functions worked.\r\n\r\n**The problem have low seeded files.**\r\n\r\n-Tested one with veary large file 20 GB file using serval tests. The download are not started.\r\n\r\n-IFS Intergalactic File Sever, and ZeroVoat what use the IFS cluster site resume download from browser request it worked longer time ago. It doesn't work somehow anymore.\r\n\r\n-In earlyer versions worked a simple HTML command #Add (example <a href=\"file.zip#Add \")  command after the file.This command resumed the file download without seed button. It no longer works without seed button.\r\n", "added": 1552817548, "modified": 1552830669, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1910#issuecomment-473664490", "source_type": "github"}], "1604067303_mirrored_mx5kevin_github": [{"comment_id": 4, "body": "> \r\n> \r\n> I don't really like the idea. First, most people will disable this feature because they most likely don't want to seed illegal content. Second, why should this feature be in the ZeroNet core? A simple site would work. And, third, we have this site already - it's ZeroUp. You can make ZeroNet download all the files (via sidebar), and then it's no different from your idea.\r\n\r\n-You currently can not start a upload in a distributed storage. (Or any upload in the system if nobody download the file) and only you the only seeder.To keep alive the file.\r\n\r\n-Users want fast the files.Want some stable download speed.\r\n\r\n-Website owners want keep alive them. \r\n\r\n-Nobody want to see lot of dead optional files.If users see this,they go elsewhere,where quickly fast get all files.To solve this problem we need more seed what default way the users and site owners can give us currently.Currently at unknown intervals seeded files we get few downloaders most of the files on ZeroNet.\r\n\r\n**A stable storage what keep alive the files until they are deleted feasible.We currently have all technology to make this!** Users want to see a working system.And not dead files everywhere.With this idea we can store the files for long time.So the files would be available years later.Until the owner all delete it.Same way as currently working on clearnet.\r\n", "added": 1559588007, "modified": 1559589848, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2039#issuecomment-498440608", "source_type": "github"}, {"comment_id": 5, "body": "> \r\n> \r\n> We can store the files _where_? On users' computers? Then how is it different from making the computer download all optional files which is supported already?\r\n\r\nDead HTML 5 players and files everywhere with the existing setup.They don't encourage anyone to be more serious invest to ZeroNet zites.Availability of files and contents with the current setup are highly limited.And this can only be solved with extra seeders.\r\n\r\nDe difference\r\n\r\nThe publishers can upload and can make extra seed, bandwidth without waiting for sombody who download the file.And reduce the servers electricity costs.Can make useful uploads,share the content without wasting for energy and lot of time to wait a user.The visitos get faster highter download speed.Get much more faster the files.The files get much more health in the system.Zites like ZroUp,KopyKate are too large to store all files the usrers.In this zites users can store only some files but not all!Without a extra shared storage its not possible to give more health the files in the system.Users will not wait to ZeroNet If that they get fast the files in clearnet or another service.Web developers and website owners they go elsewhere where 24/7 online what they share.And this is need more seed than a simple uploader and downloader system.With uploads in a shared storage if the publisher the only seeder.Can minimum triple the files health, bandwidth.And a easy way to make all files 24/7 avaible and even online forever in the system until the owner are delete it! And this is much more business for web developers and website administrators and users too!\r\n", "added": 1559764794, "modified": 1559765662, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2039#issuecomment-499286623", "source_type": "github"}, {"comment_id": 6, "body": "> \r\n> \r\n> > And this can only be solved with extra seeders.\r\n> \r\n> Okay. Then, are you recommending to add more seeders? Where would you find them? I really don't see the point.\r\n\r\nThe idea are simple.Site or file owners can upload zites and optional files in a shared strorage what operated the ZeroNet Users.From this the users get back the seeded data when download a single file from this strorage.The difference currently the user download the zite and optional files.With this setup the zite and file owners can upload automatic way files and zites to another users compjuter.When a file seed only 1 user or the file ratio are under 2.0 the file upload from the owners mashine are automatic way started.This keep every files gaurantated more than 1 seeder.More uploads in the system give extra seed.Available on request the owners (or users) can set up/file or zite a highter seed limit 2,3,4 or more for more upload (or more file coins).Disk space is unlimited and not a problem.With this setup there is not limited the data and bandwidth,uptime which could not be provided by a publisher cheap and easy way.\r\n\r\n\r\nUsers can controll the content because zites and files are downloaded the same way.But a seperated folder and credit minning sign.With a more extra function if a user allow to the auto upload.Not just the simple download the user get more and faster Byte,MB,GB (coins) from this storage.This way with minimal of us of resources we can kepp the files zites online.Similar setup use Freenet,Safe Network where the files are uploaded to another users compjuter.Freenet are a stable network what working a similar existing setup.This combinated with the existing zeronet protocoll are triple the health of files.And possible to make all files 24/7 seeded. **This is a existing working setup what currently use similar programs like Freenet,Safe Network,maybe I2P.** **The idea can be expanded see Tribler what use a similar protocoll like TOR** .And a credit minning system. **For competing similar softwares this is a working system** .And a siple way to multiply minimum 3X or highter stability,bandwidth,uptime.Large zites like KopyKate ZeroUp can strore part of optional files with this setup.So we can make large stable services like the original Google YouTube.Where particularly important to the users can play video files fast with stable download speed.And there is no time to wait hours or days for a video.Or lots of dead liks try to use where nothing can ever be downloaded.\r\n", "added": 1559804768, "modified": 1559807094, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2039#issuecomment-499433234", "source_type": "github"}, {"comment_id": 7, "body": "> \r\n> \r\n> >change the entire structure of zeronet to add in cryptocurrency and forcefully putting files on peoples' computer without their consent\r\n> \r\n> lolno\r\n\r\nI didn't say anything like that. I talked a primary storage what keep the files online. And using the existing setup. What storing the whole file or file picees. If Feenet Maidsafe users are working a similar setup. I don't understand why it wouldn't be good here. When it's good on other platforms. This be done safely the similar setups. Most users can not run a server 24/7. And if users see it is not working the system. They go somewhere else where they store their contents, files without problems.  And don't have to wait for nothing to download a content. The software developers no other decentralized solution has been found yet. See the similar decentralized projects. With the zeronet existing plugin system i'ts can be done. And those who are problem this, can disable the feature. Nobody talking about forcefully putting files on peoples' computer without their consent.", "added": 1568658180, "modified": 1568658639, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2039#issuecomment-531963832", "source_type": "github"}, {"comment_id": 8, "body": "> \r\n> \r\n> Well it doesn't work well on other networks as well, look at Freenet. I don't want to host illegal content that might accidentally be downloaded.\r\n\r\nThis is not an unsolvable problem. Lot of projects are working on this. If it wasn't a big opportunity, then not many people would work on it in serval projects. User can check and allow some contents if the system download the complete file. So  no illegal content is stored this way. Something simpler we can make using the existing setup. I2P, TOR, Freenet, technology protect the IP. And some of them encrypt the files. Some of this technologys are only store chunks in the users PC. Storj and many more modern decentralized storage techology are working this setup. Anothers working the same setup but using with the blockchain technology. And try to store the files in the blockchain. I do not think this big companies can not solve the problem that users can store this data securely. These services complety bullding to this technology. From ZeroNet missing a stable storage what keep the files online. Which is everywhere in the clearnet is a basic thing. It's a matter of time and they appear the first platforms what store the users files from paying disk space in a decentralized storage in the clearnet see (Maidsafe). Using a simle way if you give disk space, another users exchange keep too online your files frealy too. With this technology website administrators can run clearnet sites. And the users can visit them without special programs. If we combine it the existing ZeroNet protocoll, we get a powerful free decentralized 24/7 online web hosting service. Which is an competitive  alternative to the existing paid shared web hosting services. I do not know any other decentralized alternative, which  widely or otherwise working popular or non popular  platforms. I2P, Freenet, Tor onion services, and ZeroNet are they are stuck in a small place. Neither is good to use them avarage users who want a real alternative from paid servers and 3rd part free services. And For serious investors this platforms absolute not ideal for un popular websites. ZeroNet may break out of this.", "added": 1568725033, "modified": 1568725529, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2039#issuecomment-532285198", "source_type": "github"}, {"comment_id": 9, "body": "This can be a plugin.Users can allow and dissalow plugins.So if a zite or file owner or user need extra seed he could enable or disable it.This way the user could use,and the developers simple way to integrate newest different protocols and technologies.Behind one plugin several more protocols could be allowed what do the same thing but in a different way.So the user can use Freenet,MaidSafe,Storj, decentralized protocols which he can mine or buy storage with cryptocurrencies and protocols what not use this.This way we get multiple extra file storage ways,which would be good for everyone.And so the newest and best independent from each other technologies can use the users this way from extra file storage.I mean you enable or disable the blugin and theare you can enable or disable or add exrta file storage protocolls.So if you a PC user or a mobile user then there you can use or not use more file storage options.So the users needs and system properties can get the users better more premium access to the contents.", "added": 1571319163, "modified": 1571319849, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2039#issuecomment-543257362", "source_type": "github"}, {"comment_id": 10, "body": "An important technical thing,which users can store a lot of files without taking up space on they hard drive.And all data this way possible to store and keep online using serval copies.The method is simple,copy the files in the disk what only the ZeroNet client can read as existing data.And another programs and the OS can see them as data to be overwritten.Same as deleted files. So this way could use the full unused disk space.Here the data is slowly overwritten.This is an untapped resource.And it can we have been prevented if the user not seed the files,and doesn't delete them the uploader they should still stay online.The storage mechanism of the systems makes this possible on all devices.Where we have few disk space like mobile devices it is particularly effective there.Where we have many disk space,files are stored there very long.And don't be full of network broken file links.In principle,there is no obstacle if not the full file overwritten only part of it this parts seed the program.Files can encrypted,users are protected with TOR.In this would be many opportunities,which would be free for everyone who helps with this.And people can even make money see crypto mining,it would have money and business,and this opportunity would attract more people.\r\n\r\nMore about see in: https://github.com/HelloZeroNet/ZeroNet/issues/2315\r\n\r\nWe should have a solution for zite links,and linked files too.Where data is unavailable for a long time (for example,a month) then the link should be automatically deleted.And only show up automatically  when it is active again.Because this way more will be slowly dead link on the network what is working. And the network can be spammed even direct large quantities with dead links.\r\n", "added": 1585375502, "modified": 1585375578, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2039#issuecomment-605416657", "source_type": "github"}], "1604067307_mirrored_mx5kevin_github": [{"comment_id": 11, "body": "The users in the .json files are include all optional file hash. With a single 1 and multiuser sites are seperated this files. So i\u2019ts possible to select user/optional files per zite do download optional files. Example in Zero Up its possible to select only 1 user files separate from the rest. In torrent clients when the user are click the torrent file can select the files. If the user open a page what include a optional file then it would be useful to resume the download. It could be a single (button, icon) which shows the optional files in the opened page. When the user clicks it. And if there is an optional file in the current page the icon are goes red or show when a optional file exit in the opened page. It's simple and not distracting the users. I mean in the currently opened page detect ZeroNet that there is an optional file there. And if there are more in the same opened page, under one icon you can collect more files. Like the modified files Sign&Publish msg. With the discret purple number of files option.\r\n\r\nExample in Firefox\r\nIf you download The Flash and Video plugin\r\n\r\nhttps://addons.mozilla.org/hu/firefox/addon/download-video-and-flash/\r\n\r\nAnd if you go on [YouTube](https://www.youtube.com/). If you open a video the icon goes red. And if you click it you will see the files. I just thought of a simple solution but not the browser, in the 0Net software. With a simple button (download files). Like the modified files Sign&Publish msg. With the discret purple number of files option. And when you click the file the client shows the downloading are resumed. And its works like absolute  the same way what the seed button doo.\r\n", "added": 1568661817, "modified": 1568662205, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2041#issuecomment-531981467", "source_type": "github"}], "1604067585_mirrored_HelloZeroNet_github": [{"comment_id": 12, "body": "With a single user site it would be easier to allow to download big files too with default. Some websites contain large files in specified directories.It can be confusing to the users and site owners that some users can not acces to large files easy way.Because the are no mode to setup to automatic way to download all large files when the user download the zite.A button would be easier what show the total of large files size in a single site and only restrict large files download if the user click the button when the site load and not want them.When the user download the zite and currently click the button to not want them and later he think maybe later want the big files them top-right 0 button would be better one button what shows the total size of all large files in the current zite.And allow one click to download them.Plus allow all single large files a easy simple button click in the client to resume a single file download if a user click in a large file using a non flustrating MSG with a download button.What shows the client when a user click a large file.Without need the site owners to integrate +Seed button.And this is working with single and multiple user zites. This easy things can solve many seeding and downloading site +seed button intergration and using issues.Many large files currently hard to download,porly seeded,and dead.If we combinating it with this idea we can get more healt the files with site-independent file storage and de-duplication combination.", "added": 1571316913, "modified": 1571316999, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2192#issuecomment-543241718", "source_type": "github"}, {"comment_id": 13, "body": "It would be important if the same file using another file name the program can detect it and merge the seeders/leechers.Independent of the site.If we upload the same file to ZeroUp,KopyKate the filename and thus the file hash are changed but the file are absolute the same.This way you can't merge the users who seed the same file.Can not detect the program if somebody upload the same file to ZeroUp,KopyKate ETC.It would be easier for a user to be warned if the current file are exit somewhere else,on another site.Because it's from the same file you need more copies that different people are seed.This is a huge waste of resources.Not a good thing that ZeroUp,KopyKate are renaming the files like the original file.mp4 to 1234567890- file.mp4.This way you and the users can't seed the same file if exits in another site without manual editing the .json file.Existing seeders are lost if the same file are re uploaded or uploaded with another name.And unnecessary copies are stored which take up space on your hard drive.", "added": 1585463282, "modified": 1585463282, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2192#issuecomment-605608847", "source_type": "github"}], "1604067572_mirrored_mx5kevin_github": [{"comment_id": 14, "body": "imachug  It didn't help much. And it doesn't solve the problems.\r\n\r\n> Use ZeroFrame `wrapperOpen` method instead.\r\n\r\nThe wrapperOpen command does not work too.The same thing happens.\r\n\r\n> Is pressing a single button in sidebar difficult?\r\n\r\nTell users this.Users download the files and not the website owners.\r\n\r\n> This means that the original site created an invalid link (i.e. without _blank)\r\n\r\nNo,a simple another zite link does not work this.The browser give the option but it's not working.Users are simply redirected this way to a different page.And they can't go back to the original page which indexes the outside page.The  _blank issue it exacerbate the problem\r\n\r\n> Well, I'd recommend you to switch to utf8. A lot of software depends on it nowadays. It might be worth adding `<meta charset=\"...\">` though if you have HTML files.\r\n\r\nFiles must be converted.Minor problem,but it would be beneficial to support another formats.Bigger problem in large zites large quantities must rename some files.Which contain not supported characters.And it still doesn't help the .mp4 playing issues.\r\n\r\n\r\n\r\n", "added": 1571933848, "modified": 1571933848, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2241#issuecomment-546063353", "source_type": "github"}, {"comment_id": 15, "body": "> What is that \"same thing\"? You said that the page didn't open. Did you mean that no tab was opened at all, you got an error like \"escaping iframe\" or something else?\r\n\r\nThe browser open the zite in a new tab with the address,but the zite does not load tourgh the 0Net program.\r\n\r\n> Sorry, that was a typo. I mean `_top` instead of `_blank`. Could you please try `<a href=\"...\" target=\"_top\">`? I think it worked for me before.\r\n\r\nThe `_top` command redirect the pages,seems now i can go back the another original zite.But still i can not open the another page in a new tab.If i use a normal link i can not go back the original page.And the user is redirected to another page,which many website administrators are not happy with.", "added": 1571936046, "modified": 1571936046, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2241#issuecomment-546076714", "source_type": "github"}, {"comment_id": 16, "body": "> \"Does not load\" can mean a lot of things, from \"browser hangs\" to \"I forgot to plug in the computer\". What exactly happens? Do you get a white screen? Do you get a white screen with \"Escaping iframe\" text? Do you get the `0` icon in the top-right corner? A screenshot would help.\r\n\r\n`\r\n<a href=\"http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D\" target=\"_blank\">ZeroHello</a>`\r\n\r\ntarget=\"_blank\" or \"_wrapperOpen\" too.If i use the code in a zite.\r\n\r\n I get a white screen.0 icon in the top-right corner are shows.\r\n\r\n![sreen](https://user-images.githubusercontent.com/47847121/67522603-8cdaee80-f69c-11e9-9160-794f90b3a6c7.png)\r\n\r\n", "added": 1571938194, "modified": 1571938344, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2241#issuecomment-546089674", "source_type": "github"}, {"comment_id": 17, "body": "The video problem.\r\n\r\nUsing a HTML5 player code works fine the video.\r\n```\r\n<p>\r\n<center><video width=\"800\" height=\"455\" controls>\r\n  <source src=\"files/thevideo.mp4\" type=\"video/mp4\">\r\n  Your browser does not support HTML5 video.\r\n</video>\r\n</p>\r\n```\r\nLinking the video or open in ZeroHello files menu are does not working through 0Net.But without 0Net i'ts works fine the same link using a simple clearnet server or playing  through  the browser without 0Net.Not all .mp4 videos,some videos and I don't know why.Using Firefox,Microsoft Edge,Google Chrome,Internet Explorer too.And all zites have the same problem,like KopyKate.\r\n```\r\n<p>\r\nVideo \r\n<a href=\"files/thevideo.mp4\">The Video</a></center>\r\n</p>\r\n```\r\n![videosreen](https://user-images.githubusercontent.com/47847121/67525066-7d11d900-f6a1-11e9-9428-a3deb398a7a0.png)\r\n", "added": 1571940310, "modified": 1571940404, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2241#issuecomment-546103042", "source_type": "github"}, {"comment_id": 18, "body": "> > I get a white screen.0 icon in the top-right corner are shows.\r\n> \r\n> O_o I've never had such problem. I'm wondering what could cause such an issue. Can you please get to this white screen again, press F12 and open Console tab and make a screenshot again?\r\n\r\nReproduction the issue:\r\n\r\n1.Make a HTML file in your zite.Name it 123.html\r\n2.Add this code.You can use another zite the same happend.\r\n\r\n`<a href=\"http://127.0.0.1:43110/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D\" target=\"_blank\">ZeroHello</a>`\r\n\r\n3.When you open the link its open in a new tab but the zite are not loading.\r\nTested Google Crome,now Firefox,Microsoft Edge,Internet Explorer.\r\n![sreen12](https://user-images.githubusercontent.com/47847121/67571195-d837e000-f722-11e9-8cde-f49387d24cb6.png)\r\n\r\nWith Firefox 70.0, i can not make a sreenshot.I got a error this point another clearnet sites working.I maked another program the sreenshot from firefox now.The first are maked from Google Chrome.\r\nType Error: doc is null with Firefox 70.0.", "added": 1571996178, "modified": 1571996417, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2241#issuecomment-546336142", "source_type": "github"}, {"comment_id": 19, "body": "With uploaded mp4 video file,where the user have the full mp4 file.In ZeroHello files menu,or linking the video using a HTML code in the current zite (and not another zite or site).\r\n```\r\n<p>\r\nVideo \r\n<a href=\"files/thevideo.mp4\">The Video</a></center>\r\n</p>\r\n```\r\nWhen the user play certain sections and part of video. I get this error: \"Video playback has stopped due to a network error\".So nut just some video files can not play this way.Some are playing but the user get this error.And the same thing, using a embed HTML5 video code in the site are working the same video.Some video files cannot be played and some are stuck when the user try play certain sections and part of the video in ZeroHello files menu or using a simple link without HTML5 player code.", "added": 1572170704, "modified": 1572170704, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2241#issuecomment-546692773", "source_type": "github"}, {"comment_id": 20, "body": "> That can happen when you haven't downloaded the whole file and no one has the missing parts. Can that be the reason? @HelloZeroNet\r\n\r\nThis is not possible,because some files i'm the uploader.And have the full file in all case.And works using a HTML5 player code the same video files without issues.Like this:\r\n```\r\n<p>\r\n<center><video width=\"800\" height=\"455\" controls>\r\n  <source src=\"files/thevideo.mp4\" type=\"video/mp4\">\r\n  Your browser does not support HTML5 video.\r\n</video>\r\n</p>\r\n```\r\nBut when i link the file in the same zite,or try play through ZeroHello the video file are does not play or stuck when im play certain sections and part of the video.See the linked image, in the previous comments.These two different errors occur during playback.And there may be on reason for this.The file name should not cause the problem either.Because it doesn't matter the video file name 123.mp4, 1.mp4 This Is My Video.mp4. The same happening.", "added": 1572171375, "modified": 1572172076, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2241#issuecomment-546693724", "source_type": "github"}, {"comment_id": 21, "body": "Without\r\n\r\n`target=\"_top\"`\r\n\r\nCommand in the zites cannot go back to the previous page using the browser back button.On larger pages, this can be a hassle and inconvenience to users and website owners,where users navigate a lot between pages.", "added": 1572378901, "modified": 1572378901, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2241#issuecomment-547665189", "source_type": "github"}, {"comment_id": 22, "body": "> \r\n> \r\n> This is a known problem, and I have not found any solution to that, but adding `<base href=\"\" target=\"_top\" id=\"base\">` to the `<head>` solves the problem without the need of the modification of all links.\r\n\r\nI'ts possible to do this using the  content.json file?", "added": 1572379277, "modified": 1572379277, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2241#issuecomment-547666820", "source_type": "github"}, {"comment_id": 23, "body": "Py 3 version running from desktop can not find ZeroNet.exe at sytem startup under Windows 10.I think the zeronet.cmd i file not corretly index it in the Startup folder.Works with the old py 2 perfectly,but with the new py 3 are not.The user name in Users folder contains special characters \u00e1\u00e9\u0151.", "added": 1573518371, "modified": 1573520371, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2241#issuecomment-552717652", "source_type": "github"}], "1604067577_mirrored_mx5kevin_github": [{"comment_id": 24, "body": "> Do you mean that sites don't allow you to upload such big files or that file downloading stops after a certain amount of data is downloaded or downloading doesn't even start?\r\n\r\nIf you upload a 10GB single file (ISO,ZIP,RAR).The download does not start.You can upload to a zite the large file.But if you try to download the download will not start.And no matter what zite.Tested with multiple zites.There was no error in the pages.The program cannot download the single 10GB file.\r\n\r\n", "added": 1571994716, "modified": 1571994716, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2243#issuecomment-546328961", "source_type": "github"}], "1604067707_mirrored_mx5kevin_github": [{"comment_id": 25, "body": "Those users who deal with systematic Hit And Run must be filtered the owners who not deal with this from the network.We need a correct blocklist what block this users.Because they are harmful to the whole community.This is done in every large P2P community.And they are much more effective than where they don't.There are plenty of users and all contents have a lot of seeder.\r\n\r\nActually the owners are pay the users with seed,electricity,and their work.And some users after he get the file nothing are seeding back.And they should pay for it,not the users who are correctly seeding, and  not the owners.And the less seed,or too much time too wait a downloader are more cost for the owners.The user does not pay for the download.User paying with seed.If the user refuse to do so, then he pay for it with money.I think it's fair that initially with ,seeding new files,mining he can do it easily.Some easy proof of work are need at the beginning to avoid abuse.\r\n\r\nAnd if the user seed the files the files correctly later he can even make money with it.\r\n\r\nThe owners has the right to filter those users who are not willing seed back the files.And they are not willing to pay for it in any other way.Because this the website and file owners are paid.And the user if they do not get the file.\r\n", "added": 1575738463, "modified": 1575852836, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2342#issuecomment-562882111", "source_type": "github"}, {"comment_id": 26, "body": "> \r\n> \r\n> As I see Zeronet tries to be agnostic on the part how users behave. Closer to the transport then system. Only spam prevention is in place everywhere.\r\n> Additionally I can say that you have everything already available to implement it in let say user space. With identity providers and user data you can have it for example in a file sharing site.\r\n\r\nIn P2P File sharing sites users who does not have the minimal seed ratio are getting banned.There having registered data. There you can ban a user.Many places can only be accessed by invitation. In the case of ZeroNet a reliable control system is needed.Which is not easy to manipulate.Here are not possible to ban a current user with registered data.With single zites this cannot be solved.Easy to use for all users and owners. **Like a simple content.json setup.** What working in all zites.With new files the fast seeders are inportant, what keep the files online when the owner turn off his mashine.If the first users in a new content can help the seed without paying it would also solve other problems.Or in a reliable cannot be manipulated way check the user Download/Upload ratio.Another solution was the coin minning.Like in .bit domain.Later, if someone seed the files she collect lot of coin. Who doesn't he also has to give something in return.To mine or buy it. Which is a money-making opportunity for those who are actively involved in maintaining the network.And protect the file or zite owners from malicious and harmful users.\r\n\r\nThere can be many on the network who simple Hit And Run in a bunch of files.", "added": 1575745098, "modified": 1575745098, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2342#issuecomment-562890254", "source_type": "github"}], "1604067764_mirrored_jeff-hykin_github": [{"comment_id": 27, "body": "I also had a similar idea with a concrete idea. That would be a simple solution. Given a XY GB sized storage no matter how much big! It\u2019s works with single zites and optional files too! Old files are automatically deleted from the server when someone asks for new ones. This deletion depends on the storage capacity. The are a browser notification system. Becuse many things are not immediately available. If the requested file has downloaded the browser shows a popup with the link! Later, it will remain online untill other users requesting other data. And at the end of the list it is deleted. This would require one plugin. And a server access to port 80 what working like a simple http server. These servers they could communicate with each other. So if somebody's got the full thing what the user want then a simple redirection happend. This redirection can happend to multiple cilent too. As well as downloading the same thing too can make 2 or more client too.If no one has it.So if you have one server what goes offline data is still available.It could work behind TOR too. File and zite owners this way even if they not 24/7 active could easily be shared their own content in clearnet. But for that, something would be very important. For all large file need a download button regardless of the page. What resume the download.Something like this:  [Files download one click using a discrete msg, what shows the client when existing a large file in the opened page.](https://github.com/HelloZeroNet/ZeroNet/issues/2041) You could protect your own files from automatic deletion.And just a separate line need in the client like the recently downloaded sites in Zero Hello menu. And a similar seperated line in files menu. To not to get mixed up with the user own things. It could be added here the own files too as indexed from the files using a single button click.From behind Tor anonymous way anyone could set up such a server who online permanently for several hours a day or 24/7. Thats another server what have clearnet access can index too the server what server are behind TOR.This system could also be used for that to help seeding unseeded or new files too. And that's not all. Users could also be encouraged through a reward-based system. Whoever runs such a service it can be retrieved or stored data on this network. And so it can be stored long term the users his own  files and zites who help with this.\r\n", "added": 1580226541, "modified": 1580226807, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2406#issuecomment-579397811", "source_type": "github"}], "1604067776_mirrored_mx5kevin_github": [{"comment_id": 28, "body": "In ZeroBlog the picemap.msg and .mp4 file deleteion was worked perfectly. In ZeroUp i uploaded some files it doesn't work with them. The files are deleted from the cilent in the list. But still exit in the site/data/users/current user directory. The same with KopyKate Big! Each file was my own.", "added": 1580223468, "modified": 1580223468, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2407#issuecomment-579376601", "source_type": "github"}], "1604067802_mirrored_mx5kevin_github": [{"comment_id": 29, "body": "No all client the port are closed and Tor are in always mode. The page auto refreshing are too slow. The download starts when i manualy refresh the site. The problem  if the cilent does not refresh the files then there is no download. The transmission is working, the time wastage is too much when the cilent try to download the file. If i update it the zite manually the transmission always starts immediately. I have to wait too long for this automatically. It does not try to look for active seeders for too long.The files refreshing for too long inactive.Several times the two machines were active.And there was no transfer.But when I refreshed it by manualy then the transfer always started.The client always uploaded several 5 files at once used the Help distribute added optional files option.", "added": 1582118707, "modified": 1582118707, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2428#issuecomment-588308513", "source_type": "github"}], "1604067972_mirrored_mx5kevin_github": [{"comment_id": 30, "body": "> Well, sites can already use GitHub, GitLab or Git Center if they are open source and want to accept contributions. Not sure why this would have to be directly built into ZeroNet.\r\n> \r\nUnable to upload files.A separate account must be registered.There is no easily accessible common development interface.There are plenty of subprojects KopyKate,ZeroTalk plus etc.Independent simple development should be given more space.But they are still there plugins, program codes.The project is too complex and should have a personalized page insaide in ZeroNet.More single web in ZeroNet projects would also require separate development teams.Professional well-designed free and updated zite scripts need which allows users to create modern websites using the current codes.This requires an option if someone knows something better then she make and simple and upload or share it.GitHub, GitLab or Git Center there is no possibility for rapid and independent developments.What is very lacking in the project is the quality plugins.I am thinking here of integrating more serious protocolls like filecoin,freenet, storage.Paid sites option, clearnet access and etc.What you need is a team behind which only deals with the current thing.\r\n\r\n> Problem is that cryptocurrencies and blockchains use completely different network than ZeroNet. This means that any mining pool would have to be separate from ZeroNet and centrally hosted on clearnet.\r\n> \r\n> Idea of that \"dontation platform\" is interesting and some of them already exist on Ethereum (like [Gitcoin](https://gitcoin.co/) or [Bounties Network](https://bounties.network/)), but it is still separate from ZeroNet and would still need to interact with services outside ZeroNet.\r\n\r\nNo compatibility or integration required just more the popular coin walets.And a preset mining software with a download link what support GPU+CPU mining.Plus a public mining pool what show the mining status.Some people could only donate with mining.And there is a payout threshold in mining pools.This cannot be achieved by one person,but many people can generate regular income.Donations can be encouraged for what purpose we want to donate.\r\n\r\n\r\n\r\n", "added": 1592753874, "modified": 1592753874, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2570#issuecomment-647165132", "source_type": "github"}, {"comment_id": 31, "body": "That's what I was thinking.\r\n\r\nhttps://xmr.nanopool.org/blocks\r\n\r\nSeveral people come together to mine behind one wallet address.The are miner programs with CPU or CPU+GPU option.Or there are scripts that can be run in a web browser.It could be for one purpose that the donator support this development with the donation because this is what he want to wait for in the future.Donate for specific purposes.\r\n\r\nThose who develop gather volunteers for specific developments.And they only deal with that particular thing within the project.There are no strong teams who dealing with concrete projects.And in ZeroHello/More Sites selection should have a big site just for all these purposes.", "added": 1592756329, "modified": 1592756678, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2570#issuecomment-647169583", "source_type": "github"}, {"comment_id": 32, "body": "The problem with ZeroNet websoftwares (zite softwares).Someone is making a good program which is full of bugs and needs development.The developer will not deal with any development later.People clone the current site and make some design changes,they tuch into the code and in many cases even spoil it.But nothing is fixed on existing bugs.There is no page where people can collect the current clones,users can report bugs.And who understand programming make repairs.There are cases where there have been adverse changes to the original code.Like the KopyKate style change.Or see Zero Talk clones in many cases,the original code repairs are not followed.The point is there are working sites that people are  cloned and make some changes in the code.But existing bugs are not fixed, in many cases they tend to accumulate and this is a big problem.There is example the ZhiHu ZeroTalk clone with search,file and picture upload,HTML5 player option.A modern i think the best ZeroTalk clone,the development is over and landed in the trash.The existing  clones are not fixed by anyone.Yet it is one of the most modern forum software in ZeroNet and landed as done freshly in the trash.The development of these projects needs to be brought together in one place.Codes,links,fixes,bug reports own versions anyone can upload.In one place is given the clones and the original script. It is also a problem if a page works with a particular website program.It cannot be replaced by a completely different program.The key is to be the original script,and the same script clones,clone fixes be developed in one place decentralized way.And the current script the users can use or upgrade the most best version.", "added": 1592785244, "modified": 1592785458, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2570#issuecomment-647248099", "source_type": "github"}], "1604068034_mirrored_styromaniac_github": [{"comment_id": 33, "body": "It would be useful to connect the .json file data and the files using a progress bar and difrent colors.It could be an advanced option to all zites.All files listed in content.json It would be worth listing based on this.\r\n\r\nExample:\r\n\r\nFile Options\r\n\r\nDowload file,delete file,select file with select file option as as with torrent files,pause file download,edit .json files,search files.\r\n\r\nFiles\r\n\r\n1.Not downloaded files like gray color (using the json file file list)\r\n2.Half finished and downloaded files what exit in the folder\r\n3.Files what downloaded but the .json file are changed and not part of the zite anymore (using a color).This can help people to delete outdated files.\r\n\r\nMultiple user sites like ZeroUp\r\n\r\nUsing the username@zeroid.bit: +hash using red dots or etc forward other users from whom we have downloaded something.And another users using gray color.\r\n", "added": 1595332039, "modified": 1595332039, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2594#issuecomment-661906483", "source_type": "github"}], "1604068013_mirrored_mx5kevin_github": [{"comment_id": 34, "body": "For users we need to make the platform easy to use. There are many user who cannot handle a simple +SEED button in a zite. For website administrators in the same way, things need to be simplified. Copies the files to  the web page folder and signs them. In single user zites download all files what the page contains default way. In multi user zites resume and complete all clicked file download. These are the options where the user do not need any expertise to use the software. The program must also be set by default to run at system startup for seeding and downloading to be effective. It is an experience that there are many users who cannot handle even a little more complicated options. For them, a lot needs to be simplified and made more transparent things. Such as a MSG when the download is complete.", "added": 1597663880, "modified": 1597663880, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2602#issuecomment-674916760", "source_type": "github"}], "1604068122_mirrored_slrslr_github": [{"comment_id": 35, "body": "If the file are larger than 10MB and in content.json not added this files as optional parameter. Then not possible to another users download this files. If the optional parameter added then the client not download with those files with the site. In both cases, files what larger than 10MB are dead. **The seed button is not used by anyone (if integrated in the site).** **And the Help distribute added optional files option setted up default way to 10MB and no one can use it.** Files what  larger than 10MB or setted up as optional they will be inaccessible. There is currently no workable solution to this problem.\r\n\r\nSee the issues: https://github.com/HelloZeroNet/ZeroNet/issues/2566 , https://github.com/HelloZeroNet/ZeroNet/issues/2243 , https://github.com/HelloZeroNet/ZeroNet/issues/2602\r\n\r\nThe solution would be in single user sites (zites) download all files in default way when the user load the zite. In multiuser zites when the user click a file than always completely download and finish the files. Even if the system restarts.\r\n", "added": 1601812100, "modified": 1601812100, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2622#issuecomment-703266383", "source_type": "github"}], "1604068062_mirrored_JabbaDesilijicTiure_github": [{"comment_id": 36, "body": "`self.parser.add_argument('--size_limit', help='Default site size limit in MB', default=10, type=int, metavar='limit')`\r\n\r\nIf a user click a link and only load the clicked content have a sense if someone is not interested in the whole website just a part of it. Forums and multi user zite like in Zero Talk with this option, comments will not be displayed properly if the user not allow larger limit.\r\n\r\n`self.parser.add_argument('--file_size_limit', help='Maximum per file size limit in MB', default=10, type=int, metavar='limit')`\r\n\r\nThe line doesn't make any sense, it just causes problems, no matter what the limit is. Site owners can not share files what larger than the limit. Users can not download files what larger than the limit. **The program ask in if the whole site limit larger than 10MB to allow larger limit. But not ask if a current file or files size larger than 10MB (optional and not optional files) to allow larger limit include the largest file in the zite to download default way.** Single user sites will be not work correctly this way. That would make sense HTML, CSS, JS, pictiures, PDF these are displayed by the browser. And ask if the zite contains other files if they have already been downloaded to download these as well. All other files could be treated as optional files default way without adding any line in the .json file. Because all other files are what the browser does not display. This is an optional option if the user does not need larger files because the downloads, video files etc will not work this way, or must wait the user to someone seed the files this way. Or select what files want the user like in bittorrent. Default way what the site owner share with the zite they are part of the website without it the website will be unenjoyable. In a single user zite default setup download all files so users have instant access to everything. If anyone has this problem then he will set separately which two other options want.", "added": 1603335432, "modified": 1603335860, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/2647#issuecomment-714249020", "source_type": "github"}, {"comment_id": 37, "body": "`        self.parser.add_argument('--size_limit', help='Default site size limit in MB', default=10, type=int, metavar='limit')\r\n        self.parser.add_argument('--file_size_limit', help='Maximum per file size limit in MB', default=10, type=int, metavar='limit')\r\n`\r\nIf both lines were completely removed and the limit was not changed, the entire program would work much more efficiently. These are the two preset values only make the program currently unusable. Currently, there would only be benefits to deleting the values completely. ", "added": 1603340266, "modified": 1603340266, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/2647#issuecomment-714286486", "source_type": "github"}, {"comment_id": 38, "body": "> \r\n> \r\n> > Currently, there would only be benefits to deleting the values completely.\r\n> \r\n> So if you accidentally open a malicious site, it will immediately fill up your disk? Sorry, that does not sound like a good idea.\r\n\r\nThe program will not work with with these pre-set limits. Web pages can be deleted completely. The system shows that files are loading and what site are downloading files. So they can't load the hard drive either. Even if that happened in mobile devices deletes the user of that page and the problem is resolved. Currently, it would have many more advantages than disadvantages. We need transparent information about the content size of the entire page and not limits. And as optional options for advanced users by not forced all user to this too. And by default, not all users are forced with pre-set limits. The problem is that these features do not work correctly. By removing the two rows which is a few seconds. The whole system would be much more efficient. If ask the system a question from the user like \u201eSite is larger than allowed example 2000MB/10MB set limit to 2000MB\u201d  an average user doesn\u2019t even know what it is. It also just causes a problems. And it doesn't even download large optional files if the user set it up. In vain  want to get them the user the setup does not do this. The whole thing just limits the operation of the system. A modern website 1-2 GB large. And an optional file are not  10MB or 30MB they are 100MB 500MB and larger. And over 30MB with the new setup nothing can be downloaded in a single site what larger than 10MB or the new setup with 30 MB. I agree with the optional option for advanced users. But the current setup it crashes the whole system. A selective solution would work to separate those files what the browser use to display a web page. And another files video, downloadable content and etc which can be downloaded later. Because they are not required to display the full content of the website. The key thing is not to have to ask for everything to be downloaded. If the user are not prompted for large files then  can set an option when the web page loads. But this should not be imposed on those who cannot use it. Because the user will see that the content on the website does not work. By default, the program does not want to decide what file to download and what not. In a single user zite by default, download everything or by the way the content will not work for the user. For publishers the limitations this service is made into a limited storage space on a closed network. And there's the problem the optional parameter must setup in the content.json file and this cannot be set by many website owners. If we limit this would be worth measuring for the storage device and warn the user if example want use the 10% of the current site the full storage. \r\n\r\nSee the issues: https://github.com/HelloZeroNet/ZeroNet/issues/2622 , https://github.com/HelloZeroNet/ZeroNet/issues/2566, https://github.com/HelloZeroNet/ZeroNet/issues/2243 , https://github.com/HelloZeroNet/ZeroNet/issues/2602,\r\n", "added": 1603351936, "modified": 1603351936, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/2647#issuecomment-714399728", "source_type": "github"}, {"comment_id": 39, "body": "> \r\n> \r\n> > The line doesn't make any sense, it just causes problems, no matter what the limit is.\r\n> \r\n> I think this only applies to required files, not optional files. I think it's a good idea to make big files optional anyway.\r\n\r\nOptional files are limited to 10MB in the right menu. The option is not even found by most users. Even if they click on it, even files what more than 10 megabytes will not be downloaded. The other problem is that nothing indicates the largest file size on the page. And here the option should be set separately to a higher value what the biggest single optional file size in the zite. There is no automatic way to download the full page in a single zite with all files. If the user set higher limit then 10MB and the files are not optional but larger than 10MB the download just doesn't work again. Optional files also have a preset 10MB limit. Almost no one can use this option. There are few visitors and they can\u2019t use almost any option which is a little more complicated. It\u2019s really not good for the program to decide for itself that, however, it refuses to download large optional files. These preset restrictions they simply prevent you from downloading large files easily. And then there's that site owners need to setup the optional parameters. And not all website owners can do that. In multi user zites like Zero Up if the option are set up there it downloads all user files. All files which is less than 10MB and it can be several terabytes under 10MB files.\r\n\r\n", "added": 1603354862, "modified": 1603354862, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/2647#issuecomment-714424917", "source_type": "github"}, {"comment_id": 40, "body": "imachug your idea to download small parts of everything doesn\u2019t work in practice. All such solutions make the content inaccessible. I say this from experience as zite and file owner. And after years of torrenting, where there is a basis for comparison. The result of all such efforts will be that the content will not be available for the users.\r\n\r\nAllow the increase site limit popup option does not download optional or large files.\r\n\r\nAs zite and file owner I can tell from experience the half-downloaded files an inoperable thing. The single files and downloading just part of a single zite too. If the entire content is not downloaded the are no seeders in single user zites and files too. No one other than the content owner will share the content. It is a waste of resources. In torrent always download all users the entire content. And there is no limit to how big the files or total file size in the torrent can be. The total content size of the website must be showed and who needs to download it, who doesn\u2019t delete it. ZeroNet is a P2P network the user pays to help share the file. That someone downloads a little bit of everything inoperable on such a network. It\u2019s like stealing the content owner who seed the file. There are communities on the network that regularly use specific sites. Casual visitors do not seed the content. Visiting 100 sites a day is not necessarily well-intentioned. There is no need for malicious scanner visitors on the network. And this network was not invented for this. Preset site size limit in MB, does not make sense because it just crash sites. It is worth looking at how much user storage space is available. And to measure that how much space the content takes up. Today there are a lot of big data storage 300GB 500GB already basic in a old pc. 2TB 4TB 10TB are basic in modern PC and 5G are coming.  Limiting files and zites how many MB can be default way are pointless the same limit in a 10GB storage and 10TB storage. Today it is an average website 1-2 GB large, it will be even bigger in the future. Hundreds of megabytes of files 10MB-1,5GB are not uncommon on websites. Everyone wants everything right away. And this is not possible if users download incomplete pages and files. The downside to this is the need for disk space. This can be freed by deleting the files and zites which are not regularly visited. It cannot be based on a clearnet service because there is no stable bandwidth, no 24/7 online users.\r\n", "added": 1603391718, "modified": 1603392323, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/2647#issuecomment-714775619", "source_type": "github"}]}}