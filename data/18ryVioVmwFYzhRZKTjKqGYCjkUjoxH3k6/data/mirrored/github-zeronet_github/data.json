{"cert_user_id": "github-zeronet@github", "next_comment_id": 26, "comment": {"1604066327_mirrored_antilibrary_github": [{"comment_id": 1, "body": "Thanks, @HelloZeroNet , Angular apps can now load (only tested static so far, no AJAX/WebSockets or use of DB).  \r\n\r\nCan you list the security concerns for NOSANDBOX, and why each visitor to the site has to Grant the permission after being prompted with a message suggesting it is \"Dangerous!\"?  If you produce sample code for testing, can you please share that as well to help us test?    \r\n\r\nI saw a few concerns in this thread, but that was before you introduced this solution, so it isn't clear if they are still concerns.  \r\n\r\nI [figured out what this permission does](http://127.0.0.1:43110/1NtQvrYd8rJzQYP3j1snmi28mPn8wSXX4X/?Page:zeronet-design---sandbox) before finding your description here, sadly.  lol    At least I had fun learning.  \r\n  \r\n", "added": 1566173584, "modified": 1566173584, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1262#issuecomment-522395697", "source_type": "github"}, {"comment_id": 2, "body": "TYVM, imachug!  I really appreciate your help here.  \r\n\r\nI'm going to look deeper into this for possible solutions.  Please feel free to share ideas you've looked at and thoughts on why they could or could not work.  \r\n\r\nThe goal here is the ability to securely run common front-ends like Angular, Vue and React to help build the ZN community by attracting the best site developers with the ability to port investment they have made in both code and skills.  \r\n", "added": 1566216822, "modified": 1566216956, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1262#issuecomment-522621872", "source_type": "github"}, {"comment_id": 3, "body": "Do you have the latest py3 in Alt-ZeroNet?  I'd like to test it.  \r\n\r\nHopefully we can develop a security regression test suite at some point with this.   For now, that just means coming up with tests and scenarios. ", "added": 1566234670, "modified": 1566234670, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1262#issuecomment-522734659", "source_type": "github"}, {"comment_id": 4, "body": "> ...you can insert an iframe into your site. \r\n\r\nIf the issue is exposure of commands reserved for the wrapper, how do you secure it if the IFrame is inside the user's pages?  Seems either way, need to reduce commands that can be executed if a site has NOSANDBOX.  No reason such a site needs \"serverShutdown\" or \"configSet\", for instance.  \r\n\r\nIf we go this route, can we leave NOSANDBOX as is and create a new permission, because NOSANDBOX is useful for quick diagnosis.  Once a zite dev determines that resolves their immediate issues, they can then compare a permission that restricts server-side commands, but doesn't require the site user to be prompted, to determine if the restrictions create new issues.  \r\n\r\nThere could be a lot I don't understand, yet.  I'm about to review the request handling code. ", "added": 1566267035, "modified": 1566267990, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1262#issuecomment-522855526", "source_type": "github"}, {"comment_id": 5, "body": "That's a very well thought out design. What would be the ETA before we could test it?    \r\n", "added": 1566294354, "modified": 1566294354, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1262#issuecomment-522997406", "source_type": "github"}], "1604067445_mirrored_ghbjklhv1_github": [{"comment_id": 6, "body": "In zeronet.conf, add:\r\n\r\n> trackers_proxy = tor\r\n> tor = always\r\n\r\nIf [you can get Tor Always to work](http://127.0.0.1:43110/14swNBgrE3cTbreHgTGAYiGRBiPrnFCDJB/?Topic:1565465235_1D9oYXWZH2S55PeoCFDKTqq8roNXqZqP7n/ISSUE+Tor+Always+has+0+peer+connections).  ", "added": 1566051350, "modified": 1566051410, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2147#issuecomment-522254791", "source_type": "github"}, {"comment_id": 7, "body": "> Probably we should ignore the traker_proxy setting in tor=always mode\r\n\r\nI'm looking forward to understanding how Tor is used under the hood, but can only do so much in a day.  \r\n\r\nIn the meantime, I've locked ZN down in a VM that has no way out except through Tor, and in this configuration, it is using Tor Always with trackers_proxy disabled.  This configuration has been running for days, but I don't know if trackers can see the real IP if it wasn't inside this VM. If I'm using Tor Always **without** OS-level protection, how most run it, I'd expect **no tracker or peers can see the real IP**.    \r\n\r\nI just switched to trackers_proxy `tor` inside this VM.  It worked w/o restart. Then restarted to clear any cache.  Hours later, continues to work... no fade.   \r\n\r\nIs `self.ip_type` always \"onion\" when Tor always is enabled?  If not, then [this code](https://github.com/HelloZeroNet/ZeroNet/commit/ab9fe173a830a4341cd126376f3770f981115e84) change seems to disable Tor for trackers if Tor Always is selected, which is the opposite of what users expect and the behavior described in [this comment](https://github.com/HelloZeroNet/ZeroNet/issues/2158#issuecomment-522950968).  \r\n\r\nOr is it that \r\n\r\n```\r\nself.createSocket()\r\n```\r\n\r\nuses Tor in Tor Always mode, and \r\n\r\n```\r\nself.sock = self.server.tor_manager.createSocket(self.ip, self.port)\r\n```\r\nisn't needed?  \r\n\r\nNote that I have the same issue as @HostFat outside the VM, including the fade where it sometimes initially works, and have yet to resolve this.  But, since this works without issue inside this VM, I have to wonder if the problem isn't external configuration, such as firewall rules, or how Tor is configured.  \r\n", "added": 1566522008, "modified": 1566529695, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2147#issuecomment-524163590", "source_type": "github"}], "1604067453_mirrored_github-zeronet_github": [{"comment_id": 8, "body": "Thank you, @HelloZeroNet !  That resolved it.  ", "added": 1566068054, "modified": 1566068054, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2154#issuecomment-522273329", "source_type": "github"}], "1604067485_mirrored_filips123_github": [{"comment_id": 9, "body": "I like the goal of this plugin.  \r\n\r\nAs a user, I'd like to see descriptions for plug-ins.  If it will clearnet, that needs to be clear before a user enables it.  Ideally, a list of user-configurable sites it communicates with. \r\n", "added": 1566489793, "modified": 1566489793, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/2164#issuecomment-524035165", "source_type": "github"}], "1604067545_mirrored_imachug_github": [{"comment_id": 10, "body": "Nice presentation.  Very hard to get your head around without something to kick the tires on.  Hopefully it won't take much effort to get make the concept testable enough to validate it doesn't break apps or core ZN functionality like the side bar.  \r\n\r\nDoes this impact the URL at all?  Currently, the Angular app needs to set the base href so references work.  Otherwise, they try to access content from the root.  e.g., \"/site.css\".  \r\n\r\n<base href=\"/1HeLLo4uzjaLetFx6NH3PMwFP3qbRbTf3D/\">\r\n\r\nIn reality, it needs to do some parsing of the URL so you don't have to hard code the site address.  There is a current issue right now with .bit domains that I haven't tested with an app because I don't have a .bit domain.  I just know it is an issue today with relative referencing.  \r\n\r\nIt's not clear if this prefix concept in the DOM can have an impact today.  One thing that makes this challenging to predict up-front is you can't realistically know what all the third party libraries are doing in a Node-based app until you see an error.  You have the core ones used to build a basic Angular, React or Vue app, then you have a bunch more you add for app functionality (such as charting).  Later, we upgrade these, hoping they don't break.  \r\n\r\nWhat's the minimal you can do (time wise) to be able to have a branch where we can test the **highest risk portions** of the design, such as the new PREFIX (shadow DOM)?  It doesn't have to do everything or provide new functionality.  And, for testing, can still rely on NOSANDBOX, so long as it provides a way to test new scenarios.  Just need to see validate it doesn't breaks apps.  \r\n\r\n\r\n\r\n\r\n", "added": 1566356368, "modified": 1566356368, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-523309100", "source_type": "github"}, {"comment_id": 11, "body": "> > What's the minimal you can do (time wise) to be able to have a branch where we can test the highest risk portions of the design, such as the new PREFIX (shadow DOM)?\r\n> \r\n> If you're asking for a high-risk PoC (meaning unsafe, i.e. can be abused by sites), it'll probably be finished today (it's 9am for me). By now, ZeroTalk, static sites, ZeroSites and ZeroHello all _mostly_ work (except localStorage stuff and such).\r\n\r\nOne of the most useful steps I've learned to do in projects early is test high risks.  A high risk is any **threat to the success of the project**.  We begin by listing all risks, rating them High, Medium, Low, then focusing on mitigating High risks in the next step.  Your goal is to at least lower to Medium.  \r\n\r\nTypically, a risk is high because there are unknowns.  You may be including a new third party library, and don't know if this library will work because you've never used it before.  \r\n\r\nTo mitigate, you test it to verify assumptions, bringing the risk down to Med, Low or None, because you can at least verify that the library meets core assumptions of functionality. \r\n\r\nYour goal is to eliminate all high level risk with minimal effort ASAP, before spending a lot of time on the project.  What you don't want to do is spend 6 weeks developing something only to run into a show stopper or reason others can't use your project, when you could of identified it up-front with a little bit of test code.  \r\n \r\nObviously, if you have major security concerns, they could be a high level risks, too, because they can doom the project if you can't find a resolution.  But, in the case of what you're testing, a high level risk is that the shadow DOM breaks the types of applications you are trying to enable with this project.  \r\n\r\nSo, you'd want to create a test, as easy and minimal as possible, that allows us to then test the Angular 8 app I created.  That is why this test can still run it under NOSANDBOX, because this isn't production code.  Its purpose is only to prove that the shadow DOM isn't a show stopper.  \r\n\r\nThe code can be throw-away solely for the purpose of the test (testing a 3rd party library), or it can be code ultimately used in the project.  \r\n\r\n\r\n\r\n\r\n", "added": 1566517352, "modified": 1566517352, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524150616", "source_type": "github"}, {"comment_id": 12, "body": "TOTALLY OFFTOPIC:\r\n@HelloZeroNet Can you check out [this thread](http://127.0.0.1:43110/1HMLvnRWViMnuvZc5LK4Dm86sZNcSH1jdh/?Topic:1566424248_1D9oYXWZH2S55PeoCFDKTqq8roNXqZqP7n/ZeroNet+Decentralized+Development+Roadmap) in UNLIMIT TALK, please?  (not sure how best to reach you).  \r\nCan you clone ZT Talk into a new \"ZeroNet Development\" ZT with high user limits like UNLIMIT TALK, or give me or imachug the your blessing to do so?", "added": 1566517597, "modified": 1566517782, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524151385", "source_type": "github"}, {"comment_id": 13, "body": "> I've noticed that a lot of wrapper code uses jQuery. We probably don't want to pollute sites' environment, so I'm trying to port as much code as possible to Vanilla JS.\r\n\r\nI can't speak to React or Vue, but I can say that \r\n- Angular gets rid of most, but not all, needs for jQuery.\r\n- It is not used in the test app I am using to test ZN. \r\n- I have used it inside Angular, but suspect that was because I didn't understand Angular enough when I started.  I'm about to rewrite that app's UI, so will find out soon.  :)\r\n\r\n", "added": 1566518580, "modified": 1566518813, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524154424", "source_type": "github"}, {"comment_id": 14, "body": "In order to get Angular working, I have to include:\r\n```\r\n<script>document.write('<base href=\"' + document.location + '\" />');</script>\r\n```\r\nwhich effectively becomes the site's base (which works if you could hard code the site address, which isn't practical):\r\n\r\n```\r\n<base href=\"/1Gtzk5w72SmSx7GW6Y1JaGLgPfkXH2Wanz/\">\r\n```\r\n\r\nor, if I inspect it:\r\n\r\n```\r\n<base href=\"http://127.0.0.1:43110/1Gtzk5w72SmSx7GW6Y1JaGLgPfkXH2Wanz/?wrapper_nonce=a23982da7c19577d48c588e311f256b5a272db7bd0dc13212555479a0e5594f0\">\r\n```\r\nI don't know much about locking down accessing outside this because until ZN, I've always assumed the browser is insecure and relied 100% on server-side for security, tokenizing the UI with cookies and AJAX/WebSockets.  Obviously, ZN is unique in this respect.  \r\n\r\nI'm just wondering if the \"base href\" can play a role in helping you lock down a site.  You probably already dismissed it with good reason.  :)  \r\n", "added": 1566520069, "modified": 1566521344, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524158467", "source_type": "github"}, {"comment_id": 15, "body": "imachug, how could you change DNS server just for ZN without impacting other tabs, sites, browsers, app, OS?  I'd at least try to limit scope of this to the current running browser.  \r\n\r\nI can see how that would solve this problem if every site had a unique host.  I'm just not aware of ability to scope DNS to a tab, window or the browser.  I'd love to know if there is a way.  \r\n\r\nHow do subdomains play a role in all this?  Because it would be easier to minimize DNS issues if <site_address>.zeronet.xyz solved all your problems, because then you would wildcard that to 127.0.0.1.  Though, that could introduce issues with relays, and I'm not sure where this wildcarding could occur.   The challenge here is that it needs to happen in browser, so rules out URL rewriting like what Apache does, unless you get into redirects.  Redirects could be a component of your answer because it can provide backward compatibility.  e.g., \r\n\r\n127.0.0.1/<stie_address>\r\n\r\nredirects to \r\n\r\n<site_address>.zeronet.TLD\r\n\r\nIf subdomains don't work, if you are hacking DNS, then might as well consider \"zeronet\" as a TLD:\r\n\r\n<site_address>.zeronet\r\n\r\nSome of us use very complex DNS setups, and doing at OS level, among other things, prevents a user from running their own DNS or doing special configurations (e.g., other software that also extends DNS). \r\n\r\nOf course, you can solve all this if you require ZN to run by itself in a VM, and Docker could end up being the way to go if you must use port 53.  But, today, that's a lot to ask of users today.  What about mobile or light weight mesh?  It would be really nice if Docker ran in Android and you could run BIND in that. That would be a game changer!\r\n\r\nI do see that FF has a new feature where you could plug in the URL of a DNS server.  If it supports https, then it might work with HTTP and any port, avoiding conflicts with port 53:\r\n\r\nhttps://www.ghacks.net/2018/04/02/configure-dns-over-https-in-firefox/\r\n\r\nYou could test this with netcat to validate it works with any port you give it.  But, it may still require TLS.  It gets more complicated as you add support for other browsers.  But, since Tor Browser is built on FF, and I've seen many posts saying \"use FF!\", I suspect FF covers a lot of user base. \r\n\r\nAre you using a new wrapper template and tying that to a new site permission to provide backward comparability?  If so, then what I'd do for a site that required this DNS config in FF is have a fallback legacy style site it redirects to if I could detect the user doesn't not meet requirements, where I'd have instructions (use FF, configure about:config, etc,...), then a link to new site.  You'd still have to throw in something like [this](https://gist.github.com/andreif/6069838).  \r\n\r\nThis isn't ideal.  But, if you're backed into a corner, you hopefully this gives you options.    ", "added": 1566559527, "modified": 1566561851, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524335639", "source_type": "github"}, {"comment_id": 16, "body": "imachug, I understood when I responded that you were describing setting up a DNS server on port 53 at the OS level that would intercept and pass all other requests to another DNS server.  \r\n\r\nI'd never run it.  Here is why:\r\n- I've gone through great lengths to lock down DNS security.  And now you want to throw another piece of software on it and I'd have to let all my traffic on my machine run through it?  BIND has extensive peer review for security, that nothing we create can come close to.  \r\n- I already use DNS servers on port 53 to do my own configuration.  So, how can I run BIND and your DNS server on the same machine on port 53? \r\n\r\nThat said, I'm OK with localizing DNS functionality to ZN, and if need be, a single browser instance, because I can always run other browsers for other functions knowing they are not vulnerable or restricted in any way.  \r\n\r\nDNS is growing in complications as people continue to innovate and solve new problems, as evidenced by the growth in BIND plug-ins to add functionality and solve interesting problems.  You really don't want to be responsible for all the DNS on a person's machine.  \r\n\r\nThe only way I'd consider running a dedicated ZN DNS service on port 53 is in Docker or a VM where ZN is inside the container.  I'd never run it on any host where I do anything other than ZN. \r\n  \r\n", "added": 1566568432, "modified": 1566568888, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524387033", "source_type": "github"}, {"comment_id": 17, "body": "> > How do subdomains play a role in all this? Because it would be easier to minimize DNS issues if <site_address>.zeronet.xyz solved all your problems, because then you would wildcard that to 127.0.0.1.\r\n> \r\n> Using subdomains was the first thing I considered, but Linux & MacOS (not sure about Windows though) don't understand wildcards in /etc/hosts.\r\n\r\nSetting aside IP resolution, does it solve the problems in the browser, such as local storage?  \r\n\r\n> \r\n> > The challenge here is that it needs to happen in browser, so rules out URL rewriting like what Apache does, unless you get into redirects.\r\n\r\n> > Some of us use very complex DNS setups, and doing at OS level, among other things, prevents a user from running their own DNS or doing special configurations (e.g., other software that also extends DNS).\r\n\r\n> > Are you using a new wrapper template and tying that to a new site permission to provide backward comparability?\r\n> \r\n> Nope, the new prefix way must be the default one and should be the only one.\r\n\r\nWhy?  Maybe in the end it will be.  Yet, why close doors that could be opened with backward compatibility and a migration path that includes beta testing.  ", "added": 1566568741, "modified": 1566568741, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524388695", "source_type": "github"}, {"comment_id": 18, "body": "> I don't see any solution so far. Anyone with a fresh idea?\r\n\r\nDid you look at this part of my post:\r\n\r\n> https://www.ghacks.net/2018/04/02/configure-dns-over-https-in-firefox/\r\n\r\n> You could test this with netcat to validate it works with any port you give it. But, it may still require TLS. \r\n\r\nThis is a solution I'd be comfortable with as an end-user.  DNS would be inside ZN, on any port you gave it, but not 53.  **It would be local to only that browser instance**, containing the security risk. \r\n\r\nIt would be easy to do a quick test with `netcat` to verify if it requires SSL (by redirecting to a non-SSL DNS) and can be pointed to any port (if it resolves successfully) since you'd use netcat to listen on a port like 43900 and point to that. \r\n\r\nIf this does work, you may be able to create a simple FF plug-in for users to make it easy for them.  \r\n \r\nWould you like me to test that or would you like to test it?\r\n\r\n\r\n\r\n", "added": 1566569520, "modified": 1566570436, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524392700", "source_type": "github"}, {"comment_id": 19, "body": "> @imachug Are wildcard certificates really such problem? Hostname solution currently seems the best solution.\r\n> \r\n> For local ZeroNet instance, we could use `talk.zeronetwoek.bit.zeronet`. for proxy,\r\n\r\nPersonally, I haven't been a fan of .bit domains and its reliance on namecoin.  But, I do respect other's opinions on it and wouldn't want to break compatibility for them.  \r\n\r\nI do prefer the idea of a .zeronet (or similar) TLD.  If we are going to intercept all ZN DNS requests, we can implement that however we want.  The sky is the limit.  \r\n\r\n@imachug I do like where you were going with DNS.  I only oppose listening on port 53 of the host machine.  I think having a ZN DNS opens a lot of doors, otherwise.  \r\n\r\n:github-zeronet hands @imachug a frosty beer:  :)\r\n", "added": 1566570025, "modified": 1566571125, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524395245", "source_type": "github"}, {"comment_id": 20, "body": "> @KilowattJunkie \r\n\r\nI'm not sure we're all on the same page, yet because there is a lot to digest here.  I like Imachug's idea of some DNS layer not only because it helps solve some problems we're talking which has a greater purpose of allowing more portability of apps built with Angular, React and Vue, you have to keep in mind this reality today:\r\n\r\n- the browser only sees one domain ever:  127.0.0.1, or....\r\n- the browser sees the domain of the relay: myzeronetrelay.xyz\r\n\r\nLocal communications do not need SSL in the browser.  The only really good browser use case for it today is from browser to relay.  \r\n\r\nThe relays always have the option of using traditional HTTP servers such as Apache or nginx as a proxy, which can handle SSL and do any desired URL rewriting before passing to ZN.  \r\n\r\nSo, what we're looking at is a very minimally intrusive DNS that ZN can own solely for handling the 127.0.0.1 calls.  If we could scope it to 127.0.0.1:43110, we would.  But, at least we found a way to limit the scope to a browser instance.  So, you could configure your Tor Browser to use it, and all your other browsers and applications would still avoid the ZN DNS.  \r\n\r\nBecause the only host we're handling is 127.0.0.1 (setting aside relays not using a reverse proxy), it makes sense to actually allow a DNS layer here, where:\r\n\r\n<my_site>.zero\r\n\r\nresolves to 127.0.0.1 addresses, but the browser will see it as unique host for the purposes of this thread, securing zeronet while allowing it to do what is needed to run vast more web apps.  \r\n\r\nAnd since they would all point to 127.0.0.1, the benefits of a regular DNS server don't really help anyone today, except, of course, the host name of the relay on the Internet.  \r\n\r\nHaving a ZN DNS means we can actually do some creative things here.  Whereas sites have no real ability to use CNames or any other DNS functionality with their sites today, the site's content.json could include the equivalent of a ZN DNS zone record.  Can you see where this can go?\r\n\r\nI agree 100% with all your DNS security concerns, which is why this needs to be as localized as possible.  For now, we found a way to limit it to a single browser instance that we hope can work.  If we can find a way to narrow the scope further, then great.  I'm all for it.   \r\n\r\nJust keep in mind our greater goal here is to enable a broader range of sites to be able to run on ZN that cannot run on it today without serious security concerns (by disabling the IFrame sandbox).  This requires balancing competing ideals. \r\n \r\nTo be sure, even if we conclude this can work locally, we still have to evaluate the impact to relays.  \r\n", "added": 1566574504, "modified": 1566575072, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524418954", "source_type": "github"}, {"comment_id": 21, "body": "> @github-zeronet Yeah we might not be on the same page due to my admittedly poor understanding of how the current system works ...\r\n\r\nNot noise at all.  I love diverse perspectives in a complex conversation.  Your understanding of DNS is good, and that does count.  \r\n\r\n", "added": 1566577554, "modified": 1566577554, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524434182", "source_type": "github"}, {"comment_id": 22, "body": "@filips123\r\n\r\nI like to look at what can be done before discussing what should be done.  we didn't get far enough to talk about all the incredible things that can be done with a ZN DNS: site configuration, domain issuance, DNS like functionality like CNAME and MX if we can ever introduce ZN SMTP, etc,...  \r\n\r\n@imachug did a great job at looking at possibilities!  We may put ZN DNS on a side burner for now, but I'll be thinking about all the incredible possibilities in the meantime thanks to imachug's imagination.  \r\n\r\nAs for relays, I think ultimately we can package nginx or httpd in a Docker with ZN to make deployment very easy, providing any out-of-the-box reverse proxy and URL rewriting config needed.  This also allows it to be deployed on more platforms.  \r\n", "added": 1566582771, "modified": 1566583113, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524458562", "source_type": "github"}, {"comment_id": 23, "body": "At the end of the day, we need [1000 developers](http://127.0.0.1:43110/1HMLvnRWViMnuvZc5LK4Dm86sZNcSH1jdh/?Topic:1566424248_1D9oYXWZH2S55PeoCFDKTqq8roNXqZqP7n/ZeroNet+Decentralized+Development+Roadmap)!  lol", "added": 1566583330, "modified": 1566583330, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524461202", "source_type": "github"}, {"comment_id": 24, "body": "> @filips123 ... requiring user to use Docker isn't good. Docker could be hard to install, specially on Windows, where, if you don't have Pro versions, you have to install both VirtualBox and Docker Toolbox.\r\n\r\nThis was just to make **installing relays easier**.  Not for normal users.  Not a requirement for anyone.  Who in their right mind would run a Relay on Windows, anyway?  lol   \r\n", "added": 1566678236, "modified": 1566678283, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524587776", "source_type": "github"}, {"comment_id": 25, "body": "> If the solutions are about the same, I'd use proxy: it looks like it's easier to install and can be easily set per-browser (instead of at OS level).\r\n\r\nThat was all potential future state if we had ZN DNS.  Not needed at all for our current feature.  \r\n\r\nIf I understand ZeroMailProxy, its purpose is to allow a client, such as Thunderbird, to send/receive email for you through the equiv of the ZeroMail site via SMTP/POP3 protocols.  Correct?  \r\n\r\nZeroMail is a nice temporary way to solve a problem.  It has limitations preventing it from being a long-term solution in its current state.  I'm thinking more from a blank slate how to send email in a decentralized way with ZeroNet as the backbone.  \r\n\r\nOFFTOPIC: POSSIBLE FUTURE ZERONET DNS/SMTP\r\n\r\nSo, let's say I own the \"safemail.yu\" ZN domain.  I'd want a way that people could send email to its users, like \"tom@safemail.yu\".  But, the sender should not have to have a user account on that domain.  So, I'd provide an ZN SMTP server at a site address they could use to route email to those users.  The DNS record would provide an MX record pointing to that site.   I'm basically pondering how this could be done on ZN, w/o clearnet.  \r\n\r\nAny domain owner would have the ability to setup an email server (special type of site) that its users could receive email to (with its own storage and other rules).  Anyone would be able to send email to these users, even if they did not create a user at that domain.  \r\n\r\nThere's a lot more going on in my head, such as offline mesh networks with intermittent connectivity to the Internet, apps to people, apps to apps, people to apps communications in addition to people to people, decentralized autonomous message storage (in this case, the owner of a SMTP relay would control storage, forwarding and other policies for their domain, and not rely on limitations of ZeroMail.)", "added": 1566680893, "modified": 1566733902, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2169#issuecomment-524589533", "source_type": "github"}]}, "next_topic_id": 2, "topic": [{"topic_id": 1604067453, "title": "Allow a site to bust out of IFrame", "body": "**Is your feature request related to a problem? Please describe.**\r\n\r\nThe types of sites we can create is very limited today by CORS and IFrame limitations.  \r\n\r\n**Describe the solution you'd like**\r\nAllow sites the option to be served outside of IFrame. \r\n\r\nI realize the first reaction will be security concerns.  But, keep in mind, this is only for site owners choosing to do this.  By default, sites will continue to operate under the IFrame.  \r\n\r\nI don't understand the concerns about file access because these files are all viewable and editable by any user via their file system.  You would want to enforce directory traversal protections, of course.  And you can, if needed, refactor it so the site's static content is in a folder inside the base site folder.  If a browser has no way to traverse to parent folders, then only the static content can be accessed.  \r\n\r\nAs for API limitations, perhaps there is a happy way to put the IFrame inside the site, instead of outside, perhaps with a tag the server can recognize and replace.  \r\n\r\nWe could have a permission on content.json that allows a site to be served without the IFrame being wrapped around it, but allows a tag inside the site's content that can be replaced by NZ with the IFrame.\r\n\r\n**Describe alternatives you've considered**\r\nAnything and everything that solves CORS and IFrame issues.  \r\n\r\n**Additional context**\r\nThere is no known way to get a simple static Angular 8 site up and running in ZN due to the limitations of the IFrame.  The demo site works without an issue in Apache HTTPD.  \r\n\r\nHere is documentation in ZN of that test and the resulting issues:  \r\n\r\n[Testing a static Angular site in ZeroNet](http://127.0.0.1:43110/1KmgpXc9BLFxw1ccGANYVzvDh3YG95tSe3/?Topic:1565993644_1D9oYXWZH2S55PeoCFDKTqq8roNXqZqP7n/Testing+a+static+Angular+site+in+ZeroNet)\r\n\r\n... for the ZeroNet ecosystem!  ", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1566047367, "modified": 1566119729, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2154", "source_type": "github"}]}