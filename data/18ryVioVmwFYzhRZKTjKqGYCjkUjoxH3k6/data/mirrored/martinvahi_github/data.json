{"cert_user_id": "martinvahi@github", "next_comment_id": 16, "comment": {"1604064980_mirrored_HelloZeroNet_github": [{"comment_id": 1, "body": "> the files are hashed using sha512, which is not-colliding (yet)\r\n\r\nI understand that this bug report is closed, but for future developments I mention that \r\none way to alleviate the situation is to concatenate hashes of multiple hash algorithms\r\nthat are supported by \"standard\" tools like [rhash](https://sourceforge.net/projects/rhash/) or\r\n[tigerdeep](https://linux.die.net/man/1/tigerdeep) or [whirlpooldeep](https://linux.die.net/man/1/whirlpooldeep). To make parsing easier, the different hashes\r\ncan be marked with some character that is not part of the HEX digits. For example, \r\nTiger hash might be marked with \"t\" and Whirlpool hash might be marked with \"w\".\r\n\r\n    //The idea:\r\n    s_hash=\"w\"+whirlpool_hash(data)+\"_t\"+tiger_hash(data)\r\n\r\nRelational database indexes work more efficiently, if the distribution of characters \r\nat the start of the strings that are stored at the indexed columns is a uniform distribution.\r\nAs the head side of the \r\n\r\n    s_hash=\"w\"+whirlpool_hash(data)+\"_t\"+tiger_hash(data)\r\n\r\nis very non-random, namely, it consists of \"w\", and the tail side of the s_hash is very random,\r\ncontaining hex characters of the Tiger hash, then it makes sense to use a version of the\r\ns_hash, where the order of s_hash characters has been reversed.\r\n\r\n    s_hash_reversed=reverse_char_order(s_hash)  #   \"abcde\"  -->  \"edcba\"\r\n\r\nAs of 2016 the maximum file name length on Linux is [255 characters](http://unix.stackexchange.com/questions/32795/what-is-the-maximum-allowed-filename-and-folder-size-with-ecryptfs).\r\n\r\nThank You for reading my comment :-)", "added": 1518493505, "modified": 1518493873, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/163#issuecomment-365166686", "source_type": "github"}], "1604066238_mirrored_martinvahi_github": [{"comment_id": 2, "body": "I do not know, how exactly You tend/prefer to work with JavaScript code, but \r\nI have some JavaScript experience from AN ERA, WHEN THERE WERE\r\nNO FANCY DEBUGGERS embedded to web browsers, specially the \r\nnasty Microsoft Internet Explorer. To cope with the situation, I came up\r\nwith a solution, where I wrapped the bodies of ALL FUNCTIONS of \r\nMY JavaScript LIBRARY into a try-catch clauses and \r\nat the catch side I threw an exception that contained a GUID as part of the \r\nerror message. Each error message had its own GUID that was unique\r\nwithin the whole project.\r\n\r\nTo the start of the function body I placed tests, input verification,\r\nthat can be partly disabled in production, but that thoroughly\r\nCHECKED EVERYTHING that I was able to think of at that code region, \r\nWITHOUT WORRYING ABOUT PERFORMANCE, because \r\nmost of the thorough tests were enabled at debug mode only.\r\nStyle example:\r\n\r\nhttps://github.com/martinvahi/raudrohi/blob/master/src/devel/raudrohi_lang.js#L321\r\n\r\nThat way, if the JavaScript crashed or had errors, then \r\nI would have a stack trace of GUIDs at the web browser's \r\nJavaScript console. To work with that \"stack trace\", I created\r\na plugin/tool for the KomodoEdit \r\n\r\nhttps://www.activestate.com/komodo-edit\r\n\r\nhttps://github.com/martinvahi/mmmv_devel_tools/tree/master/src/mmmv_devel_tools/GUID_trace/src/JumpGUID/src/IDE_drivers/www_openkomodo_com/v_8_0_0\r\n\r\nI don't remember everything exactly any more, but the work\r\nprocess was that I manually copy-pasted the \r\n\"stacktrace\" of GUIDS from the JavaScript console of the\r\nweb browser to a text file, which was parsed by the KomodEdit\r\ntool/plugin and I was literally able to move up and down within the\r\nstack trace of GUIDs so that at a push of an arrow key or\r\nan arrow key replacement key combination \r\non my keyboard the \"cursor\" within the stack of GUIDs moved\r\nand at every move the KomodoEdit opened the file and line\r\nof the development JavaScript file, where the GUID resided.\r\n\r\nBasically, the result was that I had an interactive debugger \r\nlike experience, except that I was able to move both directions,\r\nforwards and backwards, in stead of single lines my \"step size\" was\r\none function and in stead of just seeing the code, I was able\r\nto directly EDIT the DEVELOPMENT SOURCE. \r\n\r\nThe beauty of such a solution is that if the JavaScript is minimized\r\nor I get a stack trace of GUIDs from the client's computer, then \r\nI can debug and look at the situation at my own computer, calmly, \r\nat my own pace. Another beauty of that solution is that the \r\nsolution is totally PROGRAMMING LANGUAGE AGNOSTIC.\r\nIf all of my source codes have unique GUIDs at all error messages, \r\nat all projects that I have ever done, then I can create a folder that\r\ncontains symbolic links to the source of all of my projects and then\r\ngrep the GUID from that folder. The GUIDs are unique without \r\nmuch effort: I just copy-paste the code/text with some existing GUID\r\nand then run \r\n\r\nhttps://github.com/martinvahi/mmmv_devel_tools/blob/master/src/mmmv_devel_tools/GUID_trace/src/UpGUID/COMMENTS.txt\r\n\r\nAgain, I have that tool integrated to my IDE scripts/settings, Vim, JetBrains, etc.\r\nSo all it takes, if the environment has been properly set up, is one key combination\r\nand the tool updates all GUIDs by using regexes and some other tricks that\r\nare described at:\r\n\r\nhttps://github.com/martinvahi/mmmv_devel_tools/blob/master/src/bonnet/lib/kibuvits_ruby_library/src/include/kibuvits_str.rb#L492\r\n\r\nid est using only regex is not safe enough.\r\nAnother thing that helps with JavaScript is \r\nsome form of JavaScript console. I have used \r\n\r\nhttps://yuilibrary.com/yui/docs/console/\r\n\r\nBut, of course, it's easy for me to speak here. Actually, \r\nwhat regards to user interfaces, then I currently do not\r\nhave proper, usable, JavaScript code to offer, but \r\nmy JavaScript project took place so early that I did not \r\nhave the opportunity to download the various fancy \r\nJavaScript widget libraries, so I had to develop my own.\r\nAnd I did. The code is an old, unusable mess\r\nhttps://technology.softf1.com/raudrohi/2013/09_04_v_25/\r\n(I have an upgraded, but unfinished, unpublished version @ my computer)\r\nbut I did get the architecture right, after a lot of tedious work\r\nand I tried to document it by writing a cleaner version of the ideas to:\r\n\r\nhttps://longterm.softf1.com/specifications/rastclsp_t1/\r\n\r\nI'm not aware that any other widget library has that kind of an architecture.\r\nThe main benefit of it is that it moves a lot of the code from the\r\napplication code to the library(read: reusable) code region and \r\nthat a widget is a CONTAINER that does not need a graphical \r\nrepresentation. Widgets MAY have a graphical representation, but\r\nmenus might be also sound menus, like the ones at phone services.\r\nThat spec is a result of multiple projects. The earliest of them was\r\nnot even JavaScript, but one client/paid project that was written in Java. \r\nWell, one way or the other, I currently do not have any code to offer that\r\nworks with that spec, but the implementation of that spec, mainly in the \r\nform of my Raudrohi JavaScript library upgrade, is my next step at the \r\n(proper) GUI front.\r\n\r\nThe reason I write all of that here is to offer You some inspiration. \r\nI've been in trouble with the JavaScript myself and may be at least\r\nsome of my old JavaScript development tools and methods will help You.\r\n\r\nThank You for reading my comment.", "added": 1511976247, "modified": 1511976585, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1194#issuecomment-347984981", "source_type": "github"}, {"comment_id": 3, "body": "> Now almost 2018 and they do not support WebGL\r\n\r\nThe WebGL depends on GPU, which is accessible to browsers only, if there are \r\n\r\n    DRIVERS!!!!!!!\r\n\r\navailable for the GPU on a\r\n\r\n    GIVEN OPERATING SYSTEM!!!\r\n\r\nthat has been ported to a \r\n\r\n    GIVEN HARDWARE!!!!\r\n\r\nThe rest of the contemplation is about what is the design philosophy of the ZeroNet. For example, one philosophical aspect of the ZeroNet is the choice, whether ZeroNet documents, forums, blogs, should be visible 100 years from now, like the text documents from the 80-ties are readable with year 2017 computers and like HTML-pages from the 90-ties are visible at the \r\n\r\nhttps://archive.org/\r\n\r\nor is it OK for the ZeroNet to be like the Java Applets based web pages that are impossible to use/see in 2017, because Java Applets are de facto not supported by 2017 web browsers, despite all the advances in hardware. So far the 3D technologies for the web browsers have a \r\n\r\n    TRULY BAD TRACK RECORD.\r\n\r\nApart from fancier rendering, the 2017 3D web technologies, the \r\n\r\nhttps://www.x3dom.org/\r\nand the \r\nhttps://www.khronos.org/webgl/\r\n\r\ndo not offer absolutely ANYTHING NEW. I have not noticed anything substantial that the Java Applets 3D capabilities or the VRML did not offer. The VRML demonstrated that it is not enough for the technology to be totally open, in a form of an open standard that is supported by MULTIPLE INDEPENDENT COMPANIES. I repeat: an open standard and a multitude of independent money streams from multiple companies DID NOT SAVE THE VRML. The 2017 3D web technologies, \r\n\r\nthe \r\nhttps://www.x3dom.org/\r\nand the \r\nhttps://www.khronos.org/webgl/\r\n\r\ncompete with each other and they do not have the freelancer based developer community to keep them from the same faith that the VRML had. In another words, money is not going to solve it, money DID NOT SAVE THE VRML, because the availability of money IS ALWAYS TEMPORARY. The moment Google Chrome and Mozilla, which are both corporate projects with HUGE money streams, dump the browser 3D support, just like they both dumped the Java Applets, the WebGL and the x3dom will be in the history trash can, right next to the VRML and the Java Applets and the Microsoft Silverlight and the Adobe Flash. Making 3D acceleration a  dependency for the ZeroNet GUI makes the ZeroNet GUI less portable and risks with making the ZeroNet GUI unavailable in the future. Examples of operating systems that do not have a proper set of 3D drivers:\r\n\r\n* The OpenSolaris forks: https://wiki.illumos.org/display/illumos/illumos+Home\r\n* https://www.dragonflybsd.org/\r\n* http://www.openbsd.org/\r\n* http://minix3.org/ \r\n* Probably also the https://www.haiku-os.org/\r\n* I do not know for sure, but I would not bet that the ReactOS has a proper set of 3D drivers: http://www.reactos.com/\r\n* https://www.gnu.org/s/hurd/hurd.html\r\n* http://www.vitanuova.com/inferno/screenshots.html\r\n\r\nAn example of hardware that has a thoroughly documented GPU, but lacks proper 3D drivers, is the Raspberry Pi:\r\n\r\nhttp://www.raspberryconnect.com/gamessoftware/item/314-trying_out_opengl_on_raspberry_pi_3\r\n\r\nhttps://www.raspberrypi.org/documentation/hardware/raspberrypi/\r\n(Raspberry Pi 3 GPU is the same as Raspberry Pi B+ GPU)\r\n\r\nThere are a lot of Raspberry Pi clones, competitors, just like the former IBM PC had clones that ultimately took over the market. Those clones might have very different GPUs and a very varying level of 3D driver support. The most exhaustive list of Raspberry Pi competitors that I'm aware of, is:\r\n\r\nhttps://www.board-db.org/\r\n\r\nbut some most prominent competitors are:\r\n\r\nhttp://beagleboard.org/\r\nhttp://www.orangepi.org/\r\nhttp://www.banana-pi.org/\r\nhttp://www.marsboard.com/\r\nhttp://cubieboard.org/\r\nORDROID: http://www.hardkernel.com/main/main.php\r\nhttps://www.pine64.org/\r\nhttps://getchip.com/\r\nRiotBoard: https://www.element14.com/community/community/designcenter/single-board-computers/riotboard\r\n\r\nThe Raspberry Pi like computers are specially relevant due to the fact that the Intel and AMD have formed a cartel that holds monopoly not by free market rules, but by LAWYERS. The 386 CPU patents have expired, but generally speaking, with a few small exceptions like the Via Technologies, nobody is allowed to create or even emulate x86 CPUs, although, Microsoft with its cloud services probably gives it a try:\r\n\r\nhttps://www.theregister.co.uk/2017/06/09/intel_sends_arm_a_shot_across_bow/\r\n(archival copy: https://archive.is/chFKb )\r\n\r\nNot only does the Intel-AMD cartel have a lawyers based monopoly, but, as with all monopolistic vendors, they do not work on the quality of their products, preferring cutting production costs to doing a proper job. In the case of the Intel and AMD the quality problems are in the form of security problems, which are partly described at the links of my forum post at\r\n\r\nhttps://groups.google.com/forum/#!topic/minix3/WhTHQX6f9VM\r\n(archival copy: https://archive.is/q06qT )\r\n\r\nThat is to say, the Raspberry Pi like computers ARE VERY IMPORTANT COMPETITORS that MUST BE SUPPORTED and as long as there is no \"generic 3D hardware\" interface, like there is \"generic VGA hardware\" interface, the Raspberry Pi like computers will probably lack proper 3D support even if they have openly and properly documented GPUs.\r\n\r\nThank You for reading my post.\r\n", "added": 1512449441, "modified": 1512449623, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1194#issuecomment-349223609", "source_type": "github"}], "1604066296_mirrored_elliekeli_github": [{"comment_id": 4, "body": "If revision 3703 that is published at the ZeroNet GitHub trunk on 2018_11_08 (commit comment: \"Rev3703\") is OK for You and You are willing to out-comment 3 lines as shown at the screen video with Estonian comments\r\n\r\nhttps://technology.softf1.com/software_by_third_parties/ZeroNet/2019_11_24_initially_failing_and_Ctrl-c-killed_unprepared_Estonian_demo_t1_how_to_get_the_2018_11_08_ZeroNet_Rev3703_mmmv_repackaging_t1_to_run_on_Windows10_Linux_layer.webm\r\n\r\nthen You may use my repackaged version \r\n\r\nhttps://technology.softf1.com/software_by_third_parties/ZeroNet/\r\n\r\non Windows10 with the  \"Windows Subsystem for Linux\", \r\n\r\nhttps://docs.microsoft.com/en-us/windows/wsl/faq\r\n\r\nDebian distribution. The ZeroNet code at my package is unmodified, You may just clone the original source from the ZeroNet GitHub repository, revert to the given version and recursively diff. What I did was just write 3 Bash scripts, the ones at the root folder and, well, if You read the 3 Bash scripts, You'll see it all. With some hick-ups it does work on Windows10, as shown at the screen video.", "added": 1575064623, "modified": 1575064623, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1241#issuecomment-559900874", "source_type": "github"}], "1604066389_mirrored_HelloZeroNet_github": [{"comment_id": 5, "body": "Heaven forbid, AVOID THE PROOF-OF-WORK algorithm!!!!!!\r\nIsn't the Bitcoin already contributing enough to the global warming?\r\nDetails are described at \r\nhttp://fouryears.eu/2017/07/09/the-blockchain-consensus-problem/\r\n([archival copy](https://archive.is/gN70g))\r\n", "added": 1518528130, "modified": 1518528130, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1258#issuecomment-365318910", "source_type": "github"}, {"comment_id": 6, "body": "> Do you have a saver Proof-Of... wich is as secure as ...work?\r\n\r\nI believe that if I, or You, @6543, modified the idea that I have described at \r\nhttps://www.softf1.com/cgi-bin/tree1/technology/flaws/silktorrent.bash/wiki?name=Experiment:+mmmv_symsig_t1\r\n_([archival copy](https://archive.is/OcA2h))_\r\nthen that might work.", "added": 1519327249, "modified": 1519327249, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1258#issuecomment-367842394", "source_type": "github"}, {"comment_id": 7, "body": "For the sake of contemplation, suppose we have a \r\n**MAGICAL BLACK BOX** _(does not exist in reality)_\r\nthat is \r\n**RELIABLY ALWAYS ACCESSIBLE TO EVERYBODY** _(an oxymoron in practice)_ \r\nand \r\n**NOT A CENTRAL POINT OF FAILURE** _(another oxymoron)_\r\nand that it \r\n**ALWAYS WORKS PERFECTLY and RELIABLY** _(yet another oxymoron)_\r\nand let's suppose that this magical black box gives ticket pairs, one \r\nticket to the server, telling that user U_n can perform\r\na single action A_x, and another ticket to the user, telling that\r\nYou, the user U_n, are allowed to perform action A_n only once per ticket \r\nat server S_n, then what would be the answers to the following questions:\r\n\r\n    Q_1: Who gets to modify/post to a forum that is about \r\n        some supermafia/government/regime that loves to \r\n        apply censorship (id est Russia, China, Saudi Arabia, etc.)?\r\n\r\n    Q_2: How to stop a well paid, persistent, \r\n        supermafia/government paid human troll \r\n        from flooding the forum without limiting the posting rate of \r\n        non-trolls, who's accounts, aliases, are as old or older than\r\n        that of the troll and that have the same posting frequency \r\n        pattern as the troll has?\r\n\r\n    Q_3: What to do, if the keys of a valid user get \"confiscated\"\r\n        and the supermafia/authorities start to post as that user?\r\n\r\n    Q_4: In game theory the wins and losses are calculated \r\n        in respect of a specific player. If we're talking about \r\n        trust and mistrust, different trust levels, then who are the players?\r\n        (A ZeroNet forum would be an interesting test case.)\r\n\r\nBasically, I believe that more clarity might be brought to \r\nthe contemplation, if the James Bond style requirements (social requirements)\r\nwere laid out first and the set of technical requirements \r\nwere assembled after the social requirements are fixed.\r\n\r\nThank You for reading my comment.", "added": 1526408703, "modified": 1526408822, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1258#issuecomment-389318469", "source_type": "github"}], "1604066357_mirrored_MarBlen79_github": [{"comment_id": 8, "body": "I'm NOT a ZeroNet developer, but supposedly the Microsoft has \r\nliterally ported Ubuntu Linux userspace to Windows 10. \r\nWhen I first heard about it, I thought that \r\nit must be some sort of an April fools joke, but as it turns out:\r\n\r\nhttps://www.youtube.com/watch?v=PP_T_m0UV9E\r\n\r\nhttps://docs.microsoft.com/en-us/windows/wsl/install-win10\r\n\r\nSupposedly they did it to support Ruby, because Ruby developers, including me, \r\nhave been ignoring the whole Windows platform very consistently.\r\nI haven't tried it myself. It might be crappy vaporware or \r\nyet another \"Microsoft Silverlight\" that will be dropped like the\r\nhttps://en.wikipedia.org/wiki/Windows_Services_for_UNIX\r\nand the \r\nhttps://en.wikipedia.org/wiki/IronRuby#License\r\nwere dropped. However, I believe that \"the masses\" evaluate \r\n\r\n    comfort above all else\r\n\r\nand since the core idea behind the ZeroNet is \r\nthat there are locally stored copies of HTML_JS_CSS based \r\nLibreOffice/Microsoft_Word document analogues that can\r\nbe updated by the person, who holds the private key to sign the \r\nupdates(usually the author of the 1. version of the document), \r\nthe ZeroNet does not really offer real-time\r\ncommunication the way the chat-room oriented \r\n\r\nhttps://matrix.org/\r\nhttps://about.riot.im/\r\n\r\noffers. The ZeroNet is excellent for blogs and wikis, but \r\nI would not even try to do any layman-consumer grade\r\nthings with it, because technologies that offer real-time\r\ncommunication offer more comfort features.\r\n\r\nOn Windows You may try to install things by using the\r\nhttps://chocolatey.org/\r\n", "added": 1518758606, "modified": 1518758732, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1289#issuecomment-366171410", "source_type": "github"}, {"comment_id": 9, "body": "Suppose someone frankensteins together the \r\n\r\nhttps://webtorrent.io/\r\nhttps://github.com/webtorrent/webtorrent\r\n\r\nand the ZeroNet by creating a Zite that includes both, \r\nthe ZeroNet standard JavaScript library/API and \r\nthe WebTorrent JavaScript library, then there will be 2 network access points \r\nfor the zite. One at the Python based server and the other directly\r\nfrom the browser through the WebTorrent library. \r\nI have NOT tried the combination, but at first glance \r\nI do not see any technical difficulties,  why such a Frankestein \r\nmight fail to work, except that \r\n\r\n    THE HISTORY OF SOFTWARE DEVELOPMENT\r\n\r\nshows that not all software developers take their time to \r\nthink things trough. The 2 network access points will probably\r\nstart to introduce broken zites just like the C/C++ memory \r\nmanagement introduces a lot of crashing software. \r\nI'm not saying that the C/C++ memory management is \r\nbad. In the past I have written speed optimized C++ for years as \r\npart of my main job, but I am saying that that level of \r\ncarefulness is psychologically too high requirement for an \"average\", \r\narchitecture design wise terribly sloppy, \"web developer\".\r\nPlease, DO NOT EXPECT those people to TEST their\r\nWebTorrent dependent zites in a situation, where the\r\nWebTorrent library FAILS TO CONNECT TO THE INTERNET.\r\nMany of the zites by such \"web developers\" will probably\r\nhave the state of their single page JavaScript application\r\nMESSED UP at such corner cases.\r\n\r\nAs of 2018_02 I believe that those, who really want\r\nto create the Frankenstein and who take their time\r\nto think calmly about the architecture of their zite, \r\nhave that opportunity right now already. They can \r\ndownload the \r\n\r\nhttps://github.com/webtorrent/webtorrent\r\n\r\nand create their masterpiece, but I would refrain \r\nfrom adding that library to the ZeroNet standard\r\nJavaScript library, because if that demanding feature/tool\r\ngets into the \"masses\", then many \"web developers\"\r\nare NOT GOOD ENOUGH to use it even, if they \r\nhave the knowledge, the technical skills for using it.\r\nIt's a matter of psychology: some take their time and\r\nthink calmly, others just smash whatever pile (of ...) together and \"publish away\"!\r\nIt seems to me that in this regard the various _graphics designers_ \r\nare THE WORST, because they see a site as a \"picture\", \r\nnot as \"software\". With pictures the artists do not need to think about \r\nnetwork traffic, dependencies, data sizes, algorithmic complexity, \r\nbreaking of network connections, etc. \r\n", "added": 1518784121, "modified": 1518784757, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1289#issuecomment-366266871", "source_type": "github"}, {"comment_id": 10, "body": "P.S. I'm NOT an author of the \r\n\r\nhttps://webtorrent.io/\r\nhttps://github.com/webtorrent/webtorrent\r\n\r\nbut a 10EUR bounty for a good tip would buy me ice-cream :-)\r\nBank account details: http://intervaarium.softf1.com/lounge/requisites/en/\r\n\r\n(I'm not saying that I have earned it. But, if, for some weird reason, somebody \r\nthinks that I've done something useful and there is some money to spend, \r\nthen I'll accept the ice-cream wire transfers :-)\r\n", "added": 1518785226, "modified": 1518785226, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1289#issuecomment-366272330", "source_type": "github"}, {"comment_id": 11, "body": "@MarBlen79 \r\n>...\r\n> Mobile applications:\r\n> It's difficult creating mobile apps with Python. Qt is an option. Kivy is also one option, but\r\n>...\r\n\r\nGiven that a ZeroNet node is expected to re-distribute the pages that its user viewed, \r\nthe ZeroNet mode should not run on any cellphone, because that would drain the \r\nbattery and it's probably not that healthy either, for humans, to have a cell phone near by that \r\nruns an upload to some cell tower 24/7. That is to say, Mobile Apps that depend on \r\nZeroNet should have some relatively stationary wired server to connect to and \r\nthe Mobile App should be a viewing client of that, personal, server. Let's say,\r\na Mobile App is paired with a ZeroNet node at person's home. The \"meeting point\"\r\nbetween the two can be some web software that is hosted at some cheap\r\nhosting service, may be \r\n\r\n(~12\u20ac/year, Google Translate can probably translate Estonian for You)\r\nhttps://www.planet.ee/\r\n\r\nor\r\n\r\nhttps://www.veebimajutus.ee/\r\n(~65\u20ac/year, I've been using their service for years for hosting my softf1.com,\r\nsafest place that I know of for registering domains,\r\nGoogle Translate can probably translate Estonian for You.)\r\n\r\nSome special software that runs at the same machine with the ZeroNet node, \r\nconnects to the hosting service web application and the client at the \r\ncell phone also connects to the hosting service web application and the rest\r\nis just a matter of protocol. From that point onwards the Mobile App \r\ncan be created in any technology that the Mobile App developer \r\nusually uses for creating his/her Mobile Apps.\r\n\r\nThat's just an idea. I won't be coding any of it anytime soon, except may be the \r\nmirroring web app at the web hosting site, because that's more universal\r\nthan just the solution that I described in my current comment.\r\n\r\nThank You for reading my comment :-) \r\n", "added": 1522736213, "modified": 1522736213, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1289#issuecomment-378184288", "source_type": "github"}], "1604067689_mirrored_martinvahi_github": [{"comment_id": 12, "body": "@filips123 \r\n\r\n> Can't you already make symlink just for file?\r\n\r\nI can, but it would be a MESS, because the moment they change the number of files during the natural development of the ZeroNet, the symlink creation code has to be updated. If the files were in a folder and they decide to change the name of the folder, then there's only one change group at the symlink creation code, but if the identity related files were all symlinked individually, then there's a need to update the symlink creation code every time ANY of the identity related file name or existence changes. \r\n\r\nSuppose some new fancy module wants to implement its own identity management system and wants to use its own database, may be an SQLite database. In the case of the folder, none of my code would need to change, but in the case of the alternative, for those people, who do not have the fancy module installed, my code MIGHT work, but for others it will DEFINITELY NOT work as long as I have updated my code to take to account the existence of that fancy module. And then the symlink creation code author has to start tracking all of the changes, the possible modules, the name changes or creation/deletion of the ZeroNet core specific identity files. \r\n\r\nI prefer a solution without such a mess.\r\n\r\n", "added": 1575186631, "modified": 1575186797, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2332#issuecomment-560091227", "source_type": "github"}, {"comment_id": 13, "body": "I also point out that the `data/users.json` that You mentioned does not hint at all that this is the file related to IDENTITIES. What users? Any user posting to a forum? If that is the file for the local identities, then a person should NOT have to start reading separate documentation to figure out that this is the ONLY  file that holds the information about local identities. On the other hand, if there is a folder with the name of `data/identity` or, better yet, in plural, `data/identities`, then that question gets answered WITHOUT NEEDING TO START LOOKING FOR THAT INFORMATION FROM DOCUMENTATION.", "added": 1575187213, "modified": 1575187279, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2332#issuecomment-560092345", "source_type": "github"}, {"comment_id": 14, "body": "> > I can, but it would be a MESS, because the moment they change the number of files during the natural development of the ZeroNet, the symlink creation code has to be updated.\r\n> \r\n> What do you mean with this?\r\n\r\nI mean that the symlink creation code has to include the list of files that need to be symlinked, including their names.\r\n\r\n\r\n\r\n> > I also point out that the data/users.json that You mentioned does not hint at all that this is the file related to IDENTITIES. What users?\r\n> \r\n> It contains your public and private keys, IDs, auth addresses for sites...\r\n> \r\n> > On the other hand, if there is a folder with the name of data/identity or, better yet, in plural, data/identities, then that question gets answered WITHOUT NEEDING TO START LOOKING FOR THAT INFORMATION FROM DOCUMENTATION.\r\n> \r\n> What?\r\n> \r\n> Isn't `users.json` already good way to describe that file contains users?\r\n> \r\n> Having folder which contains just one file would also be a mess.\r\n\r\nOh well, if You say that it's just that ONE users.json, then I'll live with that until something breaks. If something breaks, then I'll re-open this feature-request. Thank You for the answers.\r\n\r\nP.S. if the users.json data records were written in an SQLite database, then the SQLite engine would handle thread safety. Does the code that reads-writes the users.json handle the case, where 2 or more server processes try to read/write the same file? Lack of data corruption in that scenario guaranteed? The same with other \"JSON-file-poor-man-s-databases\", if they exist.", "added": 1575213294, "modified": 1575213294, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2332#issuecomment-560139088", "source_type": "github"}, {"comment_id": 15, "body": "> Note that better user managing and signing API would be good. With this, I mean easier support to let plugins/code store and sign data in different ways, for example, in folders, memory, SQLite, browser extensions...\r\n> \r\n> You might want to open a new feature request for this.\r\n\r\nThank You both for the answers, but as of 2019_12 I'm too stupid for that. I even failed to get the newest and greatest ZeroNet, as cloned from this repository, to run, so I experimented with various older versions in the trunk and wrote a 3 Bash scripts based wrapper to one of the versions from 2018\r\n\r\nhttps://technology.softf1.com/software_by_third_parties/ZeroNet/\r\n\r\nI even got it to run, with one hick-up/hangup_event, on Win10 Linux layer, the [Windows Subsystem for Linux (WSL)](https://docs.microsoft.com/en-us/windows/wsl/faq), Debian distribution. I did not expect to talk about the Win10 usage in English, whcih is why I used Estonian at the screen video, where I show, which of the 3 lines among my 3 Bash scripts should be commented out to make it run on Win10, but there's not that much text there, so it's probably understandable to anybody regardless of the Estonian language.\r\n\r\nhttps://technology.softf1.com/software_by_third_parties/ZeroNet/2019_11_24_initially_failing_and_Ctrl-c-killed_unprepared_Estonian_demo_t1_how_to_get_the_2018_11_08_ZeroNet_Rev3703_mmmv_repackaging_t1_to_run_on_Windows10_Linux_layer.webm\r\n\r\nWith that, the Linux version of 2018 ZeroNet works \"on Windows\" without Windows specific code. I even uploaded the repackaging deliverables to SourceForge:\r\n\r\nhttps://sourceforge.net/projects/mmmv-repackaging-projects-t1/files/repackaging_projects/repackaged_ZeroNet/\r\n", "added": 1575216198, "modified": 1575216198, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2332#issuecomment-560145571", "source_type": "github"}]}, "next_topic_id": 7, "topic": [{"topic_id": 1604065452, "title": "Startup Script Requires the Working Directory to Match with the Project Folder", "body": "The following example shows, how the star-up of ZeroNet fails, if the `pwd`  is outside of the project home folder:\n\n```\nzeronet_runner@computenode1softf1com /media/usb0/large_files/zeronet_runner $ nice -n20 python ./ZeroNet/zeronet.py \n- Starting ZeroNet...\nTraceback (most recent call last):\n  File \"./ZeroNet/zeronet.py\", line 15, in main\n    import main\n  File \"./ZeroNet/src/main.py\", line 86, in <module>\n    PluginManager.plugin_manager.loadPlugins()\n  File \"./ZeroNet/src/Plugin/PluginManager.py\", line 28, in loadPlugins\n    for dir_name in os.listdir(self.plugin_path):\nOSError: [Errno 2] No such file or directory: 'plugins'\nzeronet_runner@computenode1softf1com /media/usb0/large_files/zeronet_runner $ ls\nZeroNet  data  log\nzeronet_runner@computenode1softf1com /media/usb0/large_files/zeronet_runner $ ls ./ZeroNet/\nDockerfile  README.md    plugins           src       tools      zeronet.py\nLICENSE     Vagrantfile  requirements.txt  start.py  update.py\nzeronet_runner@computenode1softf1com /media/usb0/large_files/zeronet_runner $ uname -a\nLinux computenode1softf1com 4.1.19+ #858 Tue Mar 15 15:52:03 GMT 2016 armv6l GNU/Linux\nzeronet_runner@computenode1softf1com /media/usb0/large_files/zeronet_runner $ date\nMon Sep  5 07:09:20 UTC 2016\nzeronet_runner@computenode1softf1com /media/usb0/large_files/zeronet_runner $\n```\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1473048814, "modified": 1503501186, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/569", "source_type": "github"}, {"topic_id": 1604066238, "title": "ZeroNet GUI is not Usable Without 3D Acceleration", "body": "### Environment:\r\n\r\n  * ZeroNet version: 0.6.0 (rev. 3146)\r\n  * Operating system: Raspbian & openSUSE Linux\r\n  * Web browser: Chromium (Google Chrome)\r\n  * Tor status: disabled\r\n  * Opened port: yes\r\n\r\n\r\n### The problem:\r\n\r\nThe 3D globe at the zite settings panel \r\ndepends on 3D support(probably WebGL), but \r\nthe WebGL, GPU support, is not available at all browsers\r\nand that makes the ZeroNet much less portable.\r\n\r\n#### Steps to reproduce:\r\n\r\n  1. Open the ZeroNet GUI in some non-standard browser, like \r\nhttp://www.midori-browser.org/\r\nor\r\nhttps://rekonq.kde.org/\r\nor \r\nhttps://konqueror.org/     \r\n\r\n  2. Try to open the zite settings panel by sliding the zero icon.\r\n\r\n\r\n#### Observed Results:\r\n\r\nEither the zite does not load at all or the zite loads, but \r\nthe settings panel is empty, blank.\r\n\r\n#### Wishes:\r\n\r\nThe JavaScript of the ZeroNet GUI should first\r\ncheck, whether 3D/GPU-s are supported and \r\nload the 3D Earth only, if the WebGL/GPU support\r\nis available. If the 3D acceleration is not available, \r\nthe classical 2D \"World map\" with color-coded \r\nheight might be used, the way geography related\r\npaper-books used to depict mountain range heights\r\non maps.\r\n\r\nhttp://vterrain.org/Elevation/NOAA_Globe_680.jpg\r\n(archival copy: https://archive.fo/QFJ6k )\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1511809722, "modified": 1512449623, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1194", "source_type": "github"}, {"topic_id": 1604066263, "title": "Feature Request: Multiuser Support 4 Hundreds of Users", "body": "During the paper data carrier age families\r\nhad their own, personal, mini-libraries in a \r\nform of a set of book shelves. At the 21. century\r\nthe knowledge transfer is based on files and\r\nthe \"family library\" will likely be a  \r\nstorage server at the home LAN(hereafter: \"library_server\"). \r\n\r\n\r\nThe ZeroNet is a perfect candidate \r\nfor the home Library software. From resource usage\r\npoint of view it does not make sense that the \r\nmultiple TiB set of files is duplicated in the \r\ndevices of different family members. \"Notebooks\" and \r\nthin touchscreen devices do not have the\r\nstorage capacity that desktop computers and\r\nUSB-HDDs can have. The relatively high rate of \r\nHDD traffic that all P2P data sharing applications have\r\nmandates that the P2P data sharing applications\r\nmust run at a dedicated server, not the computers\r\nthat run the user interface for humans.\r\n\r\n\r\n\r\n# Implementation Idea and UX Issues\r\n\r\n\r\nA simple set-up is that different family members\r\nconnect to different port numbers of the \r\nlibrary_server. May be a solution might be that\r\nthe current ZeroNet software is divided into\r\n2 \"modules\": \"ZeroNet storage server\" and \r\n\"ZeroNet storage client\". Each family would run\r\na single instance of the \"ZeroNet storage server\" and\r\nthe library_server runs a separate \r\n\"ZeroNet storage client\" instance for each of the \r\nfamily members.\r\n\r\n\r\nMay be the currently existing \"Multiuser plugin\"\r\n\r\n    (renaming of plugins/disabled-Multiuser -> plugins/Multiuser)\r\n\r\nalready has all the requested functionality, but\r\nto cope with end users, who fail to analyze, \r\nwhat they are doing while they are using a \r\ncomputer(read: \"grannies\", \"mothers\"), \r\na solution, where each family member has to \r\nexplicitly select a user ID from some menu \r\nin stead of using the ZeroNet from a\r\n\r\n    http://localhost:43110/foo/bar\r\n\r\nwill likely lead to a situation, where a\r\nslightly demented \"granny\" will forget to \r\nchoose the right user ID and will carry out\r\nan accidental \"identity theft\" of some of her\r\nfamily members. If the library server has\r\none ZeroNet storage client per user, then the\r\ngranny's computer can be configured to \r\ncreate an SSH tunnel to the granny's own \r\nZeroNet storage client instance, making sure\r\nthat the granny only uses her own identity.\r\n\r\n\r\n# Test Case\r\n\r\n**An extreme test case might be a nursing home or \r\na school that has a single library_server and \r\nusers have Android touchscreen devices.**\r\nIn that case the ZeroNet storage clients\r\nsolve the issue of multi-CPU support, because\r\neach ZeroNet storage client instance is/can_be a \r\nseparate operating system process and the \r\noperating system distributes the load to different\r\nCPU-cores automatically. The security in that setting \r\ncan be solved by giving each user a dedicated\r\nSSH account on the library_server and \r\nby setting the routing tables on the library_server\r\nso that each user has its own, dedicated, \r\nloopback address that only he/she can connect to.\r\nThat is to say, the security aspects of the\r\ncurrent feature request can be solved with \r\nserver-side configuration and that the \r\nability to run the ZeroNet storage client\r\ninstances at a given port is sufficient, provided\r\nthat the ZeroNet storage clients communicate\r\nwith the ZeroNet storage server through some\r\nnamed pipe or TCP connection.\r\n\r\nAn example Bash script for creating SSH tunnels:\r\n\r\nhttps://github.com/martinvahi/mmmv_notes/blob/master/mmmv_notes/mmmv_utilities/src/various_Bash_scripts/ssh_tunnel_t1.bash\r\n\r\n(archival copy: https://archive.is/EtFKP )\r\n\r\n\r\n\r\n# Related Bug Reports\r\n\r\n* The #613 seems to be related.\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1513653339, "modified": 1513653373, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1214", "source_type": "github"}, {"topic_id": 1604066358, "title": "Central Deletion of Zites by Publishing a new Version of the Zite that has its Content Removed", "body": "My current bug report is not so much of a bug report, but \r\nrather a halve-question and it's inspired from a discussion at\r\n\r\nhttp://127.0.0.1:43110/Talk.ZeroNetwork.bit/?Topic:1518467842_1BGWexcsjvPpnPZVmmioZvwBBQ3WoZsWuQ/What+happens+if+the+owner+of+a+Zite+deletes+its+contents\r\n\r\nI just came to an idea that given that the ZeroNet does not act like \r\na version control system(or does it? I do not know yet), one way to \r\ncentrally delete/censor a zite is to raid/rob/steal the secret key of the\r\nzite publisher's ID and then publish a newer version of the zite\r\nthat has the censorable content removed/edited/modified.\r\n\r\nWith Windows users and automated mass malware(\"viruses\", \"antivirus software\", etc.)\r\nthere is probably even no need to raid the author's servers. Even if \r\nthe server resides at some place other than the location of the author's \r\nworkstation, the censors can first break/hack into the author's workstation\r\nand then jump to the ZeroNet server from there by using the very same\r\nconnection/tunnel/keys that the zite author itself uses. With the threat\r\nthat the author of the censorable zite has implemented emergency \r\nkey destruction, a physical raid to get access to the author's workstation\r\nwould risk triggering the emergency key destruction, but a secret \r\npenetration hack might avoid triggering the key destruction.\r\n\r\nhttps://www.youtube.com/watch?v=Fi6016ne1YM\r\n\r\nhttp://127.0.0.1:43110/15qHfGtzeqZb2PJiwhtYyV3sARx8zzddMG/website_bonnet/various_files/299_GAMMA-201110-FinFisher_Product_Portfolio-en.pdf\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1518538424, "modified": 1518674496, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1288", "source_type": "github"}, {"topic_id": 1604066362, "title": "Feature Request: Download size and Recursion Debth Limited Cluster Download Option", "body": "The idea is that while a person is reading one zite, \r\nthe server(Python code) checks, whether the zites that \r\nare linked from that, open, zite, have been already downloaded\r\nand if not, then downloads them in the background. \r\n\r\nOnly those zites can be downloaded in the background that\r\ndo not require the user to interact with any ZeroNet dialogues.\r\n\r\n    Maximum allowed recursion depth should be 3, \r\n\r\nbecause otherwise inexperienced users can easily freeze their system. \r\n\r\n    The default value of for the recursion depth should be 0, \r\n\r\nwhich means that the feature is SWITCHED OFF. \r\nRecursion depth of 1 means that only the \r\nzites that are directly linked from the open zite are  \r\ndownload candidates. The content.json already contains \r\nfile size fields, so it is possible to avoid downloading zites that are\r\n\"too big\". \r\n\r\nA counter-measure to an attack, where some zite links to \r\nmultiple TiB of zites, is that the overall size of the recursive\r\nbackground download of a single opened zite has a limit, \r\nwhich might be about 3MiB by default. Which zites to choose\r\nto download is the classical Knapsack problem:\r\n\r\nhttp://www.es.ele.tue.nl/education/5MC10/Solutions/knapsack.pdf\r\nThe same document at ZeroNet:\r\nhttp://127.0.0.1:43110/19r55ZDt5UJtyTwRZkQCScyQT5Rt8smZ8/website_bonnet/various_files/2018_02_16_copy_of_http_www_es_ele_tue_nl_slash_education_slash_5MC10_slash_Solutions_slash_knapsack.pdf\r\n\r\nThe \"value\" that needs to be packed into the limited data-size backpack/knapsack \r\nis the number of files. The more individual files, the better, because\r\nthe situation with their download is very similar to that of the classical FTP, \r\nwhere x MiB worth of files takes much longer to download individually than\r\nit takes to download them in a single, UN-compressed tar-file, because\r\nwith individual downloads there is the file download handshake overhead\r\nand network delays with every file, but with a single tar-file the handshake\r\nrelated overhead and network delays are borne only once.\r\n\r\nI do not know, how the ZeroNet server's download system has been implemented, but \r\none optimization option might be to store very small zites that are not\r\nowned by the server owner in a form of a pair of 2 files:\r\n\r\n    (content.json ; the_whole_zite.tar)\r\n\r\nand use a temporarily un-packed copy of the zite at some\r\ntemporary local cache for local browsing. The reason, why \r\n\r\n    tar files MUST NOT BE COMPRESSED\r\n\r\nis that compressing them introduces an attack option, where\r\nsomeone compresses multiple TiB of zeros into a very tiny compressed\r\nfile and the moment the tiny compressed file is decompressed....\r\n\r\nThank You for reading this comment :-)", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1518756694, "modified": 1518756694, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1290", "source_type": "github"}, {"topic_id": 1604067689, "title": "Feature Request: Place all Identity Specific Files to a Separate Folder Named \"identity\"", "body": "Currently the identity related files seem to reside loosely at the \"data\" folder, at \r\n\r\n    <ZeroNet instance root folder>/data\r\n\r\nIf there were\r\n\r\n    <ZeroNet instance root folder>/data/identity\r\n\r\nand all of the local server instance identity related files, for example private keys, were placed to that folder, then it would be possible to replace that folder with a symlink to a mounted encrypted file system folder. \r\n\r\nThe possibility to replace that folder with a symlink would also simplify scripting. For example, one might want to write a Bash alias that swaps the target of the symlink, which allows the downloaded zite data to be re-used by multiple identities without making any modifications to the ZeroNet core code. That kind of identity switching mechanism does not (or at least should not, if everything is kept clean at the ZeroNet architecture) interfere with any of the multi-identity plugins/modules that other people might prefer to use. \r\n\r\nFrom security point of view it is not a perfect identity switching mechanism, because for the sake of saving disk space and download time, the downloaded zites are shared between multiple identities, but it is helpful in cases, when the identity switch is done mainly to confuse search engines.\r\n\r\nThank You.\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1575066468, "modified": 1575216198, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/2332", "source_type": "github"}]}