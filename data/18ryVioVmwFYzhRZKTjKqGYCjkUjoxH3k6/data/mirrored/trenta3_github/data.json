{"cert_user_id": "trenta3@github", "next_comment_id": 65, "comment": {"1604064913_mirrored_kseistrup_github": [{"comment_id": 1, "body": "@tangdou1 From the new config page the setting on IPv6 says: \"Accept other peers using IPv4 or IPv6 address. (default: IPv4)\". What does it mean? If I enable IPv6 will I still be able to contact IPv4 peers or one must choose which type of addresses to use?", "added": 1548052741, "modified": 1548052741, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/148#issuecomment-456007968", "source_type": "github"}, {"comment_id": 2, "body": "Does this mean that if I select IPv6 then IPv4 only peers wont be able to\ncontact me (i.e. Initiate a connection), since I'm only listening to\nincoming IPv6 requests?\n\nIf it is so, since many ISPs do not provider IPv6 support yet, when\ncreating a new site it will be more convenient to change the setting to\nIPv4, isn't it?\n\nIl giorno lun 21 gen 2019, 11:20 ZeroNet <notifications@github.com> ha\nscritto:\n\n> You can connect to ipv6 and ipv4 peers in both mode. It changes what\n> interface you will use for the incoming connections.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/HelloZeroNet/ZeroNet/issues/148#issuecomment-456021757>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AKU8ETZxfGuo0Ts-u-o22AEReHUHnODmks5vFZRtgaJpZM4F4mYM>\n> .\n>\n", "added": 1548061428, "modified": 1548061428, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/148#issuecomment-456051431", "source_type": "github"}], "1604066166_mirrored_Wieke_github": [{"comment_id": 3, "body": "Please see issue #1548 and the associated PR #1549 ", "added": 1535574595, "modified": 1535574595, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1141#issuecomment-417140484", "source_type": "github"}], "1604066207_mirrored_sergei-bondarenko_github": [{"comment_id": 4, "body": "Please see issue #1548 and associated PR #1549 ", "added": 1535574847, "modified": 1535574847, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1161#issuecomment-417141325", "source_type": "github"}], "1604066574_mirrored_imachug_github": [{"comment_id": 5, "body": "@HelloZeroNet @imachug I think the plugin system should be handled much more carefully.\r\n\r\nImagine the following scenario (assuming the possibility of plugin updates from zeronet):\r\n* Someone creates a good plugin for Private Sites (or another equally requested feature)\r\n* Many people adopt it, and some even read the code and confirm it has no treat\r\n* The plugin creator starts updating the code with small extra functionalities or bug fixes and at each modification he updates the plugins (each time asking the users for permission)\r\n* At a later time, when everyone is just accepting updates to this plugin without thinking, he deploys malicious code that, starting from the next week (in order to have time to propagate to the whole net) does one of the following (at your choice):\r\n   - Redirect all requests to zeronet to a blank page, and makes the program crash if some other action is allowed\r\n   - Searches in the computer any cryptocurrencies wallet and logs user input\r\n   - Deletes user' users.json and sites.json and/or encrypt them asking for money\r\n   - ...\r\n\r\nMoreover I think such a system has other downsides:\r\n* Promotes duplication of efforts: there would be multiples copies of plugins with basically the same functionality and developed by a single author with no community support (just look at google chrome web store). This is bad since when the developer goes away, the plugin gets no security fixes and is abandoned (maybe because of non-existant documentation or commenting in source code).\r\n* With the current plugin system (\"patching\" existing functions at beginning or at the end) the risks are for the plugins to interfere (installing two of them gives problems that when used by themselves they do not have) and to just crash when a Zeronet version is updated that does some noncompatible thing. One should then either not update (BAD) or wait for the plugin developer to notice that (if even) and have time to patch.\r\n* Some plugins are just too important (such as this one) to only be optionally installable with user action. Many plugins offering additional functionality are just useless if they have to be opted in (e.g. RewriteRequest: noone would use such thing in his sites if there is the risk that some of the possible users cannot use the website, or Zeroname: many links have the domain name.bit).\r\n* Zeronet **can't** let some random python code to execute \"without control\". Malicious code can do horrible things, and very few users have the time and knowledge to read source code and understand the risks.\r\n\r\nObviously some of these problems have solutions, but I'm just saying that such a thing requires careful planning (sandboxed environment / custom plugin language, more \"modular\" code patching, ...)", "added": 1536597338, "modified": 1536597338, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1430#issuecomment-420033516", "source_type": "github"}, {"comment_id": 6, "body": "> **HelloZeroNet**: [...] On the other side I don't want to be responsible for merging a code that I'm not fully aware and reviewing new PR/plugins/changes can take lots of time. Sometime even more than writing it.\r\n\r\n@HelloZeroNet Concerning the review process, is there anything that can be done by committers to speed it up? Something about comments in the code, format of commit messages, programming style (e.g. function splitting), etc.?\r\n\r\nIf there is something that can be done, you could and should write precise requirements for code in Pull Requests in a visible place (in the main README or in a CONTRIBUTING.md). This helps both you, easing your review, and the pull request sender, who knows he is doing right and not creating too much burden on you.\r\n\r\n> **tangdou1**: [...] Users should be responsible for their behavior to decide whether or not to add a plugin from the plugin store. Also most of them do not have much time or ability to read the code of ZeroNet, but they must trust @HelloZeroNet if they want to use ZeroNet. [...]\r\n\r\nThey are two very different stories: trusting HelloZeroNet (who has built almost the whole ZeroNet software) is very different from trusting a casual account that creates a plugin for ZeroNet, since you are basically trusting everyone that knows enough python to use decorators and to copy-paste from existing plugins. Even having a \"reputation\" system based on votes or comments adds nothing from the security side, since creating many zeroid accounts in very short time can be done. \r\nYou would then have to trust HelloZeroNet in each case, since he is the one doing actual work.\r\n\r\nAs my last contribution in such discussion I'd like to add that using the current plugin infrastructure with the additional ability to add a plugin as a one-click action will be catastrophic in term of security as already explained, and there is currently no work-force to design and implement a better plugin system, so I think it just wont be done in the near future. IMHO one of the top priority should be to gain more widespread use and advertise ZeroNet as much as possible.\r\n\r\nPlease also note that the currently requested user actions for installing a plugin are: downloading the plugin code / folder in any way and putting it in a specific folder inside of the ZeroNet one. This already requires very basic abilities and little time.", "added": 1536670916, "modified": 1536670916, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1430#issuecomment-420326463", "source_type": "github"}, {"comment_id": 7, "body": "@krixano There was probably a misunderstanding: what I've said is \"using the current plugin infrastructure with the additional ability to add a plugin as a one-click action will be catastrophic\", so if we had a restricted API for plugins, it would be totally okay to have a one-click install.\r\nThe problem really arise when (with current plugin infrastructure) a one-click action could by design execute whatever code on your computer.\r\n\r\nI'm particularly interested in the malicious code scan, do you have some references to working POCs or projects for python?", "added": 1536739699, "modified": 1536739699, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1430#issuecomment-420609751", "source_type": "github"}, {"comment_id": 8, "body": "@imachug Good idea to sandbox the plugins in BackgroundProcessing.\r\n\r\nHowever, we should really change plugin architecture, since I don't think it is really modular as it currently stands out (subclassing the existing functions). Maybe having a look at [pluggy](https://github.com/pytest-dev/pluggy) or something similar?", "added": 1536758577, "modified": 1536758577, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1430#issuecomment-420710832", "source_type": "github"}, {"comment_id": 9, "body": "Just a little comment to that. \r\nIt might be possible to build a python sandbox modifying a little [byterun](https://github.com/nedbat/byterun) (a [good article about it here](http://www.aosabook.org/en/500L/a-python-interpreter-written-in-python.html)).\r\n\r\nThe idea is simply: write a python interpreter inside python itself that allows only non-builtin functions to be called. Every time some interpreted pyton code calls an external module function, the interpreter could use `inspect.isbuiltin` and raise an exception if it is. If it is not, one should compile the function bytecode and execute that.\r\n\r\nThis could at least prevent accessing the filesystem, the network and other \"external world\" functions.\r\n\r\nFiner restrictions on possible modifications of the ZeroNet classes I think would require a big amount of work.", "added": 1536865842, "modified": 1536865842, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1430#issuecomment-421169210", "source_type": "github"}, {"comment_id": 10, "body": "@blurHY I should have done that before. Please use issue #1607 to discuss about plugin system and leave this thread only for things concerning the PR.", "added": 1536911205, "modified": 1536911205, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1430#issuecomment-421318348", "source_type": "github"}], "1604066559_mirrored_trenta3_github": [{"comment_id": 11, "body": "It seems that the plugin is almost finished, and also the on-it-dependent PeerMessage.\r\nWhen will they be merged and enabled into ZeroNet release?\r\n@imachug @HelloZeroNet @DaniellMesquita", "added": 1535531566, "modified": 1535531566, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1447#issuecomment-416920434", "source_type": "github"}], "1604066571_mirrored_trenta3_github": [{"comment_id": 12, "body": "How about adding [The Amalgamation (whole source code in a single `.c` file)](https://www.sqlite.org/amalgamation.html) to the repository?\r\nThis way who downloads the repository only has to have a C compiler (which is very common I think and the build instructions are only for Linux OSes, which usually has a C compiler already installed or an `apt-get`/`ipkg` line away) and installing from repository should only be a matter of adding a couple line of instructions for the C compiler in the build phase (that should be equal for every linux distribution and for the Dockerfile and for the Vagrantfile).\r\n\r\nIf you possibly like such an idea, I might send a PR in the next days and we can talk about it in more detail.", "added": 1529247206, "modified": 1529324264, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1456#issuecomment-397895171", "source_type": "github"}, {"comment_id": 13, "body": "@imachug Yes, but for Windows and Mac there are no \"install from repo\" instructions, there are only prebuilt package so that it would be additional burden on developers only, not on end users.\r\n\r\nWe can discuss whether it is worthwhile, but I see the added benefits of:\r\n- Full text search with spellfix1 and fts5\r\n- Import of comma separated value files for \"more compact\" information storage (no need to repeat headers name) with the extension csv\r\n- R-tree for multidimensional range queries (for geospatial system, e.g. an analogue of Google Maps)\r\n\r\nMoreover **this issue is about enabling the syntax of virtual tables**, which requires no extra compiling and is a two line change.", "added": 1529324899, "modified": 1529324899, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1456#issuecomment-398094401", "source_type": "github"}], "1604066641_mirrored_trenta3_github": [{"comment_id": 14, "body": "The one thing I don't get is how can a peer prove to others that the document unit he is sending them is legit: I mean usually each peer has only one file with all its data inside and it only signs the file as a whole.\n\nMaybe we should change the signature to be the signature of a sort of merkle hash of the json document. In such a way one can, given the original signature and json document, prove to another party that the piece of information is legit by giving them the hashes from The root to the interested leaf.\n\nIf someone has better ideas on how to do that, i'd like to hear them. ", "added": 1535291924, "modified": 1535291924, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1513#issuecomment-416052839", "source_type": "github"}], "1604066705_mirrored_DaniellMesquita_github": [{"comment_id": 15, "body": "I'd like to point out that even if there is the option `clone_root` in `content.json`, the noclone option could be useful where one wants to exclude just a couple of files from being clones and duplicating all the others can be seen as a waste of space and against the DRY principle.", "added": 1535474435, "modified": 1535474435, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1528#issuecomment-416714835", "source_type": "github"}], "1604066708_mirrored_DaniellMesquita_github": [{"comment_id": 16, "body": "Given that the \"-upgrade\" infix is by default on all files, and supposing \"-noclone\" is implemented, what are possible use cases of this one that are not already solved by other means?\r\n\r\nFor reference: https://github.com/HelloZeroNet/ZeroNet/issues/1530#issuecomment-416931529", "added": 1535570226, "modified": 1535570226, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1529#issuecomment-417124788", "source_type": "github"}], "1604066710_mirrored_DaniellMesquita_github": [{"comment_id": 17, "body": "> Only files in CSS/JS folders of clonned zites are upgraded, but -upgrade prefix makes other files upgradeables.\r\n\r\nI'm not sure this happens: checking in the source of ZeroHello the click on \"Upgrade code\"\r\n\r\nhttps://github.com/HelloZeroNet/ZeroHello/blob/86dc032abd939ebfe4e5e8a62fb6f0d401073560/js/PageSites/Site.coffee#L110-L113\r\n\r\ncalls the API `siteClone` with `target_address` which is in the code below:\r\n\r\nhttps://github.com/HelloZeroNet/ZeroNet/blob/030ad0a8de20443eabbb454ffba3b02d620af93f/src/Ui/UiWebsocket.py#L930-L946\r\n\r\nhttps://github.com/HelloZeroNet/ZeroNet/blob/030ad0a8de20443eabbb454ffba3b02d620af93f/src/Ui/UiWebsocket.py#L912-L928\r\n\r\nand I don't see any mention to the \"js\" or \"css\" folders, I think the code simply gets every file that is in the cloned site, creating an exact copy except for some data in `content.json`.\r\nMaybe @HelloZeroNet can confirm or deny.", "added": 1535534255, "modified": 1535534341, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1530#issuecomment-416931529", "source_type": "github"}, {"comment_id": 18, "body": "With the new PR #1542 which modifies `Site/Site.py#clone` the files with `-noclone` should not be cloned nor upgraded...", "added": 1535534732, "modified": 1535534732, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1530#issuecomment-416933675", "source_type": "github"}, {"comment_id": 19, "body": "So I see no possible use case for this infix that is not already covered by the general update strategy: every file, if not otherwise specified with \"-noclone\", will be upgraded...\r\n\r\n@HelloZeroNet What about newly created files in the cloned site that didn't exist in the original one? Are they deleted or simply left as is?", "added": 1535570029, "modified": 1535570029, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1530#issuecomment-417123987", "source_type": "github"}], "1604066712_mirrored_DaniellMesquita_github": [{"comment_id": 20, "body": "@DaniellMesquita Could you please specify more adequately how exactly one should specify them in `content.json`.\r\nMy proposal is to add some keys such as:\r\n```\r\n\"default_files\": [\r\n  { \"to\": \"config.ini\", \"from\": \"config.ini.example\" },\r\n  ...\r\n]\r\n\r\n\"noclone_files\": [\r\n  \"css/custom.css\"\r\n  ...\r\n]\r\n``` ", "added": 1535569829, "modified": 1535569845, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1531#issuecomment-417123122", "source_type": "github"}], "1604066679_mirrored_trenta3_github": [{"comment_id": 21, "body": "I think we should support both options, for uniformity wrt the \"-default\" infix", "added": 1535556340, "modified": 1535556340, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1542#issuecomment-417056175", "source_type": "github"}, {"comment_id": 22, "body": "This commit ended up defining a different syntax than the hypothized one.\r\nIn particular the \"default_files\" key is an object and not a list.\r\nThe keys are the file sources and the values are files' destinations.\r\n\r\nI give an usage example:\r\n```\r\n\"default_files\": {\r\n  \"config.ini.example\": \"config.ini\",\r\n  ...\r\n},\r\n\"noclone_files\": [\r\n  \"uninmportant-file.txt\",\r\n  ...\r\n]\r\n```\r\n\r\nAlso note that this only works for files.\r\n\r\n@HelloZeroNet I'm unsure how to set priority for noclone and default files setted in `content.json` under `src/Worker/WorkerManager.py#getPriorityBoost`.", "added": 1536304328, "modified": 1536304328, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1542#issuecomment-419392400", "source_type": "github"}, {"comment_id": 23, "body": "@HelloZeroNet I'm also unsure on how to set up tests, since the `1TeST...` folder has to be signed by a key that I couldn't find in the repository...", "added": 1536304677, "modified": 1536304677, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1542#issuecomment-419393868", "source_type": "github"}], "1604066684_mirrored_trenta3_github": [{"comment_id": 24, "body": "Sorry I think I didn't remembered it well. Tried on a new installation of ZeroNet and it works also for me.\r\nI just didn't find the description in \r\nhttps://github.com/HelloZeroNet/ZeroNet/blob/030ad0a8de20443eabbb454ffba3b02d620af93f/src/Ui/UiWebsocket.py#L827-L833\r\n", "added": 1535554407, "modified": 1535554407, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1545#issuecomment-417045258", "source_type": "github"}], "1604066691_mirrored_trenta3_github": [{"comment_id": 25, "body": "Please do not merge it yet, since I would like to review the changes and also implement other possibilities:\r\n* Custom return code (non-200)\r\n* Matching on full url with querystring\r\n\r\n@HelloZeroNet I'm dubious on wheter the changes have to go in the place where I put them or before line 290 in `UiRequest.py`", "added": 1535719910, "modified": 1535719910, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-417707630", "source_type": "github"}, {"comment_id": 26, "body": "I would have done it yet, if I knew how to do it. I see that existing\nplugins only patch some functions either at the beginning or at the end.\n\nI also don't know where exactly to put the redirection function in the\nexisting code...\n", "added": 1536313696, "modified": 1536313696, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-419428655", "source_type": "github"}, {"comment_id": 27, "body": "I think the rewrite has to occurr in the middle of a function", "added": 1536315459, "modified": 1536315459, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-419436145", "source_type": "github"}, {"comment_id": 28, "body": "Also, what are the guidelines on when to make changes to core and when to write a plugin? \n\nEspecially when one is integrating existing core functionality this is not really clear. \n\nSorry for the triple reply. ", "added": 1536315803, "modified": 1536315803, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-419437734", "source_type": "github"}, {"comment_id": 29, "body": "I'm trying to port it as a plugin. I'm almost done, except it does not work for `.bit` domains, because I need the plugin `Zeroname` to load before mine. Is there any way I can do this?", "added": 1536510546, "modified": 1536510546, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-419738978", "source_type": "github"}, {"comment_id": 30, "body": "@imachug I'm not using it directly. I just need that it loads before mine, since it patches `SiteManager` with `domainname -> address` resolution that I need to get to read the `content.json` files.", "added": 1536511248, "modified": 1536511248, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-419739670", "source_type": "github"}, {"comment_id": 31, "body": "An example:\r\nSuppose someone wants to visit `zeroid.bit/`.\r\nI need to get its `content.json` file to see if it specifies some redirect.\r\n\r\nUnfortunately i see, reading the `PluginManager.py`, that the plugins are loaded in alphabetical order, so it is very unfortunate that what I need is the `Zeroname` plugin :)\r\n\r\nIt would be nice to be able to add dependencies to the plugin system.", "added": 1536511396, "modified": 1536511396, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-419739836", "source_type": "github"}, {"comment_id": 32, "body": "@imachug Thank you. Now it works. I had to be careful loading `Zeroname` befor `SiteManager`.\r\n\r\n```python\r\ntry:\r\n    import Zeroname\r\nexcept ImportError:\r\n    # ZeroName plugin is disabled\r\n\r\nfrom Site import SiteManager\r\n```", "added": 1536512940, "modified": 1536512955, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-419741475", "source_type": "github"}, {"comment_id": 33, "body": "@HelloZeroNet I also had to load the `TranslateSite` plugin before `Zeroname` because otherwise it raises an exception on sites that are accessed as domain name:\r\n```\r\nUiWSGIHandler error: AttributeError: 'NoneType' object has no attribute 'content_manager' in UiServer.py line 40 > pywsgi.py line 923 > pywsgi.py line 907 > TranslateSitePlugin.py line 39\r\n```", "added": 1536517777, "modified": 1536517777, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-419746320", "source_type": "github"}, {"comment_id": 34, "body": "I think the feature is now mature enough to pass to the testing phase.\r\nI've already tested it on some sites.\r\n\r\n@imachug @DaniellMesquita @Thunder33345 @blurHY Please test it and report errors.\r\n\r\nI've added documentation in the form of [a Markdown file](https://github.com/HelloZeroNet/ZeroNet/blob/64917273341f783734d594dbe76857b3662c7f84/docs/plugins/RewriteRequest.md).\r\nPlease read it and try this Plugin.", "added": 1536526601, "modified": 1536526601, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-419754543", "source_type": "github"}, {"comment_id": 35, "body": "If someone tried, please update the code with my latest commit, since I had left in the code something that completely bypassed my own code :)\r\n\r\nNow the plugin even supports conditional checks on file existance before applying a rewrite rule.\r\n[Updated documentation](https://github.com/HelloZeroNet/ZeroNet/blob/0221df99cbb2069f618707b941f6ca865a121657/docs/plugins/RewriteRequest.md)", "added": 1536559163, "modified": 1536559163, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-419840062", "source_type": "github"}, {"comment_id": 36, "body": "Please click on the Link for documentation in my previous message. It has\ndetailed description and two usage examples.\n\nThe key is 'rewrite_rules' and should be a list of dictionaries with some\nKeys. Read docs.\n\n>\n", "added": 1536775485, "modified": 1536775485, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-420797251", "source_type": "github"}, {"comment_id": 37, "body": "Also thank you for trying it. Please write about every problem you have or\nlacking of proper documentation\n\n>\n", "added": 1536775672, "modified": 1536775672, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-420798150", "source_type": "github"}, {"comment_id": 38, "body": "@DaniellMesquita Long time has passed, did you try it? Any comments?", "added": 1539528982, "modified": 1539528997, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549#issuecomment-429647372", "source_type": "github"}], "1604066698_mirrored_trenta3_github": [{"comment_id": 39, "body": "@skwerlman Good point, I agree.", "added": 1535636057, "modified": 1535636057, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1553#issuecomment-417383773", "source_type": "github"}, {"comment_id": 40, "body": "A little thought about this:\r\nHaving separate error reporting for ZeroNet core and Plugins (or Sites) could be \"difficult\": consider a python error trace that has Plugin#main.py line 32 > ZeroNetCore#db.py line 101: the error could be either in the Plugin that calls a function of db.py in the wrong way, or of ZeroNet Core that does crash when given a valid request.\r\n\r\nThis could be done only after changing plugin architecture and writing \"contracts\" about what can be passed to a ZeroNet function. I can only think of doing it with Python3 type annotations.\r\n\r\n-----\r\n\r\nSo i will rephrase this issue, adding a possible way to add automatic error report to ZeroNet:\r\n- On every catched error, write the stack trace along with some other informations to a local file of the user.\r\n- Ask the user if he wants to report such an error to the ZeroError site.\r\n- Submit to the site only the stack trace, and if the programmer (HelloZeroNet at the moment) asks for more details the user could be prompted to send encrypted the other informations with the stack trace (that could be the whole execution log, and the values of the variables occurring in the functions along the stack trace)", "added": 1539530247, "modified": 1539530247, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1553#issuecomment-429649149", "source_type": "github"}], "1604066700_mirrored_trenta3_github": [{"comment_id": 41, "body": "Thank you, I've also found the method `src/lib/pybitcointools/bitcoin/main.py#ecdsa_recover` which does exactly this.", "added": 1535656128, "modified": 1535656128, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1554#issuecomment-417483181", "source_type": "github"}], "1604066722_mirrored_trenta3_github": [{"comment_id": 42, "body": "Well one could include a JS interpreter in Python, like [jispy](https://github.com/polydojo/jispy), [pyduktape](https://github.com/stefano/pyduktape) or [pyMiniRacer](https://github.com/sqreen/PyMiniRacer) (found with a fast google search).\r\n\r\nI think the added value of this could be limitless.\r\nWe could extend such idea to execute scripts from sites in a sandboxed environment / interpreter at various actions to add many way to get the sites to be interactive.\r\n\r\nFor example, ZeroMail could execute a script that decodes new mail each time a new file arrives and if they are for the current user, it could notify him in some way.\r\n\r\nBy the way, I'm just using the issue to drop random ideas, hoping that someone (even myself) will then come along and implement code for them.", "added": 1536249264, "modified": 1536249264, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1570#issuecomment-419203902", "source_type": "github"}, {"comment_id": 43, "body": "@imachug I see only now your reply. I like the idea a lot. I think we should take some time to design an easily extensible system to have scripts executed when some actions occur.\r\n\r\nI could only think of \"new file received\" event, but there should be a lot of others.\r\n\r\nJust a question: if we resolve to adding that to BackgroundProcessing, will each site execute its own thread? Can it be set up as to have a single execution thread that dedicates a small amount of time to each site? (I'm obviously more in favour of the second solution)", "added": 1536249703, "modified": 1536249703, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1570#issuecomment-419206152", "source_type": "github"}, {"comment_id": 44, "body": "Concerning untrusted code, we could use an external project that has been\ntested extensively.\n\nI don't understand what do you mean by executing in the browser.\nTo open a page and let it do the processing stuff and then retrieve the\nresult in some way? I think this could make processing updates very slow\n(given the usual time needed to load a page) and could in the next future\nimpair scaling.\n", "added": 1536256085, "modified": 1536256085, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1570#issuecomment-419236133", "source_type": "github"}], "1604066724_mirrored_trenta3_github": [{"comment_id": 45, "body": "I tried writing an example for the code, but it does not work as it is.\r\nThe problem is that the field \"wsgi.input\" (where post data is found) is not transferred from UiRequest (where the initial request really is) to UiWebSocket (where the request to \"getPostData\" really happens).\r\n\r\n```patch\r\ndiff --git a/src/Ui/UiWebsocket.py b/src/Ui/UiWebsocket.py\r\nindex b6e7615..7c616a4 100644\r\n--- a/src/Ui/UiWebsocket.py\r\n+++ b/src/Ui/UiWebsocket.py\r\n@@ -338,6 +338,12 @@ class UiWebsocket(object):\r\n \r\n     # - Actions -\r\n \r\n+    # Returns the request body\r\n+    def actionGetPostData(self, to):\r\n+        # TODO: Here we don't have wsgi.input cause this is the request to the websocket\r\n+        input_data = self.request.env[\"wsgi.input\"].read()\r\n+        return self.response(to, input_data)\r\n+    \r\n     def actionAs(self, to, address, cmd, params=[]):\r\n         if not self.hasSitePermission(address, cmd=cmd):\r\n             return self.response(to, \"No permission for site %s\" % address)\r\n```\r\n\r\nShould I add a field to the UiServer to store post data?\r\nHow should I proceed?", "added": 1536392282, "modified": 1536393581, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1571#issuecomment-419631270", "source_type": "github"}, {"comment_id": 46, "body": "Ok, now I can't really think of a use case where reading post data should be necessary.\r\nI'm going to close this issue if noone comes out with a reasonable one.", "added": 1536400311, "modified": 1536400311, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1571#issuecomment-419639921", "source_type": "github"}], "1604066733_mirrored_trenta3_github": [{"comment_id": 47, "body": "I personally do not understand why there is this \"no-comment-approach\" to having documentation.\nIt seems to me that requests for developer documentation are continuous in this repo.\n\nYet, after first asking Hellozeronet to provide some form of contributing guidelines and then sending this pull request also to give a starting Point from where to discuss the different possibilities, I've not received a single reply.\n\nWithout documentation this project is not going to get its deserved user community.\nI would then kindly ask @HelloZeroNet to say something in this regard. ", "added": 1543158278, "modified": 1543158278, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1577#issuecomment-441459770", "source_type": "github"}], "1604066829_mirrored_trenta3_github": [{"comment_id": 48, "body": "Yes, I do have it.", "added": 1538645189, "modified": 1538645189, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1649#issuecomment-426999236", "source_type": "github"}, {"comment_id": 49, "body": "I'm closing this issue because I no longer see such messages after having updated to rev3688.", "added": 1541673697, "modified": 1541673697, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1649#issuecomment-436997218", "source_type": "github"}], "1604066928_mirrored_blurHY_github": [{"comment_id": 50, "body": "Please see #1553 in this regard.", "added": 1539528873, "modified": 1539528873, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1715#issuecomment-429647228", "source_type": "github"}], "1604067015_mirrored_trenta3_github": [{"comment_id": 51, "body": "@HelloZeroNet Yes, I stated this as write-once updates since it is more easily done and is functionally equivalent to having append-only updates, since sites could specify to source db rows from `\"data-.*\\.json\"` instead of the current `\"data\\.json\"`.\r\n\r\nOf course having (also) append-only updates better suits this need, and can be as easily implemented checking if the diff updates are only adding lines, but I think it could not work in some cases:\r\nFor example, when the diff is too large (or other peers do not have that specified version) and therefore ZN fallbacks on sending the whole file update.\r\n\r\n  I think that the receiving peer, after having checked the sign of the update, should by itself compute the diff between the two versions and only accept if the diff shows only char/lines being appended.\r\n  Checking the sign before diffing has to be done in order not to be subject to special DoS attacks (since [diff computation is worst-case quadratic time according to difflib](https://docs.python.org/2/library/difflib.html)). \r\n\r\nMy proposal is to wrap all of this update-check logic into a plugin to separate it from the core and make it more easily \"tunable\" in the future. For example, one might want to specify some sort of ACL inside the content.json that separates the insertion of records from the deletion (always using diff sequences).", "added": 1544106947, "modified": 1544106947, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1793#issuecomment-444960251", "source_type": "github"}, {"comment_id": 52, "body": "Ok I hadn't thought about these efficiency issues. I think the only valid idea is the one that allows only append updates to json files. When you receive an update, just diff it with what you have and if it only appends lines, then it is ok.\r\n\r\nAnother (and possibly more appropriate) way would be to parse the json file and allow it only if it adds some objects inside a key.\r\nSince most json files are written as:\r\n```\r\n{\r\n  \"topics\": [\r\n    { ... },\r\n    { ... }\r\n  ]\r\n}\r\n```\r\nthis would have the same effect without having to deal with \"lines\" which are a fragile concept.\r\n\r\nI think that we could also add both and see what is the better one, since I think there could be some usecases where the line-based will still be preferred.", "added": 1544686843, "modified": 1544686843, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1793#issuecomment-446922476", "source_type": "github"}, {"comment_id": 53, "body": "I'm partially against that: having the data in the filesystem in simple formats is more human readable and understandable that having only a database file with everything inside.\r\nMoreover, I've seen many database corruption since I've started using ZeroNet. What would happen when it happens?\r\n\r\nAlso possibly the only way to sync rows is to have an SQL database implementation in python and sneak in some hooks on rows update and insert. This is a point in favour since it would delete the asymmetry between inserting rows and reading the database, but I think proper care must be taken to prevent data loss by database corruption.", "added": 1544714060, "modified": 1544714060, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1793#issuecomment-447067137", "source_type": "github"}], "1604067037_mirrored_blurHY_github": [{"comment_id": 54, "body": "@HelloZeroNet It can be changed. Are you against having System notifications?\r\nThey can have an opt-out in the Config page.\r\n\r\nMoreover, I've done some research and it seems that [plyer](https://github.com/kivy/plyer), a python library with MIT license, does cross-OS notification (Win, Mac, Linux and Android).\r\n\r\nIt allows a notification to be sent in a couple of lines of code:\r\n```python\r\nfrom plyer import notification\r\n\r\nnotification.notify(\r\n    title=\"Notification title\",\r\n    message=\"Long message of the notification\",\r\n    app_name=\"Name of the app\",\r\n    app_icon=\"Path to the icon to display with the notification\",\r\n    timeout=10, # Number of seconds before it disappears\r\n    ticker=\"Text to display on status bar as the notification arrives\"\r\n)\r\n```", "added": 1544108400, "modified": 1544108400, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1801#issuecomment-444968096", "source_type": "github"}, {"comment_id": 55, "body": "Ok, I misunderstood it. I think that such a thing should be voted by the users, since it could be useful to have notification also when browser is closed (maybe also as opt-out).", "added": 1544110335, "modified": 1544110335, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1801#issuecomment-444979313", "source_type": "github"}], "1604067021_mirrored_Thunder33345_github": [{"comment_id": 56, "body": "You can see Nanasi text board\nhttp://127.0.0.1:43110/16KzwuSAjFnivNimSHuRdPrYd1pNPhuHqN/ to see it\nimplemented.\nBasically each user creates a certificate in the browser and can then use\nit to sign messages.\n\nIl giorno lun 10 dic 2018 alle ore 12:15 ZeroNet <notifications@github.com>\nha scritto:\n\n> you can already create self-signed certificates in the browser, which is\n> same as you described.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/HelloZeroNet/ZeroNet/issues/1812#issuecomment-445780431>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AKU8EUNW8MEbVrLgaTIbH8yhnit4-Bxhks5u3kJCgaJpZM4ZLFFS>\n> .\n>\n", "added": 1544441983, "modified": 1544441983, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1812#issuecomment-445838024", "source_type": "github"}, {"comment_id": 57, "body": "@Thunder33345 In your site you could choose to not display `cert_user_id`, but show the `auth_address` instead. This way `cert_user_id` would not have any significance in the displayed text.\r\n\r\nWhile this could be enforced by the backend, it is already doable.\r\nUnless there is something else I'm not getting, it should do.", "added": 1544457014, "modified": 1544457058, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1812#issuecomment-445927853", "source_type": "github"}, {"comment_id": 58, "body": "> i guess this is actually doable, why make that if something else works [...]\r\n> for the \"too many self sign certs\", who cares i guess who did anyways?\r\n> \u00af\\_(\u30c4)_/\u00af\r\n\r\nYou seem a little bit ironic in your reply. If there is something that enhances ZeroNet and that is not already provided I'm with you, but you should explain it clearly. On the other hand, the way of thinking \"this is doable, don't make it because something else works\" is actually useful to keep ZeroNet core code as small as possible (it helps readability, vulnerability analysis, etc.).\r\n\r\nIf I sounded rude before, please excuse me.\r\nI write here just to add my two cents (this time to signal an existing implementation from which to learn), and the one who really decides what gets implemented at the end is @HelloZeroNet ", "added": 1544461573, "modified": 1544461573, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1812#issuecomment-445953876", "source_type": "github"}], "1604067028_mirrored_Thunder33345_github": [{"comment_id": 59, "body": "We could adopt a memory-bounded hashing function to provide such guarantee of equalities between users.\r\n\r\nThe idea is that both ASIC and GPU have very little RAM on-board, smaller than that of the Level2 cache of many processors (about 2MB), so that picking an hashing function that has to use a couple of megabytes of RAM to compute will have similar computing times no matter with which devices it is computed.", "added": 1544702512, "modified": 1544702528, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1815#issuecomment-446999326", "source_type": "github"}, {"comment_id": 60, "body": "Some other considerations and questions about the idea, that by the way is really interesting since it seems to add far greater inequality (1:1000000) between real people and spammer by using something that humans can do and machines almost can't.\r\n\r\n1. What if the user publish an image that does not contain the real solution to the hash, rendering it unguessable? This could prevent others from posting their own post, if many people are doing this.\r\n2. Once a user solves the hash, does he publish the solution for everyone? If it is so, imachug attack could be much more effective by using the fact that each user that post a message gives a solution to a specific captcha.\r\n3. How to defend from OCR? Note that even if they don't exactly guess all of the characters in the image, a reduced bruteforce in which only a single letter is changed with all possible replacements should solve a high percentage of CAPTCHA.\r\n\r\n### Considerations\r\nThe CAPTCHAs should be lenghty enought and have salt so that a simple bruteforce is unviable (without salt and CAPTCHAs length <= 10 it should be possible to solve all of them [since they are unsalted] in about a week with a GPU)\r\n\r\n## Proposed solutions\r\n- To 1: we should have CAPTCHA providers that generate various sets of CAPTCHAs\r\n- To 2: Can't be really mitigated with simple techniques. A viable (but possibly costly to implement) alternative could be using a ZkSNARK to prove to others that you have a word whose hash is the desired one, without revealing such word.\r\n- To 3: This seems to me the fastest attack since it lets you solve all the CAPTCHAs in little time. We must check how much good are OCR now. A possible solution will be to find some other task with a definite answer (like: you can check if the user answered correctly automatically, but a machine should strive to get it done) that is easy for all humans and hard for machines.\r\n- For imachug \"Birthday paradox attack\": we should get a PoW that is more equal to calculate among device, using memory-bounded hashing function, for example CryptoNight or similar ones underlying some famous cryptocurrency just to be sure that no ASICs are possible with current techniques (since otherwise they would have done it into the market), noting that regular users still have to calculate many of them to match the last five digits of the message hash.", "added": 1544947644, "modified": 1544947644, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1815#issuecomment-447634509", "source_type": "github"}, {"comment_id": 61, "body": "@imachug I didn't know there were zksnarks for Javascript already available! In this way one could have trusted parties (external sites) specialized in captchas and with some fixed amount of them (like some millions).", "added": 1545480542, "modified": 1545480542, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1815#issuecomment-449576719", "source_type": "github"}], "1604067030_mirrored_klueq_github": [{"comment_id": 62, "body": "As of now, you need a site admin to moderate spam.\r\nBut what you want is still possible: you can create a site that lists the category sites, so for example that says that \"books/1.2.3\" has some site address.\r\nThis way all peers wanting to use your catalogue, will simply go to the main site and then select the topics that interests them and can add the book to the storage (you could allow to add only optional files).\r\n\r\nIf you want to not have a private key you could destroy it and prove to other people that you have destroyed the key. For example: organize a meeting in which you deploy the site and then delete the private key of the site, maybe by destroying the physical support (for example run that copy of ZeroNet on a USB key).\r\n\r\nOr better you could generate the key by some [Distributed Key Generation](https://en.wikipedia.org/wiki/Distributed_key_generation) and then after deploy the site have each party that helped you in creating the key to delete their own copy. If at least one of them deletes it the site is \"safe\".\r\n\r\nPlease note that if you delete a privatekey you won't be able to update the site and so to protect it from code vulnerabilities, may them be found. So I strongly advise you to delete the privatekey only on sites that only host peer data, and that don't have any code.", "added": 1544686238, "modified": 1544686238, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1820#issuecomment-446919480", "source_type": "github"}], "1604067031_mirrored_gerardo-junior_github": [{"comment_id": 63, "body": "I would only like to add that, if implemented, we should store the blobs encrypted with a password that only the user knows and that he inserts at program start. The program uses this password to decrypt the files stored locally (this is also kind of helpful to protect against malware trying to steal one's sites privatekeys).\r\n\r\nThe other suggested way of having a password per site \u00e0 la Freenet that the users send each other simply (in my opinion) does not protect oneself against incrimination for illegal content since the password is available to each one that asks for it from other peers (and so also is available to the controlling authorities that can decrypt the content by themselves).\r\n\r\nThis option should also be at least opt-out since in some countries even encrypting something can be dangerous and/or there are consequences if one refuses to give the encryption passphrase to authorities when asked to.", "added": 1544875270, "modified": 1544875270, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1821#issuecomment-447574539", "source_type": "github"}], "1604067129_mirrored_rllola_github": [{"comment_id": 64, "body": "Git Center does something that solves the problem: you can create a\nstandard site with the merged_type of your merger-site (We will call it the\nindex site) and add it automatically when the user first enters your site\n(ZeroNet code allows to add a site every ten seconds without asking the\nuser, from what I remember reading in the code). In this way you can write\nand read the information you wish to the index site. The only boring thing\nis that you have to hardcode its address in your code and remember to\nexplicitly skip it if you are considering doing some action on all the\nsites with your merged_kind.\n\nPossibly it is not allowed to store additional data in merger-site because,\nbeing a site made to scale, one could have many possible indexing sites and\ndifferent people may be interested in different indices.\nTherefore I reccomend you to follow GitCenter solution and if your site\ncould need different indexes, to find a way to recognize them when the user\nadds one (for example by prefix or by something written in the\ncontent.json) and save that information in the ZeroNet localstorage. This\ncomplicates a bit the coding, but gives your users much more flexibility in\nusing your site (and doing it now is better than later, when you will have\nto recode many parts of the site to work this way).\n\nIl giorno sab 2 feb 2019 alle ore 21:58 Lola Dam <notifications@github.com>\nha scritto:\n\n> I have a merger-site kind of site and I would like to create a table with\n> an index of all the merger-site compatible. I don't think it is possible to\n> do that ? It seems to skip the json with data. I am right ? This is not\n> allowed ?\n>\n> I think of creating another kind of merger-site with those data. Is it the\n> way of doing it ? It would also mean that the user have to accept it and I\n> kind of wanted to avoid that and have the data available with the site.\n>\n> Cheers,\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/HelloZeroNet/ZeroNet/issues/1886>, or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AKU8EW3dFT7VhBouaFt5XevvxqJWlutGks5vJfvegaJpZM4afyP2>\n> .\n>\n", "added": 1549178424, "modified": 1549178424, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1886#issuecomment-460039543", "source_type": "github"}]}, "next_topic_id": 22, "topic": [{"topic_id": 1604066559, "title": "Background tasks/services?", "body": "Is there any way to execute background tasks or services (with user permission) that persists even after the user closes the page (i.e. they are executed by the ZeroNet daemon)?\r\n\r\nIt would be awesome to have it (the ability to execute and talk with a piece of Javascript code that is runned by the daemon) as it would have many useful applications including:\r\n* A torrent client using [WebTorrent](https://webtorrent.io/)\r\n* The possibility to have custom (per site) DHT to distribute part of site contents that only needs random access (e.g. images in ZeroTalk discussion threads or more generally optional files)\r\n* Other kind of work during which the user does not need to have the page of the site open\r\n\r\nIf there is no such way, is it a thing that would be useful in your opinion?\r\nIf the opinions are positive, I might implement it (I think as a Plugin is more appropriate).\r\nPlease let me know if it is a good thing or not.\r\n\r\nNote that I'm aware of HTML Web Services but they do \"expire\" after the user closes the page or navigates away.", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1528129351, "modified": 1543158674, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1447", "source_type": "github"}, {"topic_id": 1604066571, "title": "Support virtual sqlite3 tables in dbschema.json", "body": "Sqlite has two very useful extensions: [Full Text Search](https://www.sqlite.org/fts5.html) and [Spellfix search](https://www.sqlite.org/spellfix1.html) that could make searching on Zites more meaningful and very fast.\r\n\r\nLooking briefly at files in `src/Db`, I think that it would be a very short change to enable virtual tables: One could just modify a couple of lines in the function [`createTable@DbCursor.py`](https://github.com/HelloZeroNet/ZeroNet/blob/master/src/Db/DbCursor.py#L106-L114).\r\n\r\nSo a new virtual table using fts5 could be defined as\r\n```\r\n\"fts_posts\": {\r\n    \"virtual\": true,\r\n    \"payload\": fts5(title, body, uuid UNINDEXED)\",\r\n    \"schema_changed\": 1\r\n}\r\n```\r\nthat would be translated into `CREATE VIRTUAL TABLE fts_posts USING fts5(title, body, uuid UNINDEXED)`. Update and delete queries works as in a standard table.\r\n\r\nIt is indeed true that such extensions are optional, but since ZeroNet ships with its built version of sqlite3 I think we can make sure such extensions are enabled.", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1529239247, "modified": 1529511478, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1456", "source_type": "github"}, {"topic_id": 1604066592, "title": "Feature request: Archival Plugin", "body": "It would be very good to have a Plugin for archiving content on the local hard disk:\r\n\r\n*Usage example*: ZeroMail has the downside that if the person who has sent me the mail needs space, he will delete his message that will shortly after deleted also from my account.\r\n\r\nIf we had such a plugin, the sites could ask the permission to use some local HD space to save every mail that I receive and only delete them if I want to.", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1530611463, "modified": 1534802985, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1472", "source_type": "github"}, {"topic_id": 1604066641, "title": "Discussion on Feature request: Document Unit specification", "body": "# Proposed Feature\r\nAdd a way to specify what the document unit (i.e. informations that are in a single page) for each site is. To explain it better I'm going to use ZeroTalk as an example, but first:\r\n \r\n## Why do we want such a thing?\r\n* For a possible search engine: to be able to index documents by document unit for each site (this would allow not to scrape html pages, be able to only index actual content rather than fixed header/footer/menu and allow it to be very fast, since it would only need to do some queries to the database)\r\n* For possibly archiving sites: for example after a month that a topic has no more replies (the document unit ids do not change) simply move those \"lines\" to another site (impossible to do at current state)\r\n\r\n## Example of proposed `docunit.json` for ZeroTalk\r\n```\r\n{\r\n    \"unit_topic\": {\r\n\t\t\"url\": \"?Topic:<topic_id:int>\",\r\n                \"id_list\": \"SELECT topic_id FROM topic\",\r\n\t\t\"db_lines\": {\r\n\t\t\t\"topic\": \"SELECT topic_id FROM topic WHERE topic_id = :topic_id\",\r\n\t\t\t\"comment\": \"SELECT comment_id FROM comment WHERE topic_uri = :topic_id\",\r\n\t\t\t\"comment_vote\": \"SELECT ...\",\r\n\t\t\t\"topic_vote\": \"SELECT ...\"\r\n\t\t}\r\n    }\r\n}\r\n```\r\n### Explanation of the above stub\r\nThe global object has one key for each \"type of document unit\" (ZeroTalk has only one kind, i.e. topics, but a size could have many). For each of these we have three compulsory keys:\r\n* `url`: That gives the url (relative to the site one) to get to view that document unit (useful for search engines, but also can be used in reverse: when we are visiting a page and want, as an example, to locally save the content in it for archival purposes, we could parse the url we are in and use the parameters in it to get the important lines in each of the database table).\r\n  The parameters are in the form `<param_name:param_type>`: param_type is useful for parsing, and param_name for referring at it, both in the `id_list` and in `db_lines`.\r\n* `id_list`: Database query to select the valid values for parameters (i.e. to get all of the topics the site currently has). The returned table must return under the column `param_name` the possible `param_value`s.\r\n* `db_lines`: This is an object, where the keys are the database tables and the values are the database queries that return the ids identifying the objects pertaining to that document unit.\r\n\r\nI'm not so good at explaining things, as you can see by reading the above stuff. I hope it is clear enough. If not, do not hesitate to ask.\r\n\r\n#### Possible proposed parameters for url\r\n* `<integer:int>`: `/[0-9]+/`\r\n* `<string:str>`: `/[a-zA-Z0-9\\_\\-]+/` (may be changed to account for alphanumeric characters in other languages, diacritics, ...)\r\n* `<everything:all>`: Matches the whole url parameter\r\n\r\n## Pro and Cons\r\n**Pro**:\r\n* No need to write code to have it done, just need to agree on a format for it, so *please add your two cents* and propose improvements and other possible use cases for the format.\r\n\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1534658070, "modified": 1535291924, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1513", "source_type": "github"}, {"topic_id": 1604066677, "title": "Feature request: Selfdestroying / temporary updates", "body": "# What\nAllow users and site owner to specify how long a `.json` file should be retained. After such amount of time, an automatic deletion should be performed by each ZN client.\n\n# Use cases\nIn ZeroMail send each mail in a separate file and globally set them to be canceled after e.g. 1 month. This allows the other party to receive the email, and with the archival plugin to have it permanently, while at the same time not cluttering the global hard disk space of everyone.\n\nThis could be the scaling solution for all sites where users put some data just to rely on their continuous presence online, but the data is only  useful for some of the other users or for a Limited amount of time (for example a user run news site or a board Like zeroboard or for temporary notes on nullpaste)\n\n# Possible problems\nThere should be a clock that is agreed upon or one can simply let each client use it's own (in ZN code there is already some points where it is assumed that the client clocks are not too far from each other, i.e. Within one day)\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1535451873, "modified": 1541794498, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1541", "source_type": "github"}, {"topic_id": 1604066679, "title": "Added noclone suffix for files that should not be cloned", "body": "This commit should solve issue #1528\r\ni.e. this does not clone files or directories which have \"-noclone\" in their names.\r\n\r\nI've tested the patch on a couple of sites but I couldn't understand how to adjust the asserts in the Test folder. This means tests for the patch are missing.", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1535472870, "modified": 1541159897, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1542", "source_type": "github"}, {"topic_id": 1604066684, "title": "Enhancement: Add description when adding permission", "body": "A lot of permissions (I don't know the exact list of which are available) don't have any description.\r\nFor example the permission `Merger:___` says nothing about it, and as a user the first time I saw it in GitCenter I did not know what I was granting...", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1535537901, "modified": 1535576173, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1545", "source_type": "github"}, {"topic_id": 1604066689, "title": "Feature Request: Add URL rewriting to sites", "body": "Allow each site to specify an URL rewriting scheme in `content.json`.\r\nProposed syntax:\r\n```\r\n\"rewrite_rules\": [\r\n    { match: \"files/.*\", terminate: true },\r\n    { match: \"(.*)\", replace: \"index.html?url=\\1\", terminate: true },\r\n]\r\n```\r\n\r\nThe rewriting rules are:\r\n* The URL which is checked to match against the regexp is the part after the site address, non including initial backslash.\r\n* The matching rules are applied recursively until one with `terminate = true` is found. The first matched rule is the one which is applied at each step, each time starting from the first one.\r\n* If the `replace` key is missing the returned string is not modified.\r\n\r\nThe final url should be then internally rendered and such page returned.\r\nThere should not be any html redirect.\r\n\r\nIf after 100 rewrites the url did not find a terminate condition, the site will log an error and the original request will be made.", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1535546052, "modified": 1535550146, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1548", "source_type": "github"}, {"topic_id": 1604066691, "title": "[Testing] Added basic URL rewriting to sites", "body": "Solves issue #1548 \r\nPlease note that the currently implemented form differs slightly from the specifications in the issue\r\n\r\nUsage example: in content.json add the key rewrite_rules:\r\n```\r\n\"rewrite_rules\": [\r\n  {\r\n   \"match\": \"index.html\",\r\n   \"terminate\": true\r\n  },\r\n  {\r\n   \"match\": \"files/.*\",\r\n   \"terminate\": true\r\n  },\r\n  {\r\n   \"match\": \"(.*)\",\r\n   \"replace\": \"index.html\",\r\n   \"replace_query_string\": \"url=$1\",\r\n   \"terminate\": true\r\n  }\r\n ]\r\n```\r\n\r\nNow the requests are transformed as follows:\r\n```\r\nindex.html?x=5 --> index.html?x=5\r\nfiles/example.txt --> files/example.txt\r\nexample.html --> index.html?url=example.html\r\nexample.html?x=5 --> index.html?url=example.html\r\n```\r\n\r\nCaveats:\r\n* `match` is mandatory, `terminate` defaults to false, `replace` and `replace_query_string` defaults to the global match\r\n* The URL to be checked agains `match` is only the part after the site address, not including the initial backslash and not including the query string\r\n* `replace` is the expression to replace the base part\r\n* `replace_query_string` is the expression to replace the query string part\r\n* There is no way as of now to preserve query string parameters in rewriting", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1535556411, "modified": 1539528997, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1549", "source_type": "github"}, {"topic_id": 1604066694, "title": "Why is the documentation in another repository?", "body": "I think that documentation should be in this repo, in a `docs` folder.\r\nThis could help in that when issuing PRs, one could at the same time update the documentation.\r\nIs there a reason for the current situation?", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1535556652, "modified": 1535556652, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1550", "source_type": "github"}, {"topic_id": 1604066698, "title": "[Enhancement] Automatic Error Reporting, for ZeroNet, for Plugins and for Sites", "body": "It would be great to add automatic error reporting for ZeroNet core, for Plugins and for Sites.\r\n\r\nBasically there should be a site that clients automatically report errors to, when they occurr with a standard ZeroNet/Plugin/Site version (we could check in some way that the user did not customize it).\r\n\r\n* Each Plugin/Site specifies a site address to which errors are reported\r\n* In such site errors are aggregated according to stack trace and to ZN/Plugin/Site version and the information found in the debug page is written to it, encrypted to the site owner/moderators\r\n* Such sites could be hidden from the user view and be given an higher default space limit\r\n* On error one could possibly redirect the user to the page of its error report and ask him to add some comments\r\n* The user could be notified about possible comments or requests of site owner/moderators\r\n\r\n## TODOLIST\r\n- [ ] Create example site that can be cloned and to which reports can be submitted \r\n- Insert error handler and submitter in\r\n  - [ ] ZeroNet core\r\n  - [ ] Plugin\r\n  - [ ] Sites `content.json` key `error_report_address`\r\n\r\n----\r\nSidenote: obviously the site should be named \"ZeroError\"", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1535617720, "modified": 1539592484, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1553", "source_type": "github"}, {"topic_id": 1604066700, "title": "Is there a way to obtain user public key given its address?", "body": "I know that the address of a site / user is an hash of its public key, and therefore the point on the elliptic curve cannot be recovered from it alone.\r\n\r\nI want to know what function in ZeroNet allows me to get user public key.\r\nI think there should be one such method because it is mandatory to have the public key in order to verify signatures as for ECDSA.\r\n\r\n@HelloZeroNet @shortcutme ", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1535652112, "modified": 1535656128, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1554", "source_type": "github"}, {"topic_id": 1604066722, "title": "[Feature request] Allow sites to be able to specify if an update is valid or not", "body": "# What?\r\nAllow sites to specify javascript code to check that a valid update has been received.\r\n\r\nIn `content.json` add field `update_verifier` which value should be a valid javascript file with a function `verify_update` which gets as parameter the path and the content of the modified file and can read other files using `fileGet`. The result is a boolean specifying wheter the update is valid or has to be rejected.\r\n\r\n# Why?\r\nThis can be useful if, for example, we want to ensure that peers only send valid json files, or to restrict modifications to a database table only by some trusted entities...\r\n\r\nAt the same time, it is not the most desirable solution...", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1536230939, "modified": 1536285132, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1570", "source_type": "github"}, {"topic_id": 1604066724, "title": "[Enhancement] Possibility for a page to access post data", "body": "Especially useful if we really want to have Error-collection sites as per #1553, since GET request length has limits for some browsers.\r\nZeronet should insert that as a page special variable or send it to the page on request (e.g. `getPostData`). \r\n\r\n[A reference for url length](https://boutell.com/newfaq/misc/urllength.html)", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1536237886, "modified": 1543158346, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1571", "source_type": "github"}, {"topic_id": 1604066733, "title": "[Ready to be merged] Example of documentation folder inside the repository, with template for new entries", "body": "Related to issue #1550 \r\n\r\nA simple example of a documentation folder with an explanation of folder structure and a template for documenting new functionality.\r\n@HelloZeroNet Please provide feedback", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1536327197, "modified": 1543158278, "source_link": "https://github.com/HelloZeroNet/ZeroNet/pull/1577", "source_type": "github"}, {"topic_id": 1604066749, "title": "Allow complex node paths in `dbschema.json`", "body": "```\r\nIn `maps`, `*/data.json`, `to_table`:\r\n{\r\n  \"node\": \"topics\", # Allow more complex paths in form of array\r\n   # \"node\": [], --> The whole file object has to be used in the table\r\n   # \"node\": [\"main\", \"topics\"] --> The node data[\"main\"][\"topics\"] has to be used\r\n  \"table\": \"topic\"\r\n}\r\n``` \r\n\r\nSimply allow `to_table:node` to be either a string or an array of strings.\r\nIn case of the array the multiple strings specify the path from the root to reach the target to include in the table.\r\n\r\nThis would allow to use frameworks that natively store namespaced data (i.e. path of two nodes) as for example does [Mavo](http://mavo.io).", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1536563906, "modified": 1536721992, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1588", "source_type": "github"}, {"topic_id": 1604066773, "title": "[Discussion] New plugin system", "body": "Moving the discussion from the PR #1430 (read from [this comment](https://github.com/HelloZeroNet/ZeroNet/pull/1430#issuecomment-420003512) onwards) to here.\r\n\r\n*Topic*: How to write a plugin architecture for ZeroNet in such a way that everyone can install plugins from \"plugin store\" in sites?\r\n\r\n*Possible choices* are to have one-click install with current plugin system, change plugin system to a more modular one, and to sandbox plugin execution in some way.\r\n\r\nPlease read the other PR before writing here.", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1536911120, "modified": 1544268461, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1607", "source_type": "github"}, {"topic_id": 1604066829, "title": "verify sign error: AttributeError: 'NoneType' object has no attribute 'get'", "body": "### Step 1: Please describe your environment\r\n\r\n  * ZeroNet version: 0.6.3 r3612\r\n  * Operating system: Debian GNU/Linux\r\n  * Web browser: Chrome 67.0.3396.79 (64-bit)\r\n  * Tor status: disabled\r\n  * Opened port: no\r\n\r\n### Step 2: Describe the problem:\r\nThe error below presents itself multiple times and for various sites. There is no apparent problem, but I think it is worth to signal it.\r\n\r\nBelow there are a couple of such error messages, but I have lots of these concerning ZeroMail:\r\n```\r\n[12:23:35] Site:1MaiL5..Ju27 data/users/16Tc8fJMB7GW92WzWxPd8omozQzH1JSu5Z/content.json: verify sign error: AttributeError: 'NoneType' object has no attribute 'get' in ContentManager.py line 913 > ContentManager.py line 749\r\n[12:46:59] Site:1TaLkF..jipT data/users/1PFWGebEqZssXXnM9u2gk7yJpXUoMPQG8D/content.json: verify sign error: AttributeError: 'NoneType' object has no attribute 'get' in ContentManager.py line 913 > ContentManager.py line 749\r\n[12:23:30] Site:1MaiL5..Ju27 data/users/1LtMKKnifXoSsbhPpXbQGsWgj9txdMsx3w/content.json: verify sign error: AttributeError: 'NoneType' object has no attribute 'get' in ContentManager.py line 913 > ContentManager.py line 749\r\n[12:23:30] Site:1MaiL5..Ju27 data/users/14F4FTRqKvRSdmxGU7SDje4Y5EuGYbTrU8/content.json: verify sign error: AttributeError: 'NoneType' object has no attribute 'get' in ContentManager.py line 913 > ContentManager.py line 749\r\n[12:23:30] Site:1MaiL5..Ju27 data/users/17QRUNRyn7y42DR9vUvmpWrZ1eALbQEeiM/content.json: verify sign error: AttributeError: 'NoneType' object has no attribute 'get' in ContentManager.py line 913 > ContentManager.py line 749\r\n[12:23:30] Site:1MaiL5..Ju27 data/users/1KKPDUfTwTVyoac63vRuMPLEN6LZvUZ3rx/content.json: verify sign error: AttributeError: 'NoneType' object has no attribute 'get' in ContentManager.py line 913 > ContentManager.py line 749\r\n[12:23:30] Site:1MaiL5..Ju27 data/users/14TDWFVHuTXNcg8pp6LRr7v9ZcfbFsMSyx/content.json: verify sign error: AttributeError: 'NoneType' object has no attribute 'get' in ContentManager.py line 913 > ContentManager.py line 749\r\n[12:23:30] Site:1MaiL5..Ju27 data/users/15PQoR1HKmZrndc4s6FYr2gRDjTAH6pv12/content.json: verify sign error: AttributeError: 'NoneType' object has no attribute 'get' in ContentManager.py line 913 > ContentManager.py line 749\r\n[12:23:30] Site:1MaiL5..Ju27 data/users/1F29P9HzhCJSYikBSKATJTDvXU9nDbnV3R/content.json: verify sign error: AttributeError: 'NoneType' object has no attribute 'get' in ContentManager.py line 913 > ContentManager.py line 749\r\n[12:23:30] Site:1MaiL5..Ju27 data/users/1BBE25z3gPfPN7ZpWVF5ymPrR7yEFMj824/content.json: verify sign error: AttributeError: 'NoneType' object has no attribute 'get' in ContentManager.py line 913 > ContentManager.py line 749\r\n[12:23:30] Site:1MaiL5..Ju27 data/users/19rnQdzRSHq4YZ2PUfvnhn4mophYt2PGgj/content.json: verify sign error: AttributeError: 'NoneType' object has no attribute 'get' in ContentManager.py line 913 > ContentManager.py line 749\r\n[12:23:30] Site:1MaiL5..Ju27 data/users/12ETjYdAqyFq3T1LxfE4NwKwWkB1D4QZ54/content.json: verify sign error: AttributeError: 'NoneType' object has no attribute 'get' in ContentManager.py line 913 > ContentManager.py line 749\r\n```\r\n#### Steps to reproduce:\r\nIt happens every time I start ZeroNet (originally downloaded with 0.6.2 Bundle and then upgraded to 0.6.3 r3621).\r\n\r\n#### Expected Results:\r\nNo errors of such type happened before, so I think that should not happen.", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1537689359, "modified": 1541673697, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1649", "source_type": "github"}, {"topic_id": 1604066873, "title": "[Question] ZeroFrame command to get IPv4 / IPv6 address of peers?", "body": "Is it possible for a site to get a list of the addresses peers the current client is connected to?\r\n\r\nThis would be very useful if one wants to use e.g. [Webtorrent](webtorrent.io), [GUN](gun.eco) (a graph database) or other in-browser things that require peer addresses to work properly. This would enable their use on ZeroNet, completely decentralized.\r\n\r\nDon't know if it has \"deanonimizing\" implications: e.g. one site may georesolve those IPs and guess our location, or something like that. In that case one could have such a feature on permission.", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1538751271, "modified": 1538756240, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1682", "source_type": "github"}, {"topic_id": 1604067015, "title": "[Feature Request] Force Write-once / Non-updatable Updates for some users", "body": "It would be nice to support in `content.json` a way to specify that some IDs are allowed to send updates / write files to that location but only once, i.e. peers should ignore future updates of that files coming from said IDs.\r\n\r\nThis could be useful:\r\n- in a write-once site, where users cannot censor themselves.\r\n- in zerowiki, where small updates could be saved as diff wrt others, without having to trust the original user to not delete its edit.\r\n- Implementing it in the syntax of content.json could also restrict the admin to change some part of a site after they have been written (also by having the content.json itself be subject to such a policy) which in turn could allow to create non-censorable sites (also by the owner himself) that would act as append-only logs.\r\n\r\nIn particular the last use could at least in theory solve #1288 and could partially solve some need for the more difficult site archival feature, since this one seems to be only a couple of line change.\r\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1543410576, "modified": 1544714060, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1793", "source_type": "github"}, {"topic_id": 1604067065, "title": "Redirect .bit domain in URLs to real site address", "body": "**Is your feature request related to a problem? Please describe.**\r\nRelated to link breaking (i.e. when clicking on a old link and the origin has changed)\r\n\r\n**Describe the solution you'd like**\r\nWhen a user visits `ZERONET/somesite.bit/page?query` the browser gets a redirect to `ZERONET/siteaddress/page?query` to ensure that if the users copy the URL and he posts it somewhere, years later the links points at least to the same site (obviously the content may have gone, but at least it won't point to some other site as is currently doing `zeroblog.bit` and other `.bit` domains that have expired meanwhile).\r\n\r\nGo visit http://127.0.0.1:43110/zeroblog.bit/?Post:5 to see if it is what you think...\r\n\r\nI think this breaks the links that many people have spread in the whole ZeroNet in a crappy way: I can stand the content being removed from site owner or the site not being served anymore (which are just physiological, for example if noone is interested in such content) but not the URL pointing now to some other content just because of the renewal rules of Namecoin...\r\n\r\nAlso the only harm the proposed solutions does is to make URLs more \"ugly\" but I think it is worth the added benefit of referential integrity... I'd also like to see other opinions on the topic", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1545583594, "modified": 1546442317, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/1832", "source_type": "github"}]}