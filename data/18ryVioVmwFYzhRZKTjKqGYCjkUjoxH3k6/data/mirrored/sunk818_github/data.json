{"cert_user_id": "sunk818@github", "next_comment_id": 6, "comment": {"1604064869_mirrored_Idealcoder_github": [{"comment_id": 1, "body": "Rather than deduplication, could you also copy file from other HelloZeroNet location to new location? Not deduplication, but at least a local copy will save bandwidth.\n", "added": 1434644814, "modified": 1434644814, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/115#issuecomment-113265342", "source_type": "github"}], "1604064883_mirrored_sunk818_github": [{"comment_id": 2, "body": "Hopefully, I can figure out how to apply the new code to the existing ZeroBundle. I take it the ZeroBundle is not part of the GitHub zip file, so I have take ZeroNet-master.zip and merge it with the existing files...?\n", "added": 1434719137, "modified": 1434719137, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/125#issuecomment-113558410", "source_type": "github"}], "1604064888_mirrored_sunk818_github": [{"comment_id": 3, "body": "I see. It seems to crash the client or makes it unusable. What about a way to disallow sites of a certain size, or a better way to handle it getting stuck? Long term, I wouldn't mind hosting/peering a 3GB site  if ZeroNet could could provide a way to handle it. You check for the overall size of a site... how about if the content.json is too big, you reject distributing the site for now?\n", "added": 1435150693, "modified": 1435190739, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/128#issuecomment-114924680", "source_type": "github"}, {"comment_id": 4, "body": "The thought is of making multiple ZeroNet addresses and breaking up the site into logical groups is definitely a better work around. Things like static blog publishing, or even torrent indexers could be published this way. You have the main address everyone comes to and say every month, the older content gets owned by a different address. My only concern there is how one goes about searching for content across different \"domains\".\n", "added": 1436584742, "modified": 1436584742, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/128#issuecomment-120583274", "source_type": "github"}, {"comment_id": 5, "body": "Hi, just revisiting this idea again.. I'm curious about your thoughts on open source publications such as scientific journals. Would we follow a particular subscription and those subscriptions merged into our Merger account?\n", "added": 1459770845, "modified": 1459770845, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/128#issuecomment-205334053", "source_type": "github"}]}, "next_topic_id": 5, "topic": [{"topic_id": 1604064883, "title": "Unhandled Exception", "body": "I get an unhandled exception when ZeroNet first starts up. I have a lot of sites I am trying to visit, especially the Mozilla Developer Network image. I think it choked on that, then I'm not sure what happened.\n\n```\nStarting ZeroNet/start.py...\n- Starting ZeroNet...\n[23:58:58] - Version: 0.3.1 r242, Python 2.7.9 (default, Dec 10 2014, 12:24:55) [MSC v.1500 32 bit (Intel)], Gevent: 1.0.1\n[23:58:58] - OpenSSL loaded, version: 01000201F\n[23:58:58] - Creating UiServer....\n[23:58:59] - Removing old SSL certs...\n[23:58:59] - Creating FileServer....\n[23:59:00] - Starting servers....\n[23:59:00] Ui.UiServer --------------------------------------\n[23:59:00] Ui.UiServer Web interface: http://127.0.0.1:43110/\n[23:59:00] Ui.UiServer --------------------------------------\n[23:59:00] - Opening browser: default_browser...\n[23:59:02] FileServer Checking port 15441 using portchecker.co...\n[23:59:02] FileServer [OK :)] Port open: Port 15441 is open.\n[23:59:22] - Unhandled exception\nTraceback (most recent call last):\n  File \"C:\\temp\\ZeroBundle-v0.1.0\\ZeroBundle\\Python\\lib\\site-packages\\gevent\\greenlet.py\", line 327, in run\n    result = self._run(*self.args, **self.kwargs)\n  File \"C:\\temp\\ZeroBundle-v0.1.0\\ZeroBundle\\ZeroNet\\src\\Connection\\ConnectionServer.py\", line 65, in handleIncomingConnection\n    connection.handleIncomingConnection(sock)\n  File \"C:\\temp\\ZeroBundle-v0.1.0\\ZeroBundle\\ZeroNet\\src\\Connection\\Connection.py\", line 90, in handleIncomingConnection\n    if sock.recv( 1, gevent.socket.MSG_PEEK ) == \"\\x16\":\n  File \"C:\\temp\\ZeroBundle-v0.1.0\\ZeroBundle\\Python\\lib\\site-packages\\gevent\\socket.py\", line 385, in recv\n    return sock.recv(*args)\nerror: [Errno 10054] An existing connection was forcibly closed by the remote host\nTraceback (most recent call last):\n  File \"C:\\temp\\ZeroBundle-v0.1.0\\ZeroBundle\\Python\\lib\\site-packages\\gevent\\greenlet.py\", line 327, in run\n    result = self._run(*self.args, **self.kwargs)\n  File \"C:\\temp\\ZeroBundle-v0.1.0\\ZeroBundle\\ZeroNet\\src\\Connection\\ConnectionServer.py\", line 65, in handleIncomingConnection\n    connection.handleIncomingConnection(sock)\n  File \"C:\\temp\\ZeroBundle-v0.1.0\\ZeroBundle\\ZeroNet\\src\\Connection\\Connection.py\", line 90, in handleIncomingConnection\n    if sock.recv( 1, gevent.socket.MSG_PEEK ) == \"\\x16\":\n  File \"C:\\temp\\ZeroBundle-v0.1.0\\ZeroBundle\\Python\\lib\\site-packages\\gevent\\socket.py\", line 385, in recv\n    return sock.recv(*args)\nsocket.error: [Errno 10054] An existing connection was forcibly closed by the remote host\n```\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1434686571, "modified": 1434723228, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/125", "source_type": "github"}, {"topic_id": 1604064888, "title": "Mozilla Dev Network 3GB unable to sync", "body": "http://127.0.0.1:43110/1MoZDevNsM5NAitt2y17jCvPWRazbjYqLe\n\nZeroNet seems to choke every time it tries to connect to this URL.\n\nAm I not being patient enough?\n\n[19:58:46] Site:1MoZDe..YqLe Content.json not exist: data/1MoZDevNsM5NAitt2y17jCvPWRazbjYqLe/content.json\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1435104159, "modified": 1502787315, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/128", "source_type": "github"}, {"topic_id": 1604064890, "title": "Auto discovery of new sites", "body": "I know there is a web site called [BTDigg](https://en.wikipedia.org/wiki/BTDigg) that is a search engine based on data from DHT. I wonder if a similar search engine could be devised for ZeroNet. I know there is a namecoin directory, but it seems limited to namecoin domains only. There must be sites that exist we are not finding yet that exist on the DHT network. \n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1435151016, "modified": 1492101696, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/129", "source_type": "github"}, {"topic_id": 1604064892, "title": "Site too large 101549465 > 10485760, aborting task... (bluishcoder.bit changed from 10MB to 108MB?)", "body": "It seems if we already peer with a site, the original limit is not asked to be increased if the data folder already exists? If I erase the 1Bluish folder and go the web site again, I am asked to increase the max capacity to 200MB. I guess, there isn't the capacity to grow the web site beyond the initial max capacity we have set?\n\n[19:59:38] FileServer [OK :)] Port open: Port 15441 is open.\n[20:00:03] Site:1BLuis..oYQw content.json: Site too large 101549465 > 10485760, aborting task...\n[20:00:03] Site:1BLuis..oYQw content.json: Site too large 101549465 > 10485760, aborting task...\n[20:00:04] Site:1BLuis..oYQw content.json: Site too large 101549465 > 10485760, aborting task...\n[20:00:04] Site:1BLuis..oYQw content.json: Site too large 101549465 > 10485760, aborting task...\n[20:00:04] Site:1BLuis..oYQw content.json: Site too large 101549465 > 10485760, aborting task...\n[20:00:04] Site:1BLuis..oYQw content.json: Site too large 101549465 > 10485760, aborting task...\n", "parent_topic_uri": "1604062980_users_1Cy3ntkN2GN9MH6EaW6eHpi4YoRS2nK5Di", "added": 1435191128, "modified": 1435249278, "source_link": "https://github.com/HelloZeroNet/ZeroNet/issues/130", "source_type": "github"}]}