{
	"pages": [
		{
			"id": "05b26320-1d31-11e8-9b8c-4fc00ae2929f",
			"body": "Proposal: distributed database system (DBMS) for ZeroNet over distributed hashtables (DHTs).\n\nProposal by lxpz@zeroid.bit. Contact me by ZeroMail or ZeroMe if you are interested.\n\nOh, by the way, I already have a name for this feature: ZeroNet Shard, in reference to database sharding, a standard feature of industry-grade DB systems.\n\n## Problems we are trying to solve\n\n- When visiting a zite, you have to download all the zite's data, which is quickly too big in the case of zites with many users / lots of contents\n- Even with optional files, you have to store the index, which can be too big in the case of many small files such as the Wikipedia mirror project\n- If we are able to build distributed database indexes, we would be able to index in a single place all the content of a given kind (ex: music, videos, posts, pages) and do a search on all of ZeroNet at once, without the need for discovery and downloading of all the individual zites that exist.\n\nExamples of existing databases we could simply dump into this new format:\n- wikipedia\n- torrents\n- libgen, sci-hub\n\n## Overview of proposed solution\n\n- Use distributed hashtables as a foundation for a database system. This has been studied in several academic publications such as https://seer.ufmg.br/index.php/jidm/article/viewFile/107/63 or https://files.ifi.uzh.ch/CSG/staff/bocek/extern/theses/MA-Franceso-Luminati.pdf\n- Use a mechanism of attribution using public/private key cryptography to attribute ownership to all rows in a database table, so that only the original owner of an item may modify or delete it. This also allows blacklisting users that spam the database with useless content.\n- By default when downloading a zite, a user would store on his node the rows that he owns + 10 MB or such attributed to storing other user's data. He can also \"pin\" data, such as storing all rows that match a certain property, or simply storing the whole table when it is not too big. Note that in the case of small tables, the 10MB limit is actually enough to store the whole content, so everybody would have a full copy of the zite data and querying would be as fast as it is currently. For big sites the data would start to become distributed but we can expect such big sites to have many users, therefore many nodes ready to answer DHT queries, so browsing should not be too slow.\n- Build distributed fulltext indexes for textual search, the technology exists in publications such as https://arxiv.org/abs/1610.03332\n\n## Functionnality\n\nDHT layer functionality:\n\n\n- Separate data into groups (1 group can be data for a table or an index for instance, basically it's a sub-DHT that splits data according to their origin). Each group is owned by a zite, therefore it's function is defined by the zite's code.\n- Nodes are subscribed to some groups and not others, and have a per-group storage limit. Typically a node subscribes to the groups used by the zites it is serving.\n- Each identity can store 1 message per key per group, with a revision number (can be a timestamp) so that values can be updated. Stored messages are signed by the identity that published them.\n- Data is replicated and nodes do their best to prevent data from disappearing\n- Query is done for a group+key or group+key+identity\n- The condition for storing a (key, value) pair on a node is a OR condition: store if it's data owned by an identity of that node, if we are close to the hash of the key (standard DHT condition) or if any other user-defined predicate is respected. An active replication process can be held on a given node to ensure that all data matching the predicate is present on that node.\n\nDatabase layer functionality:\n\n- Table storage = 1 DHT group of key -> value, where key = hash of value + identity\n- Exact index storage = 1 DHT group of key -> value, where key = hash of value of indexed column and value = set of keys for identity's item matching the criterion\n- Range index storage = 1 DHT group for a distributed segment tree. Question: who maintains the DST? Each user for his data only? Or a collective effort for all data? (makes more sense, but makes it vulnerable to attacks)\n- Fulltext index storage = ??\n- The owner of an identity always keeps a local copy of all the data he inserted in the DB so that he can re-upload it if necessary\n- SQL engine that implements standard DB functionality over such a data structure\n\nUser interface functionality:\n\n- Examine what is taking up space (table data, indexes)\n- Examine who is the owner of how much data\n- Select what data to keep locally\n- Ban some identities from the database if they are spamming\n- Complex queries: report progress if they need to take time\n\n\n## Details\n\n- Do we want to have a SQL-like language for querying? This is probably not a priority, but it would be nice.\n- Can we make it a transparent replacement to the current system based on SQlite? Then we need to have a full support for the SQL language that SQlite offers. Another problem is that the underlying table structure would not be the same (eg. we would not have a table for json files, but all rows would automatically have an owner field)\n- We have to make this as fast as possible for querying, and we want the system to minimize network usage (number of DHT queries necessary to resolve a SQL query). But let's build a prototype first!\n- If some types of query are known to be slow (ex. ranged queries or fulltext searches) it would be nice if the system could report on query progress, then we could have a nice UI with a progress bar. People would be more willing to wait some time for the request to complete if they are explicitly told that what they asked is actually a complicated task, and progress is reported regularly. IMO the awesome UI of ZeroNet is one of its main advantages and a reason why it might be more successful than any other project.\n- To allow imports from previous zites, we could allow the zite owner to sign data for other identities (i.e. inserting DHT key-value pairs for these identities without knowing the associated private key) instead of these identities having to do it themselves. However this needs to be clearly mentioned in the user interface.",
			"date_added": 1519895702099,
			"slug": "dhtdbms"
		},
		{
			"id": "c2e3aad0-014d-11e8-865c-c1adc143a6ba",
			"body": "Proposal: distributed database system (DBMS) for ZeroNet over distributed hashtables (DHTs).\n\nProposal by lxpz@zeroid.bit. Contact me by ZeroMail or ZeroMe if you are interested.\n\nOh, by the way, I already have a name for this feature: ZeroNet Shard, in reference to database sharding, a standard feature of industry-grade DB systems.\n\n## Problems we are trying to solve\n\n- When visiting a zite, you have to download all the zite's data, which is quickly too big in the case of zites with many users / lots of contents\n- Even with optional files, you have to store the index, which can be too big in the case of many small files such as the Wikipedia mirror project\n- If we are able to build distributed database indexes, we would be able to index in a single place all the content of a given kind (ex: music, videos, posts, pages) and do a search on all of ZeroNet at once, without the need for discovery and downloading of all the individual zites that exist.\n\n## Overview of proposed solution\n\n- Use distributed hashtables as a foundation for a database system. This has been studied in several academic publications such as https://seer.ufmg.br/index.php/jidm/article/viewFile/107/63 or https://files.ifi.uzh.ch/CSG/staff/bocek/extern/theses/MA-Franceso-Luminati.pdf\n- Use a mechanism of attribution using public/private key cryptography to attribute ownership to all rows in a database table, so that only the original owner of an item may modify or delete it. This also allows blacklisting users that spam the database with useless content.\n- By default when downloading a zite, a user would store on his node the rows that he owns + 10 MB or such attributed to storing other user's data. He can also \"pin\" data, such as storing all rows that match a certain property, or simply storing the whole table when it is not too big. Note that in the case of small tables, the 10MB limit is actually enough to store the whole content, so everybody would have a full copy of the zite data and querying would be as fast as it is currently. For big sites the data would start to become distributed but we can expect such big sites to have many users, therefore many nodes ready to answer DHT queries, so browsing should not be too slow.\n- Build distributed fulltext indexes for textual search, the technology exists in publications such as https://arxiv.org/abs/1610.03332\n\n## Functionnality\n\nDHT layer functionality:\n\n\n- Separate data into groups (1 group can be data for a table or an index for instance, basically it's a sub-DHT that splits data according to their origin). Each group is owned by a zite, therefore it's function is defined by the zite's code.\n- Nodes are subscribed to some groups and not others, and have a per-group storage limit. Typically a node subscribes to the groups used by the zites it is serving.\n- Each identity can store 1 message per key per group, with a revision number (can be a timestamp) so that values can be updated. Stored messages are signed by the identity that published them.\n- Data is replicated and nodes do their best to prevent data from disappearing\n- Query is done for a group+key or group+key+identity\n- The condition for storing a (key, value) pair on a node is a OR condition: store if it's data owned by an identity of that node, if we are close to the hash of the key (standard DHT condition) or if any other user-defined predicate is respected. An active replication process can be held on a given node to ensure that all data matching the predicate is present on that node.\n\nDatabase layer functionality:\n\n- Table storage = 1 DHT group of key -> value, where key = hash of value + identity\n- Exact index storage = 1 DHT group of key -> value, where key = hash of value of indexed column and value = set of keys for identity's item matching the criterion\n- Range index storage = 1 DHT group for a distributed segment tree. Question: who maintains the DST? Each user for his data only? Or a collective effort for all data? (makes more sense, but makes it vulnerable to attacks)\n- Fulltext index storage = ??\n- The owner of an identity always keeps a local copy of all the data he inserted in the DB so that he can re-upload it if necessary\n- SQL engine that implements standard DB functionality over such a data structure\n\nUser interface functionality:\n\n- Examine what is taking up space (table data, indexes)\n- Examine who is the owner of how much data\n- Select what data to keep locally\n- Ban some identities from the database if they are spamming\n- Complex queries: report progress if they need to take time\n\n\n## Details\n\n- Do we want to have a SQL-like language for querying? This is probably not a priority, but it would be nice.\n- Can we make it a transparent replacement to the current system based on SQlite? Then we need to have a full support for the SQL language that SQlite offers. Another problem is that the underlying table structure would not be the same (eg. we would not have a table for json files, but all rows would automatically have an owner field)\n- We have to make this as fast as possible for querying, and we want the system to minimize network usage (number of DHT queries necessary to resolve a SQL query). But let's build a prototype first!\n- If some types of query are known to be slow (ex. ranged queries or fulltext searches) it would be nice if the system could report on query progress, then we could have a nice UI with a progress bar. People would be more willing to wait some time for the request to complete if they are explicitly told that what they asked is actually a complicated task, and progress is reported regularly. IMO the awesome UI of ZeroNet is one of its main advantages and a reason why it might be more successful than any other project.\n- To allow imports from previous zites, we could allow the zite owner to sign data for other identities (i.e. inserting DHT key-value pairs for these identities without knowing the associated private key) instead of these identities having to do it themselves. However this needs to be clearly mentioned in the user interface.",
			"date_added": 1516829412862,
			"slug": "dhtdbms"
		},
		{
			"id": "437cce20-0134-11e8-bfd0-859a9678c240",
			"body": "Proposal: distributed database system (DBMS) for ZeroNet over distributed hashtables (DHTs).\n\nProposal by lxpz@zeroid.bit. Contact me by ZeroMail or ZeroMe if you are interested.\n\nOh, by the way, I already have a name for this feature: ZeroNet Shard, in reference to database sharding, a standard feature of industry-grade DB systems.\n\n## Problems we are trying to solve\n\n- When visiting a zite, you have to download all the zite's data, which is quickly too big in the case of zites with many users / lots of contents\n- Even with optional files, you have to store the index, which can be too big in the case of many small files such as the Wikipedia mirror project\n- If we are able to build distributed database indexes, we would be able to index in a single place all the content of a given kind (ex: music, videos, posts, pages) and do a search on all of ZeroNet at once, without the need for discovery and downloading of all the individual zites that exist.\n\n## Overview of proposed solution\n\n- Use distributed hashtables as a foundation for a database system. This has been studied in several academic publications such as https://seer.ufmg.br/index.php/jidm/article/viewFile/107/63 or https://files.ifi.uzh.ch/CSG/staff/bocek/extern/theses/MA-Franceso-Luminati.pdf\n- Use a mechanism of attribution using public/private key cryptography to attribute ownership to all rows in a database table, so that only the original owner of an item may modify or delete it. This also allows blacklisting users that spam the database with useless content.\n- By default when downloading a zite, a user would store on his node the rows that he owns + 10 MB or such attributed to storing other user's data. He can also \"pin\" data, such as storing all rows that match a certain property, or simply storing the whole table when it is not too big. Note that in the case of small tables, the 10MB limit is actually enough to store the whole content, so everybody would have a full copy of the zite data and querying would be as fast as it is currently. For big sites the data would start to become distributed but we can expect such big sites to have many users, therefore many nodes ready to answer DHT queries, so browsing should not be too slow.\n- Build distributed fulltext indexes for textual search, the technology exists in publications such as https://arxiv.org/abs/1610.03332\n\n## Functionnality\n\nDHT layer functionality:\n\n\n- Separate data into groups (1 group can be data for a table or an index for instance, basically it's a sub-DHT that splits data according to their origin). Each group is owned by a zite, therefore it's function is defined by the zite's code.\n- Nodes are subscribed to some groups and not others, and have a per-group storage limit. Typically a node subscribes to the groups used by the zites it is serving.\n- Each identity can store 1 message per key per group, with a revision number (can be a timestamp) so that values can be updated. Stored messages are signed by the identity that published them.\n- Data is replicated and nodes do their best to prevent data from disappearing\n- Query is done for a group+key or group+key+identity\n- The condition for storing a (key, value) pair on a node is a OR condition: store if it's data owned by an identity of that node, if we are close to the hash of the key (standard DHT condition) or if any other user-defined predicate is respected. An active replication process can be held on a given node to ensure that all data matching the predicate is present on that node.\n\nDatabase layer functionality:\n\n- Table storage = 1 DHT group of key -> value, where key = hash of value + identity\n- Exact index storage = 1 DHT group of key -> value, where key = hash of value of indexed column and value = set of keys for identity's item matching the criterion\n- Range index storage = ??\n- Fulltext index storage = ??\n- The owner of an identity always keeps a local copy of all the data he inserted in the DB so that he can re-upload it if necessary\n- SQL engine that implements standard DB functionality over such a data structure\n\nUser interface functionality:\n\n- Examine what is taking up space (table data, indexes)\n- Examine who is the owner of how much data\n- Select what data to keep locally\n- Ban some identities from the database if they are spamming\n- Complex queries: report progress if they need to take time\n\n\n## Details\n\n- Do we want to have a SQL-like language for querying? This is probably not a priority, but it would be nice.\n- Can we make it a transparent replacement to the current system based on SQlite? Then we need to have a full support for the SQL language that SQlite offers. Another problem is that the underlying table structure would not be the same (eg. we would not have a table for json files, but all rows would automatically have an owner field)\n- We have to make this as fast as possible for querying, and we want the system to minimize network usage (number of DHT queries necessary to resolve a SQL query). But let's build a prototype first!\n- If some types of query are known to be slow (ex. ranged queries or fulltext searches) it would be nice if the system could report on query progress, then we could have a nice UI with a progress bar. People would be more willing to wait some time for the request to complete if they are explicitly told that what they asked is actually a complicated task, and progress is reported regularly. IMO the awesome UI of ZeroNet is one of its main advantages and a reason why it might be more successful than any other project.\n- To allow imports from previous zites, we could allow the zite owner to sign data for other identities (i.e. inserting DHT key-value pairs for these identities without knowing the associated private key) instead of these identities having to do it themselves. However this needs to be clearly mentioned in the user interface.",
			"date_added": 1516818461698,
			"slug": "dhtdbms"
		},
		{
			"id": "24b67fa0-0133-11e8-bfd0-859a9678c240",
			"body": "Proposal: distributed database system (DBMS) for ZeroNet over distributed hashtables (DHTs).\n\nProposal by lxpz@zeroid.bit. Contact me by ZeroMail or ZeroMe if you are interested.\n\nOh, by the way, I already have a name for this feature: ZeroNet Shard, in reference to database sharding, a standard feature of industry-grade DB systems.\n\n## Problems we are trying to solve\n\n- When visiting a zite, you have to download all the zite's data, which is quickly too big in the case of zites with many users / lots of contents\n- Even with optional files, you have to store the index, which can be too big in the case of many small files such as the Wikipedia mirror project\n- If we are able to build distributed database indexes, we would be able to index in a single place all the content of a given kind (ex: music, videos, posts, pages) and do a search on all of ZeroNet at once, without the need for discovery and downloading of all the individual zites that exist.\n\n## Overview of proposed solution\n\n- Use distributed hashtables as a foundation for a database system. This has been studied in several academic publications such as https://seer.ufmg.br/index.php/jidm/article/viewFile/107/63 or https://files.ifi.uzh.ch/CSG/staff/bocek/extern/theses/MA-Franceso-Luminati.pdf\n- Use a mechanism of attribution using public/private key cryptography to attribute ownership to all rows in a database table, so that only the original owner of an item may modify or delete it. This also allows blacklisting users that spam the database with useless content.\n- By default when downloading a zite, a user would store on his node the rows that he owns + 10 MB or such attributed to storing other user's data. He can also \"pin\" data, such as storing all rows that match a certain property, or simply storing the whole table when it is not too big. Note that in the case of small tables, the 10MB limit is actually enough to store the whole content, so everybody would have a full copy of the zite data and querying would be as fast as it is currently. For big sites the data would start to become distributed but we can expect such big sites to have many users, therefore many nodes ready to answer DHT queries, so browsing should not be too slow.\n- Build distributed fulltext indexes for textual search, the technology exists in publications such as https://arxiv.org/abs/1610.03332\n\n## Functionnality\n\nDHT layer functionality:\n\n\n- Separate data into groups (1 group can be data for a table or an index for instance, basically it's a sub-DHT that splits data according to their origin). Each group is owned by a zite, therefore it's function is defined by the zite's code.\n- Nodes are subscribed to some groups and not others, and have a per-group storage limit. Typically a node subscribes to the groups used by the zites it is serving.\n- Each identity can store 1 message per key per group, with a revision number (can be a timestamp) so that values can be updated\n- Data is replicated and nodes do their best to prevent data from disappearing\n- Query is done for a group+key or group+key+identity\n- The condition for storing a (key, value) pair on a node is a OR condition: store if it's data owned by an identity of that node, if we are close to the hash of the key (standard DHT condition) or if any other user-defined predicate is respected. An active replication process can be held on a given node to ensure that all data matching the predicate is present on that node.\n\nDatabase layer functionality:\n\n- Table storage = 1 DHT group of key -> value, where key = hash of value + identity\n- Exact index storage = 1 DHT group of key -> value, where key = hash of value of indexed column and value = set of keys for identity's item matching the criterion\n- Range index storage = ??\n- Fulltext index storage = ??\n- The owner of an identity always keeps a local copy of all the data he inserted in the DB so that he can re-upload it if necessary\n- SQL engine that implements standard DB functionality over such a data structure\n\nUser interface functionality:\n\n- Examine what is taking up space (table data, indexes)\n- Examine who is the owner of how much data\n- Select what data to keep locally\n- Ban some identities from the database if they are spamming\n- Complex queries: report progress if they need to take time\n\n\n## Details\n\n- Do we want to have a SQL-like language for querying? This is probably not a priority, but it would be nice.\n- Can we make it a transparent replacement to the current system based on SQlite? Then we need to have a full support for the SQL language that SQlite offers. Another problem is that the underlying table structure would not be the same (eg. we would not have a table for json files, but all rows would automatically have an owner field)\n- We have to make this as fast as possible for querying, and we want the system to minimize network usage (number of DHT queries necessary to resolve a SQL query). But let's build a prototype first!\n- If some types of query are known to be slow (ex. ranged queries or fulltext searches) it would be nice if the system could report on query progress, then we could have a nice UI with a progress bar. People would be more willing to wait some time for the request to complete if they are explicitly told that what they asked is actually a complicated task, and progress is reported regularly. IMO the awesome UI of ZeroNet is one of its main advantages and a reason why it might be more successful than any other project.",
			"date_added": 1516817980570,
			"slug": "dhtdbms"
		},
		{
			"id": "e1b7bb20-0131-11e8-bfd0-859a9678c240",
			"body": "Proposal: distributed database system (DBMS) for ZeroNet over distributed hashtables (DHTs).\n\nProposal by lxpz@zeroid.bit. Contact me by ZeroMail or ZeroMe if you are interested.\n\n## Problems we are trying to solve\n\n- When visiting a zite, you have to download all the zite's data, which is quickly too big in the case of zites with many users / lots of contents\n- Even with optional files, you have to store the index, which can be too big in the case of many small files such as the Wikipedia mirror project\n- If we are able to build distributed database indexes, we would be able to index in a single place all the content of a given kind (ex: music, videos, posts, pages) and do a search on all of ZeroNet at once, without the need for discovery and downloading of all the individual zites that exist.\n\n## Overview of proposed solution\n\n- Use distributed hashtables as a foundation for a database system. This has been studied in several academic publications such as https://seer.ufmg.br/index.php/jidm/article/viewFile/107/63 or https://files.ifi.uzh.ch/CSG/staff/bocek/extern/theses/MA-Franceso-Luminati.pdf\n- Use a mechanism of attribution using public/private key cryptography to attribute ownership to all rows in a database table, so that only the original owner of an item may modify or delete it. This also allows blacklisting users that spam the database with useless content.\n- By default when downloading a zite, a user would store on his node the rows that he owns + 10 MB or such attributed to storing other user's data. He can also \"pin\" data, such as storing all rows that match a certain property, or simply storing the whole table when it is not too big. Note that in the case of small tables, the 10MB limit is actually enough to store the whole content, so everybody would have a full copy of the zite data and querying would be as fast as it is currently. For big sites the data would start to become distributed but we can expect such big sites to have many users, therefore many nodes ready to answer DHT queries, so browsing should not be too slow.\n- Build distributed fulltext indexes for textual search, the technology exists in publications such as https://arxiv.org/abs/1610.03332\n\n## Functionnality\n\nDHT layer functionality:\n\n\n- Separate data into groups (1 group can be data for a table or an index for instance, basically it's a sub-DHT that splits data according to their origin). Each group is owned by a zite, therefore it's function is defined by the zite's code.\n- Nodes are subscribed to some groups and not others, and have a per-group storage limit. Typically a node subscribes to the groups used by the zites it is serving.\n- Each identity can store 1 message per key per group, with a revision number (can be a timestamp) so that values can be updated\n- Data is replicated and nodes do their best to prevent data from disappearing\n- Query is done for a group+key or group+key+identity\n- The condition for storing a (key, value) pair on a node is a OR condition: store if it's data owned by an identity of that node, if we are close to the hash of the key (standard DHT condition) or if any other user-defined predicate is respected. An active replication process can be held on a given node to ensure that all data matching the predicate is present on that node.\n\nDatabase layer functionality:\n\n- Table storage = 1 DHT group of key -> value, where key = hash of value + identity\n- Exact index storage = 1 DHT group of key -> value, where key = hash of value of indexed column and value = set of keys for identity's item matching the criterion\n- Range index storage = ??\n- Fulltext index storage = ??\n- The owner of an identity always keeps a local copy of all the data he inserted in the DB so that he can re-upload it if necessary\n- SQL engine that implements standard DB functionality over such a data structure\n\nUser interface functionality:\n\n- Examine what is taking up space (table data, indexes)\n- Examine who is the owner of how much data\n- Select what data to keep locally\n- Ban some identities from the database if they are spamming\n- Complex queries: report progress if they need to take time\n\n\n## Details\n\n- Do we want to have a SQL-like language for querying? This is probably not a priority, but it would be nice.\n- Can we make it a transparent replacement to the current system based on SQlite? Then we need to have a full support for the SQL language that SQlite offers. Another problem is that the underlying table structure would not be the same (eg. we would not have a table for json files, but all rows would automatically have an owner field)\n- We have to make this as fast as possible for querying, and we want the system to minimize network usage (number of DHT queries necessary to resolve a SQL query). But let's build a prototype first!\n- If some types of query are known to be slow (ex. ranged queries or fulltext searches) it would be nice if the system could report on query progress, then we could have a nice UI with a progress bar. People would be more willing to wait some time for the request to complete if they are explicitly told that what they asked is actually a complicated task, and progress is reported regularly. IMO the awesome UI of ZeroNet is one of its main advantages and a reason why it might be more successful than any other project.",
			"date_added": 1516817438674,
			"slug": "dhtdbms"
		}
	]
}