{
	"title": "è´ªåƒçš„çŒ«",
	"description": "éšä¾¿ç©ç©",
	"links": "[ä¸€äº›æœ‰ç”¨çš„ä¸œè¥¿](http://127.0.0.1:43110/17cZ5zprTJXq2qww7yL3RQWaLXpQgbpA6U/?Post:6:%E4%B8%80%E4%BA%9B%E6%9C%89%E7%94%A8%E7%9A%84%E4%B8%9C%E8%A5%BF%EF%BC%88%E8%BD%AC%E8%BD%BD%EF%BC%89)\n***\n\nèƒœäººè€…åŠ›ï¼Œè‡ªèƒœè€…å¼ºã€‚\nçŸ¥äººè€…æ™ºï¼Œè‡ªçŸ¥è€…æ˜ã€‚\n***\n\n#å‹æƒ…é“¾æ¥\n<a href=\"http://127.0.0.1:43110/cxg2014.bit/\" target=\"_blank\">CXG2014</a>\n<a href=\"http://127.0.0.1:43110/Blog.ZeroNetwork.bit\" target=\"_blank\">ZeroBlog</a>\n<a href=\"http://127.0.0.1:43110/gfwtalk.bit\" target=\"_blank\">GFW Talk</a>\n<a href=\"http://127.0.0.1:43110/0net123.bit/\" target=\"_blank\">ğŸˆNet123 ä¸­æ–‡å¯¼èˆª</a>\n<a href=\"http://127.0.0.1:43110/mosen.bit/\" target=\"_blank\">æµ®ç”Ÿç¶²å¿—</a>\n\n- [Source code](https://github.com/HelloZeroNet)",
	"next_post_id": 29,
	"demo": false,
	"modified": 1472745217,
	"post": [
		{
			"post_id": 28,
			"title": "pythonå­¦ä¹ å°è®°",
			"date_published": 1472744824.908,
			"body": " æˆ‘å¯¹Pythonæ„Ÿå…´è¶£çš„åŸå› æ˜¯æƒ³è¦ç”¨Pythonæ¥å†™çˆ¬è™«ï¼Œç”¨æ¥çˆ¬ä¸€äº›æ•°æ®ï¼ˆæœ€ä¸»è¦çš„æ˜¯sfacgçš„å›¾ä¹¦å…ƒæ•°æ® **å®ƒçš„æœç´¢å¤ªè®©äººæŠ“ç‹‚äº†ï¼ï¼ï¼**ï¼‰ã€‚\n \n ç„¶åæˆ‘å°±å¼€å§‹å­¦Python\n \n\nå…ˆçœ‹çš„æ˜¯[Python 2.7æ•™ç¨‹ - å»–é›ªå³°çš„å®˜æ–¹ç½‘ç«™](http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000)ï¼Œçœ‹äº†å¤§åŠæ„Ÿè§‰æŒæ¡äº†ä¸€äº›**PythonçŸ¥è¯†**ï¼Œå¯ä»¥å†™ä¸€äº›ç®€å•çš„ä¸œè¥¿äº†ã€‚ç„¶åå¼€å§‹çœ‹**çˆ¬è™«æ–¹é¢**çš„çŸ¥è¯†ï¼Œçœ‹çš„æ˜¯[Pythonçˆ¬è™«å­¦ä¹ ç³»åˆ—æ•™ç¨‹](http://cuiqingcai.com/1052.html)ï¼ŒæŒ‰ç…§ä¸Šé¢çš„ä¸€ç¯‡ç¯‡çš„å­¦ï¼ŒåŸºæœ¬ä¸Šåˆ·äº†ä¸€éã€‚\n\nç„¶åå¼€å§‹åŠ¨æ‰‹ã€‚\n\nå†™äº†ä¸€äº›å°è„šæœ¬ç”¨æ¥çˆ¬æ•°æ®**ï¼ˆ`book.sfacg.com`ï¼‰**ï¼Œå¼€å§‹çš„æ—¶å€™ä»ç›®å½•é¡µçˆ¬ï¼Œç„¶åå‘ç°ç»“æœä¸å…¨ï¼Œè€Œä¸”å°é¢ä¹Ÿéƒ½æ˜¯ä¸€äº›å°å›¾**ï¼ˆè¦çš„å°±æ˜¯å°é¢ï¼‰**ï¼Œè¿™å¯ä¸è¡Œã€‚\n\nç„¶åå‡†å¤‡ä¸Šæ¡†æ¶ï¼Œç„¶åå¼€å§‹å­¦**Scrapyæ¡†æ¶**ï¼Œæ²¡æœ‰åœ¨ç½‘ä¸Šå‘ç°å¥½çš„æ•™ç¨‹ï¼Œä¸»è¦æ˜¯è‡ªå·±çœ‹å®ƒçš„[å®˜æ–¹æ–‡ä»¶](https://scrapy-chs.readthedocs.io/zh_CN/0.24/intro/overview.html)ï¼Œè¾¹çœ‹è¾¹å†™ï¼Œé‡åˆ°é—®é¢˜äº†å°±ä¸Šç½‘æœã€‚åæ¥å‘ç°ä¸­æ–‡ç¿»è¯‘çš„å·²ç»æœ‰äº›è½åäº†ï¼Œå°±å¼€å§‹çœ‹[è‹±æ–‡çš„å®˜æ–¹æ–‡æœ¬](http://doc.scrapy.org/en/latest/intro/overview.html)ï¼Œå‘ç°åŸºæœ¬å’Œç”¨çš„è½¯ä»¶ç‰ˆæœ¬å¯¹çš„ä¸Šï¼Œæ²¡æœ‰ä»€ä¹ˆé—®é¢˜ã€‚\n\nåæ¥åŸºæœ¬ä¸Šå†™å®Œäº†ï¼Œbugä¹Ÿä¸å®Œäº†åï¼Œç„¶åå°±è§‰å¾—è‡ªå·±çš„ä»»åŠ¡ç»ˆäºå®Œäº†ï¼Œä¸€ç§ç©ºè™šæ„Ÿã€‚\n\nåæ¥æœ‰å†™äº†ä¸€ä¸ªçˆ¬**`iqing.in`**çš„çˆ¬è™«ï¼Œè¿™ä¸ªæ˜¯çˆ¬å…¨æ–‡çš„ã€‚\n\nå½“ç„¶ï¼Œç»ƒä¹ çš„æ—¶å€™ä¹Ÿå†™äº†ä¸€äº›å°ä½œå“ç»ƒäº†ç»ƒæ‰‹ã€‚\n\nç°åœ¨å­¦ä¸šç¹å¿™ï¼Œå‡†å¤‡æ”¾ä¸‹è¿™äº›æ‚ä¸šï¼Œæ‰€ä»¥ä»Šå¤©å†™æ–‡æ€»ç»“ä¸€ä¸‹ã€‚\n\nå†™çš„å‡ ä¸ªæˆç†Ÿçš„ä½œå“ä¹Ÿå‘å‡ºæ¥è®©å¤§å®¶çœ‹çœ‹ã€‚**ï¼ˆæ–°æ‰‹ï¼Œä¸è¦è§ç¬‘å•Šï¼ï¼‰**\n\n#PS:ä¸€äº›å°ä½œå“\n##ç›®å½•ï¼š\n- è·Ÿè¸ªè·¯ç”±å¹¶ç°å®ipå½’å±åœ°çš„å°è„šæœ¬\n- ä»£ç†çˆ¬è™«\n- sfacg çˆ¬è™«\n- iqing.in çˆ¬è™«\n\n---\n##è·Ÿè¸ªè·¯ç”±å¹¶ç°å®ipå½’å±åœ°çš„å°è„šæœ¬\n```\n#!/usr/bin/env python2\n# -*- coding:utf-8 -*-\n\n__author__='YYW'\n\nimport requests\nimport re\nimport sys\nimport commands\n\nclass IPlocation(object):\n    def __init__(self):\n        self.patten = re.compile(r'(((2[0-4]\\d|25[0-5]|[01]?\\d\\d?)\\.){3}(2[0-4]\\d|25[0-5]|[01]?\\d\\d?))')\n        self.ips = []\n        self.webstatus = 403\n        self.trace = ''\n        self.input = sys.argv\n\n    def tracerouter(self, input):\n       if len(input) == 2:\n           t = commands.getoutput('traceroute -n ' +str(input[1]))\n           self.trace = t\n       else:\n           print('è¯·è¾“å…¥IPæˆ–åŸŸå')\n           exit()\n\n    def dealdata(self):#å¤„ç†è¾“å‡ºips\n        o = self.trace\n        ips = re.findall(self.patten, o)\n        self.ips = ips\n        return None\n    \n    def query_ip(self, ip):#åˆ©ç”¨ipip.net api æŸ¥è¯¢åœ°å€\n        payload = {'ip': ip}\n        r = requests.get(\"http://freeapi.ipip.net/\", params=payload)\n        self.webstatus = r.status_code\n        return r.text\n    \n    def netest(self):#ç½‘ç»œæ£€æµ‹\n        temp = self.query_ip('8.8.8.8')\n        nettest = re.search(\"202.204.32.54\", temp)\n        if nettest:\n            print('æœªè¿æ¥æ ¡å›­ç½‘,è¯·æ£€æŸ¥ç½‘ç»œ')\n            exit()\n    \n    def start(self):\n        self.netest()\n        self.tracerouter(self.input)\n        print(self.trace)\n        self.dealdata()\n        i = -1\n        if self.input[1][:1] in [str(x) for x in range(10)]:\n            m = 1\n        else:\n            m = 0\n        print('\\nè·¯ç”±è·Ÿè¸ª:')\n        for ipt in self.ips[m:]:\n            i = i + 1\n            ip = ipt[0]\n            ipq = self.query_ip(ip)\n            while self.webstatus != 200:\n                ipq = self.query_ip(ip)\n            print('%d\\t%s\\t%s' % (i, ipt[0], ipq))  \n\ns = IPlocation()\ns.start()\n```\n***\n##ä»£ç†çˆ¬è™«\n###items.py\n```\n# -*- coding: utf-8 -*-\n\n# Define here the models for your scraped items\n#\n# See documentation in:\n# http://doc.scrapy.org/en/latest/topics/items.html\n\nimport scrapy\n\n\nclass HttpProxiesItem(scrapy.Item):\n    # define the fields for your item here like:\n    # name = scrapy.Field()\n    proxie_ip = scrapy.Field()\n    #proxie_type = scrapy.Field()\n    proxie_location = scrapy.Field()\n```\n###spider *(proxies_spiders.py)*\n```\n# -*- coding: utf-8 -*-\n\nimport scrapy\nfrom scrapy.spiders import CrawlSpider, Rule\nfrom http_proxies.items import HttpProxiesItem\nfrom scrapy.linkextractors import LinkExtractor\nimport re\n\nclass Http_proxie_spider(CrawlSpider):\n    name = 'http_proxies'\n    allowed_domains = ['youdaili.net']\n    start_urls = ['http://www.youdaili.net/Daili/http/']\n    rules = (\n        Rule(LinkExtractor(allow=('/Daili/http/list_\\d+.html'))), \n        Rule(LinkExtractor(allow=('/Daili/http/\\d+.html')), callback='parse_item')\n    )\n    \n    def parse_item(self, response):\n        self.log('Hi, this is an item page! %s' % response.url)\n        \n        patten = re.compile(r'(((2[0-4]\\d|25[0-5]|[01]?\\d\\d?)\\.){3}(2[0-4]\\d|25[0-5]|[01]?\\d\\d?):\\d+)@(\\w+)#(.*?)<')\n        t = re.findall(patten, response.text)\n        proxie_ips = [t[x][0] for x in range(len(t))]\n        proxie_types = [t[x][-2] for x in range(len(t))]\n        proxie_locations = [t[x][-1] for x in range(len(t))]\n        item = HttpProxiesItem()\n        for i in range(len(proxie_ips)):\n            item['proxie_ip'] = proxie_ips[i]\n            #item['proxie_type'] = proxie_types[i]\n            item['proxie_location'] = proxie_locations[i]\n            yield item\n```\n***\n##sfacgçˆ¬è™«\n###items.py\n```\n# -*- coding: utf-8 -*-\n\n# Define here the models for your scraped items\n#\n# See documentation in:\n# http://doc.scrapy.org/en/latest/topics/items.html\n\nimport scrapy\n\n\nclass SfacgItem(scrapy.Item):\n    # define the fields for your item here like:\n    # name = scrapy.Field()\n    bookid = scrapy.Field()\n    bookname = scrapy.Field()\n    author = scrapy.Field()\n    word_number = scrapy.Field()\n    view_time = scrapy.Field()\n    sum_point = scrapy.Field()  #æ€»è¯„åˆ†\n    point = scrapy.Field()  #è¯„åˆ†å…·ä½“\n    bookMarknum = scrapy.Field() #ç±»å‹\n    favSticks = scrapy.Field()  #èµ\n    pointUserCount = scrapy.Field() #è¯„åˆ†äººæ•°\n    type = scrapy.Field()   #ç±»å‹\n    update_time = scrapy.Field()\n    brief_introduction = scrapy.Field()\n    cover = scrapy.Field()\n    cover_time = scrapy.Field()\n    cover_status = scrapy.Field()\n    cover_path = scrapy.Field()\n    MonTicketNum = scrapy.Field()\n    Tags = scrapy.Field() #<type 'list'>,<type 'dict'>\n    is_VIP = scrapy.Field()\n    VIP_time = scrapy.Field()\n    hav_beitou = scrapy.Field()\n    left_beitou = scrapy.Field()\n    left_beitou_time = scrapy.Field()\n    left_beitou_status = scrapy.Field()\n    left_beitou_path = scrapy.Field()\n    right_beitou = scrapy.Field()\n    right_beitou_time = scrapy.Field()\n    right_beitou_status = scrapy.Field()\n    right_beitou_path = scrapy.Field()\n    status = scrapy.Field() #çŠ¶æ€\n    sumNumbook = scrapy.Field()#å…±æœ‰Xæœ¬ä¹¦\n    max_page = scrapy.Field()#å…±æœ‰Xé¡µ\n    brief_commen_num = scrapy.Field() #çŸ­è¯„æ•°\n    long_commen_num = scrapy.Field() #é•¿è¯„æ•°\n    text_time = scrapy.Field()\n```\n###setting.py\n```\n# -*- coding: utf-8 -*-\n\n# Scrapy settings for sfacg project\n#\n# For simplicity, this file contains only settings considered important or\n# commonly used. You can find more settings consulting the documentation:\n#\n#     http://doc.scrapy.org/en/latest/topics/settings.html\n#     http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html\n#     http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html\n\nBOT_NAME = 'sfacg'\n\nSPIDER_MODULES = ['sfacg.spiders']\nNEWSPIDER_MODULE = 'sfacg.spiders'\n\n\n# Crawl responsibly by identifying yourself (and your website) on the user-agent\n#USER_AGENT = 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'\nUSER_AGENT = 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:25.0) Gecko/20100101 Firefox/25.0'\n\n# Obey robots.txt rules\nROBOTSTXT_OBEY = True\n\n# Configure maximum concurrent requests performed by Scrapy (default: 16)\nCONCURRENT_REQUESTS = 96\n#CONCURRENT_REQUESTS = 32\n\n# Configure a delay for requests for the same website (default: 0)\n# See http://scrapy.readthedocs.org/en/latest/topics/settings.html#download-delay\n# See also autothrottle settings and docs\n#DOWNLOAD_DELAY = 3\n# The download delay setting will honor only one of:\n#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n#CONCURRENT_REQUESTS_PER_IP = 16\n\n# Disable cookies (enabled by default)\n#COOKIES_ENABLED = False\n\n# Disable Telnet Console (enabled by default)\nTELNETCONSOLE_ENABLED = True\nTELNETCONSOLE_PORT = '6321'\n\n# Override the default request headers:\nDEFAULT_REQUEST_HEADERS = {\n   'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n   'Accept-Language': 'zh',\n}\n\n# Enable or disable spider middlewares\n# See http://scrapy.readthedocs.org/en/latest/topics/spider-middleware.html\n#SPIDER_MIDDLEWARES = {\n#    'sfacg.middlewares.MyCustomSpiderMiddleware': 543,\n#}\n\n# Enable or disable downloader middlewares\n# See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html\nDOWNLOADER_MIDDLEWARES = {\n    'sfacg.middlewares.Test': 543,\n}\n\n# Enable or disable extensions\n# See http://scrapy.readthedocs.org/en/latest/topics/extensions.html\n#EXTENSIONS = {\n#    'scrapy.extensions.telnet.TelnetConsole': 300,\n##    'scrapy.extensions.feedexport.FeedExporter': 500,\n#}\n\n# Configure item pipelines\n# See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.html\nITEM_PIPELINES = {\n#    'sfacg.pipelines.Pre_deal': 200,\n    'sfacg.pipelines.Save_image': 300,\n#    'sfacg.pipelines.JsonWriterPipeline': 400\n#    'sfacg.pipelines.Csv_Writer':400\n}\n#LOG_LEVEL = 'ERROR'\nLOG_LEVEL = 'INFO'\n#LOG_LEVEL = 'DEBUG'\nIMAGES_STORE = '/srv/xxx'\n#IMAGES_EXPIRES = 90\n\n# Enable and configure the AutoThrottle extension (disabled by default)\n# See http://doc.scrapy.org/en/latest/topics/autothrottle.html\n#AUTOTHROTTLE_ENABLED = True\n# The initial download delay\n#AUTOTHROTTLE_START_DELAY = 5\n# The maximum download delay to be set in case of high latencies\n#AUTOTHROTTLE_MAX_DELAY = 60\n# The average number of requests Scrapy should be sending in parallel to\n# each remote server\n#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n# Enable showing throttling stats for every response received:\n#AUTOTHROTTLE_DEBUG = False\n\n# Enable and configure HTTP caching (disabled by default)\n# See http://scrapy.readthedocs.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\n#HTTPCACHE_ENABLED = True\n#HTTPCACHE_EXPIRATION_SECS = 0\n#HTTPCACHE_DIR = 'httpcache'\n#HTTPCACHE_IGNORE_HTTP_CODES = []\n#HTTPCACHE_STORAGE = 'scrapy.extensions.httpcache.FilesystemCacheStorage'\n\n#Feed exports\nFEED_URI = 'file:///srv/xxx.json'\nFEED_FORMAT = 'json'\n#CSV_STORE = '/srv/xxx.csv'\n#JSON_STORE = '/srv/xxx.json'\n#FEED_URI = 'file:///srv/xxx.csv'\n#FEED_FORMAT = 'csv'\n```\n###piplines.py\n```\n# -*- coding: utf-8 -*-\n\n# Define your item pipelines here\n#\n# Don't forget to add your pipeline to the ITEM_PIPELINES setting\n# See: http://doc.scrapy.org/en/latest/topics/item-pipeline.html\n\n#from scrapy.pipelines.images import ImagesPipeline\n#from scrapy.exceptions import DropItem\n#import json\nfrom sfacg import settings\nfrom hashlib import md5\nimport time, os,  requests\n\nclass Save_image(object):\n    def __init__(self):\n        self.dir_path = settings.IMAGES_STORE\n#        self.session = requests.Session()\n\n    def download_img(self, item, name):#ä¸‹è½½å›¾ç‰‡\n        request_url = item[name]\n        checksun = md5(request_url.encode('utf-8')).hexdigest()\n        #åˆ›å»ºsession,ä¿®æ”¹åŒ…å¤´\n        s = requests.Session()\n        headers={\n#        'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36',\n        'User-Agent': 'Mozilla/5.0 (Windows NT 6.2; WOW64; rv:39.0) Gecko/20100101 Firefox/39.0',\n        'Referer': 'http://book.sfacg.com/Novel/%s/' % str(item['bookid'])\n        }\n        s.headers.update(headers)\n        #ä¸‹è½½\n        try:\n            img = s.get(request_url, timeout = 5, stream=True)\n        except Exception:\n            try:\n                img = s.get(request_url, timeout = 5, stream=True)\n            except Exception:\n                item['%s_status' % name] = False\n                return item\n        finally:\n            if img.status_code == 200:\n                img_type= os.path.splitext(request_url)[-1]\n                path = '%s/%s/%s/%s%s' % (self.dir_path, name, checksun[:2], checksun, str(img_type))\n                t_c = img.content\n                #å†™å…¥æ–‡ä»¶\n                with open(path, 'wb') as f:\n                    f.write(t_c)\n                #è¿”å›çŠ¶æ€\n                now_time = time.ctime()\n                item['%s_status' % name] = True\n                item['%s_time' % name] = now_time\n                item['%s_path' % name] = checksun\n                return item\n            else:\n                item['%s_status' % name] = False\n                return item\n\n    def isexists(self, item, name):\n        request_url = item[name]\n        checksun = md5(request_url.encode('utf-8')).hexdigest()\n        img_type= os.path.splitext(request_url)[-1]\n        path = '%s/%s/%s/%s%s' % (self.dir_path, name, checksun[:2], checksun, str(img_type))\n        dir_path = '%s/%s/%s' % (self.dir_path, name, checksun[:2])\n        isExist_dir = os.path.exists(dir_path)\n        if not isExist_dir:\n            os.makedirs(dir_path)\n        isExists = os.path.exists(path)\n        if isExists:\n            item['%s_path' % name] = checksun\n            return [item, isExists]\n        else:\n            return [item, isExists]\n\n    def mkdir(self):\n        cover_path = '%s/%s' % (self.dir_path, 'cover')\n        left_beitou_path = '%s/%s' % (self.dir_path, 'left_beitou')\n        right_beitou_path = '%s/%s' % (self.dir_path, 'right_beitou')\n        if not os.path.exists(self.dir_path):\n            os.mkdir(self.dir_path)\n        for x in [cover_path, left_beitou_path, right_beitou_path]:\n            if not os.path.exists(x):\n                os.mkdir(x)\n        return\n\n    def process_item(self,item, spider):\n        self.mkdir()\n        if item.get('cover'):\n            #cover\n            t = self.isexists(item,'cover')\n            item = t[0]\n            if not t[1]:\n                item = self.download_img(item,'cover')\n            #beitou\n            if item['hav_beitou'] :\n                t = self.isexists(item,'left_beitou')\n                item = t[0]\n                if not t[1]:\n                    item = self.download_img(item,'left_beitou')\n                t = self.isexists(item,'right_beitou')\n                item = t[0]\n                if not t[1]:\n                    item = self.download_img(item,'right_beitou')\n                return item\n            else:\n                return item\n        else:\n            return item\n```\n\n###middleware.py\n```\n# -*- coding: utf-8 -*-\n\n#from scrapy.exceptions import IgnoreRequest\n#from scrapy.contrib.downloadermiddleware import DownloaderMiddleware\nimport time\nimport re\n\nclass Test(object):\n    def __init__(self):\n        self.T = {}\n        \n    def get_bookid(self, request):\n        bookid = int(re.findall(r'Novel/(\\d+\\d)', str(request.url))[0])\n        return bookid\n        \n    def process_request(self,request,spider):\n        if re.search(r'Novel/\\d+\\d','request.url'):        \n            now_time = time.time()\n            bookid = self.get_bookid(request)\n            if self.T.get('%d' % bookid) == None:        \n                self.T['%d' % bookid] = now_time\n                return None\n            elif now_time - self.T['%d' % bookid] >= 10800 :\n                return None\n            else:\n                raise IgnoreRequest(\"The novel is't update\")\n        else:\n            return None\n```\n\n###spider.py\n```\n# -*- coding: utf-8 -*-\n\nimport scrapy\nfrom scrapy.spiders import CrawlSpider, Rule\nfrom scrapy.linkextractors import LinkExtractor\nfrom sfacg.items import SfacgItem\nimport re, requests, time, random\n\nclass SfacfgSpider(CrawlSpider):\n    name = 'sfacg'\n    rules=(\n        Rule(LinkExtractor(allow=('/List/default.aspx?PageIndex=\\d+'))),\n        Rule(LinkExtractor(allow=('/Novel/\\d+/'),deny=('/List/default.aspx?PageIndex=\\d+')),callback='detail_parse')\n        )\n    allowed_domains = ['sfacg.com']\n    start_urls = ['http://book.sfacg.com/List/']\n\n    def test_url(self, url):#æ£€æŸ¥url\n        if re.match(r'^/', url):\n            out = 'http://book.sfacg.com' +str(url)\n        else:\n            out = url\n        return out\n\n    def parse_start_url(self, response):#åˆå§‹åŒ–ä¸‹è½½ï¼Œè·å¾—æ€»é¡µæ•°ã€æ€»ä¹¦ç±æ•°\n        max_page = int(response.xpath('//div[@class=\"list_pages\"]/ul[@class=\"nav pagebar\"]/li[last()-1]/a/text()').extract()[0])\n        sumNumbook = int(response.xpath('//div[@class=\"list_pages\"]/div[@class=\"page_l\"]/span/text()').extract()[0])\n        page_baseurl = 'http://book.sfacg.com/List/default.aspx?PageIndex='\n        Item = SfacgItem()\n        Item['bookid'] = 0\n        Item['bookname'] = 'sum'\n        Item['text_time'] = time.ctime()\n        Item['sumNumbook'] = sumNumbook\n        Item['max_page'] = max_page\n        t = requests.post(\"http://book.sfacg.com/ajax/ashx/Common.ashx?op=getunlockhour\", {'nid': 44068})\n        Item['VIP_time'] = int(re.findall(r'(\\d+)', t.text)[0])\n        yield Item\n        for page_url in [page_baseurl +str(i) for i in range(max_page+1)[1:]]:\n            yield scrapy.Request(page_url)\n\n    def detail_parse(self, response):#ä¹¦ç±ä¿¡æ¯è·å¾—\n        bookid = int(re.findall(r'Novel/(\\d+\\d)', str(response.url))[0])\n        Item =SfacgItem()\n        Item['text_time'] = time.ctime()\n        ##é™æ€éƒ¨åˆ†è·å–\n        Item['bookid'] = bookid\n        Item['bookname'] = response.xpath('//ul[@class=\"synopsises_font\"]/li[1]/img/@alt').extract()[0]\n        Item['author'] = response.xpath('//ul[@class=\"synopsises_font\"]/li[2]/a/text()').extract()[1]\n        Item['word_number'] = response.xpath('//ul[@class=\"synopsises_font\"]/li[2]/span/text()').extract()[4]\n        Item['type'] = response.xpath('//ul[@class=\"synopsises_font\"]/li[2]/a/text()').extract()[0]\n        commen_num = response.xpath('//span[@class=\"content_title\"]/span/a/text()').re('\\d+')\n        l_c = len(commen_num)\n        if  l_c == 0:       \n            Item['brief_commen_num'] = 0\n            Item['long_commen_num'] = 0\n        elif l_c == 1:\n            Item['brief_commen_num'] = int(commen_num[0])\n            Item['long_commen_num'] = 0\n        else:\n            Item['brief_commen_num'] = int(commen_num[0])\n            Item['long_commen_num'] = int(commen_num[1])\n        #VIP\n        if response.xpath('//ul[@class=\"synopsises_font\"]/descendant::img/@src').re('vip.gif'):\n            is_VIP = True\n        else:\n            is_VIP = False\n        Item['is_VIP'] = is_VIP\n        b = response.xpath(\"//ul[@class='synopsises_font']/li[2]/child::text()\").extract()\n        i = 0\n        while b[i] == u'\\r\\n' or b[i] == u'\\r\\n\\r\\n':\n            i = i + 1\n        if i >= 5:\n            Item['brief_introduction'] = ''\n        else:\n            Item['brief_introduction'] = b[i]\n        Item['update_time'] = response.xpath('//ul[@class=\"synopsises_font\"]/descendant::text()').re('(\\d{4}.+\\d\\d)')[-1]\n        Item['status'] = response.xpath('//ul[@class=\"synopsises_font\"]/li[2]/descendant::text()').re('\\[(.*)\\]')[-1]\n        ##åŠ¨æ€éƒ¨åˆ†è·å–\n        #æµè§ˆå™¨\n        headers={'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'}\n        s = requests.Session()\n        s.headers.update(headers)\n        #ä¸€èˆ¬åŠ¨æ€\n        data0 = {'nid': bookid}\n        t1 = s.get(\"http://book.sfacg.com/ajax/ashx/GetTags.ashx\", params=data0)\n        Item['Tags'] = t1.json()\n        t2 = s.get(\"http://book.sfacg.com/Ajax/ashx/GetTicketNum.ashx\", params=data0)\n        Item['MonTicketNum'] = t2.json()\n        t3 = s.get(\"http://book.sfacg.com/Ajax/ashx/GetNovelPointSet.ashx\", params=data0)\n        Item['point'] = t3.json()\n        t4 = s.get(\"http://book.sfacg.com/NovelData/Statistic/%d.js\" % bookid)\n        time.sleep(0.15*random.random())\n        p1 = int(re.findall(r'viewTimes.*?(\\d+)', t4.text)[0])\n        p2 = int(re.findall(r'bookMarknum.*?(\\d+)', t4.text)[0])\n        p3 = int(re.findall(r'favSticks.*?(\\d+)', t4.text)[0])\n        p4 = int(re.findall(r'pointUserCount.*?(\\d+)', t4.text)[0])\n        p5 = int(re.findall(r'point.*?(\\d+)', t4.text)[0])\n        Item['view_time'] = p1\n        Item['bookMarknum'] = p2\n        Item['favSticks'] = p3\n        Item['pointUserCount'] = p4\n        Item['sum_point'] = p5\n        ##å›¾ç‰‡\n        cover_url = response.xpath(\"//ul[@class='synopsises_font']/li[1]/img/@src\").extract()[0]\n        Item['cover'] = self.test_url(cover_url) \n        #èƒŒæŠ•\n        beitou = response.xpath('//head/style/text()').re('(http://rs.sfacg.com/web/novel/images/images/beitou.*?)\\\\\"')        \n        if len(beitou) == 0:\n            Item['hav_beitou'] = False\n        else:\n            Item['hav_beitou'] = True\n            Item['left_beitou'] = self.test_url(beitou[0])\n            Item['right_beitou'] = self.test_url(beitou[1])\n        return Item\n\n```\n##iqing.inçˆ¬è™«\n###iqing_in.py\n```\n#!/usr/bin/env python3\n# -*- encoding: utf-8 -*-\n\nimport requests,re, os, time, codecs, random, json\nimport markdown_make\n\nclass down_book(object):\n    def __init__(self,url,down_type, sleep=False, update=False):\n        #base\n        self.in_url = url\n        self.sleep = sleep\n        self.time = time.ctime()\n        self.os_name = os.name\n        if down_type == 'l':    #web(w) or local(l)\n            self.down_type = True\n        else:\n            self.down_type = False\n        #base2\n        self.cover_url = ''\n        self.c_ids = []\n        self.i = 0\n        self.img_dir = ''\n        self.txt_dir = ''\n        self.c_start = []\n        self.book_url = ''\n        self.json1 = dict()\n        self.json2 = dict()\n        self.json3 = set()\n        #extends\n        if re.search('book',self.in_url):\n            book_id = re.findall('(\\d+)',url)[0]\n            self.index(book_id)\n            self.c_start = self.down_web(self.c_ids[0])\n        elif re.search('read',self.in_url):\n            c_id = re.findall('(\\d+)',url)[0]\n            self.c_start = self.down_web(c_id)\n            book_id = self.c_start[3]\n            self.index(book_id)\n        else:\n            print('the url error')\n        path_now = os.path.abspath('.')\n        if self.down_type:\n            dir_name = self.c_start[3] +'_' +self.c_start[2] +'_' +self.c_start[4] +'_l'\n        else:\n            dir_name = self.c_start[3] +'_' +self.c_start[2] +'_' +self.c_start[4] +'_w'\n        self.s_dir = os.path.join(path_now,dir_name)\n        if not os.path.exists(self.s_dir):\n            os.mkdir(self.s_dir)\n        self.txt_dir = os.path.join(self.s_dir, 'md')\n        #json\n        json_path = os.path.join(self.s_dir,'json.json')\n        if os.path.exists(json_path):\n            with codecs.open(json_path,'r','utf-8') as j:\n                json_s = j.read()\n            json_in = json.loads(json_s)\n            self.json1 = json_in[0]\n            self.json2 = json_in[1]\n            self.json3 = set(json_in[2])\n            if update:\n                self.json3.clear()               \n        #down\n        print('\\nä¸‹è½½å¼€å§‹â€¦â€¦')\n        print(self.s_dir)\n        print(self.c_ids)\n        print(self.book_url)\n        if self.down_type:\n            self.down_img(self.cover_url,'cover')\n        for c_id in self.c_ids:\n            if not self.json3.__contains__(c_id):\n                self.down_web(c_id)\n                if self.sleep:\n                    sleep_time = 0.05+random.random()*0.1\n                    time.sleep(sleep_time)\n        #log\n        self.log()\n\n    def index(self,book_id):\n        in_url = 'http://www.iqing.in/book/%s/' % book_id\n        self.book_url = in_url\n        index = requests.get(in_url)\n        i_c = index.text\n        cover_urls = re.findall(r'src=\"(https://image.iqing.in/cover/.+?)\\?imageView|src=\"(https://image.iqing.in/submit/image/.+?)\\?imageView',i_c)[0]\n        for cover_url in cover_urls:\n            if cover_url != '':\n                c_ids = re.findall(r'href=\"/read/(\\d+)\"',i_c)\n                c_ids.pop(0)\n                self.c_ids = c_ids\n                i = 1\n                for t in self.c_ids:\n                    self.json1[i] = t\n                    i = i + 1\n                self.cover_url = cover_url\n                return\n\n    def down_img(self,url,append=''):\n        self.img_dir = os.path.join(self.s_dir,'img')\n        print(url)\n        if not os.path.exists(self.img_dir):\n            os.mkdir(self.img_dir)\n        if append == '':\n            img_name = os.path.split(url)[1]\n        else:\n            img_name = '!' +append +'_' +os.path.split(url)[1]\n        img_path = os.path.join(self.img_dir,img_name)\n        if (not os.path.exists(img_path)) and append != 'n':\n            i_r = requests.get(url, stream=True)\n            i_r_c = i_r.content\n            with open(img_path, 'wb') as i_f:\n                i_f.write(i_r_c)\n        return img_name\n\n    def down_web(self,c_id):\n        print(c_id)\n        c_url = 'http://www.iqing.in/content/' +c_id +'/chapter/'\n        r = requests.get(c_url).json()\n        volume_title = r[u'volume_title']\n        chapter_title = r[u'chapter_title']\n        book_title = r[u'book_title']\n        book_id = str(r[u'book_id'])\n        # next_chapter_id = r[u'next_chapter_id']\n        author_name = r[u'author_name']\n        updated_time = r[u'updated_time']\n        self.json2[c_id] = {'volume_title':volume_title,'chapter_title':chapter_title,'updated_time':updated_time}\n        t = [volume_title,chapter_title,book_title,book_id,author_name,updated_time,c_id]\n        if self.i != 0:\n            self.text_write(r,t)\n            self.json3.add(c_id)\n        self.i = self.i + 1\n        return t\n\n    def text_write(self,r,t):\n        self.txt_dir = os.path.join(self.s_dir, 'md')\n        if not os.path.exists(self.txt_dir):\n            os.mkdir(self.txt_dir)\n        # file_name_r = str(self.i) +'_' +t[0] +'_' +t[6] +'_' +t[1] +'.txt'\n        # if self.os_name == 'nt':\n        #     file_name = re.sub(r'\\\\|\\/|\\:|\\*|\\?|\\\"|\\<|\\>|\\|', '_', file_name_r)\n        # else:\n        #     file_name = re.sub(r'\\/', '_', file_name_r)\n        file_name = t[6] +'.md'\n        txt_path = os.path.join(self.txt_dir, file_name)\n        updated_time = '*' +re.sub('T',' ',t[-2]) +'*'\n        # f = codecs.open(txt_path,'w','utf-8')\n        with codecs.open(txt_path,'w','utf-8') as f:\n            c = '##%s\\n\\n**%s**\\n\\n%s\\n\\n---\\n\\n' % (t[1],t[0],updated_time)\n            f.write(c)\n            for c_r in r[u'results']:\n                #æ–‡å­—\n                if c_r[u'type'] == 0:\n                    r_c = c_r[u'value'] +'\\n'\n                    c = re.sub('\\n', '\\n\\n', r_c)\n                    f.write(c)\n                elif c_r[u'type'] == 1:\n                    img_url = c_r[u'value']\n                    if self.down_type:\n                        img_name = self.down_img(img_url)\n                        c = '![%s](img/%s)' % (img_name, img_name) +'\\n\\n'\n                        f.write(c)\n                    else:\n                        img_name = self.down_img(img_url,'n')\n                        c = '![%s](%s)' % (img_name,img_url) +'\\n\\n'\n                        f.write(c)\n            f.close()\n\n    def log(self):\n        end_path = os.path.join(self.txt_dir,'9999.md')\n        with codecs.open(end_path, 'w', 'utf-8') as end:\n            i_end_c = '##Book Infomations\\n\\n---\\n\\n**BookName:** [%s](%s)\\n\\n**BookId:** %s\\n\\n**BookAuthor:** %s\\n\\n**DownTime:** %s' % (self.c_start[2],self.book_url,self.c_start[3],self.c_start[4],self.time)\n            end.write(i_end_c)\n        if self.json1.get('9999', True) == True:\n            self.json1[9999]='9999'\n            self.json2['9999']={'volume_title':'END', 'chapter_title':'Book Infomations'}\n        #json\n        json_path = os.path.join(self.s_dir,'json.json')\n        json3 = list(self.json3)\n        with codecs.open(json_path,'w','utf-8') as j:\n            json_out = [self.json1,self.json2,json3]\n            json_s = json.dumps(json_out)\n            j.write(json_s)\n        #xhtml\n        markdown_make.mark2html(self.s_dir)\n        #final log\n        with codecs.open('iqing.in_history.log' , 'a', 'utf-8') as f:\n            history = '%s,%s,%s,%s,%s,%s\\n' % (self.time, self.c_start[2], self.in_url,self.c_start[3],self.c_start[4], self.down_type)\n            f.write(history)\n\nif __name__=='__main__':\n    url = input('plese input url: ')\n    down_type = input('plese input download type(web(w) or local(l)): ')\n    update_in = input('update(t:True,f:False)')\n    if update_in == 't':\n        update = True\n    else:\n        update = False\n    Iqing = down_book(url,down_type, update=update)\n```\n\n###markdown_make.py\n```\n#!/usr/bin/env python3\n# -*- coding: utf-8 -*-\n\nimport markdown,codecs,os,re,json, shutil\n\nclass mark2html(object):\n    def __init__(self,folder):\n        #æ ¹ç›®å½•\n        self.folder_r = folder\n        print('å¼€å§‹è½¬æ¢â€¦â€¦')\n        print(folder)\n        #æº\n        self.folder_s = os.path.join(self.folder_r, 'md')\n        #ç»“æœ\n        self.folder = os.path.join(folder, 'xhtml')\n        #delete dir\n        if os.path.exists(self.folder):\n            shutil.rmtree(self.folder, True)\n            print('%s removed!' % self.folder)\n        #mkdir\n        if not os.path.exists(self.folder):\n            os.mkdir(self.folder)\n        #json\n        json_path = os.path.join(self.folder_r,'json.json')\n        if os.path.exists(json_path):\n            with codecs.open(json_path,'r','utf-8') as j:\n                json_s = j.read()\n            json_in = json.loads(json_s)\n            self.json1 = json_in[0]\n            self.json2 = json_in[1]\n            self.i_n = dict()\n            for ts_0 in self.json1:\n                self.i_n[int(ts_0)]=self.json1[ts_0]\n        #covert\n        self.volume = set()\n        self.markdown_covert()\n\n    def markdown_covert(self):\n        for md_n in self.i_n:\n            #md\n            md_cid = self.i_n[md_n]\n            md_name = md_cid +'.md'\n            md_path = os.path.join(self.folder_s, md_name)\n            with codecs.open(md_path, 'r', 'utf-8') as f_in:\n                md_content = f_in.read()\n            #json\n            json2 = self.json2[md_cid]\n            volume_title = json2['volume_title']\n            chapter_title = json2['chapter_title']\n            #updated_time = json2['updated_time']\n            #volume\n            self.volume_file(md_n, volume_title)\n            #web\n            web_title = volume_title +'-' +chapter_title\n            web_title = self.web_title_deal(web_title)\n            web_head = '<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\\n\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\\n<head>\\n<title>%s</title>\\n</head>\\n<body>\\n' % web_title\n            web_body = markdown.markdown(md_content)\n            web_tail = '</body>\\n</html>'\n            web = web_head +web_body +web_tail\n            #xhtml\n            xhtml_name = str(md_n) +'_' +md_cid +'_' +volume_title +'_' +chapter_title +'.xhtml'\n            if os.name == 'nt':\n                xhtml_name = re.sub(r'\\\\|\\/|\\:|\\*|\\?|\\\"|\\<|\\>|\\|', '_', xhtml_name)\n            else:\n                xhtml_name = re.sub(r'\\/', '_', xhtml_name)\n            xhtml_path = os.path.join(self.folder, xhtml_name)\n            with codecs.open(xhtml_path, 'w', 'utf-8') as f_out:\n                f_out.write(web)\n            print('%s\\t%s' % (md_n, md_cid))\n    \n    def volume_file(self, cid, volume_title):\n        web_title = volume_title\n        web_title = self.web_title_deal(web_title)\n        web_head = '<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\"\\n\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\\n<head>\\n<title>%s</title>\\n</head>\\n<body>\\n' % web_title\n        web_body = '<h1 style=\"text-align: center; \">%s</h1>\\n' % volume_title\n        web_tail = '</body>\\n</html>'\n        web = web_head +web_body +web_tail\n        #xhtml\n        vid = cid -1\n        xhtml_name = str(vid)  +'_' +volume_title +'.xhtml'\n        if os.name == 'nt':\n            xhtml_name = re.sub(r'\\\\|\\/|\\:|\\*|\\?|\\\"|\\<|\\>|\\|', '_', xhtml_name)\n        else:\n            xhtml_name = re.sub(r'\\/', '_', xhtml_name)\n        xhtml_path = os.path.join(self.folder, xhtml_name)\n        if not self.volume.__contains__(volume_title):\n            self.volume.add(volume_title)\n            with codecs.open(xhtml_path, 'w', 'utf-8') as vf_out:\n                vf_out.write(web)\n            print('volume\\t%s' % vid)\n    \n    def web_title_deal(self, web_title):\n        web_title = re.sub(r'\"', '&quot;', web_title)\n        web_title = re.sub(r'&', '&amp;', web_title)\n        web_title = re.sub(r'<', '&lt;', web_title)\n        web_title = re.sub(r'>', '&gt;', web_title)\n        return web_title\n\nif __name__=='__main__':\n    path = os.path.abspath('.')\n    mark2html(path)\n```"
		},
		{
			"post_id": 26,
			"title": "æ— é¢˜",
			"date_published": 1467817098.82,
			"body": "![2.png](data/res/1467822483592-2.png)\nä»–å…ˆå‰èµ°ç€ï¼Œå¦‚æœç°åœ¨å›å¤´çš„è¯â€”â€”é‚£äººä¸€å®šä¹Ÿä¼šå›å¤´ï¼Œä»–å¼ºçƒˆåœ°æ‹¥æœ‰è¿™ç§æƒ³æ³•ã€‚æ²¡æœ‰æ ¹æ®ï¼Œå´å……æ»¡è‡ªä¿¡ã€‚\näºæ˜¯ï¼Œåœ¨å®Œå…¨èµ°è¿‡é“é“çš„æ—¶å€™ï¼Œä»–ç¼“ç¼“è½¬è¿‡èº«çœ‹å‘é‚£ä½å¥³æ€§ã€‚å¥¹ä¹Ÿæ…¢æ…¢è½¬äº†è¿‡æ¥ï¼ŒäºŒäººç›®å…‰äº¤é”™ã€‚\nå°±åœ¨å¿ƒä¸è®°å¿†å³å°†æ²¸è…¾çš„ç¬é—´ï¼Œå°ç”°æ€¥çº¿çš„ç‰¹å¿«åˆ—è½¦æŒ¡ä½äº†äºŒäººçš„è§†é‡ã€‚\n\nç”µè½¦é€šè¿‡ä¹‹åï¼Œä»–æƒ³ã€‚å¥¹åº”è¯¥è¿˜åœ¨é‚£é‡Œå§ã€‚\n\nä¸è¿‡éƒ½æ— æ‰€è°“ã€‚å¦‚æœä»–å°±æ˜¯é‚£ä¸ªäººçš„è¯ï¼Œè¿™å·²ç»ç®—æ˜¯ä¸ªå¥‡è¿¹äº†ã€‚ä»–æƒ³â€¦â€¦\nç­‰è¿™åˆ—ç”µè½¦å¼€è¿‡ä¹‹åå°±å‘å‰èµ°ï¼Œä»–åœ¨å¿ƒé‡Œä½œå‡ºå†³å®šã€‚\n![1.png](data/res/1467822470666-1.png)"
		},
		{
			"post_id": 25,
			"title": "2016-07-06",
			"date_published": 1467815889.708,
			"body": "è¿™ä¸ªæœˆå¿™ç€è€ƒè¯•ï¼Œæ„Ÿè§‰æˆ‘è¿™ä¸ªç½‘ç«™å¥½åƒå·²ç»æ­»äº†ï¼ï¼\n\n***\nPS1ï¼š\nåˆšåˆšå‘äº†ä¸€ä¸‹ï¼Œå‘ç°è¿˜æœ‰ä¸€ä¸ªèŠ‚ç‚¹åœ¨ã€‚\nPS2:\nä¹‹å‰å‘å¸ƒçš„æ—¶å€™éƒ½æ˜¯ç”¨whonixè¿æ¥torï¼Œä¼°è®¡æ˜¯å—åˆ°ç¼–ç¨‹éšæƒ³çš„å½±å“ã€‚\nä½†æ˜¯ä¸å¾—ä¸è¯´ï¼Œé€Ÿåº¦æœ‰ä¸€äº›å ªå¿§å‘€ï¼å½“ç„¶ä¹Ÿæ²¡æœ‰é‚£ä¹ˆæ…¢ï¼Œæ¯•ç«Ÿæ˜¯è‡ªå»ºçš„ssæœåŠ¡å™¨ï¼Œä¸»è¦æ˜¯å¼€å…³è™šæ‹Ÿæœºæœ‰ä¸€ç‚¹éº»çƒ¦ï¼Œè€Œä¸”å‘å¸ƒè¦å®å¥½å‡ æ¬¡æ‰èƒ½æˆåŠŸ**ï¼ˆå½“æ—¶ç‰¹æ®Šæ—¶æœŸï¼Œç°åœ¨åŸºæœ¬ä¸ä¼šäº†ï¼‰**ã€‚\näºæ˜¯è®¡åˆ’ä¸æˆ´toräº†ï¼Œè£¸èº«ä¸Šé˜µã€‚\nå¦‚æœæˆ‘è¿™éƒ½è¢«XXXäº†ï¼Œé‚£æˆ‘ä¹Ÿæ— è¯å¯è¯´äº†ï¼\nPS3:\næ„Ÿè§‰è‡ªå·±çš„ç½‘ç«™å¥½ä¸‘ï¼Œæ‰“ç®—ä¼˜åŒ–ä¸€ä¸‹ã€‚\nè®¡åˆ’åŠ ä¸Šæ ‡ç­¾ã€‚\nå½“ç„¶è¿™è¿˜ä¸åœ¨æ—¥ç¨‹ä¸Šï¼Œæ¯•ç«Ÿè¿˜æœ‰å…¶ä»–äº‹æƒ…è¦åšã€‚"
		},
		{
			"post_id": 24,
			"title": "2015.6.4",
			"date_published": 1465049590.9,
			"body": "ä»Šå¤©ç­”è¾©ç»ˆäºå®Œäº†ï¼Œå¿™äº†å¥½ä¸€ä¼šã€‚\n\nåˆšåˆšåœ¨è®ºå›é‡Œçœ‹åˆ°æœ‰äººå‘æœ‰å…³6.4çš„çºªå¿µå¸–å­ã€‚\n>[ç´€å¿µ89å­¸é‹27é€±å¹´ï¼Œç‚º64æ­»é›£è€…é»˜å“€](http://127.0.0.1:43110/gfwtalk.bit/?Topic:3_1Fv1xGsCxVzHNkCyCMLkJsXaqHSqc5VS45/+89+27+64)\n>å‘ç‚ºäº†æ°‘ä¸»è¨´æ±‚è€ŒçŠ§ç‰²é»˜å“€ï¼Œç‚ºäº†ç„¡è¾œæ…˜é­å± æ®ºçš„å¸‚æ°‘é»˜å“€ï¼\n\nä»¥å‰çœ‹äº†6.4çš„çºªå½•ç‰‡ï¼Œç¡®å®æœ‰ä¸€äº›æ„Ÿæƒ³ï¼Œç°åœ¨å›æƒ³èµ·è¿˜æ˜¯æœ‰ä¸€äº›æ„Ÿæƒ³ï¼Œä½†æ›´å¤šçš„æ˜¯ä¸€äº›é™é»˜ï¼Œä¸€ç§æ¼ ä¸å…³å¿ƒã€‚\næˆ‘ä¸çŸ¥é“æ˜¯ä»€ä¹ˆæ”¹å˜äº†ã€‚\nç°åœ¨æˆ‘åªæ˜¯é»˜é»˜çš„çœ‹çœ‹ï¼Œç¿»å¢™å‡ºå»ç„ç„ï¼Œçœ‹çœ‹éƒ½æœ‰ä»€ä¹ˆåŠ¨å‘ï¼Œä½†å¹¶æ²¡æœ‰ä»€ä¹ˆé¸Ÿç”¨ã€‚\n\nä¹Ÿè®¸æ”¿æ²»è¿™ç§ä¸œè¥¿æ˜¯è‚‰é£Ÿè€…å…³å¿ƒçš„äº‹ï¼Œæˆ‘ä»¬å±æ°‘å°±å¥½å¥½å¾…ç€å§ï¼\n\nPS:[ä¸­å›½äº’è”ç½‘ç»´æŠ¤æ—¥äº’è”ç½‘å¯ç”¨æ€§æµ‹è¯•](http://127.0.0.1:43110/gfwtalk.bit/?Topic:3_1958F7oCppj78MP966AfojMQwHg2WUupzq/)\n\n---\n>æ­å·ç”µä¿¡ï¼š\n>    æ— ç•Œï¼šæ‰¾ä¸åˆ°æœåŠ¡å™¨\n>    è‡ªç”±é—¨ï¼šæ‰¾ä¸åˆ°æœåŠ¡å™¨ï¼Œä½¿ç”¨ DNSCrypt åå¯ä»¥æ‰¾åˆ°æœåŠ¡å™¨ï¼Œä½†æ˜¯è®¿é—®ä¸äº†ç½‘é¡µ\n>    èµ›é£ï¼šæ­£å¸¸è¿æ¥ï¼Œé€Ÿåº¦å°šå¯\n >   è“ç¯ï¼šè¿æ¥ä¸Šä½†ä¸ç¨³å®šï¼Œé€Ÿåº¦æä½å¸¸å¸¸æ— æ³•è®¿é—®ï¼Œæç¤ºè¿æ¥è¢«é‡ç½®\n >   æŸå•†ä¸š Shadowsocks æœåŠ¡ï¼šè¿æ¥æ­£å¸¸\n>\n>æ­å·ç§»åŠ¨ï¼š\n>\n>    æ— ç•Œï¼šæ­£å¸¸è¿æ¥\n>    è‡ªç”±é—¨ï¼šæ­£å¸¸è¿æ¥\n>    èµ›é£ï¼šæ— æ³•è¿æ¥\n>    è“ç¯ï¼š æ­£å¸¸è¿æ¥\n>    æŸå•†ä¸š Shadowsocks æœåŠ¡ï¼šè¿æ¥æ­£å¸¸\n>    Freenet Opennetï¼šæ€§èƒ½æ˜æ˜¾å‡ä½ï¼Œè¿æ¥æ•°å‡å°‘\n>    Tor -meek-amazonï¼šæ­£å¸¸è¿æ¥\n>    Tor -meek-azureï¼šæ­£å¸¸è¿æ¥\n>\n>çœ‹èµ·æ¥ç§»åŠ¨ä¸‹æŒ‚æ‰çš„æƒ…å†µä¸æ˜¯å¾ˆä¸¥é‡ï¼Œç”µä¿¡è¿˜æ˜¯æŒºä¸¥é‡çš„ï¼Œä¸è¿‡è‡³å°‘è¿˜èƒ½ç”¨ã€‚\n"
		},
		{
			"post_id": 23,
			"title": "2015.06.02",
			"date_published": 1464879787.1,
			"body": "è€å‘¨æ›¾ç»è¯´è¿‡ï¼Œå¿™å®Œç§‹æ”¶å¿™ç§‹ç§ï¼Œå­¦ä¹ å­¦ä¹ å†å­¦ä¹ ã€‚\n\nä½†æ˜¯ä¸Šäº†å¤§å­¦ä»¥æ¥å°±æ²¡æ€ä¹ˆåŠªåŠ›å­¦ä¹ ï¼Œç»©ç‚¹ä¹Ÿæœ‰ä¸€ç‚¹æƒ¨ä¸å¿ç¹ã€‚\né©¬ä¸Š6çº§äº†ï¼Œæ²¡æœ‰å¤ä¹ ï¼Œå…«æˆè¿‡ä¸äº†"
		},
		{
			"post_id": 22,
			"title": "å…­ä¸€å„¿ç«¥èŠ‚å¿«ä¹",
			"date_published": 1464879733.3,
			"body": "è™½ç„¶å·²ç»6æœˆ2å·äº†"
		},
		{
			"post_id": 21,
			"title": "å¤ªçƒ­äº†",
			"date_published": 1464624101.2,
			"body": "åˆšåˆšçœ‹äº†ä¸‹æ¸©åº¦è®¡29åº¦ï¼Œæ²¡æœ‰ç©ºè°ƒçš„å¤å¤©çœŸçš„å¾ˆéš¾è¿‡ï¼"
		},
		{
			"post_id": 20,
			"title": "å…³äºä¸Šç½‘ç™½åå•çš„è®¨è®ºï¼Œé™„æ–°ç–†æ–­ç½‘æ—§æ–‡ä¸€ç¯‡",
			"date_published": 1464511679.2,
			"body": "<a href=\"http://127.0.0.1:43110/1Nse6WcodQ5Mj6ZwvZvuyCVvQESwuxbCUy/?Topic:2_12kgNNnBaR3s7bN761BCQtkzSC7EbrK2Jd/\"target=\"_blank\">å‘ƒã€‚ã€‚ã€‚ã€‚æœ‰äººæ‹…å¿ƒå¼€å¯ç™½åå•æ¨¡å¼äº†</a>\n\n##é™„ï¼š äº’è”ç½‘ä¸Šä½ ä¸çŸ¥é“çš„æ–°ç–†æ–­ç½‘<a href=\"http://www.kaixin001.com/repaste/6750921_3102996832.html\"target=\"_blank\">ï¼ˆè½¬è´´ï¼‰</a>\näº’è”ç½‘ä¸Šä½ ä¸çŸ¥é“çš„æ–°ç–†æ–­ç½‘ï¼ˆè½¬è´´ï¼‰\n\nå¤§ç‰›ç¼–å‰è¯­ï¼šä¸‹é¢è¿™ç¯‡æ–‡ç« æ˜¯æ–°ç–†æ–­ç½‘æ—¶ä¸€ä½çƒ­å¿ƒç½‘å‹å†™çš„å¹¶ä¸”å¸–åœ¨æ–°ç–†å®¶å›­å¤©ç½‘ä¸Šï¼Œè®°å½•äº†æ–°ç–†ä»æ–­ç½‘åˆ°2009å¹´12æœˆ25æ—¥æœŸé—´çš„äº’è”ç½‘å†å²ã€‚åœ¨è¿™ä¸ªä¸­åäººæ°‘å…±å’Œå›½æˆç«‹61å¹´çš„å¤§å–œæ—¥å­é‡Œï¼Œæœ¬ç€å†å²ä¸èƒ½å‡ºç°æ–­æ¡£çš„åŸåˆ™ï¼Œæˆ‘æŠŠä»–è½¬è´´å‡ºæ¥ï¼Œä½œè€…ä¸è¯¦ï¼Œæ„Ÿè°¢å¤©ç½‘ï¼Œè°¢ç»æœ¬çœè·¨çœçš„ä¸€åˆ‡å½¢å¼çš„è¿½æ•ã€‚\n\n---\näº’è”ç½‘ä¸Šä½ ä¸çŸ¥é“çš„æ–°ç–†æ–­ç½‘\n\nç°åœ¨æ–°ç–†å…¨å¢ƒä¾ç„¶æ˜¯æ–­ç½‘æ–­çŸ­ä¿¡æ–­å›½é™…é•¿é€”ä¸‰æ–­ä¸­ã€‚è¿™ç§ä¸­æ–­è·Ÿå†…åœ°çš„GFWä¸å°½ç›¸åŒï¼Œå¯¹äºæ™®é€šç”¨æˆ·åŸºæœ¬ä¸Šç®—æ˜¯ç‰©ç†éš”ç¦»ï¼Œå‡ ä¹æ‰€æœ‰**ipå’Œ**ç«¯å£å‡æ— æ³•è®¿é—®ã€‚èƒ½å¤Ÿè®¿é—®çš„åªæœ‰ç–†å†…çš„ç«™ï¼Œä»¥åŠæå°‘æ•°ipå’Œä¸»æœºåœ¨å¤–åœ°çš„å›½å®¶çº§å®˜æ–¹ç½‘ç«™ï¼ˆå¦‚ç½‘ç«™å¤‡æ¡ˆæŸ¥è¯¢ã€å„ç§è€ƒè¯•æŠ¥åç½‘ç«™ï¼‰ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå›½å†…å…¬ä¼—ç½‘çš„GFWæ˜¯é»˜è®¤æ”¾è¡Œï¼Œéƒ¨åˆ†ipå’ŒåŸŸåæ‹¦æˆª+å…³é”®è¯æ‹¦æˆªï¼›è€Œæ–°ç–†æ˜¯é»˜è®¤æ–­å¼€ï¼Œä¸ªåˆ«ipå’ŒåŸŸåæ”¾è¡Œã€‚\n\nä¸Šç½‘æ–¹å¼æ–¹é¢ï¼Œ7æœˆ6æ—¥å‡Œæ™¨4ç‚¹chinanetå…¨éƒ¨å°é”ï¼Œéšåæ˜¯ç§»åŠ¨ã€è”é€šçš„å…¬ä¼—ç½‘ç»œã€‚æ•™è‚²ç½‘ï¼ˆCERNETï¼‰ä¼°è®¡æ˜¯ç”¨çš„ç”µä¿¡å‡ºå£ï¼Œä¹Ÿæ˜¯åŒæ­¥è¢«å°ã€‚ç§‘æŠ€ç½‘ï¼ˆé‡‘æ¡¥ï¼‰å¤šæ’‘äº†ä¸¤å¤©ï¼Œäº7æœˆ9*è¢«å°é”ã€‚æ‰‹æœºä¸Šç½‘æ–¹é¢ï¼ŒNETæ–¹å¼å‡åŒæ—¶è¢«å°é”ï¼ŒWAPæ–¹å¼åˆ™æ¨è¿Ÿåˆ°ä¸ƒæœˆåå‡ *å·¦å³æ‰å°é”ï¼Œå…¶ä¸­ç”µä¿¡çš„WAPæ–¹å¼ç”šè‡³åˆ°äº† 8æœˆä¸­æ‰å°é”å®Œæ¯•ï¼ŒæœŸé—´ä¸€ç›´å¯ä»¥ç™»å½•WAPQQã€‚3Gä¸Šç½‘å¡æ–¹é¢ï¼ŒåŸºæœ¬æ˜¯åŒæ—¶å°é”ï¼Œæœ‰ä¼ é—»æ˜¯å¦‚æœç”¨å¤©ç¿¼3Gæ‹¨å·æ—¶è·å¾—çš„IPæ˜¯120.X.X.Xå°±å¯ä»¥é¡ºåˆ©ä¸Šç½‘ï¼Œä¸è¿‡è¿™ä¸ªä¼ é—»æœªéªŒè¯ã€‚æ™®é€šç”¨æˆ·èƒ½å¤Ÿç¿»å‡ºGFWç»ˆæç‰ˆçš„ä¸Šç½‘æ–¹å¼åªæœ‰æ‹¨å·ä¸€ç§äº†ï¼Œä¹Ÿå°±æ˜¯10å¹´å‰æˆ‘ä»¬å¤§å®¶å¸¸ç”¨çš„56kçª„å¸¦æ‹¨å·ã€‚å…·ä½“æ–¹å¼åæ–‡è¯¦è¿°ã€‚\n\nçŸ­ä¿¡æ–¹é¢ï¼Œç‚¹å¯¹ç‚¹çŸ­ä¿¡å‡æ— æ³•å‘é€ï¼Œæ‰‹æœºç«¯ç›´æ¥æŠ¥é”™ï¼Œåº”è¯¥æ˜¯ç‚¹å¯¹ç‚¹çŸ­ä¿¡ç½‘å…³æ ¹æœ¬å°±æ²¡å¯åŠ¨ã€‚ä»…æœ‰éƒ¨åˆ†å…¬ä¼—SPä¸šåŠ¡å¼€é€šï¼Œå¦‚å¤©æ°”é¢„æŠ¥ã€æ‰‹æœºæŠ¥ã€ 10000/10086/10010è¿™ç±»çš„è¿è¥å•†å®˜æ–¹ä¿¡æ¯ï¼Œç”¨æˆ·å¯ä»¥æ¥åˆ°ã€‚éœ€è¦æ³¨æ„çš„æ˜¯å¤–åœ°æ‰‹æœºæ¼«æ¸¸è‡³æ–°ç–†ï¼Œä¸€æ ·æ— æ³•å‘çŸ­ä¿¡ï¼Œæ‰€ä»¥ä¸è¦å¦„æƒ³ä¹°ä¸ªå¤–åœ°çŸ­ä¿¡å¡å°±èƒ½åœ¨æ–°ç–†èŠå¤©äº†ã€‚æˆ‘è‡ªå·±æ›¾ç»å‘çŸ­ä¿¡å¦‚é£çš„æ‰‹æŒ‡ï¼Œç°åœ¨ä¹Ÿå¿«ä¸çŸ¥é“æ€ä¹ˆæŒ‰äº†ã€‚å¯ä»¥è¯´è¿™å‡ ä¸ªæœˆæ–°ç–†çš„SPå’ŒCPç±»å…¬å¸é­åˆ°äº†é‡åˆ›ï¼Œå€’é—­å…³é—¨æˆ–æ’¤å›å†…åœ°çš„ä¸è®¡å…¶æ•°ã€‚\n\nå›½é™…é•¿é€”æ–¹é¢ï¼Œå¤§æ¦‚æ˜¯7æœˆ7*å¼€å§‹å°±éå¸¸éš¾ä»¥æ‹¨å…¥ï¼Œ8æœˆä»¥åå°±åŸºæœ¬æ— æ³•æ‹¨å…¥äº†ã€‚å‘¼å‡ºæ–¹é¢ï¼Œé™¤äº†å½“å±€æŒ‡å®šçš„ä»…æœ‰å‡ ä¸ªæœºå…³å•ä½å’Œå‡ ä¸ªå¤§çš„ç”µä¿¡è¥ä¸šå…å¯ä»¥æ‰“ï¼ˆåƒä¸åƒ80å¹´ä»£ï¼‰ï¼Œå…¶ä»–å…¨éƒ¨çš„ç›´æ’­ã€IPã€ç½‘ç»œå›½é™…é•¿é€”ç”µè¯å‡æ— æ³•å‘¼å‡ºã€‚æ‰¹å‘å›½é™…ipå¡çš„å•†å®¶äºåˆ°å‡ºå±ï¼Œæ–°ç–†å¤§æ‰¹åšä¸­äºšå¤–è´¸çš„å•†å®¶ä¹Ÿéƒ½éš¾ä»¥å¼€å±•ä¸šåŠ¡ã€‚æˆ‘çš„è¡¨å¦¹åœ¨é©¬æ¥è¥¿äºšä¸Šå­¦ï¼Œå¿«åŠå¹´äº†æ²¡ä¸€ä¸ªç”µè¯ï¼Œå¥¹è€å¦ˆè¢«é€¼çš„è¯·äº†å‡å»å†…åœ°ä¸Šç½‘ï¼Œç»ˆäºåœ¨QQä¸Šå¾—ä»¥ä¸€è§ã€‚\n\næ–­ç½‘åçš„è¿™äº›å°é”ï¼Œé™¤å›½å†…é•¿é€”å°é”æ—¶é—´è¾ƒçŸ­ï¼Œæ–­ç½‘åå‡ å¤©å³è§£é™¤å¤–ï¼Œå…¶ä»–çš„ç›´åˆ°ç°åœ¨ï¼ˆ12æœˆ25*ï¼‰ä¹Ÿæ²¡æœ‰ä¸€ç‚¹å„¿æ”¾æ¾çš„è¿¹è±¡ã€‚åŸºæœ¬æ¯ä¸ªæœˆéƒ½æœ‰ä¼ é—»è¯´è¿™ä¸ªæœˆ/ä¸‹ä¸ªæœˆè¦å¼€ç½‘ï¼Œä»€ä¹ˆæ—¶å€™å¼€ç½‘ä¹Ÿæ˜¯ç–†å†…å„è®ºå›æœ€å¸¸è®¨è®ºçš„ä¸€ä¸ªè¯é¢˜ï¼Œå·²ç»ä¸èƒ½ç”¨*ç»æ¥å½¢å®¹äº†ã€‚å¯æƒœè¿™äº›æœŸæœ›ï¼Œæœ€åéƒ½æ˜¯ä»¥å¤±æœ›å‘Šç»ˆã€‚\n\næ–­ç½‘æŒç»­48å°æ—¶ï¼šè¿™æ˜¯7æœˆ6*æœ€åˆçš„ä¼ é—»ï¼Œæ®è¯´æ¥è‡ªäºè¿è¥å•†ã€‚å¯æƒœéšç€7æœˆ7*æ±‰æ—å¤§è§„æ¨¡æ¸¸è¡Œè­¦å‘Šå‘Šå¹ã€‚\n\næ–­ç½‘ä¸€å‘¨ï¼šå‚ç…§çŸ³é¦–ï¼Œè¿™ä¸ªä¼ é—»å¾ˆå¿«å‘Šå¹ã€‚\n\næ–­ç½‘åŠä¸ªæœˆ/ä¸€ä¸ªæœˆï¼šè¯´è¥¿è—314æ—¶æ–­ç½‘å°±è¿™ä¹ˆä¹…ï¼Œæ–°ç–†ä¹Ÿä¼šå‚ç…§ã€‚å¯æƒœæ®æˆ‘æœ¬äººè€ƒè¯ï¼Œè¥¿è—å½“æ—¶ä¼¼ä¹æ²¡æœ‰æ–­ç½‘ï¼Œæˆ–æ–­ç½‘æ—¶é—´å¾ˆçŸ­ã€‚åœ¨Googleä¸Šæœâ€œè¥¿è— æ–­ç½‘â€ï¼Œè²Œä¼¼æ²¡æœ‰ä»€ä¹ˆæœ‰ä»·å€¼çš„ä¿¡æ¯ï¼Œå¸Œæœ›æœ‰äº†è§£æƒ…å†µçš„JRè¯´è¯´ã€‚\n\n10æœˆå›½åº†åå¼€ç½‘ï¼šè¿™ä¸ªä¼ é—»æ˜¯è¯´éƒ½60å¤§å¯¿äº†ï¼Œå®‰å®šå’Œè°çš„å¤©æœè‚¯å®šä¼šç»™æˆ‘ä»¬è¿™2000w*æ°‘å¼€ç½‘ã€‚å‘Šå¹ã€‚\n\n11æœˆ1*å¼€éƒ¨åˆ†é—¨æˆ·ç½‘ç«™ï¼Œæ˜¥èŠ‚æ”¾å¼€å…¨éƒ¨ï¼šè¿™ä¸ªä¼ é—»æ˜¯æœ€æœ‰æ¨¡æœ‰æ ·çš„ï¼Œæ®è¯´æ˜¯è‡ªæ²»åŒºçº§é¢†å¯¼å®‰æ’ï¼Œå¤§éƒ¨åˆ†è¿è¥å•†éƒ½å†…éƒ¨é€šæŠ¥äº†ã€‚å¯æƒœç°åœ¨é©¬ä¸Šæ–°å¹´äº†ï¼Œä»ç„¶æ²¡æœ‰ä¸€ä¸ªé—¨æˆ·ç½‘ç«™èƒ½å¤Ÿè®¿é—®ã€‚è¿™ä¸ªä¼ é—»åº”è¯¥ä¸ºçœŸï¼Œæ®è¯´æœ€åæ˜¯è‡ªæ²»åŒºæ”¿æ³•å§”ä¹¦è®°ç¬¦å¼ºåŒå¿—å¼ºåŠ›å‹äº†ä¸‹æ¥ã€‚\n\næœ€æ–°çš„ä¼ é—»æ˜¯è¯´1æœˆä»½è¦å¼€æ”¾éƒ¨åˆ†é—¨æˆ·ï¼Œå…¨éƒ¨æ”¾å¼€åˆ°2010å¹´5æœˆä»½å·¦å³ï¼šè¿™ä¸ªæ¶ˆæ¯åŒæ ·æ¥è‡ªè¿è¥å•†å†…éƒ¨ï¼Œç„¶åˆ™å·²ç»æ²¡æœ‰å¤šå°‘äººå…³å¿ƒäº†ã€‚å¯¹é€šç½‘çš„ä¼ é—»æ–°ç–†çš„ç½‘æ°‘æ—©å·²éº»æœ¨ï¼Œå¯¹è¿™ç±»æ¶ˆæ¯éƒ½æ˜¯æ— å¥ˆçš„ä¸€ç¬‘äº†ä¹‹ã€‚\n\näºŒã€ç¿»å¢™\n\nä¸‹é¢æ¥è¯´è¯´å¤§å®¶æœ€å…³å¿ƒçš„ï¼Œé‚£äº›èƒ½ä¸Šç½‘çš„æ–°ç–†äººï¼Œæ˜¯æ€ä¹ˆä»é“æ¡¶ä¸€èˆ¬çš„å¢™é‡Œç¿»å‡ºæ¥çš„ã€‚\n\né¦–å…ˆï¼Œå†…åœ°å…¬ç½‘ä½¿ç”¨çš„ç¿»å¢™æ–¹æ³•å®Œå…¨ä¸é€‚ç”¨äºæ–°ç–†ï¼Œå› ä¸ºå°é”çš„åŸç†ä¸åŒã€‚æ–°ç–†ç°åœ¨å°±æ˜¯ä¸€ä¸ªå¤§å±€åŸŸç½‘ï¼Œæ–­ç½‘æ ¹æœ¬å°±ä¸é€šï¼Œä½ æä¾›å“ªäº›å›½å¤–çš„ç¿»å¢™ç½‘ç«™æˆ–è€…ç¿»å¢™è½¯ä»¶ï¼Œè‡ªç„¶åªä¼š404 not foundæˆ–è€…service unveilabeã€‚ç°åœ¨å·²çŸ¥çš„æ˜¯å¦‚ä¸‹å‡ ç§æ–¹æ³•ï¼š\n\nè¿™ä¸ªæ˜¯åº”ç”¨æœ€å¹¿æ³›çš„æ‹¨å·æ–¹å¼ï¼Œä½ ä¸éœ€è¦æœ‰ç‰¹æƒï¼Œä¹Ÿä¸éœ€è¦ä¸Šé¢æœ‰äººï¼Œåªè¦ä½ æœ‰ä¸€ä¸ªç ´æ—§çš„56kçª„å¸¦çŒ«ï¼Œè¿ä¸Šç”µè¯çº¿å°±å¯ä»¥ã€‚è™½ç„¶é€Ÿåº¦å¾ˆæ…¢ï¼Œå¼€ä¸ªæ–°æµªéƒ½è¦ç­‰2åˆ†é’Ÿï¼Œä½†æ˜¯ï¼Œé‚£æ˜¯**å•Šï¼ˆè¯·è‡ªè¡Œè„‘è¡¥åŠ å…¥æµæ³ª233è¡¨æƒ…ï¼‰ï¼å½“ç„¶ï¼Œä½ ä¸èƒ½æ‹¨æœ¬åœ°çš„çª„å¸¦æ¥å…¥å·ï¼Œé‚£ä¸€æ ·åªèƒ½è®¿é—®ç–†å†…ç½‘ã€‚\n\næµè¡Œçš„æ‹¨å·å·ç æœ‰è¿™äº›ï¼š\n\n022-16300ã€0891-16300ï¼š8æœˆèµ·ï¼Œè¿™ä¸¤ä¸ªå·ç é€ ç¦äº†å¾ˆå¤šç½‘æ°‘ã€‚ç¨³å®šï¼Œä½†ä¸å®¹æ˜“æ‹¨å…¥ï¼Œå¹³å‡æ‹¨å·5æ¬¡èƒ½å¤Ÿè¿æ¥ä¸Šï¼Œ10æœˆä»½è¢«å°ã€‚\n\n010-95700ï¼š10æœˆåˆ°12æœˆé—´ï¼Œè¿™æ˜¯æœ€æµè¡Œçš„æ‹¨å·æ¥å…¥å·ï¼Œæ‹¨é€šç‡éå¸¸é«˜ã€‚å¦‚æœä½ çœ‹åˆ°æœ‰äººå®¶é‡Œå›ºè¯ç”µè¯è´¹çªç„¶å‡åˆ°å¥½å‡ ç™¾å…ƒç”šè‡³ä¸Šåƒå…ƒï¼Œé‚£ä¸ç”¨é—®ï¼Œè‚¯å®šæ˜¯å¤©å¤©95700å‘¢ã€‚è¿™ä¸ªå·ç 12æœˆåˆè¢«å°ã€‚\n\n0756-96169ï¼š95700ä¸åœ¨çš„æ—¥å­ï¼Œæˆ‘ä»¬åˆæ‰¾åˆ°äº†96169ã€‚å¯æƒœæ²¡èƒ½åšæŒ1ä¸ªæœˆå°±è¢«å°äº†ã€‚\n\nå‹æƒ…æé†’ï¼šæ‹¨é•¿é€”çª„å¸¦ISPå·ç å‰è¯·åŠ æ‹¨11808ï¼Œè¿™æ ·ä¸€å°æ—¶è¯è´¹èƒ½å¤Ÿæ§åˆ¶åœ¨5å…ƒä»¥å†…ï¼Œå¦åˆ™è¯·æŒ‰é•¿é€”æ ‡å‡†èµ„è´¹ï¼ˆå¤§çº¦1åˆ†é’Ÿ7æ¯›é’±ï¼‰æ¢ç®—è‡ªå·±çš„ç”µè¯è´¹ã€‚\n\n2ã€ä¼ä¸šå†…ç½‘ï¼š\n\nå¤§å®¶çŸ¥é“å¾ˆå¤šå¤§å‹ä¼ä¸šçš„å†…éƒ¨ç½‘ç»œéƒ½æ˜¯å…¨å›½è¿é€šçš„ï¼Œç”µä¿¡è¿è¥å•†è‡ªä¸å¿…è¯´ï¼Œå…¶ä»–åŒ…æ‹¬é“è·¯ã€çŸ³æ²¹ã€é“¶è¡Œç­‰éƒ½æœ‰è‡ªå·±çš„å…¨å›½æ€§ç½‘ç»œï¼Œç”±äºå„ä¼ä¸šçš„ä¸šåŠ¡éœ€è¦ï¼Œè¿™äº›å†…ç½‘æ˜¯ä¸å¯èƒ½æ–­æ‰çš„ã€‚è¿™å°±ç»™é€šè¿‡å†…ç½‘ç¿»å¢™å¸¦æ¥äº†å¯èƒ½æ€§ã€‚åªè¦åœ¨å…¶ä»–çœä»½æ‰¾åˆ°ä¸€å°åŒåœ¨å†…ç½‘ä¸”å¯ä»¥ä¸Šç½‘çš„æœºå™¨ï¼Œäºå…¶ä¸Šå¼€ä¸ªä»£ç†ï¼Œä¾¿å¯ä»¥é¡ºåˆ©ä¸Šç½‘ã€‚ä¸€æ—¶é—´ï¼Œâ€œå†…åœ°åŒäº‹ â€æˆäº†æŠ¢æ‰‹è´§ï¼Œç–†å†…è½¯ä»¶ç½‘ç«™ä¸Šccproxyã€wingateè¿™äº›ä»£ç†è½¯ä»¶ä¹Ÿéƒ½ä¸Šå‡åˆ°ä¸‹è½½æ¦œå‰åˆ—ã€‚\n\nè¿™ç§ç¿»å¢™æ–¹å¼ç½‘é€Ÿå°šå¯ï¼Œå®ç°éš¾åº¦ä¹Ÿä¸ç®—å¤ªé«˜ï¼Œä¹Ÿç®—æ˜¯æ¯”è¾ƒæµè¡Œçš„ç¿»å¢™æ–¹å¼ã€‚å½“å±€ä¸‹å¼ºç¡¬å‘½ä»¤è¦æ±‚å„å•ä½é€æœºæ¸…ç†çš„7-5è§†é¢‘ï¼Œå¤§å¤šä¹Ÿæ˜¯è¿™ç§æ–¹å¼æµä¼ å‡ºå»çš„ã€‚\n\n3ã€æµ·äº‹å«æ˜Ÿç­‰å«æ˜Ÿé€šè®¯æ–¹å¼ï¼š\n\nå«æ˜Ÿé€šè®¯æ–¹å¼çš„ç‰¹æ€§å†³å®šäº†å®ƒä¸å¯èƒ½åƒæœ‰çº¿ç½‘ç»œä¸€æ ·è¢«åœ°åŒºæ€§ä¸­æ–­ï¼Œæœ‰æ¡ä»¶çš„å•ä½å’Œä¸ªäººï¼Œå¯ä»¥é€šè¿‡è¿™ç§æ–¹å¼ç¿»å¢™ã€‚ä¸è¿‡è¿™ç§æ–¹å¼ç½‘é€Ÿä¸æ€æ ·ï¼Œè€Œä¸”èµ„è´¹æè´µï¼Œæ‰€ä»¥åŸºæœ¬åªæœ‰å°‘æ•°å•ä½åœ¨ä½¿ç”¨ã€‚\n\næœ‰æ¬¡ç¿»å¢™å‡ºæ¥ä¸ŠQQé‡åˆ°ä¸€ä¸ªç–†å†…çš„æœ‹å‹ï¼Œé—®ä»–æ€ä¹ˆä¸Šç½‘çš„ï¼Œä¾¿ç»™æˆ‘ç‚«è€€å…¶å•ä½ç‰¹æƒç”³è¯·äº†å«æ˜Ÿä¸“çº¿4æ¡ï¼ŒåŠå…¬å®¤ç”µè„‘éƒ½èƒ½ä¸Šç½‘äº†äº‘äº‘ã€‚\n\n4ã€ç‰¹æƒ\n\nåœ¨ä¸­å›½ï¼Œä»»ä½•äº‹æƒ…çš„é™åˆ¶èŒƒå›´ï¼Œéƒ½å¯ä»¥åŠ ä¸€æ¡ï¼šé¢†å¯¼ä¾‹å¤–â€”â€”å°±è¿æ–­ç½‘éƒ½æ–­å¾—è¿™ä¹ˆæœ‰ä¸­å›½ç‰¹è‰²ã€‚é™¤äº†é€šè®¯ç®¡ç†å±€ã€å…¬å®‰å…ã€å®‰å…¨å…è¿™äº›è·Ÿäº’è”ç½‘ç›´æ¥æœ‰å…³çš„å•ä½å¯ä»¥ä¸Šç½‘å¤–ï¼Œæ®æˆ‘æ‰€çŸ¥è¿˜æœ‰å„é€šè®¯è¿è¥å•†å¤„çº§ä»¥ä¸Šé¢†å¯¼ï¼Œå½“å±€æœºå…³çš„éƒ¨åˆ†éƒ¨é—¨ï¼Œç–†å†…å®˜æ–¹å¤§ç«™çš„è¿è¥éƒ¨é—¨ï¼ˆäºšå¿ƒç½‘ã€å¤©è„‰ã€äºšå¿ƒç½‘ã€äºšå¿ƒç½‘ã€**ï¼‰ï¼Œå‡å¯ä»¥é¡ºåˆ©ä¸Šç½‘ã€‚å½“ç„¶ï¼Œå„å•ä½éƒ½æœ‰ç›¸åº”çš„ç®¡åˆ¶æ‰‹æ®µï¼Œå¦‚é™åˆ¶éƒ¨åˆ†ç«¯å£ï¼Œé™åˆ¶QQç™»å½•ç­‰ï¼Œä½†è¿˜æ˜¯è®©æ™®é€šç™¾å§“ç¾¡æ…•ä¸å·²ã€‚\n\nå½“ç„¶ï¼Œæ™®é€šä¼ä¸šå’Œä¸ªäººâ€œåŸåˆ™ä¸Šâ€ä¹Ÿå¯ä»¥ç”³è¯·å¼€é€šï¼Œä½†é™¤éä½ èƒ½é€šè¿‡ç”µä¿¡è¿è¥å•†-é€šè®¯ç®¡ç†å±€-å…¬å®‰/å®‰å…¨/è‡ªæ²»åŒºå½“å±€å¤šä¸ªéƒ¨é—¨å±‚å±‚å®¡æ‰¹é€šè¿‡æ‰è¡Œï¼Œè‡³ä»Šé€šè¿‡çš„å…¬å¸å¯¥å¯¥æ— å‡ ï¼Œä¸ªäººæ›´æ˜¯ä¸è¦å¥¢æœ›äº†ã€‚\n\n5ã€å¼‚åœ°ä¸Šç½‘æ–¹å¼\n\nä¹‹æ‰€ä»¥æ–°ç–†èƒ½è¢«è¿™ä¹ˆå½»åº•çš„æ–­ç½‘ï¼Œè·Ÿæ–°ç–†çš„åœ°ç†ä½ç½®ä¹Ÿæœ‰å¾ˆå¤§å…³ç³»ã€‚å¦‚æœå†…åœ°çš„æŸä¸ªçœä»½å‡ºäº‹è¢«æ–­ç½‘ï¼Œç½‘æ°‘å¾ˆå®¹æ˜“å°±èƒ½åˆ°åˆ«çš„çœå»ï¼Œè€Œä¸”å†…åœ°é”™ç»¼å¤æ‚çš„çº¿è·¯ä¹Ÿä¸æ˜¯èƒ½è¯´æ–­å°±æ–­çš„ã€‚æ–°ç–†çš„éª¨å¹²ç½‘å‡ºç–†ç«¯å£åªæœ‰ä¸¤æ¡ï¼Œå¾ˆå®¹æ˜“å°±èƒ½å°é”ã€‚å¦‚æœä½ æƒ³å‡ºå»å¤–çœï¼Œå“ªæ€•æ˜¯åˆ°æœ€è¿‘çš„ç”˜è‚ƒï¼Œé‚£ä¸€åƒå¤šå…¬é‡Œçš„è·¯ç¨‹è‡³å°‘ä¹Ÿå¾—1æ•´å¤œçš„ç«è½¦ã€‚\n\nä½†å³ä¾¿è¿™æ ·ï¼Œä»ç„¶æœ‰éš¾ä»¥å¿è€çš„ç½‘æ°‘è·‘å»å¤–çœä¸Šç½‘ã€‚BBCå°±æŠ¥é“è¿‡ä¸€ä¸ªæ–°ç–†äººåé£æœºå»æ·±åœ³ä¸Šç½‘çš„äº‹æƒ…ã€‚è€Œæ–°ç–†æœ¬åœ°QQä¸Šæµä¼ çš„ä¸€æ¡ä¿¡æ¯åˆ™æ˜¯ï¼šâ€œæŸ³å›­ä¸€å‡ºè½¦ç«™å°±æœ‰å¥½å‡ å®¶ç½‘å§ï¼Œæˆ‘å»è¿‡äº†ã€‚ç½‘å§å¯¹é¢å°±æ˜¯æ—…é¦†ï¼Œä¸‹ç«è½¦å‡ºç«™å°±å¯ä»¥ä¸Šç½‘äº†ã€‚é‚£ä¸ªç½‘å§å…¨æ˜¯æ–°ç–†è¿™è¾¹çš„ï¼Œæœ¬åœ°äººåŸºæœ¬æ²¡ä¸å‡ ä¸ªï¼Œåˆ°äº†æ™šä¸Š8ç‚¹å…¨æ˜¯æ–°ç–†çš„ç½‘æ°‘ã€‚åŒ…å¤œ 8 å—é’±ã€‚10ç‚¹åˆ°æ—©ä¸Š9ç‚¹ã€‚å°±è¿™äº›äº†ã€‚è¿‡å¹´æ—¶å€™æˆ‘ä¹Ÿè¦å» æˆ‘çš„ç”µè¯136699xxxxxè¦å»ä¸€èµ·å‘µå‘µï¼â€â€”â€”æŸ³å›­æ˜¯ç”˜è‚ƒçœç¦»æ–°ç–†æœ€è¿‘çš„ä¸€ä¸ªå°ç«è½¦ç«™ã€‚\n\nè¿˜æœ‰ä¸€åˆ™æœªç»è¯å®çš„æ¶ˆæ¯ï¼Œæ˜¯è¯´æœ‰äººåˆ©ç”¨æ‰‹æœºåŸºç«™ä¿¡å·çš„è¾¹ç•Œé‡å ï¼Œå»æ–°ç–†ä¸œå—è¾¹çš„è‹¥ç¾Œå¿ç”¨é’æµ·çœçš„3Gä¿¡å·ä¸Šç½‘ã€‚ä¹‹æ‰€ä»¥è¯´æœªç»è¯å®ï¼Œæ˜¯å› ä¸ºé‚£é‡Œæ˜¯**äººå£å 90%ä»¥ä¸Šçš„æ°‘æ—èšå±…åœ°ï¼Œå°±ç®—èƒ½3Gä¸Šç½‘ï¼Œä½†å°å‘½ä¸ä¸€å®šèƒ½ä¿å…¨å•Šâ€¦â€¦\n\nä»¥ä¸ŠåŸºæœ¬å°±æ˜¯æ–°ç–†å¢ƒå†…ç¿»å¢™çš„æ–¹æ³•ï¼Œå‘å‡ºæ¥ç»™å¯¹ç½‘ç»œä¹ ä»¥ä¸ºå¸¸çš„é‡Œå±‚JRä»¬çœ‹çœ‹ï¼Œæ–°ç–†äººæ°‘ä¸Šä¸ªç½‘æ˜¯å¤šä¹ˆéš¾ã€‚æœ‰çš„äººQQå¯†ç å¿˜äº†ï¼Œæœ‰çš„äººè‹¦å¿ƒç»è¥çš„ç½‘ç«™åºŸäº†ï¼Œè¿èœåœ°éƒ½å¿«åŠå¹´æ²¡æ”¶æˆäº†â€¦â€¦å»å†…åœ°å‡ºå·®å›æ¥çš„åŒäº‹è¯´ï¼šâ€œä½ çŸ¥ä¸çŸ¥é“å½“æˆ‘è¾“å…¥ä¸‰è¾¾å¸ƒæºœæ·˜å®ç‚¹åº·æœ¨ä¸€å›è½¦ï¼Œçœ‹åˆ°é‚£ç†Ÿæ‚‰çš„é»„è‰²é¡µé¢å‡ºç°æ—¶ï¼Œæ‰çœŸæ­£çš„ä½“ä¼šåˆ°äº†ä»€ä¹ˆå«è¿™ä¸€åˆ»æˆ‘å†…ç‰›æ»¡é¢â€¦â€¦\n\nä¸‰ã€ç°çŠ¶\n\næ–­ç½‘å‰æ–°ç–† 90%ä»¥ä¸Šçš„äº’è”ç½‘æµé‡éƒ½æ˜¯æµå‘å†…åœ°çš„ï¼Œä½†ç°åœ¨è¿™ä¸ªå¤§å±€åŸŸç½‘å·²ç„¶æˆäº†ç§æœå’Œå±±å¯¨ç½‘ç«™çš„ä¹åœŸã€‚å„ç§ç½‘æ¸¸ç§æœå±‚å‡ºä¸ç©·ï¼›åˆ©ç”¨äºšå¿ƒç½‘å’Œ***æ­å»ºçš„æ–°ç–†QQä¹Ÿæœ‰Nä¸ªç‰ˆæœ¬äº†ï¼›å±±å¯¨å¼€å¿ƒç½‘ä¸ä¸‹10ä¸ªï¼Œè™½ç„¶ç”¨çš„éƒ½æ˜¯åŒä¸€å¥—æºä»£ç è¿ç•Œé¢é…è‰²éƒ½ä¸€æ¨¡ä¸€æ ·ï¼›hao123ç±»çš„ç–†å†…ç½‘ç«™å¯¼èˆªå·²çŸ¥çš„å°±æœ‰å‡ åä¸ªï¼›ç”šè‡³è¿ç™¾åº¦å’Œ Googleéƒ½è¢«å±±å¯¨äº†ï¼ˆå‚è§é™„å›¾ï¼‰ï¼Œè™½ç„¶åšçš„æœ‰å¤Ÿçƒ‚â€¦â€¦æœ€è¿‘æœ€ç«çš„ï¼Œåˆ™æ˜¯ä¸€ä¸ªå«zn11çš„ç½‘ç«™ï¼Œç‚¹å‡»ç‡è¶…çº§é«˜ã€‚è¿™ä¸ªç½‘ç«™æ˜¯å¹²ä»€ä¹ˆçš„å‘¢ï¼Œè¯´å‡ºæ¥å¤–é¢çš„å„ä½å¯èƒ½ä¼šå“‘ç„¶å¤±ç¬‘â€”â€”å°±æ˜¯ç”¨teleportæŠŠæ–°æµªã€è…¾è®¯ã€ç½‘æ˜“ç­‰å‡ ä¸ªå¤§ç«™çš„é¦–é¡µå’Œ2ã€3çº§é¡µé¢ç¦»çº¿ä¸‹è½½ï¼Œç„¶åæŒ‚åˆ°ç«™ä¸Šã€‚è™½ç„¶å¯èƒ½å‡ å¤©æ‰æ›´æ–°ä¸€æ¬¡ï¼Œå¤§é‡é“¾æ¥ç‚¹ä¸å¼€ï¼Œè§†é¢‘ä¹Ÿæ— æ³•æ”¶çœ‹ï¼Œä½†è¿˜æ˜¯æœ‰å¾ˆå¤šäººä¸Šç­ç¬¬ä¸€ä»¶äº‹å°±æ˜¯æ‰“å¼€è¿™ä¸ªzn11ã€‚ä¹Ÿè®¸æ˜¯è®©è‡ªå·±è§‰å¾—ç¦»çœŸæ­£çš„äº’è”ç½‘è¿‘ä¸€ç‚¹å§â€¦â€¦\n\nè¿™æ˜¯ä¸€ä¸ªæœ€å¥½çš„æ—¶ä»£ï¼Œè¿™æ˜¯ä¸€ä¸ªæœ€åçš„æ—¶ä»£ã€‚å¯¹äºç§æœå’Œå±±å¯¨ç½‘ç«™è¿è¥è€…æ¥è¯´ï¼Œæ˜¾ç„¶æ˜¯å‰è€…ã€‚ä½†å¯¹äºç”µä¿¡è¿è¥å•†æ¥è¯´ï¼Œå¾ˆæœ‰å¯èƒ½æ˜¯åè€…ã€‚è™½ç„¶å¹¿æ’­æŠ¥çº¸ä¸Šç”µä¿¡ç§»åŠ¨è”é€šä¸‰å®¶çš„3Gå¹¿å‘Šè¿˜æ˜¯é“ºå¤©ç›–åœ°ï¼Œä½†æ˜¯è°éƒ½ä¼šå¯¹â€œWCDMAï¼Œä¸Šç½‘é€Ÿåº¦å¯è¾¾7.2å…†â€çš„å¹¿å‘Šä¸€ç¬‘äº†ä¹‹ï¼Œç½‘éƒ½æ²¡äº†æ¨å¹¿ä»€ä¹ˆ3Gå•Šã€‚æŸå¤±æœ€é‡çš„æ˜¯ä¸»è¦æ”¶å…¥æ¥è‡ªäºå®½å¸¦ä¸šåŠ¡çš„æ–°ç–†ç”µä¿¡ï¼Œ7æœˆä»½å…¨ç–†å®½å¸¦è´¹ç”¨å…¨å…ï¼Œä¸€ä¸ªæœˆç›´æ¥æŸå¤±5000å¤šä¸‡ï¼Œå…³è”æŸå¤±8000å¤šä¸‡ã€‚8æœˆä»½ä»¥åå®½å¸¦è´¹ç”¨é‡‡ç”¨ç”¨å¤šå°‘äº¤å¤šå°‘ä¸ç”¨ä¸äº¤ï¼Œæœ€å¤šæ”¶å–åŸè´¹ç”¨8æŠ˜çš„æ–¹æ³•ï¼Œä½†å·²ç„¶æŠ‘åˆ¶ä¸ä½æ¯æœˆé£™å‡çš„å®½å¸¦æ‹†æœºé‡äº†ã€‚\n\nä¸Šä¸äº†ç½‘çš„ä¸æ–¹ä¾¿ï¼Œå¾ˆå¤šäººå·²ç»æ¸æ¸ä¹ æƒ¯äº†ã€‚å®˜æ–¹å¤§ç«™ä¸Šä¸å°‘â€œæ²¡æœ‰äº’è”ç½‘çš„*å­ï¼Œæˆ‘è¿‡å¾—æ›´å¥½äº†â€è¿™ç±»çš„å‚»é€¼å¸–å­ï¼Œç”šè‡³æˆ‘æœ‹å‹é‡Œä¹Ÿå‡ºç°äº†æ–¯å¾·å“¥å°”æ‘©ç»¼åˆç—‡æ‚£è€…ã€‚ä½†æˆ‘æƒ³å¤§å®¶æ›´ä¸ºæ‹…å¿§çš„ï¼Œåº”è¯¥æ˜¯TGåœ¨è§‚å¯Ÿè¿‡æ–°ç–†ç™¾å§“å¯¹ä¸‰æ–­çš„ååº”ä¹‹åï¼Œä¼šä¸ä¼šæŠŠè¿™ä¸ªæŸæ‹›ç”¨åœ¨å…¶ä»–çœä»½ï¼Œç”šè‡³å…¨å›½ã€‚\n"
		},
		{
			"post_id": 19,
			"title": "å‘µå‘µå“’",
			"date_published": 1464508551.1,
			"body": "æ¯•ç«Ÿè¥¿æ¹–\\*\\*æœˆä¸­,é£å…‰ä¸ä¸\\*\\*æ—¶åŒã€‚"
		},
		{
			"post_id": 18,
			"title": "5æœˆ35æ—¥",
			"date_published": 1464443869.467,
			"body": "åœ¨5æœˆ35æ—¥æ¥ä¸´å‰å¤•ï¼Œè®©æˆ‘ä»¬ç”¨æ›´ä¼Ÿå¤§çš„å¢™æ¬¢è¿å®ƒçš„åˆ°æ¥!\n\n![greatfirewall.png](data/res/1464444511190-greatfirewall.png)\n"
		},
		{
			"post_id": 17,
			"title": "è€ƒå®Œè¯•äº†",
			"date_published": 1464422468.545,
			"body": "å¦‚é¢˜\nä»Šå¤©æ—©ä¸Šè€ƒå®Œè¯•äº†ã€‚\nä¼°è®¡åˆšåˆšè¿‡çš„æ ·å­ã€‚\n\nè¿™å­¦æœŸæœç„¶å •è½äº†"
		},
		{
			"post_id": 16,
			"title": "æ¬è¿è®¡åˆ’è¿›åº¦",
			"date_published": 1464191644.441,
			"body": "#Step1:å®‰è£…hostç³»ç»Ÿï¼ˆdebianï¼‰\n##æ•°æ®å¤‡ä»½\n###Windowséƒ¨åˆ†\n1.å°†windowsè‡ªå·±ç”¨çš„è½¯ä»¶çš„åˆ—è¡¨æ•´ç†äº†å‡ºæ¥ä»¥ä¾›å¤‡ç”¨\nä¸€éƒ¨åˆ†è½¯ä»¶åˆ—è¡¨ï¼ˆéƒ½æ˜¯å¥½ç”¨çš„ä¸œä¸œï¼‰\n```\nGreenshot\nEverything\nEvernote\nWox\nBitTorrent Sync\nppsspp\nWinHTTrack\nSigil\nPotPlayer\nEverything\nCCleaner\nâ€¦â€¦\n ```\n2.å°†ç¡¬ç›˜ä¸Šçš„ä¸œä¸œcopyåˆ°ç§»åŠ¨ç¡¬ç›˜ä¸Š\n###Linuxéƒ¨åˆ†\n1.å¤‡ä»½è½¯ä»¶\n`sudo dpkg --get-selections > /tmp/package.selections`\n2.æ‰“åŒ…homeæ–‡ä»¶å¤¹\n`tar -cvp -f /tmp/home.tar /home/user`\n3.å¤‡ä»½ä¸€äº›å…¶ä»–ä¸œè¥¿\n`tar -cvpj -f /tmp/etc.tar.bz2 /etc`\n##è¿˜åŸ\n1.å®‰è£…debian\nåˆ†åŒºæ–¹æ¡ˆï¼š\nåŒç¡¬ç›˜ï¼Œç³»ç»Ÿè£…åœ¨120G SSDä¸Š\n```\nsdb                     8:16   0 111.8G  0 disk  \nâ”œâ”€sdb1                  8:17   0   512M  0 part  /boot/efi\nâ”œâ”€sdb2                  8:18   0   244M  0 part  /boot\nâ””â”€sdb3                  8:19   0 111.1G  0 part  \n  â””â”€sdb3_crypt        254:0    0 111.1G  0 crypt \n    â”œâ”€catcat--vg-var  254:4    0   2.8G  0 lvm   /var\n    â”œâ”€catcat--vg-tmp  254:5    0   380M  0 lvm   /tmp\n    â”œâ”€catcat--vg-root 254:6    0  18.6G  0 lvm   /\n    â”œâ”€catcat--vg-swap 254:7    0   7.5G  0 lvm   [SWAP]\n    â””â”€catcat--vg-home 254:8    0  81.8G  0 lvm   /home\n```\nLVM+åŠ å¯†\n2.è¿˜åŸè½¯ä»¶\nä¸Šä¸€ç¯‡åšå®¢è´´çš„æ–¹æ³•æœ‰é—®é¢˜\nå‘½ä»¤åº”ä¸º\n`dpkg --set-selections < package.selections && apt-get dselect-upgrade`\nè¯¦è§https://debian-handbook.info/browse/stable/sect.apt-get.html\n3.è¿˜åŸhome\n4.ä¸€äº›æ”¶å°¾å·¥ä½œ\n#Step2:è™šæ‹Ÿæœº\nï¼ˆå¾…ç»­â€¦â€¦ï¼‰\n"
		},
		{
			"post_id": 15,
			"title": "è™šæ‹Ÿæœºæ¬è¿è®¡åˆ’æ­£å¼å¯åŠ¨",
			"date_published": 1464167300.391,
			"body": "ä¸ºäº†æ–¹ä¾¿å¤‡ä»½ä¸é‡è£…\nå‡†å¤‡å°†Windowsç³»ç»Ÿé‡è£…åˆ°è™šæ‹Ÿæœºï¼Œhostè®¡åˆ’ä½¿ç”¨Debian\n\n##é™„ï¼š[é‡è£…ä¹Ÿä¸æ€• æ•™ä½ æ€æ ·å¤‡ä»½Ubuntu](http://www.linuxidc.com/Linux/2010-08/28181.htm)\nå½“ç³»ç»Ÿå‡ºç°é—®é¢˜éœ€è¦é‡è£…æˆ–è€…æ–°ç‰ˆæœ¬çš„å‡ºç°éœ€è¦é‡æ–°å®‰è£…Ubuntuçš„æ—¶å€™\n\nä½ å¯èƒ½æ·±æœ‰ä½“ä¼šï¼Ÿé‡æ–°å®‰è£…ç³»ç»Ÿåï¼Œéœ€è¦ä¸€ä¸ªä¸€ä¸ªå®‰è£…ä½ æ‰€ç”¨åˆ°çš„è½¯ä»¶ï¼Œé‚£æœ‰æ²¡æœ‰æ›´ç®€ä¾¿çš„æ–¹æ³•å‘¢ï¼Ÿ\n\n---\nç­”æ¡ˆæ˜¯è‚¯å®šçš„ï¼Œä¸€èˆ¬æ¥è¯´æˆ‘ä»¬åœ¨é‡è£…å‰è¦å¤‡ä»½å®‰è£…è½¯ä»¶çš„åˆ—è¡¨ï¼Œè½¯ä»¶æºï¼Œç”¨æˆ·æ–‡ä»¶ï¼Œä¸‹é¢è®©æˆ‘ä»¬æ¥çœ‹çœ‹æ€æ ·å®ç°çš„ï¼\n\n1.å¤‡ä»½å·²å®‰è£…è½¯ä»¶åŒ…åˆ—è¡¨\n\nsudo dpkg â€“get-selections > /home/user/package.selections\n\n2.å¤‡ä»½Homeä¸‹çš„ç”¨æˆ·æ–‡ä»¶å¤¹\n\nå¦‚æœä½ å·²ç»å°†Homeæ”¾åœ¨é¢å¤–çš„åˆ†åŒºï¼Œè¿™ä¸€æ­¥å°±ä¸å¿…äº†ï¼Œå¤åˆ¶æ‰€æœ‰ç”¨æˆ·æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰å†…å®¹åˆ°å¦å¤–çš„åˆ†åŒºï¼Œæ³¨æ„è¦åŒ…å«éšè—æ–‡ä»¶ï¼ˆCtrl+Hideï¼‰\n\n3.å¤‡ä»½è½¯ä»¶æºåˆ—è¡¨ï¼Œå°†/etc/apt/æ–‡ä»¶å¤¹ä¸‹çš„sources.listæ‹·è´å‡ºæ¥ä¿å­˜å³å¯\n\næ–°ç³»ç»Ÿå®‰è£…åçš„æ¢å¤ï¼š\n\n1.å¤åˆ¶å¤‡ä»½çš„Sources.listæ–‡ä»¶åˆ°æ–°ç³»ç»Ÿçš„/etc/apt/ç›®å½•ï¼Œè¦†ç›–åŸæ–‡ä»¶ï¼Œå¹¶æ›¿æ¢ï¼ˆCtrl+Hï¼‰æ–‡æ¡£ä¸­çš„intrepidä¸ºjauntyã€‚ç„¶åæ›´æ–°è½¯ä»¶æºï¼ˆsudo apt-get updateï¼‰ã€‚\n\n2.é‡æ–°ä¸‹è½½å®‰è£…ä¹‹å‰ç³»ç»Ÿä¸­çš„è½¯ä»¶ï¼ˆå¦‚æœä½ å®‰è£…çš„è½¯ä»¶æ•°é‡æ¯”è¾ƒå¤šï¼Œå¯èƒ½ä¼šèŠ±è´¹è¾ƒé•¿æ—¶é—´ï¼‰\n\nsudo dpkg â€“set-selections /home/package.selections && apt-get dselect-upgrade\n\n3.æœ€åå°†å¤‡ä»½çš„ä¸»æ–‡ä»¶å¤¹ï¼ˆ/home/ç”¨æˆ·åï¼‰ç²˜è´´å¹¶è¦†ç›–ç°æœ‰ä¸»æ–‡ä»¶å¤¹\n\nå¥½äº†ï¼Œç”¨è¿™ä¸ªæ–¹æ³•æˆ‘ä»¬å¯ä»¥åŸºæœ¬åœ¨ä¸ä¸¢å¤±ç°æœ‰ç³»ç»Ÿå’Œè½¯ä»¶è®¾ç½®çš„æƒ…å†µä¸‹ä½¿ç”¨å…¨æ–°çš„Ubuntuç³»ç»Ÿäº†ï¼"
		},
		{
			"post_id": 14,
			"title": "BT sync å¯†é’¥å¤‡ä»½",
			"date_published": 1464166407,
			"body": "ç”µè„‘ç¡¬ç›˜ä¸­åŒæ­¥çš„æ‰€æœ‰BT syncå¯†é’¥\n\n---\n##ç¼–ç¨‹éšæƒ³\nBRSSYZTSAC6UGYTUOJ22L4GCO7QESPPBD    æ”¿æ²»\nBNZ6DOA6W577O6GUNH7C3MY6DWC6FTDQB    å¿ƒç†å­¦\nBSH7FXJFVWJTKWGSX5GTWX7PHZZ2D2M7Q    å†å²\nB2FRYA6AXCDW6CF4YJVFWKH2HAXOFICOX    ç»æµ\nB3WNBTAAFFAODFR6FQ3E3L5BBSJAFNBSJ    ç®¡ç†\nBZR4TTYHT25QWUIE6YNMAKWUGBHKSGLC6    ç¤¾ä¼šå­¦\nBMBB5YLBIJJAE5H6TP27OS7YCEUKCYHZK    æ–‡è‰º\nB6WWVBXPMZDI5IL4KED6AAHA5FO4UNKQF    å“²å­¦\nBMWWZALG4P56LREF47EE2WSWHZEM4E6BL    å†›äº‹\nBUPSDXFA3TP7KCMLHALRHLIX2FEJEUJFE    IT\nBTLZ4A4UD3PEWKPLLWEOKH3W7OQJKFPLG    ç¿»å¢™è½¯ä»¶ï¼ˆåŒ…å«å¸¸è§çš„ç¿»å¢™è½¯ä»¶ï¼Œæ—¶å¸¸æ›´æ–°ï¼‰\nB7P64IMWOCXWEYOXIMBX6HN5MHEULFS4V    â€œåšå®¢ç¦»çº¿æµè§ˆâ€ä»¥åŠâ€œåšå®¢ç”µå­ä¹¦åˆ¶ä½œè„šæœ¬â€\n##ç”µå­ä¹¦\n###è‹è‡è¨ç™¾åº¦ç›˜ä¹¦ï¼ˆ[çŸ¥ä¹é“¾æ¥](https://www.zhihu.com/question/44354572/answer/98331745)ï¼‰\nç¬¬ä¸€éƒ¨åˆ†ï¼šB3EWLQK7C6O6RK3CU5CG3PZUYDUJLMYCP\nç¬¬äºŒéƒ¨åˆ†ï¼šB25G263OSC7ZAXPLCZESSL3DFJOHK6UQ3\n###è‰²é…·å…¨ä¹¦live\nBBZOUOJQOMCLAG3UUVP5RWZD6G2QGQU5P\n\n"
		},
		{
			"post_id": 13,
			"title": "æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½æµ‹è¯•",
			"date_published": 1464094709.861,
			"body": "[Mahuri.svg](data/res/1464095051568-Mahuri.svg)\næµ‹è¯•\n\næŠ€æœ¯æ”¯æŒ\n[ZeroBlog æ‰©å±•: æ›´æ–¹ä¾¿çš„æ–‡ä»¶ä¸Šä¼ ](http://127.0.0.1:43110/1KUiLpPjyCCVst5sGuhzLAsJmBDyvYQm8g/?Post:8:ZeroBlog+%E6%89%A9%E5%B1%95:+%E6%9B%B4%E6%96%B9%E4%BE%BF%E7%9A%84%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0)"
		},
		{
			"post_id": 8,
			"title": "15-05-24",
			"date_published": 1464088993.336,
			"body": "é©¬ä¸Šè¦è€ƒè¯•ï¼Œæœ‰ä¸€ç‚¹å°å¿™ã€‚\n\nè¿˜åœ¨çœ‹ã€Šå¼‚ä¸–ç•Œå¥³ç¥ä¼ ã€‹ï¼Œçœ‹åˆ°#28924ï¼Œå‘å±•çœŸæ˜¯æ··ä¹±å•Šï¼\n\né©¬ä¸Šè¦è€ƒè¯•ï¼ŒåŠªåŠ›èƒŒä¹¦å§ï¼\n"
		},
		{
			"post_id": 7,
			"title": "è½¬è½½",
			"date_published": 1464000723.2,
			"body": "å¦‚æœå¤©ç©ºæ˜¯é»‘æš—çš„ï¼Œé‚£å°±æ‘¸é»‘ç”Ÿå­˜ï¼›\nå¦‚æœå‘å‡ºå£°éŸ³æ˜¯å±é™©çš„ï¼Œé‚£å°±ä¿æŒæ²‰é»˜ï¼›\nå¦‚æœè‡ªè§‰æ— åŠ›å‘å…‰çš„ï¼Œé‚£å°±èœ·ä¼äºå¢™è§’ã€‚\nä½†ä¸è¦ä¹ æƒ¯äº†é»‘æš—å°±ä¸ºé»‘æš—è¾©æŠ¤ï¼›\nä¸è¦ä¸ºè‡ªå·±çš„è‹Ÿä¸”è€Œå¾—æ„ï¼›\nä¸è¦å˜²è®½é‚£äº›æ¯”è‡ªå·±æ›´å‹‡æ•¢çƒ­æƒ…çš„äººä»¬ã€‚\næˆ‘ä»¬å¯ä»¥å‘å¾®å¦‚å°˜åœŸï¼Œä¸å¯æ‰­æ›²å¦‚è›†è™«ã€‚"
		},
		{
			"post_id": 6,
			"title": "ä¸€äº›æœ‰ç”¨çš„ä¸œè¥¿ï¼ˆè½¬è½½ï¼‰",
			"date_published": 1464000193.659,
			"body": "##ZeroNet\n[ZeroNetç»“æ„è§£æ/å…¨åŠ¨æ€ç½‘ç«™/æ— é™åˆ¶ç½‘ç«™](http://127.0.0.1:43110/1LcQTyUYkq3n458rkHVQxhHyvUdmSYFURd/?Post:14#Comments)\n[æˆåŠŸå¼•å…¥æ ‡ç­¾ç³»ç»Ÿå’Œç¿»é¡µç³»ç»Ÿ](http://127.0.0.1:43110/eroz.bit/?Post:10#Comments)\n[ZeroNet åœ¨è¿œç¨‹æœåŠ¡å™¨](http://ryc111.com/2016/05/03/zeronet-on-vps/)\n[ä¸€ä¸ªç²—ç•¥çš„åšå®¢æ ·å¼ä¿®æ”¹æŒ‡å—](http://127.0.0.1:43110/1HotJMoS9Z1v8UwDCmv3VDG3q88c5na8cZ/?Post:7)\n<a href=\"http://127.0.0.1:43110/mosen.bit/?Post:8:ZeroNet+%E5%9C%A8%E6%96%87%E7%AB%A0%E4%B8%AD%E8%AE%BE%E7%BD%AE%E9%93%BE%E6%8E%A5%E6%96%B0%E7%AA%97%E5%8F%A3%E6%89%93%E5%BC%80%E7%9A%84%E6%96%B9%E6%B3%95\"target=\"_blank\">ZeroNet åœ¨æ–‡ç« ä¸­è®¾ç½®é“¾æ¥æ–°çª—å£æ‰“å¼€çš„æ–¹æ³•</a>\n[ZeroBlog æ–°æ‰‹æŒ‡å¯¼](http://127.0.0.1:43110/mosen.bit/?Post:5:ZeroBlog+%E6%96%B0%E6%89%8B%E6%8C%87%E5%AF%BC)\n[é€šç”¨çš„è‡ªåŠ¨å¿«ç…§è„šæœ¬æ¥åˆ›å»ºä¸€ç³»åˆ—ZeroNetç½‘ç«™å¿«ç…§ï¼Œå®ç°çœŸæ­£ä¸å¯èƒ½å…³é—­çš„ç½‘ç«™ï¼](http://127.0.0.1:43110/gfwtalk.bit/?Topic:30_13Z7XxTa7JuFat3KzzMWu3onwM6biLuurJ/+ZeroNet+5+14+UPDATE)\n##markdownç”¨æ³•\n[ç”¨Markdown ä¼˜é›…çš„åœ¨ ZeroNet ä¸Šå†™æ–‡ç« ](http://127.0.0.1:43110/gfwtalk.bit/?Topic:6_1Q7UWk3im88kJkzmhzfD5q44rQDXLatxYq)\n[Zeronet Markdown Cheatsheet](http://127.0.0.1:43110/cryptonbits.bit/?Post:6:Zeronet+Markdown+Cheatsheet)\n[Links](http://127.0.0.1:43110/148or6yKMeNV4qdmKyCtpaNiFAeU1cccCw/?Post:10:%D0%BF%D0%BE%D0%B4%D1%81%D0%BA%D0%B0%D0%B7%D0%BA%D0%B0+%D0%B4%D0%BB%D1%8F+Markdown)\n##shadowsocks\n[Centos 7å®‰è£…é…ç½®Shadowsocks](https://www.ifshow.com/centos-7-installation-and-configuration-shadowsocks/)\n[CentOS 7 Shadowsocksä¼˜åŒ–](https://www.ifshow.com/centos-7-shadowsocks-optimization/)\n##å…¬ç½‘ä»£ç†åˆ—è¡¨\n[ZeroProxies.bit](http://127.0.0.1:43110/zeroproxies.bit/)\nå½“å‰æœ‰æ•ˆçš„å¼€æ”¾ä»£ç†\nhttps://bit.no.com:43110/\nhttp://proxy.zeroexpose.com/\nhttp://zero.pags.to:43110/\n##å…¶ä»–\n[BitTorrent Sync å…¬å…±èµ„æºç´¢å¼•](/mydf.bit/?Post:72#Comments)\n##Python\n[Python 2.7æ•™ç¨‹](http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000)\n[Pythonçˆ¬è™«å­¦ä¹ ç³»åˆ—æ•™ç¨‹](http://cuiqingcai.com/1052.html)\n[Scrapy](http://scrapy-chs.readthedocs.io/zh_CN/0.24/intro/overview.html)"
		},
		{
			"post_id": 5,
			"title": "æ¯æ—¥ä¸€è®°\t",
			"date_published": 1463998679.174,
			"body": "ä»Šå¤©å¼€äº†ä¸€ä¸‹ç­ä¼šï¼Œä¼šä¸Šå…ˆç€é‡å¼ºè°ƒäº†ä¸€ä¸‹ä»€ä¹ˆåæçš„é—®é¢˜ï¼Œè¿˜è¦ç­¾ä»€ä¹ˆæ‰¿è¯ºä¹¦ï¼Œæ‰¿è¯ºä¸æ•£æ’­ææ€–è§†é¢‘ã€è‡ªè¡Œåˆ é™¤è‡ªå·±ç”µè„‘ä¸­çš„ææ€–è§†é¢‘ä»€ä¹ˆçš„å·´æ‹‰å·´æ‹‰ä¸€å¤§å †ã€‚åæä¹Ÿè®¸è¿™æ˜¯æœ‰äº›é“ç†ï¼Œä½†æ˜¯å¯¹äºæ‰€è°“çš„ææ€–è§†é¢‘çš„å®šä¹‰æˆ‘æ˜¯åœ¨æ˜¯ä¸æ•¢è‹ŸåŒã€‚\nä¹‹åè¯´äº†ä¸€äº›å¹²è´§ã€‚å¤§å­¦å†³å®šä¸€ä¸ªäººä¸€ç”Ÿçš„é‡è¦æ—¶æœŸï¼Œç°åœ¨å¤§å­¦ä¹Ÿè¿‡å»äº†å°†è¿‘ä¸¤å¹´ï¼Œä¹Ÿå°±æ˜¯åœ¨æš‘å‡ä¹‹å‰å°±åº”è¯¥å¯¹è‡ªå·±çš„ä»¥åçš„äººç”Ÿè·¯è¯¥å¦‚ä½•èµ°æœ‰ä¸€äº›è®¤è¯†ã€‚\nè¿™ä¹Ÿè®¸æ˜¯æœ‰ä¸€äº›è€ç”Ÿé•¿è°ˆï¼Œæˆ‘çš„è½¬è¿°ä¹Ÿé—å¤±é¢‡å¤šï¼Œä½†æ˜¯è¿™çš„ç¡®å¯¹æˆ‘ç°åœ¨æ¥è¯´è§¦åŠ¨æå¤§ã€‚\n\nè‡ªå·±æœ€è¿‘ååˆ†è¿·èŒ«ï¼Œä¸çŸ¥é“å¹²ä»€ä¹ˆï¼Œæ„Ÿè§‰å¥½åƒäººç”Ÿå¤±å»äº†å‰è¿›çš„åŠ¨åŠ›ã€‚è¿™å†å’Œâ€œå®…å®…ç»¼åˆå¾â€ç»“åˆèµ·æ¥ä¸€èµ·æ¥ï¼Œå®åœ¨æ˜¯è®©äººæ›´åŠ è¿·èŒ«ä¸æ­¢æ‰€æªã€‚\nåªæœ‰åŠªåŠ›å°½ä»Šæ—¥ï¼Œç„¶åè¯•ç€æ‰¾æ‰¾æœªæ¥çš„æ–¹å‘å§ï¼\n\npsï¼šä»€ä¹ˆå‡çº§è€ƒè¯•ä¹Ÿè¯¥å‡†å¤‡äº†ã€‚"
		},
		{
			"post_id": 4,
			"title": "å…³äºå†…å¿ƒçš„é˜´æš—é¢",
			"date_published": 1463931670.213,
			"body": "æ¯ä¸ªäººå†…å¿ƒéƒ½æœ‰ä¸€äº›é˜´å½±çš„è§’è½ï¼Œæš—è—ç€ä¸€äº›ä¸ä¸ºäººçŸ¥(æ¢è€Œè¨€ä¹‹ä¸æƒ³ä¸ºä»–äººæ‰€çŸ¥ï¼‰çš„äº‹æƒ…ã€‚\nè®°å¾—ã€Šæ¥¼ä¸‹çš„æˆ¿å®¢ã€‹é‡Œæœ‰è¿™æ ·çš„ä¸€å¥è¯å¤§æ„æ˜¯ç–¯ç‹‚æ˜¯ç”±äºå†…å¿ƒé˜´æš—é¢çš„ç´¯è®¡ã€‚é‚£æˆ¿ä¸œä¹Ÿä¾é æŒ‘æ‹¨ä¼—äººå¿ƒä¸­çš„é˜´æš—ï¼Œæœ€ç»ˆçœ‹åˆ°äº†ä¸€åœºè‡ªç›¸æ®‹æ€çš„å¥½æˆã€‚\n\næˆ‘ä¹Ÿæœ‰ä¸€äº›ä¸æƒ³ä¸ºä»–äººæ‰€çŸ¥çš„äº‹æƒ…ï¼Œè™½ç„¶å¯ä»¥å†™åœ¨æ—¥è®°æœ¬ä¸­ï¼Œé”åœ¨æŸœå­é‡Œï¼Œä½†å´æœ‰çŸ›ç›¾çš„æƒ³è®©ä»–äººçŸ¥é“ï¼Œè¿™ä¹Ÿè®¸æ˜¯äººçŸ›ç›¾æ€§çš„ä¸€ä¸ªä¾‹è¯ã€‚\nä¸ºäº†ä¸è®©è¿™äº›ä¸œè¥¿æ†‹æ­»ï¼Œæˆ‘å†³å®šå·å·å°†å…¶å‘å¸ƒåˆ°é›¶ç½‘ä¸Šã€‚\nå¤§æ¦‚å°±æ˜¯è¿™æ ·ã€‚"
		},
		{
			"post_id": 3,
			"title": "æ¯æ—¥ä¸€è®°",
			"date_published": 1463931060.254,
			"body": "ä»Šå¤©å¤–å‡ºå‚åŠ äº†ä¸€äº›æ´»åŠ¨ã€‚ç„¶åæ„Ÿè§‰è‡ªå·±çœŸçš„æœ‰ä¸€äº›å°é—­ã€‚\nåæ­£è§‰å¾—è‡ªå·±å¥½åƒè¶Šæ¥è¶Šå®…äº†ï¼Œè¿™å¥½åƒä¸æ˜¯ä¸€ä¸ªå¥½ç°è±¡ã€‚\n\næœ€è¿‘åœ¨çœ‹ã€Šå¼‚ä¸–ç•Œå¥³ç¥è½¬ã€‹ï¼Œæœå¦‚ç½‘å‹è¯„è®ºçš„ä¸€æ ·ï¼Œåˆ°äº†ç¬¬äº”å·ä»¥åå°±å¥½çœ‹å¤šäº†ã€‚\n\næœ€åæ˜¯å­¦ä¹ ä¸Šçš„ä¸€äº›äº‹æƒ…ï¼Œå¥½å¥½åŠªåŠ›å§ï¼\næ„Ÿè§‰å¥½é¢“åºŸã€‚\n16-05-22"
		},
		{
			"post_id": 1,
			"title": "First bloger",
			"date_published": 1433033779.604,
			"body": "test"
		}
	]
}